X nd y are loaded for temporal feature extraction
X shape is (36000, 10000)
y shape is (36000,)
  0%|          | 0/36000 [00:00<?, ?it/s]  1%|▏         | 462/36000 [00:00<00:07, 4611.64it/s]  3%|▎         | 924/36000 [00:00<00:09, 3778.51it/s]  4%|▎         | 1312/36000 [00:00<00:12, 2797.17it/s]  4%|▍         | 1616/36000 [00:00<00:13, 2537.35it/s]  7%|▋         | 2449/36000 [00:00<00:08, 4114.78it/s]  8%|▊         | 2918/36000 [00:01<00:17, 1870.52it/s]  9%|▉         | 3256/36000 [00:01<00:21, 1542.16it/s] 11%|█         | 4042/36000 [00:01<00:13, 2395.76it/s] 12%|█▏        | 4467/36000 [00:01<00:13, 2253.61it/s] 13%|█▎        | 4820/36000 [00:02<00:14, 2157.76it/s] 14%|█▍        | 5152/36000 [00:02<00:13, 2353.45it/s] 15%|█▌        | 5487/36000 [00:02<00:11, 2545.78it/s] 16%|█▌        | 5805/36000 [00:02<00:26, 1145.29it/s] 17%|█▋        | 6041/36000 [00:03<00:41, 718.15it/s]  17%|█▋        | 6215/36000 [00:04<00:51, 575.04it/s] 18%|█▊        | 6346/36000 [00:04<00:59, 501.27it/s] 18%|█▊        | 6447/36000 [00:04<00:57, 514.33it/s] 20%|██        | 7223/36000 [00:05<00:23, 1244.25it/s] 21%|██        | 7518/36000 [00:05<00:22, 1292.55it/s] 22%|██▏       | 7768/36000 [00:05<00:21, 1329.26it/s] 22%|██▏       | 7987/36000 [00:05<00:20, 1357.88it/s] 23%|██▎       | 8191/36000 [00:05<00:18, 1471.73it/s] 23%|██▎       | 8396/36000 [00:05<00:17, 1582.22it/s] 24%|██▍       | 8603/36000 [00:05<00:16, 1687.11it/s] 25%|██▍       | 8875/36000 [00:05<00:14, 1930.77it/s] 27%|██▋       | 9712/36000 [00:06<00:07, 3551.13it/s] 28%|██▊       | 10119/36000 [00:06<00:08, 2940.25it/s] 29%|██▉       | 10466/36000 [00:06<00:10, 2404.20it/s] 30%|██▉       | 10757/36000 [00:06<00:17, 1481.89it/s] 31%|███       | 10981/36000 [00:07<00:21, 1190.97it/s] 31%|███       | 11158/36000 [00:07<00:23, 1069.93it/s] 31%|███▏      | 11305/36000 [00:07<00:25, 985.26it/s]  32%|███▏      | 11430/36000 [00:07<00:25, 974.95it/s] 32%|███▏      | 11545/36000 [00:07<00:25, 963.64it/s] 32%|███▏      | 11653/36000 [00:08<00:25, 955.14it/s] 33%|███▎      | 11757/36000 [00:08<00:25, 950.72it/s] 33%|███▎      | 11858/36000 [00:08<00:25, 940.92it/s] 33%|███▎      | 11956/36000 [00:08<00:25, 931.81it/s] 34%|███▎      | 12125/36000 [00:08<00:21, 1121.24it/s] 34%|███▍      | 12366/36000 [00:08<00:16, 1460.06it/s] 35%|███▌      | 12606/36000 [00:08<00:13, 1715.22it/s] 36%|███▌      | 12816/36000 [00:08<00:12, 1817.67it/s] 36%|███▌      | 13005/36000 [00:09<00:17, 1352.22it/s] 37%|███▋      | 13162/36000 [00:09<00:19, 1164.08it/s] 37%|███▋      | 13297/36000 [00:09<00:21, 1055.27it/s] 37%|███▋      | 13416/36000 [00:09<00:22, 983.42it/s]  38%|███▊      | 13524/36000 [00:09<00:24, 933.21it/s] 38%|███▊      | 13624/36000 [00:09<00:23, 939.74it/s] 38%|███▊      | 13786/36000 [00:09<00:20, 1100.68it/s] 39%|███▊      | 13945/36000 [00:09<00:18, 1223.09it/s] 39%|███▉      | 14099/36000 [00:10<00:16, 1306.59it/s] 40%|███▉      | 14262/36000 [00:10<00:15, 1393.34it/s] 40%|████      | 14416/36000 [00:10<00:15, 1433.89it/s] 41%|████      | 14802/36000 [00:10<00:09, 2129.16it/s] 42%|████▏     | 15192/36000 [00:10<00:07, 2643.89it/s] 43%|████▎     | 15518/36000 [00:10<00:07, 2824.20it/s] 44%|████▍     | 15841/36000 [00:10<00:06, 2941.36it/s] 45%|████▍     | 16139/36000 [00:10<00:09, 2083.56it/s] 46%|████▌     | 16385/36000 [00:11<00:14, 1391.66it/s] 46%|████▌     | 16579/36000 [00:11<00:16, 1148.93it/s] 46%|████▋     | 16736/36000 [00:11<00:18, 1019.61it/s] 47%|████▋     | 16868/36000 [00:11<00:19, 1003.82it/s] 47%|████▋     | 17018/36000 [00:11<00:17, 1092.20it/s] 48%|████▊     | 17159/36000 [00:12<00:16, 1156.30it/s] 48%|████▊     | 17310/36000 [00:12<00:15, 1234.80it/s] 48%|████▊     | 17459/36000 [00:12<00:14, 1296.16it/s] 49%|████▉     | 17602/36000 [00:12<00:13, 1321.79it/s] 49%|████▉     | 17743/36000 [00:12<00:23, 762.24it/s]  50%|████▉     | 17853/36000 [00:13<00:30, 601.71it/s] 50%|████▉     | 17941/36000 [00:13<00:34, 528.92it/s] 50%|█████     | 18014/36000 [00:13<00:37, 485.39it/s] 50%|█████     | 18076/36000 [00:13<00:39, 455.72it/s] 50%|█████     | 18130/36000 [00:13<00:41, 434.11it/s] 50%|█████     | 18179/36000 [00:13<00:42, 414.52it/s] 51%|█████     | 18224/36000 [00:14<00:44, 399.75it/s] 51%|█████     | 18266/36000 [00:14<00:45, 389.28it/s] 51%|█████     | 18306/36000 [00:14<00:45, 385.40it/s] 51%|█████     | 18346/36000 [00:14<00:46, 380.98it/s] 51%|█████     | 18385/36000 [00:14<00:46, 378.31it/s] 51%|█████     | 18424/36000 [00:14<00:47, 369.04it/s] 51%|█████▏    | 18462/36000 [00:14<00:47, 366.95it/s] 51%|█████▏    | 18500/36000 [00:14<00:47, 369.47it/s] 51%|█████▏    | 18539/36000 [00:14<00:46, 373.40it/s] 52%|█████▏    | 18577/36000 [00:15<00:47, 367.65it/s] 52%|█████▏    | 18614/36000 [00:15<00:48, 362.00it/s] 52%|█████▏    | 18651/36000 [00:15<00:47, 362.67it/s] 52%|█████▏    | 18689/36000 [00:15<00:47, 365.10it/s] 52%|█████▏    | 18728/36000 [00:15<00:46, 372.24it/s] 52%|█████▏    | 18767/36000 [00:15<00:46, 374.58it/s] 52%|█████▏    | 18805/36000 [00:15<00:45, 375.82it/s] 52%|█████▏    | 18843/36000 [00:15<00:46, 371.82it/s] 52%|█████▏    | 18881/36000 [00:15<00:47, 363.28it/s] 53%|█████▎    | 18919/36000 [00:15<00:46, 366.28it/s] 53%|█████▎    | 18956/36000 [00:16<00:47, 362.05it/s] 53%|█████▎    | 18993/36000 [00:16<00:46, 362.19it/s] 53%|█████▎    | 19035/36000 [00:16<00:44, 377.01it/s] 53%|█████▎    | 19073/36000 [00:16<00:46, 367.87it/s] 53%|█████▎    | 19112/36000 [00:16<00:45, 371.51it/s] 53%|█████▎    | 19150/36000 [00:16<00:45, 366.35it/s] 53%|█████▎    | 19187/36000 [00:16<00:45, 365.83it/s] 54%|█████▎    | 19308/36000 [00:16<00:27, 611.83it/s] 54%|█████▍    | 19483/36000 [00:16<00:17, 946.00it/s] 55%|█████▍    | 19658/36000 [00:17<00:13, 1183.53it/s] 55%|█████▌    | 19834/36000 [00:17<00:11, 1352.65it/s] 56%|█████▌    | 20014/36000 [00:17<00:10, 1484.49it/s] 57%|█████▋    | 20369/36000 [00:17<00:07, 2099.16it/s] 58%|█████▊    | 20725/36000 [00:17<00:06, 2534.53it/s] 58%|█████▊    | 20980/36000 [00:17<00:09, 1604.06it/s] 59%|█████▉    | 21184/36000 [00:18<00:12, 1177.96it/s] 59%|█████▉    | 21347/36000 [00:18<00:14, 996.22it/s]  60%|█████▉    | 21481/36000 [00:18<00:16, 898.58it/s] 60%|█████▉    | 21595/36000 [00:18<00:17, 838.38it/s] 60%|██████    | 21695/36000 [00:18<00:17, 825.54it/s] 61%|██████    | 21788/36000 [00:18<00:17, 823.95it/s] 61%|██████    | 21878/36000 [00:19<00:17, 821.66it/s] 61%|██████    | 21966/36000 [00:19<00:17, 812.34it/s] 61%|██████▏   | 22051/36000 [00:19<00:17, 809.51it/s] 61%|██████▏   | 22135/36000 [00:19<00:17, 808.31it/s] 62%|██████▏   | 22218/36000 [00:19<00:17, 802.86it/s] 62%|██████▏   | 22300/36000 [00:19<00:17, 799.40it/s] 62%|██████▏   | 22381/36000 [00:19<00:16, 801.81it/s] 63%|██████▎   | 22509/36000 [00:19<00:14, 935.56it/s] 63%|██████▎   | 22652/36000 [00:19<00:12, 1076.31it/s] 63%|██████▎   | 22794/36000 [00:19<00:11, 1175.65it/s] 64%|██████▎   | 22937/36000 [00:20<00:10, 1249.44it/s] 64%|██████▍   | 23080/36000 [00:20<00:09, 1300.12it/s] 64%|██████▍   | 23215/36000 [00:20<00:09, 1312.88it/s] 65%|██████▍   | 23347/36000 [00:20<00:10, 1226.81it/s] 65%|██████▌   | 23472/36000 [00:20<00:10, 1174.80it/s] 66%|██████▌   | 23591/36000 [00:20<00:10, 1135.22it/s] 66%|██████▌   | 23706/36000 [00:20<00:11, 1114.00it/s] 66%|██████▌   | 23819/36000 [00:20<00:10, 1110.17it/s] 66%|██████▋   | 23931/36000 [00:20<00:10, 1099.52it/s] 67%|██████▋   | 24055/36000 [00:21<00:10, 1138.18it/s] 67%|██████▋   | 24203/36000 [00:21<00:09, 1236.32it/s] 68%|██████▊   | 24348/36000 [00:21<00:08, 1297.79it/s] 68%|██████▊   | 24492/36000 [00:21<00:08, 1338.88it/s] 68%|██████▊   | 24639/36000 [00:21<00:08, 1375.15it/s] 69%|██████▉   | 24787/36000 [00:21<00:07, 1403.54it/s] 69%|██████▉   | 24928/36000 [00:21<00:08, 1268.62it/s] 70%|██████▉   | 25058/36000 [00:21<00:09, 1180.73it/s] 70%|██████▉   | 25179/36000 [00:21<00:09, 1119.33it/s] 70%|███████   | 25294/36000 [00:22<00:09, 1085.29it/s] 71%|███████   | 25404/36000 [00:22<00:10, 1057.09it/s] 71%|███████   | 25511/36000 [00:22<00:10, 1038.00it/s] 71%|███████   | 25622/36000 [00:22<00:09, 1057.02it/s] 72%|███████▏  | 25813/36000 [00:22<00:07, 1296.04it/s] 72%|███████▏  | 26001/36000 [00:22<00:06, 1463.19it/s] 73%|███████▎  | 26193/36000 [00:22<00:06, 1595.22it/s] 73%|███████▎  | 26376/36000 [00:22<00:05, 1661.66it/s] 74%|███████▎  | 26544/36000 [00:23<00:08, 1101.86it/s] 74%|███████▍  | 26680/36000 [00:23<00:11, 845.29it/s]  74%|███████▍  | 26791/36000 [00:23<00:12, 731.77it/s] 75%|███████▍  | 26884/36000 [00:23<00:13, 668.77it/s] 75%|███████▍  | 26964/36000 [00:23<00:14, 614.66it/s] 75%|███████▌  | 27035/36000 [00:23<00:15, 594.25it/s] 75%|███████▌  | 27100/36000 [00:24<00:14, 593.86it/s] 75%|███████▌  | 27164/36000 [00:24<00:15, 584.19it/s] 76%|███████▌  | 27225/36000 [00:24<00:14, 587.40it/s] 76%|███████▌  | 27304/36000 [00:24<00:13, 636.52it/s] 76%|███████▌  | 27396/36000 [00:24<00:12, 710.28it/s] 76%|███████▋  | 27492/36000 [00:24<00:10, 776.90it/s] 77%|███████▋  | 27573/36000 [00:24<00:10, 782.57it/s] 77%|███████▋  | 27658/36000 [00:24<00:10, 801.17it/s] 77%|███████▋  | 27750/36000 [00:24<00:09, 835.07it/s] 77%|███████▋  | 27835/36000 [00:25<00:09, 821.51it/s] 78%|███████▊  | 27923/36000 [00:25<00:09, 836.65it/s] 78%|███████▊  | 28008/36000 [00:25<00:10, 766.15it/s] 78%|███████▊  | 28087/36000 [00:25<00:16, 492.62it/s] 78%|███████▊  | 28150/36000 [00:25<00:19, 412.11it/s] 78%|███████▊  | 28202/36000 [00:25<00:20, 373.52it/s] 78%|███████▊  | 28247/36000 [00:26<00:22, 338.84it/s] 79%|███████▊  | 28286/36000 [00:26<00:24, 316.73it/s] 79%|███████▊  | 28321/36000 [00:26<00:25, 302.35it/s] 79%|███████▉  | 28354/36000 [00:26<00:25, 296.20it/s] 79%|███████▉  | 28385/36000 [00:26<00:26, 291.62it/s] 79%|███████▉  | 28415/36000 [00:26<00:26, 286.21it/s] 79%|███████▉  | 28445/36000 [00:26<00:27, 278.01it/s] 79%|███████▉  | 28474/36000 [00:27<00:27, 276.28it/s] 79%|███████▉  | 28502/36000 [00:27<00:27, 274.98it/s] 79%|███████▉  | 28530/36000 [00:27<00:27, 268.04it/s] 79%|███████▉  | 28557/36000 [00:27<00:28, 263.70it/s] 79%|███████▉  | 28584/36000 [00:27<00:28, 263.68it/s] 79%|███████▉  | 28611/36000 [00:27<00:28, 263.35it/s] 80%|███████▉  | 28640/36000 [00:27<00:27, 269.34it/s] 80%|███████▉  | 28668/36000 [00:27<00:27, 270.16it/s] 80%|███████▉  | 28696/36000 [00:27<00:27, 267.61it/s] 80%|███████▉  | 28723/36000 [00:27<00:27, 262.06it/s] 80%|███████▉  | 28752/36000 [00:28<00:27, 267.34it/s] 80%|███████▉  | 28782/36000 [00:28<00:26, 273.34it/s] 80%|████████  | 28883/36000 [00:28<00:14, 485.81it/s] 81%|████████  | 29096/36000 [00:28<00:07, 965.30it/s] 81%|████████▏ | 29317/36000 [00:28<00:05, 1330.95it/s] 82%|████████▏ | 29541/36000 [00:28<00:04, 1598.79it/s] 83%|████████▎ | 29703/36000 [00:28<00:04, 1486.51it/s] 83%|████████▎ | 29855/36000 [00:28<00:04, 1343.47it/s] 83%|████████▎ | 29994/36000 [00:28<00:04, 1258.28it/s] 84%|████████▎ | 30124/36000 [00:29<00:04, 1196.94it/s] 84%|████████▍ | 30247/36000 [00:29<00:05, 1149.37it/s] 84%|████████▍ | 30364/36000 [00:29<00:04, 1140.07it/s] 85%|████████▍ | 30517/36000 [00:29<00:04, 1244.97it/s] 85%|████████▌ | 30685/36000 [00:29<00:03, 1363.79it/s] 86%|████████▌ | 30853/36000 [00:29<00:03, 1451.30it/s] 86%|████████▌ | 31021/36000 [00:29<00:03, 1515.27it/s] 87%|████████▋ | 31186/36000 [00:29<00:03, 1554.49it/s] 87%|████████▋ | 31343/36000 [00:29<00:03, 1501.35it/s] 87%|████████▋ | 31495/36000 [00:30<00:03, 1478.97it/s] 88%|████████▊ | 31649/36000 [00:30<00:02, 1491.09it/s] 88%|████████▊ | 31811/36000 [00:30<00:02, 1525.43it/s] 89%|████████▉ | 31973/36000 [00:30<00:02, 1547.10it/s] 89%|████████▉ | 32129/36000 [00:30<00:03, 1266.15it/s] 90%|████████▉ | 32265/36000 [00:30<00:03, 1111.35it/s] 90%|████████▉ | 32385/36000 [00:30<00:03, 1022.25it/s] 90%|█████████ | 32494/36000 [00:30<00:03, 965.16it/s]  91%|█████████ | 32595/36000 [00:31<00:03, 933.01it/s] 91%|█████████ | 32691/36000 [00:31<00:03, 910.83it/s] 91%|█████████ | 32784/36000 [00:31<00:03, 891.01it/s] 91%|█████████▏| 32881/36000 [00:31<00:03, 911.12it/s] 92%|█████████▏| 32981/36000 [00:31<00:03, 934.52it/s] 92%|█████████▏| 33081/36000 [00:31<00:03, 952.59it/s] 92%|█████████▏| 33180/36000 [00:31<00:02, 963.19it/s] 92%|█████████▏| 33282/36000 [00:31<00:02, 979.44it/s] 93%|█████████▎| 33381/36000 [00:31<00:02, 981.58it/s] 93%|█████████▎| 33483/36000 [00:31<00:02, 992.01it/s] 93%|█████████▎| 33586/36000 [00:32<00:02, 1002.29it/s] 94%|█████████▍| 33830/36000 [00:32<00:01, 1428.43it/s] 95%|█████████▍| 34098/36000 [00:32<00:01, 1801.00it/s] 95%|█████████▌| 34365/36000 [00:32<00:00, 2058.71it/s] 96%|█████████▌| 34572/36000 [00:32<00:01, 1284.02it/s] 96%|█████████▋| 34737/36000 [00:32<00:01, 1003.17it/s] 97%|█████████▋| 34871/36000 [00:33<00:01, 882.45it/s]  97%|█████████▋| 34984/36000 [00:33<00:01, 796.36it/s] 97%|█████████▋| 35081/36000 [00:33<00:01, 743.31it/s] 98%|█████████▊| 35167/36000 [00:33<00:01, 711.20it/s] 99%|█████████▊| 35483/36000 [00:33<00:00, 1196.45it/s]100%|██████████| 36000/36000 [00:33<00:00, 1063.12it/s]
Shape of temporal_X: (36000, 2, 1000)
X nd y are loaded for temporal feature extraction
X shape is (4500, 10000)
y shape is (4500,)
  0%|          | 0/4500 [00:00<?, ?it/s]  7%|▋         | 324/4500 [00:00<00:01, 3233.82it/s] 14%|█▍        | 648/4500 [00:00<00:01, 2360.67it/s] 20%|█▉        | 898/4500 [00:00<00:02, 1244.64it/s] 24%|██▎       | 1067/4500 [00:00<00:02, 1340.22it/s] 30%|██▉       | 1328/4500 [00:00<00:01, 1638.18it/s] 34%|███▍      | 1529/4500 [00:01<00:02, 1339.59it/s] 38%|███▊      | 1694/4500 [00:01<00:02, 1285.77it/s] 42%|████▏     | 1904/4500 [00:01<00:01, 1465.53it/s] 46%|████▌     | 2072/4500 [00:01<00:01, 1411.30it/s] 50%|████▉     | 2228/4500 [00:01<00:01, 1204.76it/s] 52%|█████▏    | 2362/4500 [00:01<00:02, 781.02it/s]  55%|█████▍    | 2467/4500 [00:02<00:02, 766.83it/s] 59%|█████▊    | 2636/4500 [00:02<00:01, 935.02it/s] 61%|██████    | 2753/4500 [00:02<00:01, 874.00it/s] 64%|██████▎   | 2864/4500 [00:02<00:01, 922.23it/s] 66%|██████▋   | 2983/4500 [00:02<00:01, 982.51it/s] 69%|██████▉   | 3117/4500 [00:02<00:01, 1068.14it/s] 72%|███████▏  | 3234/4500 [00:02<00:01, 1093.68it/s] 74%|███████▍  | 3351/4500 [00:02<00:01, 1001.64it/s] 77%|███████▋  | 3458/4500 [00:03<00:01, 863.59it/s]  79%|███████▉  | 3552/4500 [00:03<00:01, 662.17it/s] 81%|████████  | 3630/4500 [00:03<00:01, 582.31it/s] 84%|████████▍ | 3782/4500 [00:03<00:00, 767.65it/s] 88%|████████▊ | 3954/4500 [00:03<00:00, 974.89it/s] 90%|█████████ | 4070/4500 [00:03<00:00, 983.92it/s] 93%|█████████▎| 4182/4500 [00:03<00:00, 973.37it/s] 96%|█████████▌| 4327/4500 [00:04<00:00, 1091.41it/s] 99%|█████████▉| 4445/4500 [00:04<00:00, 1025.28it/s]100%|██████████| 4500/4500 [00:04<00:00, 1078.98it/s]
Shape of temporal_X: (4500, 2, 1000)
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Train: X=torch.Size([36000, 1, 2, 1000]), y=torch.Size([36000])
Valid: X=torch.Size([4500, 1, 2, 1000]), y=torch.Size([4500])
num_classes: 45
No pre-trained model
Loss for training is CrossEntropyLoss
torch.Size([200, 1, 2, 1000])
epoch: 0
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:01<05:25,  1.82s/it]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:42,  4.14it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:02<00:18,  9.23it/s]going through batches for holmes training:  10%|█         | 18/180 [00:02<00:10, 15.05it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:02<00:07, 21.43it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:02<00:05, 27.87it/s]going through batches for holmes training:  20%|██        | 36/180 [00:02<00:04, 33.94it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:02<00:03, 39.44it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:02<00:02, 44.18it/s]going through batches for holmes training:  30%|███       | 54/180 [00:02<00:02, 48.04it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:02<00:02, 50.98it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:02<00:02, 53.23it/s]going through batches for holmes training:  40%|████      | 72/180 [00:03<00:01, 55.04it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:03<00:01, 56.35it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:03<00:01, 57.28it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:03<00:01, 57.91it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:03<00:01, 58.38it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:03<00:01, 58.76it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:03<00:01, 58.92it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:03<00:01, 56.82it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:03<00:01, 57.49it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 58.01it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:04<00:00, 58.39it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:04<00:00, 58.55it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:04<00:00, 58.85it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:04<00:00, 59.05it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:04<00:00, 59.26it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:04<00:00, 59.05it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:04<00:00, 59.28it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:04<00:00, 59.31it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 59.44it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 36.63it/s]
epoch 0: train_loss = 2.437
0: {'Accuracy': 0.8649, 'Precision': 0.8861, 'Recall': 0.8649, 'F1-score': 0.8666}
epoch: 1
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:31,  1.18it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.20it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.54it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 24.86it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 33.35it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.21it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.27it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.03it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.13it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.50it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.15it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:02, 56.47it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.39it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.93it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.41it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.85it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 59.07it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.32it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.44it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.53it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.51it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:02<00:00, 59.62it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.68it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.73it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.72it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.71it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.73it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.81it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.91it/s]
epoch 1: train_loss = 1.23
1: {'Accuracy': 0.9342, 'Precision': 0.9391, 'Recall': 0.9342, 'F1-score': 0.9345}
epoch: 2
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:47,  1.07it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:23,  7.54it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 14.24it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 23.89it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.22it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.26it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.24it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.35it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.60it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.09it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 54.87it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.22it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.19it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.94it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.45it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.75it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.98it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.15it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.36it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.49it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.93it/s]
epoch 2: train_loss = 0.843
2: {'Accuracy': 0.9458, 'Precision': 0.9504, 'Recall': 0.9458, 'F1-score': 0.9464}
epoch: 3
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:20,  1.27it/s]going through batches for holmes training:   2%|▏         | 3/180 [00:00<00:43,  4.07it/s]going through batches for holmes training:   5%|▌         | 9/180 [00:01<00:12, 13.53it/s]going through batches for holmes training:   8%|▊         | 15/180 [00:01<00:07, 22.16it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:05, 31.40it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:04, 37.89it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 43.24it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 47.47it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 50.78it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 53.24it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 54.97it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:01<00:02, 56.27it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:02<00:02, 54.63it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 55.89it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 56.81it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 57.60it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 58.21it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 58.60it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 58.85it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:02<00:00, 59.32it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.30it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.70it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.46it/s]
epoch 3: train_loss = 0.648
3: {'Accuracy': 0.9558, 'Precision': 0.9584, 'Recall': 0.9558, 'F1-score': 0.9562}
epoch: 4
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:26,  1.22it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:17,  9.75it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:08, 19.60it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 28.50it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 35.15it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 40.83it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 45.49it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 49.20it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 51.98it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 54.14it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 55.73it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:01<00:01, 56.83it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.68it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 58.26it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.68it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 59.15it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.32it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.44it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.31it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:02<00:00, 59.35it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.65it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.49it/s]
epoch 4: train_loss = 0.529
4: {'Accuracy': 0.9616, 'Precision': 0.9638, 'Recall': 0.9616, 'F1-score': 0.9618}
epoch: 5
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:33,  1.17it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.08it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.48it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 24.41it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.91it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.93it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.97it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.06it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.20it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.50it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.22it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.18it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.03it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.72it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.12it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.49it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.68it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 58.97it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.08it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.17it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.15it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.40it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.53it/s]
epoch 5: train_loss = 0.443
5: {'Accuracy': 0.9644, 'Precision': 0.9681, 'Recall': 0.9644, 'F1-score': 0.965}
epoch: 6
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:53,  1.03it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:23,  7.34it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:12, 13.96it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:07, 22.11it/s]going through batches for holmes training:  13%|█▎        | 23/180 [00:01<00:05, 29.80it/s]going through batches for holmes training:  16%|█▌        | 29/180 [00:01<00:04, 36.47it/s]going through batches for holmes training:  19%|█▉        | 35/180 [00:01<00:03, 42.08it/s]going through batches for holmes training:  23%|██▎       | 41/180 [00:01<00:02, 46.59it/s]going through batches for holmes training:  26%|██▌       | 47/180 [00:01<00:02, 50.05it/s]going through batches for holmes training:  29%|██▉       | 53/180 [00:01<00:02, 52.69it/s]going through batches for holmes training:  33%|███▎      | 59/180 [00:01<00:02, 54.63it/s]going through batches for holmes training:  36%|███▌      | 65/180 [00:02<00:02, 56.01it/s]going through batches for holmes training:  39%|███▉      | 71/180 [00:02<00:02, 54.38it/s]going through batches for holmes training:  43%|████▎     | 77/180 [00:02<00:01, 55.70it/s]going through batches for holmes training:  46%|████▌     | 83/180 [00:02<00:01, 56.81it/s]going through batches for holmes training:  49%|████▉     | 89/180 [00:02<00:01, 57.62it/s]going through batches for holmes training:  53%|█████▎    | 95/180 [00:02<00:01, 58.23it/s]going through batches for holmes training:  56%|█████▌    | 101/180 [00:02<00:01, 58.62it/s]going through batches for holmes training:  59%|█████▉    | 107/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  63%|██████▎   | 113/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  66%|██████▌   | 119/180 [00:03<00:01, 59.27it/s]going through batches for holmes training:  69%|██████▉   | 125/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  73%|███████▎  | 131/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  76%|███████▌  | 137/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  79%|███████▉  | 143/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  83%|████████▎ | 149/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  86%|████████▌ | 155/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  89%|████████▉ | 161/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  93%|█████████▎| 167/180 [00:03<00:00, 59.32it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.54it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.36it/s]
epoch 6: train_loss = 0.386
6: {'Accuracy': 0.97, 'Precision': 0.972, 'Recall': 0.97, 'F1-score': 0.9704}
epoch: 7
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:19,  1.28it/s]going through batches for holmes training:   2%|▏         | 3/180 [00:00<00:46,  3.79it/s]going through batches for holmes training:   5%|▌         | 9/180 [00:01<00:13, 13.12it/s]going through batches for holmes training:   9%|▉         | 16/180 [00:01<00:07, 23.37it/s]going through batches for holmes training:  13%|█▎        | 23/180 [00:01<00:04, 32.12it/s]going through batches for holmes training:  16%|█▌        | 29/180 [00:01<00:03, 38.19it/s]going through batches for holmes training:  19%|█▉        | 35/180 [00:01<00:03, 43.39it/s]going through batches for holmes training:  23%|██▎       | 41/180 [00:01<00:02, 47.52it/s]going through batches for holmes training:  26%|██▌       | 47/180 [00:01<00:02, 50.74it/s]going through batches for holmes training:  29%|██▉       | 53/180 [00:01<00:02, 53.13it/s]going through batches for holmes training:  33%|███▎      | 59/180 [00:01<00:02, 54.88it/s]going through batches for holmes training:  36%|███▌      | 65/180 [00:01<00:02, 56.11it/s]going through batches for holmes training:  39%|███▉      | 71/180 [00:02<00:01, 57.13it/s]going through batches for holmes training:  43%|████▎     | 77/180 [00:02<00:01, 57.81it/s]going through batches for holmes training:  46%|████▌     | 83/180 [00:02<00:01, 58.38it/s]going through batches for holmes training:  49%|████▉     | 89/180 [00:02<00:01, 58.62it/s]going through batches for holmes training:  53%|█████▎    | 95/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  56%|█████▌    | 101/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  59%|█████▉    | 107/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  63%|██████▎   | 113/180 [00:02<00:01, 59.29it/s]going through batches for holmes training:  66%|██████▌   | 119/180 [00:02<00:01, 59.35it/s]going through batches for holmes training:  69%|██████▉   | 125/180 [00:02<00:00, 59.37it/s]going through batches for holmes training:  73%|███████▎  | 131/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  76%|███████▌  | 137/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  79%|███████▉  | 143/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  83%|████████▎ | 149/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  86%|████████▌ | 155/180 [00:03<00:00, 59.24it/s]going through batches for holmes training:  89%|████████▉ | 161/180 [00:03<00:00, 59.06it/s]going through batches for holmes training:  93%|█████████▎| 167/180 [00:03<00:00, 59.24it/s]going through batches for holmes training:  96%|█████████▌| 173/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.54it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.52it/s]
epoch 7: train_loss = 0.345
7: {'Accuracy': 0.9722, 'Precision': 0.9741, 'Recall': 0.9722, 'F1-score': 0.9725}
epoch: 8
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:13,  1.34it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:23,  7.33it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:00<00:10, 16.67it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 26.76it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 35.05it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 40.74it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 45.45it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 49.20it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 52.05it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 54.11it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.69it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:01, 56.85it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.59it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 58.22it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.66it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.94it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.34it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.45it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.30it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:02<00:00, 59.40it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.22it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.57it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.90it/s]
epoch 8: train_loss = 0.306
8: {'Accuracy': 0.9696, 'Precision': 0.972, 'Recall': 0.9696, 'F1-score': 0.9701}
epoch: 9
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:38,  1.13it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:22,  7.91it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 14.82it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:07, 23.21it/s]going through batches for holmes training:  13%|█▎        | 23/180 [00:01<00:05, 30.82it/s]going through batches for holmes training:  16%|█▌        | 29/180 [00:01<00:04, 37.50it/s]going through batches for holmes training:  19%|█▉        | 35/180 [00:01<00:03, 42.92it/s]going through batches for holmes training:  23%|██▎       | 41/180 [00:01<00:02, 47.26it/s]going through batches for holmes training:  26%|██▌       | 47/180 [00:01<00:02, 50.67it/s]going through batches for holmes training:  29%|██▉       | 53/180 [00:01<00:02, 53.18it/s]going through batches for holmes training:  33%|███▎      | 59/180 [00:01<00:02, 54.89it/s]going through batches for holmes training:  36%|███▌      | 65/180 [00:02<00:02, 56.22it/s]going through batches for holmes training:  39%|███▉      | 71/180 [00:02<00:01, 57.22it/s]going through batches for holmes training:  43%|████▎     | 77/180 [00:02<00:01, 55.37it/s]going through batches for holmes training:  46%|████▌     | 83/180 [00:02<00:01, 56.25it/s]going through batches for holmes training:  49%|████▉     | 89/180 [00:02<00:01, 57.18it/s]going through batches for holmes training:  53%|█████▎    | 95/180 [00:02<00:01, 57.87it/s]going through batches for holmes training:  56%|█████▌    | 101/180 [00:02<00:01, 58.35it/s]going through batches for holmes training:  59%|█████▉    | 107/180 [00:02<00:01, 58.74it/s]going through batches for holmes training:  63%|██████▎   | 113/180 [00:02<00:01, 58.98it/s]going through batches for holmes training:  66%|██████▌   | 119/180 [00:02<00:01, 59.14it/s]going through batches for holmes training:  69%|██████▉   | 125/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  73%|███████▎  | 131/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  76%|███████▌  | 137/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  79%|███████▉  | 143/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  83%|████████▎ | 149/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  86%|████████▌ | 155/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  89%|████████▉ | 161/180 [00:03<00:00, 59.17it/s]going through batches for holmes training:  93%|█████████▎| 167/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  96%|█████████▌| 173/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.15it/s]
epoch 9: train_loss = 0.271
9: {'Accuracy': 0.9751, 'Precision': 0.9763, 'Recall': 0.9751, 'F1-score': 0.9753}
epoch: 10
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.34it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.71it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.72it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.94it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.11it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.19it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.13it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.13it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.46it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.16it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:02, 56.26it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.19it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.84it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.27it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.56it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.67it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 58.86it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 58.31it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 58.46it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:01, 58.71it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 58.86it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.07it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.17it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.21it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.17it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.43it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.60it/s]
epoch 10: train_loss = 0.247
10: {'Accuracy': 0.9778, 'Precision': 0.9791, 'Recall': 0.9778, 'F1-score': 0.978}
epoch: 11
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:26,  1.23it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:20,  8.34it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:09, 17.12it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 26.66it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 34.82it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.21it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.93it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.60it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.53it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.66it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.05it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.33it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.30it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.94it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.43it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.78it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.04it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.22it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.21it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.30it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.60it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.60it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.20it/s]
epoch 11: train_loss = 0.223
11: {'Accuracy': 0.9784, 'Precision': 0.9798, 'Recall': 0.9784, 'F1-score': 0.9787}
epoch: 12
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:37,  1.14it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  7.93it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.18it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.61it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.72it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.84it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.75it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.80it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.98it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.41it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.20it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.48it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.38it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 56.26it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 57.32it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.04it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.51it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 58.85it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.30it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.56it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.41it/s]
epoch 12: train_loss = 0.202
12: {'Accuracy': 0.9793, 'Precision': 0.9801, 'Recall': 0.9793, 'F1-score': 0.9795}
epoch: 13
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:21,  1.26it/s]going through batches for holmes training:   2%|▏         | 4/180 [00:00<00:31,  5.60it/s]going through batches for holmes training:   6%|▌         | 10/180 [00:00<00:11, 15.24it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:06, 25.60it/s]going through batches for holmes training:  13%|█▎        | 23/180 [00:01<00:04, 33.13it/s]going through batches for holmes training:  16%|█▌        | 29/180 [00:01<00:03, 39.32it/s]going through batches for holmes training:  19%|█▉        | 35/180 [00:01<00:03, 44.46it/s]going through batches for holmes training:  23%|██▎       | 41/180 [00:01<00:02, 48.19it/s]going through batches for holmes training:  26%|██▌       | 47/180 [00:01<00:02, 51.32it/s]going through batches for holmes training:  29%|██▉       | 53/180 [00:01<00:02, 53.51it/s]going through batches for holmes training:  33%|███▎      | 59/180 [00:01<00:02, 55.24it/s]going through batches for holmes training:  36%|███▌      | 65/180 [00:01<00:02, 56.47it/s]going through batches for holmes training:  39%|███▉      | 71/180 [00:02<00:01, 57.27it/s]going through batches for holmes training:  43%|████▎     | 77/180 [00:02<00:01, 57.96it/s]going through batches for holmes training:  46%|████▌     | 83/180 [00:02<00:01, 58.44it/s]going through batches for holmes training:  49%|████▉     | 89/180 [00:02<00:01, 58.72it/s]going through batches for holmes training:  53%|█████▎    | 95/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  56%|█████▌    | 101/180 [00:02<00:01, 58.98it/s]going through batches for holmes training:  59%|█████▉    | 107/180 [00:02<00:01, 59.15it/s]going through batches for holmes training:  63%|██████▎   | 113/180 [00:02<00:01, 59.23it/s]going through batches for holmes training:  66%|██████▌   | 119/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  69%|██████▉   | 125/180 [00:02<00:00, 59.33it/s]going through batches for holmes training:  73%|███████▎  | 131/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  76%|███████▌  | 137/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  79%|███████▉  | 143/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  83%|████████▎ | 149/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  86%|████████▌ | 155/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  89%|████████▉ | 161/180 [00:03<00:00, 59.22it/s]going through batches for holmes training:  93%|█████████▎| 167/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  96%|█████████▌| 173/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.52it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.23it/s]
epoch 13: train_loss = 0.188
13: {'Accuracy': 0.9804, 'Precision': 0.9814, 'Recall': 0.9804, 'F1-score': 0.9806}
epoch: 14
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:12,  1.35it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:23,  7.42it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:00<00:10, 16.68it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 26.72it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 34.97it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 40.67it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 45.33it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 49.02it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.81it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.96it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.51it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:02, 56.34it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.14it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.81it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.27it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.54it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.78it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 58.96it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.08it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.14it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:02<00:00, 59.21it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.20it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.03it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 58.99it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.14it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.70it/s]
epoch 14: train_loss = 0.169
14: {'Accuracy': 0.9798, 'Precision': 0.9806, 'Recall': 0.9798, 'F1-score': 0.98}
epoch: 15
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:22,  1.26it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:20,  8.50it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:09, 17.42it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:05, 27.13it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 35.21it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.81it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 45.41it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 49.04it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.77it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.53it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 54.96it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:02, 55.96it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 56.88it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.60it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.14it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.44it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.08it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.49it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 58.73it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 58.89it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 58.99it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.10it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.18it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.18it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.10it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.17it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.10it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.04it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.14it/s]
epoch 15: train_loss = 0.155
15: {'Accuracy': 0.9811, 'Precision': 0.9819, 'Recall': 0.9811, 'F1-score': 0.9813}
epoch: 16
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:41,  1.11it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:22,  7.71it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 15.92it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.26it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.33it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.49it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.60it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.68it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.87it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.25it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.01it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.21it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.15it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.85it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.22it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.56it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.68it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 58.92it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.14it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.18it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.03it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.13it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.08it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.24it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.37it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.18it/s]
epoch 16: train_loss = 0.149
16: {'Accuracy': 0.9833, 'Precision': 0.9844, 'Recall': 0.9833, 'F1-score': 0.9836}
epoch: 17
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:33,  1.17it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.14it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.80it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 26.21it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 33.28it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.33it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.10it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.10it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.14it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.51it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.23it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:02, 56.49it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.24it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.90it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.41it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.71it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.98it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.29it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.37it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:02<00:00, 59.43it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.30it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.57it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.84it/s]
epoch 17: train_loss = 0.135
17: {'Accuracy': 0.9829, 'Precision': 0.9837, 'Recall': 0.9829, 'F1-score': 0.9831}
epoch: 18
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:28,  1.20it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:25,  6.75it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:10, 15.39it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 25.05it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 33.34it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.08it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.04it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.03it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.14it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.51it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.21it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.46it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.34it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 58.04it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.52it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.83it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 59.02it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 58.78it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.01it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.14it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.30it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.24it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.46it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.68it/s]
epoch 18: train_loss = 0.129
18: {'Accuracy': 0.9804, 'Precision': 0.9811, 'Recall': 0.9804, 'F1-score': 0.9806}
epoch: 19
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:15,  1.32it/s]going through batches for holmes training:   2%|▏         | 3/180 [00:00<00:42,  4.16it/s]going through batches for holmes training:   5%|▌         | 9/180 [00:00<00:12, 14.16it/s]going through batches for holmes training:   8%|▊         | 15/180 [00:01<00:07, 23.49it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:04, 32.87it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:03, 39.28it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 44.38it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 48.35it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 51.41it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 53.65it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 55.27it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:01<00:02, 56.43it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:02<00:01, 57.25it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 57.88it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 58.31it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 58.60it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 59.00it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:02<00:00, 59.25it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 59.32it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 59.32it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.64it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.17it/s]
epoch 19: train_loss = 0.119
19: {'Accuracy': 0.9853, 'Precision': 0.9861, 'Recall': 0.9853, 'F1-score': 0.9855}
epoch: 20
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:31,  1.18it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.17it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.67it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 26.20it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 34.33it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.08it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.81it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.63it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.58it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.83it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.46it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.63it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.56it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 58.10it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.57it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.07it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.24it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.42it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.64it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.61it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.02it/s]
epoch 20: train_loss = 0.109
20: {'Accuracy': 0.9858, 'Precision': 0.9866, 'Recall': 0.9858, 'F1-score': 0.986}
epoch: 21
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:24,  1.23it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:26,  6.68it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:10, 15.44it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:06, 23.95it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 32.72it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 38.93it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.91it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.93it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.99it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.05it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 54.79it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 56.09it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 56.93it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.58it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.08it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.43it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.61it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 58.86it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.04it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 58.18it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 58.56it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 58.80it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 58.93it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 58.99it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.08it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.18it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 58.97it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.13it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.36it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.42it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.59it/s]
epoch 21: train_loss = 0.104
21: {'Accuracy': 0.9838, 'Precision': 0.9844, 'Recall': 0.9838, 'F1-score': 0.9839}
epoch: 22
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<01:52,  1.60it/s]going through batches for holmes training:   1%|          | 2/180 [00:00<00:58,  3.05it/s]going through batches for holmes training:   2%|▏         | 4/180 [00:00<00:28,  6.27it/s]going through batches for holmes training:   6%|▌         | 10/180 [00:00<00:09, 17.46it/s]going through batches for holmes training:   9%|▉         | 16/180 [00:01<00:06, 26.90it/s]going through batches for holmes training:  13%|█▎        | 23/180 [00:01<00:04, 36.16it/s]going through batches for holmes training:  16%|█▌        | 29/180 [00:01<00:03, 41.96it/s]going through batches for holmes training:  19%|█▉        | 35/180 [00:01<00:03, 46.56it/s]going through batches for holmes training:  23%|██▎       | 41/180 [00:01<00:02, 50.00it/s]going through batches for holmes training:  26%|██▌       | 47/180 [00:01<00:02, 52.56it/s]going through batches for holmes training:  29%|██▉       | 53/180 [00:01<00:02, 54.56it/s]going through batches for holmes training:  33%|███▎      | 59/180 [00:01<00:02, 56.01it/s]going through batches for holmes training:  36%|███▌      | 65/180 [00:01<00:02, 57.04it/s]going through batches for holmes training:  39%|███▉      | 71/180 [00:02<00:01, 57.76it/s]going through batches for holmes training:  43%|████▎     | 77/180 [00:02<00:01, 58.26it/s]going through batches for holmes training:  46%|████▌     | 83/180 [00:02<00:01, 58.65it/s]going through batches for holmes training:  49%|████▉     | 89/180 [00:02<00:01, 58.58it/s]going through batches for holmes training:  53%|█████▎    | 95/180 [00:02<00:01, 58.77it/s]going through batches for holmes training:  56%|█████▌    | 101/180 [00:02<00:01, 59.01it/s]going through batches for holmes training:  59%|█████▉    | 107/180 [00:02<00:01, 58.93it/s]going through batches for holmes training:  63%|██████▎   | 113/180 [00:02<00:01, 59.09it/s]going through batches for holmes training:  66%|██████▌   | 119/180 [00:02<00:01, 59.15it/s]going through batches for holmes training:  69%|██████▉   | 125/180 [00:02<00:00, 59.30it/s]going through batches for holmes training:  73%|███████▎  | 131/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  76%|███████▌  | 137/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  79%|███████▉  | 143/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  83%|████████▎ | 149/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  86%|████████▌ | 155/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  89%|████████▉ | 161/180 [00:03<00:00, 58.66it/s]going through batches for holmes training:  93%|█████████▎| 167/180 [00:03<00:00, 59.01it/s]going through batches for holmes training:  96%|█████████▌| 173/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.48it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.33it/s]
epoch 22: train_loss = 0.096
22: {'Accuracy': 0.9849, 'Precision': 0.9859, 'Recall': 0.9849, 'F1-score': 0.9851}
epoch: 23
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:11,  1.36it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:16, 10.77it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:00<00:08, 19.86it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 29.44it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 37.30it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 42.57it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 46.82it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 50.16it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 52.77it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 54.66it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 56.05it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:01<00:01, 57.05it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:01<00:01, 57.79it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 58.36it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.70it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.97it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 59.13it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.21it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.28it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.35it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.32it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:02<00:00, 59.33it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:02<00:00, 59.36it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.55it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 47.60it/s]
epoch 23: train_loss = 0.09
23: {'Accuracy': 0.9862, 'Precision': 0.9867, 'Recall': 0.9862, 'F1-score': 0.9863}
epoch: 24
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:20,  1.27it/s]going through batches for holmes training:   1%|          | 2/180 [00:00<01:11,  2.49it/s]going through batches for holmes training:   4%|▍         | 8/180 [00:01<00:13, 12.39it/s]going through batches for holmes training:   8%|▊         | 15/180 [00:01<00:07, 23.10it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:04, 32.10it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:03, 38.33it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 43.51it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 47.71it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 50.90it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 53.37it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 55.15it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:01<00:02, 56.43it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:02<00:01, 57.34it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 58.05it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 58.51it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 58.81it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 59.01it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 59.13it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.35it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.43it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:02<00:00, 59.37it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 58.44it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 58.27it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 58.49it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 58.81it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.06it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  99%|█████████▉| 178/180 [00:03<00:00, 59.53it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.59it/s]
epoch 24: train_loss = 0.085
24: {'Accuracy': 0.9844, 'Precision': 0.9849, 'Recall': 0.9844, 'F1-score': 0.9845}
epoch: 25
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:47,  1.07it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:23,  7.52it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 14.19it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 23.83it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.18it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.23it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.39it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.53it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.72it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.17it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 54.99it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.36it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.31it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.94it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.46it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.83it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.14it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.32it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.38it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.44it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.87it/s]
epoch 25: train_loss = 0.08
25: {'Accuracy': 0.9853, 'Precision': 0.986, 'Recall': 0.9853, 'F1-score': 0.9855}
epoch: 26
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:30,  1.19it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:17,  9.64it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:08, 19.45it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 28.33it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 34.94it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 40.63it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 45.37it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 48.79it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 51.70it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 53.84it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 55.48it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:01<00:01, 56.65it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.24it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 57.85it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.37it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.75it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 59.02it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.21it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.32it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.45it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:02<00:00, 59.49it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.71it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.34it/s]
epoch 26: train_loss = 0.072
26: {'Accuracy': 0.9876, 'Precision': 0.9882, 'Recall': 0.9876, 'F1-score': 0.9877}
epoch: 27
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:29,  1.19it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.47it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.91it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 27.10it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.96it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.84it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.62it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.50it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.42it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.67it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.33it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.57it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.40it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.97it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.36it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.65it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.21it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.34it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.45it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.47it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.65it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 56.99it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 57.31it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 57.76it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 58.34it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 58.80it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.93it/s]
epoch 27: train_loss = 0.069
27: {'Accuracy': 0.9873, 'Precision': 0.9877, 'Recall': 0.9873, 'F1-score': 0.9874}
epoch: 28
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.39it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.50it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.46it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.79it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.65it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.58it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.53it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.53it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.86it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.48it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.70it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.56it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 58.19it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.63it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.93it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.32it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.45it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.45it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.60it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.65it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.77it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.99it/s]
epoch 28: train_loss = 0.065
28: {'Accuracy': 0.986, 'Precision': 0.9866, 'Recall': 0.986, 'F1-score': 0.9862}
epoch: 29
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:33,  1.16it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.09it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.38it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 24.40it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 31.92it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 38.35it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.64it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.83it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.98it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.41it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 55.20it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 56.45it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 57.36it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 58.00it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.35it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.68it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.92it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 59.13it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.37it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.32it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:02<00:00, 59.36it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.65it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.66it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.67it/s]
epoch 29: train_loss = 0.063
29: {'Accuracy': 0.9873, 'Precision': 0.9878, 'Recall': 0.9873, 'F1-score': 0.9874}
epoch: 30
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.25it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.18it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 26.31it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.21it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.19it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.17it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.76it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.81it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.25it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 54.98it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.27it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.28it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.91it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.42it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.73it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.93it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.40it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.42it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 58.40it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 58.63it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 58.91it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.51it/s]
epoch 30: train_loss = 0.059
30: {'Accuracy': 0.9869, 'Precision': 0.9874, 'Recall': 0.9869, 'F1-score': 0.987}
epoch: 31
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:24,  1.24it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:20,  8.52it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:10, 15.75it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:06, 24.24it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 33.22it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 39.44it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 44.49it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 48.43it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 51.51it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.75it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 55.36it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 56.62it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 57.40it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 58.05it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.48it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.72it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.98it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.23it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.38it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:02<00:00, 59.42it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.24it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.55it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.65it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.32it/s]
epoch 31: train_loss = 0.051
31: {'Accuracy': 0.9867, 'Precision': 0.9872, 'Recall': 0.9867, 'F1-score': 0.9868}
epoch: 32
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:37,  1.14it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.33it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.62it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 26.86it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.77it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.73it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.64it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.54it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.46it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.51it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.27it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.39it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.30it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.91it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.11it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.46it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.71it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.23it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.55it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.88it/s]
epoch 32: train_loss = 0.052
32: {'Accuracy': 0.9871, 'Precision': 0.9877, 'Recall': 0.9871, 'F1-score': 0.9872}
epoch: 33
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:25,  1.23it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:20,  8.46it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:08, 18.75it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 27.95it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 34.77it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.53it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 45.17it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.88it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.68it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.90it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.43it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.43it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.30it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.87it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.30it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.62it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.73it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.87it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 58.99it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.09it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.16it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.21it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.20it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.17it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 58.31it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 58.87it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.34it/s]
epoch 33: train_loss = 0.047
33: {'Accuracy': 0.9844, 'Precision': 0.9851, 'Recall': 0.9844, 'F1-score': 0.9846}
epoch: 34
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:30,  1.19it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:17,  9.64it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:08, 19.41it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 28.36it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 34.97it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 40.66it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 45.36it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 49.05it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 51.92it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 54.07it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 55.64it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:01<00:01, 56.74it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.63it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 58.26it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.64it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.96it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.39it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.48it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:02<00:00, 59.55it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.63it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.66it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.41it/s]
epoch 34: train_loss = 0.047
34: {'Accuracy': 0.9873, 'Precision': 0.9878, 'Recall': 0.9873, 'F1-score': 0.9874}
epoch: 35
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:18,  1.29it/s]going through batches for holmes training:   2%|▏         | 3/180 [00:00<00:42,  4.20it/s]going through batches for holmes training:   5%|▌         | 9/180 [00:00<00:12, 14.06it/s]going through batches for holmes training:   9%|▉         | 16/180 [00:01<00:06, 24.67it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:04, 32.25it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:03, 38.68it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 43.65it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 47.81it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 50.87it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 53.22it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 54.91it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:01<00:02, 56.15it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:02<00:01, 56.96it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 57.62it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 58.14it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 58.45it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 58.51it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 58.73it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:02<00:00, 59.19it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  99%|█████████▉| 178/180 [00:03<00:00, 59.64it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.09it/s]
epoch 35: train_loss = 0.046
35: {'Accuracy': 0.9876, 'Precision': 0.988, 'Recall': 0.9876, 'F1-score': 0.9876}
epoch: 36
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:30,  1.19it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.51it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.70it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.68it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.95it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.76it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.61it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.50it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.41it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.67it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.27it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.49it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.41it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 58.06it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.50it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.82it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.94it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.27it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.54it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.00it/s]
epoch 36: train_loss = 0.042
36: {'Accuracy': 0.9871, 'Precision': 0.9876, 'Recall': 0.9871, 'F1-score': 0.9872}
epoch: 37
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:31,  1.18it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.55it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:08, 19.30it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 28.14it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 34.69it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 40.31it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 45.05it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 48.86it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 51.65it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 53.82it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 55.37it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:01<00:01, 56.51it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.43it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 58.03it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.51it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.78it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 58.94it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.38it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.64it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.18it/s]
epoch 37: train_loss = 0.039
37: {'Accuracy': 0.9873, 'Precision': 0.9879, 'Recall': 0.9873, 'F1-score': 0.9874}
epoch: 38
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:40,  1.11it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  9.02it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.20it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 26.33it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.23it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.24it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.21it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.19it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.25it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.52it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.22it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.49it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.30it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.94it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.42it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.76it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.22it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.38it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.38it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.59it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.55it/s]
epoch 38: train_loss = 0.038
38: {'Accuracy': 0.9878, 'Precision': 0.9885, 'Recall': 0.9878, 'F1-score': 0.9879}
epoch: 39
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:27,  1.21it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:17,  9.83it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 18.50it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 27.85it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 34.73it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.55it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 45.30it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 49.05it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.89it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 54.04it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.64it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.74it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.58it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 58.18it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.56it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.86it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.40it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.44it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.64it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.52it/s]
epoch 39: train_loss = 0.034
39: {'Accuracy': 0.9867, 'Precision': 0.9873, 'Recall': 0.9867, 'F1-score': 0.9868}
epoch: 40
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:45,  1.08it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.89it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:09, 18.16it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 26.71it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 33.22it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 39.02it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 43.76it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 47.71it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 50.77it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 53.16it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 54.95it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:02<00:01, 56.26it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 56.88it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 57.62it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.22it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.61it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.13it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.37it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.34it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  99%|█████████▉| 178/180 [00:03<00:00, 59.61it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.26it/s]
epoch 40: train_loss = 0.032
40: {'Accuracy': 0.9873, 'Precision': 0.9877, 'Recall': 0.9873, 'F1-score': 0.9874}
epoch: 41
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.31it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.29it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 26.43it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.36it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.39it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.34it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.29it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.31it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.64it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.37it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.60it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.45it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.99it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.42it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.77it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.06it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.21it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.38it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.44it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.66it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.79it/s]
epoch 41: train_loss = 0.031
41: {'Accuracy': 0.9876, 'Precision': 0.988, 'Recall': 0.9876, 'F1-score': 0.9876}
epoch: 42
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:26,  1.22it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:17,  9.66it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 18.23it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 27.51it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 34.40it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.30it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 45.14it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.93it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.86it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 54.03it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.63it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.83it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.60it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 58.12it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.29it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.67it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.94it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.17it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.32it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.63it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.39it/s]
epoch 42: train_loss = 0.031
42: {'Accuracy': 0.9876, 'Precision': 0.9882, 'Recall': 0.9876, 'F1-score': 0.9877}
epoch: 43
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:32,  1.17it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.00it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 14.97it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:06, 23.60it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 32.50it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 38.70it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.78it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.84it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.99it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.37it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 55.18it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 56.32it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 57.24it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.87it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.28it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.63it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.85it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 58.62it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.08it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.22it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.22it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.56it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.70it/s]
epoch 43: train_loss = 0.028
43: {'Accuracy': 0.988, 'Precision': 0.9883, 'Recall': 0.988, 'F1-score': 0.9881}
epoch: 44
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:20,  1.28it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:24,  7.13it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:10, 16.13it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 26.07it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 34.38it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 40.20it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.98it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.77it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.68it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.84it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.49it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:01, 56.62it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.41it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 58.01it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.46it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.75it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.06it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.19it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:02<00:00, 59.21it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.11it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.43it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.38it/s]
epoch 44: train_loss = 0.025
44: {'Accuracy': 0.9887, 'Precision': 0.9889, 'Recall': 0.9887, 'F1-score': 0.9887}
epoch: 45
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.25it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.46it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 26.64it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.51it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.46it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.37it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.25it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.30it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.56it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.25it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.45it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.34it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.99it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.40it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.76it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.29it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.34it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.54it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.87it/s]
epoch 45: train_loss = 0.028
45: {'Accuracy': 0.9891, 'Precision': 0.9895, 'Recall': 0.9891, 'F1-score': 0.9892}
epoch: 46
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.09it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 15.11it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 24.98it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 33.32it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.24it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.22it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.17it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.20it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.46it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.20it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.49it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.36it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 58.01it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.49it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.70it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.95it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.33it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.58it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.73it/s]
epoch 46: train_loss = 0.025
46: {'Accuracy': 0.9882, 'Precision': 0.9885, 'Recall': 0.9882, 'F1-score': 0.9883}
epoch: 47
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.04it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.27it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 24.42it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.91it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.79it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.61it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.68it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.86it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.25it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.04it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.35it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.19it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.89it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.39it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.74it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.92it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.08it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.20it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.29it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.28it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.58it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.52it/s]
epoch 47: train_loss = 0.023
47: {'Accuracy': 0.9833, 'Precision': 0.9838, 'Recall': 0.9833, 'F1-score': 0.9834}
epoch: 48
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:12,  1.35it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:19,  8.74it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:00<00:09, 17.70it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:05, 27.46it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 35.59it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 41.14it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 45.64it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 49.23it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.87it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.88it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.45it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.58it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.38it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.92it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.24it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.55it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.76it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.86it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.00it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.09it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.20it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.26it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.16it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.10it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.14it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.32it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.42it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.74it/s]
epoch 48: train_loss = 0.024
48: {'Accuracy': 0.9893, 'Precision': 0.9897, 'Recall': 0.9893, 'F1-score': 0.9894}
epoch: 49
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:41,  1.11it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.94it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 15.50it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 24.95it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.14it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.36it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.56it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.74it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.90it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.31it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.10it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.40it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.30it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.95it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.42it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.73it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.29it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.37it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.65it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.31it/s]
epoch 49: train_loss = 0.022
49: {'Accuracy': 0.9893, 'Precision': 0.9896, 'Recall': 0.9893, 'F1-score': 0.9894}
epoch: 50
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<01:17,  2.31it/s]going through batches for holmes training:   1%|          | 2/180 [00:00<01:03,  2.82it/s]going through batches for holmes training:   2%|▏         | 3/180 [00:00<00:42,  4.15it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:18,  9.43it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:07, 22.51it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:04, 32.72it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:03, 40.46it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 45.33it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:02, 49.10it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 51.95it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 54.08it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 55.65it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 56.75it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:02<00:01, 57.57it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 58.11it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 58.47it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.84it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 59.14it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.21it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.29it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.41it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.44it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.59it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.12it/s]
epoch 50: train_loss = 0.021
50: {'Accuracy': 0.9898, 'Precision': 0.9902, 'Recall': 0.9898, 'F1-score': 0.9899}
epoch: 51
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.05it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.30it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.69it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.73it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.89it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.97it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.01it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.14it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.47it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.16it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.44it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.35it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.98it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.41it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.68it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.93it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.28it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.36it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.34it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.64it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.77it/s]
epoch 51: train_loss = 0.018
51: {'Accuracy': 0.9873, 'Precision': 0.9878, 'Recall': 0.9873, 'F1-score': 0.9874}
epoch: 52
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:43,  1.10it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:22,  7.66it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 15.73it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 23.84it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.32it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.41it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.51it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.50it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.62it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.10it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 54.93it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.19it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.13it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.85it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.32it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.69it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.98it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.15it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.23it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.37it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.60it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.30it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.60it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.22it/s]
epoch 52: train_loss = 0.022
52: {'Accuracy': 0.9836, 'Precision': 0.9846, 'Recall': 0.9836, 'F1-score': 0.9838}
epoch: 53
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:22,  1.26it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:24,  7.10it/s]going through batches for holmes training:   6%|▌         | 10/180 [00:01<00:11, 14.68it/s]going through batches for holmes training:   9%|▉         | 16/180 [00:01<00:06, 23.48it/s]going through batches for holmes training:  13%|█▎        | 23/180 [00:01<00:04, 32.73it/s]going through batches for holmes training:  16%|█▌        | 29/180 [00:01<00:03, 39.05it/s]going through batches for holmes training:  19%|█▉        | 35/180 [00:01<00:03, 44.16it/s]going through batches for holmes training:  23%|██▎       | 41/180 [00:01<00:02, 48.21it/s]going through batches for holmes training:  26%|██▌       | 47/180 [00:01<00:02, 51.36it/s]going through batches for holmes training:  29%|██▉       | 53/180 [00:01<00:02, 53.72it/s]going through batches for holmes training:  33%|███▎      | 59/180 [00:01<00:02, 55.42it/s]going through batches for holmes training:  36%|███▌      | 65/180 [00:01<00:02, 56.66it/s]going through batches for holmes training:  39%|███▉      | 71/180 [00:02<00:01, 57.55it/s]going through batches for holmes training:  43%|████▎     | 77/180 [00:02<00:01, 58.18it/s]going through batches for holmes training:  46%|████▌     | 83/180 [00:02<00:01, 58.66it/s]going through batches for holmes training:  49%|████▉     | 89/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  53%|█████▎    | 95/180 [00:02<00:01, 59.16it/s]going through batches for holmes training:  56%|█████▌    | 101/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  59%|█████▉    | 107/180 [00:02<00:01, 59.37it/s]going through batches for holmes training:  63%|██████▎   | 113/180 [00:02<00:01, 59.44it/s]going through batches for holmes training:  66%|██████▌   | 119/180 [00:02<00:01, 59.50it/s]going through batches for holmes training:  69%|██████▉   | 125/180 [00:02<00:00, 59.54it/s]going through batches for holmes training:  73%|███████▎  | 131/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  76%|███████▌  | 137/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  79%|███████▉  | 143/180 [00:03<00:00, 59.64it/s]going through batches for holmes training:  83%|████████▎ | 149/180 [00:03<00:00, 59.69it/s]going through batches for holmes training:  86%|████████▌ | 155/180 [00:03<00:00, 59.66it/s]going through batches for holmes training:  89%|████████▉ | 161/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  93%|█████████▎| 167/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  96%|█████████▌| 173/180 [00:03<00:00, 59.65it/s]going through batches for holmes training:  99%|█████████▉| 179/180 [00:03<00:00, 59.75it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.13it/s]
epoch 53: train_loss = 0.017
53: {'Accuracy': 0.9887, 'Precision': 0.9891, 'Recall': 0.9887, 'F1-score': 0.9888}
epoch: 54
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:49,  1.06it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.73it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 16.76it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 25.75it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 32.62it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 38.64it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 43.69it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.72it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.91it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.22it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 54.99it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.23it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.17it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.87it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.31it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.65it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.93it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.08it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.21it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.33it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.07it/s]
epoch 54: train_loss = 0.013
54: {'Accuracy': 0.988, 'Precision': 0.9886, 'Recall': 0.988, 'F1-score': 0.9881}
epoch: 55
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:37,  1.14it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.32it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.67it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:05, 26.87it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.76it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.64it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.53it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.41it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.43it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.44it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.13it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.33it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.24it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.92it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.31it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.66it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.89it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.04it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.14it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.22it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.26it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.51it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.79it/s]
epoch 55: train_loss = 0.013
55: {'Accuracy': 0.9889, 'Precision': 0.9894, 'Recall': 0.9889, 'F1-score': 0.989}
epoch: 56
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:21,  1.26it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:24,  7.10it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:10, 16.07it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:06, 24.31it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 33.16it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 39.26it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.77it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.76it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.92it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.30it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 55.06it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 56.34it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 57.24it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.97it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.37it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.73it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 59.01it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 59.14it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.23it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.38it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.42it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:02<00:00, 59.51it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.12it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.26it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.14it/s]
epoch 56: train_loss = 0.012
56: {'Accuracy': 0.9891, 'Precision': 0.9896, 'Recall': 0.9891, 'F1-score': 0.9892}
epoch: 57
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<01:33,  1.91it/s]going through batches for holmes training:   1%|          | 2/180 [00:00<01:01,  2.87it/s]going through batches for holmes training:   2%|▏         | 3/180 [00:01<00:54,  3.24it/s]going through batches for holmes training:   5%|▌         | 9/180 [00:01<00:13, 12.65it/s]going through batches for holmes training:   8%|▊         | 15/180 [00:01<00:07, 21.20it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:05, 30.56it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:04, 37.19it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 42.66it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 47.04it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 50.39it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 52.88it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 54.82it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:02<00:02, 56.24it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:02<00:01, 57.22it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 57.94it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 58.40it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 58.67it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 58.87it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 59.06it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.30it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.57it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.65it/s]going through batches for holmes training:  99%|█████████▉| 178/180 [00:03<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.42it/s]
epoch 57: train_loss = 0.014
57: {'Accuracy': 0.9891, 'Precision': 0.9894, 'Recall': 0.9891, 'F1-score': 0.9892}
epoch: 58
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<01:41,  1.77it/s]going through batches for holmes training:   1%|          | 2/180 [00:00<01:17,  2.30it/s]going through batches for holmes training:   4%|▍         | 8/180 [00:01<00:14, 11.62it/s]going through batches for holmes training:   8%|▊         | 15/180 [00:01<00:07, 21.95it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:05, 30.95it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:04, 37.34it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 42.68it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 46.98it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 50.34it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 52.94it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 54.77it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:01<00:02, 56.16it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:02<00:01, 57.16it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 57.88it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 58.39it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 58.69it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 59.04it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.36it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.44it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:02<00:00, 59.47it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 59.60it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  99%|█████████▉| 178/180 [00:03<00:00, 59.56it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.86it/s]
epoch 58: train_loss = 0.014
58: {'Accuracy': 0.9907, 'Precision': 0.9909, 'Recall': 0.9907, 'F1-score': 0.9907}
epoch: 59
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:01<03:07,  1.05s/it]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:21,  7.95it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:10, 15.47it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 24.20it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 31.02it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 37.17it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 42.44it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 46.74it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.10it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 52.67it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:02<00:02, 54.07it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:02, 55.48it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 56.58it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.48it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.11it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.54it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.81it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.01it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.17it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.25it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:04<00:00, 59.63it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 43.94it/s]
epoch 59: train_loss = 0.012
59: {'Accuracy': 0.9884, 'Precision': 0.9887, 'Recall': 0.9884, 'F1-score': 0.9885}
epoch: 60
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:40,  1.11it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:22,  7.78it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 14.63it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:07, 22.87it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 31.75it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 37.98it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.19it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.28it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.47it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 52.89it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 54.73it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:02<00:02, 56.05it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 56.87it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.53it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.09it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.50it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.87it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.28it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.44it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.48it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.60it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.71it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.74it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.02it/s]
epoch 60: train_loss = 0.012
60: {'Accuracy': 0.9884, 'Precision': 0.989, 'Recall': 0.9884, 'F1-score': 0.9886}
epoch: 61
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:37,  1.13it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:18,  9.11it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 15.74it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.25it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.45it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.65it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.74it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.83it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 50.99it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.35it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.11it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.39it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.25it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.91it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.30it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.68it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.87it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.20it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.35it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.46it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.51it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.54it/s]
epoch 61: train_loss = 0.01
61: {'Accuracy': 0.9887, 'Precision': 0.9891, 'Recall': 0.9887, 'F1-score': 0.9888}
epoch: 62
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:35,  1.15it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:21,  8.04it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:11, 15.00it/s]going through batches for holmes training:   9%|▉         | 17/180 [00:01<00:06, 23.59it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 32.51it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 38.70it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.82it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.84it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.94it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.26it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 55.02it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 56.32it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 57.24it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.88it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.40it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.28it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.57it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 58.89it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.16it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.29it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.34it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.62it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.67it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.51it/s]
epoch 62: train_loss = 0.011
62: {'Accuracy': 0.9896, 'Precision': 0.9899, 'Recall': 0.9896, 'F1-score': 0.9896}
epoch: 63
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:48,  1.06it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.75it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 16.70it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 25.73it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 32.61it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 38.65it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 43.72it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.50it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.68it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 52.98it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 54.76it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.04it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 56.98it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.59it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.19it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.51it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.75it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.84it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.16it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 58.76it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 58.90it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.04it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.01it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.23it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.23it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.90it/s]
epoch 63: train_loss = 0.01
63: {'Accuracy': 0.9889, 'Precision': 0.9894, 'Recall': 0.9889, 'F1-score': 0.989}
epoch: 64
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:47,  1.07it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.79it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:09, 18.03it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 26.62it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 33.24it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 39.08it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 43.88it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 47.81it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 50.95it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 53.26it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 54.99it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:02<00:01, 56.28it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.15it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 57.81it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.18it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.45it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 58.66it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 58.87it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.00it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.12it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.27it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.43it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.31it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.50it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.10it/s]
epoch 64: train_loss = 0.01
64: {'Accuracy': 0.9891, 'Precision': 0.9894, 'Recall': 0.9891, 'F1-score': 0.9892}
epoch: 65
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:48,  1.06it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:20,  8.64it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:11, 15.05it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:07, 23.03it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:05, 30.58it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:04, 37.08it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 42.54it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 46.88it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.29it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 52.75it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 54.62it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:02<00:02, 55.96it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 56.91it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.66it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.08it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.45it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.72it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 58.87it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.04it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.28it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.13it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.42it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.57it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.72it/s]
epoch 65: train_loss = 0.011
65: {'Accuracy': 0.9893, 'Precision': 0.9896, 'Recall': 0.9893, 'F1-score': 0.9894}
epoch: 66
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:38,  1.13it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:22,  7.88it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.38it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.81it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.91it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.06it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.15it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.04it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.16it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.46it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.18it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:02, 56.40it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.33it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.97it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.52it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.82it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 58.94it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.15it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.31it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.35it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 58.91it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.48it/s]
epoch 66: train_loss = 0.009
66: {'Accuracy': 0.9898, 'Precision': 0.9903, 'Recall': 0.9898, 'F1-score': 0.9899}
epoch: 67
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<01:07,  2.64it/s]going through batches for holmes training:   1%|          | 2/180 [00:00<01:12,  2.45it/s]going through batches for holmes training:   4%|▍         | 8/180 [00:00<00:14, 12.20it/s]going through batches for holmes training:   8%|▊         | 15/180 [00:01<00:07, 22.77it/s]going through batches for holmes training:  12%|█▏        | 22/180 [00:01<00:04, 31.86it/s]going through batches for holmes training:  16%|█▌        | 28/180 [00:01<00:03, 38.15it/s]going through batches for holmes training:  19%|█▉        | 34/180 [00:01<00:03, 43.39it/s]going through batches for holmes training:  22%|██▏       | 40/180 [00:01<00:02, 47.55it/s]going through batches for holmes training:  26%|██▌       | 46/180 [00:01<00:02, 50.79it/s]going through batches for holmes training:  29%|██▉       | 52/180 [00:01<00:02, 53.19it/s]going through batches for holmes training:  32%|███▏      | 58/180 [00:01<00:02, 54.93it/s]going through batches for holmes training:  36%|███▌      | 64/180 [00:01<00:02, 56.21it/s]going through batches for holmes training:  39%|███▉      | 70/180 [00:01<00:01, 57.14it/s]going through batches for holmes training:  42%|████▏     | 76/180 [00:02<00:01, 57.83it/s]going through batches for holmes training:  46%|████▌     | 82/180 [00:02<00:01, 58.31it/s]going through batches for holmes training:  49%|████▉     | 88/180 [00:02<00:01, 58.55it/s]going through batches for holmes training:  52%|█████▏    | 94/180 [00:02<00:01, 58.78it/s]going through batches for holmes training:  56%|█████▌    | 100/180 [00:02<00:01, 58.91it/s]going through batches for holmes training:  59%|█████▉    | 106/180 [00:02<00:01, 59.06it/s]going through batches for holmes training:  62%|██████▏   | 112/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  66%|██████▌   | 118/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  69%|██████▉   | 124/180 [00:02<00:00, 59.29it/s]going through batches for holmes training:  72%|███████▏  | 130/180 [00:02<00:00, 59.30it/s]going through batches for holmes training:  76%|███████▌  | 136/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  79%|███████▉  | 142/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  82%|████████▏ | 148/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  86%|████████▌ | 154/180 [00:03<00:00, 59.41it/s]going through batches for holmes training:  89%|████████▉ | 160/180 [00:03<00:00, 59.38it/s]going through batches for holmes training:  92%|█████████▏| 166/180 [00:03<00:00, 59.20it/s]going through batches for holmes training:  96%|█████████▌| 172/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  99%|█████████▉| 178/180 [00:03<00:00, 59.44it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 47.01it/s]
epoch 67: train_loss = 0.006
67: {'Accuracy': 0.9904, 'Precision': 0.9907, 'Recall': 0.9904, 'F1-score': 0.9905}
epoch: 68
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:40,  1.11it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  9.10it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:08, 18.51it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 27.23it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 33.80it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 39.59it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 44.43it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 48.33it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 51.10it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 53.35it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 54.95it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:02<00:01, 56.21it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.20it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 57.78it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.29it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.64it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 58.82it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.10it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.26it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.33it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.28it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.53it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.54it/s]
epoch 68: train_loss = 0.007
68: {'Accuracy': 0.9847, 'Precision': 0.9856, 'Recall': 0.9847, 'F1-score': 0.9847}
epoch: 69
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:54,  1.03it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:20,  8.38it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:10, 16.12it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 24.99it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 31.88it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 37.98it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 43.11it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.28it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.48it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 52.95it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:02<00:02, 54.75it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.10it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.04it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.69it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.22it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.58it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.86it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.03it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.18it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.22it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.28it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.42it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.21it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.36it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.47it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.49it/s]
epoch 69: train_loss = 0.012
69: {'Accuracy': 0.9873, 'Precision': 0.988, 'Recall': 0.9873, 'F1-score': 0.9875}
epoch: 70
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:38,  1.13it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:22,  7.89it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 16.05it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 25.42it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 32.54it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 38.73it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 43.88it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 47.97it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.13it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.52it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.25it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:02<00:01, 56.52it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.33it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 57.98it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.46it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.81it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 59.00it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.35it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.37it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:03<00:00, 59.45it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.73it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.50it/s]
epoch 70: train_loss = 0.01
70: {'Accuracy': 0.9876, 'Precision': 0.9879, 'Recall': 0.9876, 'F1-score': 0.9876}
epoch: 71
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:30,  1.19it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:20,  8.29it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:09, 16.96it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 25.33it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 32.83it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 39.15it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 44.14it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 48.18it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 51.18it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.48it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 55.14it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:01<00:02, 55.84it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 56.80it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.60it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.08it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.42it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.44it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 58.58it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 58.77it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 58.97it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:02<00:00, 59.14it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.22it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.26it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.33it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.20it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.37it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.48it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.60it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.94it/s]
epoch 71: train_loss = 0.006
71: {'Accuracy': 0.99, 'Precision': 0.9903, 'Recall': 0.99, 'F1-score': 0.9901}
epoch: 72
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:34,  1.16it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:00<00:18,  9.39it/s]going through batches for holmes training:   8%|▊         | 14/180 [00:01<00:08, 19.01it/s]going through batches for holmes training:  12%|█▏        | 21/180 [00:01<00:05, 27.85it/s]going through batches for holmes training:  15%|█▌        | 27/180 [00:01<00:04, 34.48it/s]going through batches for holmes training:  18%|█▊        | 33/180 [00:01<00:03, 40.23it/s]going through batches for holmes training:  22%|██▏       | 39/180 [00:01<00:03, 44.58it/s]going through batches for holmes training:  25%|██▌       | 45/180 [00:01<00:02, 48.41it/s]going through batches for holmes training:  28%|██▊       | 51/180 [00:01<00:02, 51.38it/s]going through batches for holmes training:  32%|███▏      | 57/180 [00:01<00:02, 53.60it/s]going through batches for holmes training:  35%|███▌      | 63/180 [00:01<00:02, 55.30it/s]going through batches for holmes training:  38%|███▊      | 69/180 [00:02<00:01, 56.49it/s]going through batches for holmes training:  42%|████▏     | 75/180 [00:02<00:01, 57.38it/s]going through batches for holmes training:  45%|████▌     | 81/180 [00:02<00:01, 58.01it/s]going through batches for holmes training:  48%|████▊     | 87/180 [00:02<00:01, 58.12it/s]going through batches for holmes training:  52%|█████▏    | 93/180 [00:02<00:01, 58.56it/s]going through batches for holmes training:  55%|█████▌    | 99/180 [00:02<00:01, 58.90it/s]going through batches for holmes training:  58%|█████▊    | 105/180 [00:02<00:01, 59.02it/s]going through batches for holmes training:  62%|██████▏   | 111/180 [00:02<00:01, 59.05it/s]going through batches for holmes training:  65%|██████▌   | 117/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  68%|██████▊   | 123/180 [00:02<00:00, 59.31it/s]going through batches for holmes training:  72%|███████▏  | 129/180 [00:03<00:00, 59.32it/s]going through batches for holmes training:  75%|███████▌  | 135/180 [00:03<00:00, 59.35it/s]going through batches for holmes training:  78%|███████▊  | 141/180 [00:03<00:00, 59.48it/s]going through batches for holmes training:  82%|████████▏ | 147/180 [00:03<00:00, 59.39it/s]going through batches for holmes training:  85%|████████▌ | 153/180 [00:03<00:00, 59.28it/s]going through batches for holmes training:  88%|████████▊ | 159/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  92%|█████████▏| 165/180 [00:03<00:00, 59.18it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.40it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.56it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.88it/s]
epoch 72: train_loss = 0.005
72: {'Accuracy': 0.9887, 'Precision': 0.989, 'Recall': 0.9887, 'F1-score': 0.9887}
epoch: 73
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:47,  1.07it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:01<00:23,  7.51it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 15.50it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 24.73it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 32.77it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 38.67it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 43.59it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.66it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.84it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.28it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.05it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.35it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.31it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.94it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.45it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.85it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.06it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.22it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.39it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.45it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.50it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.56it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.53it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.68it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.71it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.99it/s]
epoch 73: train_loss = 0.005
73: {'Accuracy': 0.9876, 'Precision': 0.988, 'Recall': 0.9876, 'F1-score': 0.9877}
epoch: 74
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:43,  1.10it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.98it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 17.16it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 26.24it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 33.14it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 39.14it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.01it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.85it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.86it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.23it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 54.95it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.20it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.19it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.81it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.21it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.44it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.71it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.92it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 58.85it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 58.96it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.08it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.12it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 58.92it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.05it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.19it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.27it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.30it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 58.89it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.14it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.35it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.35it/s]
epoch 74: train_loss = 0.008
74: {'Accuracy': 0.99, 'Precision': 0.9906, 'Recall': 0.99, 'F1-score': 0.9901}
epoch: 75
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:40,  1.12it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:22,  7.80it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:10, 15.91it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 23.84it/s]going through batches for holmes training:  13%|█▎        | 24/180 [00:01<00:04, 31.35it/s]going through batches for holmes training:  17%|█▋        | 30/180 [00:01<00:03, 37.81it/s]going through batches for holmes training:  20%|██        | 36/180 [00:01<00:03, 43.10it/s]going through batches for holmes training:  23%|██▎       | 42/180 [00:01<00:02, 47.35it/s]going through batches for holmes training:  27%|██▋       | 48/180 [00:01<00:02, 50.70it/s]going through batches for holmes training:  30%|███       | 54/180 [00:01<00:02, 53.15it/s]going through batches for holmes training:  33%|███▎      | 60/180 [00:01<00:02, 54.98it/s]going through batches for holmes training:  37%|███▋      | 66/180 [00:02<00:02, 56.33it/s]going through batches for holmes training:  40%|████      | 72/180 [00:02<00:01, 56.51it/s]going through batches for holmes training:  43%|████▎     | 78/180 [00:02<00:01, 57.39it/s]going through batches for holmes training:  47%|████▋     | 84/180 [00:02<00:01, 58.04it/s]going through batches for holmes training:  50%|█████     | 90/180 [00:02<00:01, 58.52it/s]going through batches for holmes training:  53%|█████▎    | 96/180 [00:02<00:01, 58.80it/s]going through batches for holmes training:  57%|█████▋    | 102/180 [00:02<00:01, 59.09it/s]going through batches for holmes training:  60%|██████    | 108/180 [00:02<00:01, 59.28it/s]going through batches for holmes training:  63%|██████▎   | 114/180 [00:02<00:01, 59.34it/s]going through batches for holmes training:  67%|██████▋   | 120/180 [00:02<00:01, 59.43it/s]going through batches for holmes training:  70%|███████   | 126/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  73%|███████▎  | 132/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  77%|███████▋  | 138/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  80%|████████  | 144/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  83%|████████▎ | 150/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  87%|████████▋ | 156/180 [00:03<00:00, 59.59it/s]going through batches for holmes training:  90%|█████████ | 162/180 [00:03<00:00, 59.32it/s]going through batches for holmes training:  93%|█████████▎| 168/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  97%|█████████▋| 174/180 [00:03<00:00, 59.59it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 59.68it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.26it/s]
epoch 75: train_loss = 0.006
75: {'Accuracy': 0.9887, 'Precision': 0.9889, 'Recall': 0.9887, 'F1-score': 0.9887}
epoch: 76
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:26,  1.22it/s]going through batches for holmes training:   3%|▎         | 6/180 [00:00<00:20,  8.40it/s]going through batches for holmes training:   7%|▋         | 12/180 [00:01<00:09, 16.99it/s]going through batches for holmes training:  11%|█         | 19/180 [00:01<00:06, 26.58it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 34.62it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 40.25it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 44.94it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 48.77it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.67it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.90it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.51it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:01<00:01, 56.71it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.61it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 58.21it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.61it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.92it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.22it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.37it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.49it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.56it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:02<00:00, 59.58it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.61it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.58it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.62it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  95%|█████████▌| 171/180 [00:03<00:00, 59.68it/s]going through batches for holmes training:  98%|█████████▊| 177/180 [00:03<00:00, 59.77it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.16it/s]
epoch 76: train_loss = 0.005
76: {'Accuracy': 0.9904, 'Precision': 0.9908, 'Recall': 0.9904, 'F1-score': 0.9905}
epoch: 77
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:41,  1.11it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:19,  8.99it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:09, 16.82it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 25.86it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 32.77it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 38.82it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 43.91it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.99it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 51.08it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 53.48it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:01<00:02, 55.20it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:01, 56.50it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 57.39it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.96it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 58.49it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.86it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 59.07it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 59.27it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 59.36it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.40it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:02<00:00, 59.45it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.51it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.55it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.65it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.69it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.70it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.66it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.54it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.66it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.71it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 45.46it/s]
epoch 77: train_loss = 0.007
77: {'Accuracy': 0.9849, 'Precision': 0.9853, 'Recall': 0.9849, 'F1-score': 0.9849}
epoch: 78
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:28,  1.21it/s]going through batches for holmes training:   3%|▎         | 5/180 [00:00<00:25,  6.88it/s]going through batches for holmes training:   6%|▌         | 11/180 [00:01<00:10, 15.95it/s]going through batches for holmes training:  10%|█         | 18/180 [00:01<00:06, 25.83it/s]going through batches for holmes training:  14%|█▍        | 25/180 [00:01<00:04, 34.15it/s]going through batches for holmes training:  17%|█▋        | 31/180 [00:01<00:03, 39.95it/s]going through batches for holmes training:  21%|██        | 37/180 [00:01<00:03, 44.75it/s]going through batches for holmes training:  24%|██▍       | 43/180 [00:01<00:02, 48.59it/s]going through batches for holmes training:  27%|██▋       | 49/180 [00:01<00:02, 51.55it/s]going through batches for holmes training:  31%|███       | 55/180 [00:01<00:02, 53.77it/s]going through batches for holmes training:  34%|███▍      | 61/180 [00:01<00:02, 55.37it/s]going through batches for holmes training:  37%|███▋      | 67/180 [00:01<00:01, 56.53it/s]going through batches for holmes training:  41%|████      | 73/180 [00:02<00:01, 57.39it/s]going through batches for holmes training:  44%|████▍     | 79/180 [00:02<00:01, 58.06it/s]going through batches for holmes training:  47%|████▋     | 85/180 [00:02<00:01, 58.52it/s]going through batches for holmes training:  51%|█████     | 91/180 [00:02<00:01, 58.81it/s]going through batches for holmes training:  54%|█████▍    | 97/180 [00:02<00:01, 59.00it/s]going through batches for holmes training:  57%|█████▋    | 103/180 [00:02<00:01, 59.19it/s]going through batches for holmes training:  61%|██████    | 109/180 [00:02<00:01, 59.33it/s]going through batches for holmes training:  64%|██████▍   | 115/180 [00:02<00:01, 59.39it/s]going through batches for holmes training:  67%|██████▋   | 121/180 [00:02<00:00, 59.45it/s]going through batches for holmes training:  71%|███████   | 127/180 [00:02<00:00, 59.47it/s]going through batches for holmes training:  74%|███████▍  | 133/180 [00:03<00:00, 59.44it/s]going through batches for holmes training:  77%|███████▋  | 139/180 [00:03<00:00, 59.49it/s]going through batches for holmes training:  81%|████████  | 145/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  84%|████████▍ | 151/180 [00:03<00:00, 59.50it/s]going through batches for holmes training:  87%|████████▋ | 157/180 [00:03<00:00, 59.52it/s]going through batches for holmes training:  91%|█████████ | 163/180 [00:03<00:00, 59.34it/s]going through batches for holmes training:  94%|█████████▍| 169/180 [00:03<00:00, 59.47it/s]going through batches for holmes training:  97%|█████████▋| 175/180 [00:03<00:00, 59.54it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:03<00:00, 46.13it/s]
epoch 78: train_loss = 0.016
78: {'Accuracy': 0.9893, 'Precision': 0.9895, 'Recall': 0.9893, 'F1-score': 0.9894}
epoch: 79
going through batches for holmes training:   0%|          | 0/180 [00:00<?, ?it/s]going through batches for holmes training:   1%|          | 1/180 [00:00<02:50,  1.05it/s]going through batches for holmes training:   4%|▍         | 7/180 [00:01<00:20,  8.53it/s]going through batches for holmes training:   7%|▋         | 13/180 [00:01<00:10, 16.29it/s]going through batches for holmes training:  11%|█         | 20/180 [00:01<00:06, 25.17it/s]going through batches for holmes training:  14%|█▍        | 26/180 [00:01<00:04, 31.98it/s]going through batches for holmes training:  18%|█▊        | 32/180 [00:01<00:03, 38.05it/s]going through batches for holmes training:  21%|██        | 38/180 [00:01<00:03, 43.19it/s]going through batches for holmes training:  24%|██▍       | 44/180 [00:01<00:02, 47.32it/s]going through batches for holmes training:  28%|██▊       | 50/180 [00:01<00:02, 50.52it/s]going through batches for holmes training:  31%|███       | 56/180 [00:01<00:02, 52.99it/s]going through batches for holmes training:  34%|███▍      | 62/180 [00:02<00:02, 53.95it/s]going through batches for holmes training:  38%|███▊      | 68/180 [00:02<00:02, 55.33it/s]going through batches for holmes training:  41%|████      | 74/180 [00:02<00:01, 56.47it/s]going through batches for holmes training:  44%|████▍     | 80/180 [00:02<00:01, 57.29it/s]going through batches for holmes training:  48%|████▊     | 86/180 [00:02<00:01, 57.86it/s]going through batches for holmes training:  51%|█████     | 92/180 [00:02<00:01, 58.35it/s]going through batches for holmes training:  54%|█████▍    | 98/180 [00:02<00:01, 58.64it/s]going through batches for holmes training:  58%|█████▊    | 104/180 [00:02<00:01, 58.82it/s]going through batches for holmes training:  61%|██████    | 110/180 [00:02<00:01, 58.99it/s]going through batches for holmes training:  64%|██████▍   | 116/180 [00:02<00:01, 59.11it/s]going through batches for holmes training:  68%|██████▊   | 122/180 [00:03<00:00, 59.18it/s]going through batches for holmes training:  71%|███████   | 128/180 [00:03<00:00, 59.22it/s]going through batches for holmes training:  74%|███████▍  | 134/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  78%|███████▊  | 140/180 [00:03<00:00, 59.29it/s]going through batches for holmes training:  81%|████████  | 146/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  84%|████████▍ | 152/180 [00:03<00:00, 59.25it/s]going through batches for holmes training:  88%|████████▊ | 158/180 [00:03<00:00, 59.28it/s]going through batches for holmes training:  91%|█████████ | 164/180 [00:03<00:00, 59.09it/s]going through batches for holmes training:  94%|█████████▍| 170/180 [00:03<00:00, 59.24it/s]going through batches for holmes training:  98%|█████████▊| 176/180 [00:03<00:00, 59.37it/s]going through batches for holmes training: 100%|██████████| 180/180 [00:04<00:00, 44.67it/s]
epoch 79: train_loss = 0.006
79: {'Accuracy': 0.99, 'Precision': 0.9903, 'Recall': 0.99, 'F1-score': 0.9901}
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Valid: X=torch.Size([4500, 1, 2, 1000]), y=torch.Size([4500])
num_classes: 45
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:22<16:31, 22.53s/it]  4%|▍         | 2/45 [00:44<16:02, 22.38s/it]  7%|▋         | 3/45 [01:06<15:34, 22.24s/it]  9%|▉         | 4/45 [01:29<15:14, 22.30s/it] 11%|█         | 5/45 [01:51<14:50, 22.25s/it] 13%|█▎        | 6/45 [02:13<14:28, 22.26s/it] 16%|█▌        | 7/45 [02:36<14:06, 22.27s/it] 18%|█▊        | 8/45 [02:58<13:45, 22.31s/it] 20%|██        | 9/45 [03:20<13:22, 22.29s/it] 22%|██▏       | 10/45 [03:43<13:01, 22.32s/it] 24%|██▍       | 11/45 [04:05<12:39, 22.33s/it] 27%|██▋       | 12/45 [04:27<12:14, 22.27s/it] 29%|██▉       | 13/45 [04:49<11:51, 22.25s/it] 31%|███       | 14/45 [05:11<11:29, 22.25s/it] 33%|███▎      | 15/45 [05:34<11:09, 22.31s/it] 36%|███▌      | 16/45 [05:56<10:46, 22.29s/it] 38%|███▊      | 17/45 [06:19<10:24, 22.31s/it] 40%|████      | 18/45 [06:41<10:01, 22.27s/it] 42%|████▏     | 19/45 [07:03<09:38, 22.26s/it] 44%|████▍     | 20/45 [07:25<09:16, 22.27s/it] 47%|████▋     | 21/45 [07:48<08:54, 22.28s/it] 49%|████▉     | 22/45 [08:10<08:32, 22.29s/it] 51%|█████     | 23/45 [08:32<08:11, 22.32s/it] 53%|█████▎    | 24/45 [08:55<07:48, 22.31s/it] 56%|█████▌    | 25/45 [09:17<07:25, 22.30s/it] 58%|█████▊    | 26/45 [09:39<07:03, 22.30s/it] 60%|██████    | 27/45 [10:02<06:41, 22.33s/it] 62%|██████▏   | 28/45 [10:24<06:19, 22.33s/it] 64%|██████▍   | 29/45 [10:46<05:57, 22.33s/it] 67%|██████▋   | 30/45 [11:09<05:34, 22.33s/it] 69%|██████▉   | 31/45 [11:31<05:12, 22.32s/it] 71%|███████   | 32/45 [11:53<04:50, 22.34s/it] 73%|███████▎  | 33/45 [12:15<04:27, 22.33s/it] 76%|███████▌  | 34/45 [12:38<04:05, 22.33s/it] 78%|███████▊  | 35/45 [13:00<03:43, 22.36s/it] 80%|████████  | 36/45 [13:22<03:20, 22.31s/it] 82%|████████▏ | 37/45 [13:45<02:58, 22.32s/it] 84%|████████▍ | 38/45 [14:07<02:36, 22.34s/it] 87%|████████▋ | 39/45 [14:29<02:14, 22.33s/it] 89%|████████▉ | 40/45 [14:52<01:51, 22.33s/it] 91%|█████████ | 41/45 [15:14<01:29, 22.33s/it] 93%|█████████▎| 42/45 [15:36<01:07, 22.34s/it] 96%|█████████▌| 43/45 [15:59<00:44, 22.33s/it] 98%|█████████▊| 44/45 [16:21<00:22, 22.36s/it]100%|██████████| 45/45 [16:44<00:00, 22.34s/it]100%|██████████| 45/45 [16:44<00:00, 22.31s/it]
shape of attr_values: (45, 1000)
starting data augmentation script for train
  0%|          | 0/36000 [00:00<?, ?it/s]  2%|▏         | 816/36000 [00:00<00:04, 8154.64it/s]  5%|▍         | 1656/36000 [00:00<00:04, 8293.60it/s]  7%|▋         | 2524/36000 [00:00<00:03, 8468.20it/s]  9%|▉         | 3371/36000 [00:00<00:03, 8444.46it/s] 12%|█▏        | 4238/36000 [00:00<00:03, 8522.40it/s] 14%|█▍        | 5095/36000 [00:00<00:03, 8536.05it/s] 17%|█▋        | 5949/36000 [00:00<00:03, 8467.04it/s] 19%|█▉        | 6796/36000 [00:00<00:03, 8174.23it/s] 21%|██▏       | 7655/36000 [00:00<00:03, 8298.10it/s] 24%|██▎       | 8503/36000 [00:01<00:03, 8350.97it/s] 26%|██▌       | 9375/36000 [00:01<00:03, 8459.66it/s] 28%|██▊       | 10233/36000 [00:01<00:03, 8494.22it/s] 31%|███       | 11084/36000 [00:01<00:02, 8453.46it/s] 33%|███▎      | 11930/36000 [00:01<00:02, 8413.60it/s] 36%|███▌      | 12784/36000 [00:01<00:02, 8449.28it/s] 38%|███▊      | 13630/36000 [00:01<00:02, 8399.82it/s] 40%|████      | 14483/36000 [00:01<00:02, 8437.82it/s] 43%|████▎     | 15342/36000 [00:01<00:02, 8482.63it/s] 45%|████▍     | 16191/36000 [00:01<00:02, 8459.57it/s] 47%|████▋     | 17038/36000 [00:02<00:02, 8408.31it/s] 50%|████▉     | 17879/36000 [00:02<00:02, 8368.07it/s] 52%|█████▏    | 18716/36000 [00:02<00:02, 8228.84it/s] 54%|█████▍    | 19540/36000 [00:02<00:02, 8205.89it/s] 57%|█████▋    | 20397/36000 [00:02<00:01, 8311.03it/s] 59%|█████▉    | 21239/36000 [00:02<00:01, 8340.40it/s] 61%|██████▏   | 22074/36000 [00:02<00:01, 8319.00it/s] 64%|██████▎   | 22918/36000 [00:02<00:01, 8354.85it/s] 66%|██████▌   | 23760/36000 [00:02<00:01, 8372.86it/s] 68%|██████▊   | 24605/36000 [00:02<00:01, 8395.00it/s] 71%|███████   | 25451/36000 [00:03<00:01, 8412.59it/s] 73%|███████▎  | 26306/36000 [00:03<00:01, 8451.20it/s] 75%|███████▌  | 27152/36000 [00:03<00:01, 8379.24it/s] 78%|███████▊  | 27991/36000 [00:03<00:00, 8360.27it/s] 80%|████████  | 28828/36000 [00:03<00:00, 8189.42it/s] 82%|████████▏ | 29685/36000 [00:03<00:00, 8299.43it/s] 85%|████████▍ | 30525/36000 [00:03<00:00, 8328.93it/s] 87%|████████▋ | 31376/36000 [00:03<00:00, 8382.41it/s] 90%|████████▉ | 32222/36000 [00:03<00:00, 8403.95it/s] 92%|█████████▏| 33063/36000 [00:03<00:00, 8401.44it/s] 94%|█████████▍| 33913/36000 [00:04<00:00, 8428.59it/s] 97%|█████████▋| 34758/36000 [00:04<00:00, 8432.36it/s] 99%|█████████▉| 35602/36000 [00:04<00:00, 8429.24it/s]100%|██████████| 36000/36000 [00:04<00:00, 8383.24it/s]

Size Analysis:
--------------
Total raw size: 8.05 GB
Estimated compressed size: 4.02 GB
Overhead: 1.50 KB

Size per array:
X: 8.05 GB
y: 843.75 KB
Generate /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/aug_train.npz done.
finished data augmentation script for train
starting data augmentation script for valid
  0%|          | 0/4500 [00:00<?, ?it/s] 17%|█▋        | 782/4500 [00:00<00:00, 7812.80it/s] 35%|███▌      | 1593/4500 [00:00<00:00, 7986.46it/s] 53%|█████▎    | 2397/4500 [00:00<00:00, 8010.18it/s] 71%|███████▏  | 3212/4500 [00:00<00:00, 8062.85it/s] 89%|████████▉ | 4022/4500 [00:00<00:00, 8075.18it/s]100%|██████████| 4500/4500 [00:00<00:00, 8054.55it/s]

Size Analysis:
--------------
Total raw size: 1.01 GB
Estimated compressed size: 515.04 MB
Overhead: 1.50 KB

Size per array:
X: 1.01 GB
y: 105.47 KB
Generate /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/aug_valid.npz done.
finished data augmentation script for valid
starting gen taf script for aug_train
  0%|          | 0/108000 [00:00<?, ?it/s]  0%|          | 413/108000 [00:00<00:26, 4116.65it/s]  1%|          | 825/108000 [00:00<01:55, 931.02it/s]   1%|          | 1031/108000 [00:01<01:58, 900.43it/s]  1%|          | 1181/108000 [00:01<01:56, 919.68it/s]  1%|          | 1311/108000 [00:01<02:03, 866.49it/s]  1%|▏         | 1420/108000 [00:01<01:59, 890.54it/s]  1%|▏         | 1526/108000 [00:01<02:08, 831.61it/s]  2%|▏         | 1649/108000 [00:01<01:56, 911.14it/s]  2%|▏         | 1752/108000 [00:01<01:58, 897.64it/s]  2%|▏         | 1851/108000 [00:01<01:55, 919.06it/s]  2%|▏         | 1949/108000 [00:02<02:02, 866.28it/s]  2%|▏         | 2040/108000 [00:02<02:11, 808.31it/s]  2%|▏         | 2124/108000 [00:02<02:16, 775.69it/s]  2%|▏         | 2204/108000 [00:02<02:16, 774.11it/s]  2%|▏         | 2283/108000 [00:02<02:20, 754.57it/s]  2%|▏         | 2381/108000 [00:02<02:14, 783.65it/s]  2%|▏         | 2460/108000 [00:02<02:22, 740.77it/s]  2%|▏         | 2535/108000 [00:02<02:39, 661.20it/s]  2%|▏         | 2603/108000 [00:03<02:39, 662.10it/s]  2%|▏         | 2682/108000 [00:03<02:33, 685.86it/s]  3%|▎         | 2752/108000 [00:03<02:35, 677.02it/s]  3%|▎         | 2821/108000 [00:03<02:36, 672.23it/s]  3%|▎         | 2889/108000 [00:03<02:39, 660.74it/s]  3%|▎         | 2971/108000 [00:03<02:30, 697.50it/s]  3%|▎         | 3042/108000 [00:03<02:32, 688.11it/s]  3%|▎         | 3117/108000 [00:03<02:31, 691.79it/s]  3%|▎         | 3206/108000 [00:03<02:21, 741.70it/s]  3%|▎         | 3281/108000 [00:03<02:23, 729.96it/s]  3%|▎         | 3355/108000 [00:04<02:45, 634.10it/s]  3%|▎         | 3429/108000 [00:04<02:41, 647.25it/s]  3%|▎         | 3496/108000 [00:04<02:44, 636.87it/s]  3%|▎         | 3588/108000 [00:04<02:26, 710.95it/s]  3%|▎         | 3664/108000 [00:04<02:25, 715.13it/s]  3%|▎         | 3751/108000 [00:04<02:20, 740.05it/s]  4%|▎         | 3826/108000 [00:04<02:20, 739.61it/s]  4%|▎         | 3901/108000 [00:04<02:23, 723.79it/s]  4%|▎         | 3974/108000 [00:05<02:34, 675.49it/s]  4%|▎         | 4043/108000 [00:05<02:37, 660.39it/s]  4%|▍         | 4110/108000 [00:05<02:41, 644.21it/s]  4%|▍         | 4177/108000 [00:05<02:40, 648.82it/s]  4%|▍         | 4249/108000 [00:05<02:35, 666.16it/s]  4%|▍         | 4323/108000 [00:05<02:31, 685.74it/s]  4%|▍         | 4392/108000 [00:05<02:35, 666.92it/s]  4%|▍         | 4459/108000 [00:05<02:36, 662.94it/s]  4%|▍         | 4548/108000 [00:05<02:22, 726.02it/s]  4%|▍         | 4621/108000 [00:05<02:31, 683.91it/s]  4%|▍         | 4691/108000 [00:06<02:31, 681.48it/s]  4%|▍         | 4776/108000 [00:06<02:21, 727.52it/s]  5%|▍         | 4884/108000 [00:06<02:05, 824.60it/s]  5%|▍         | 4968/108000 [00:06<02:06, 815.04it/s]  5%|▍         | 5082/108000 [00:06<01:53, 904.02it/s]  5%|▍         | 5186/108000 [00:06<01:49, 935.41it/s]  5%|▍         | 5296/108000 [00:06<01:44, 982.85it/s]  5%|▍         | 5395/108000 [00:06<01:45, 973.47it/s]  5%|▌         | 5515/108000 [00:06<01:39, 1029.47it/s]  5%|▌         | 5630/108000 [00:06<01:36, 1062.89it/s]  5%|▌         | 5737/108000 [00:07<01:46, 963.72it/s]   5%|▌         | 5860/108000 [00:07<01:38, 1035.64it/s]  6%|▌         | 5974/108000 [00:07<01:35, 1065.13it/s]  6%|▌         | 6083/108000 [00:07<01:36, 1056.46it/s]  6%|▌         | 6190/108000 [00:07<01:36, 1058.19it/s]  6%|▌         | 6301/108000 [00:07<01:36, 1057.34it/s]  6%|▌         | 6434/108000 [00:07<01:29, 1134.88it/s]  6%|▌         | 6549/108000 [00:07<01:32, 1097.74it/s]  6%|▌         | 6660/108000 [00:07<01:35, 1066.04it/s]  6%|▋         | 6768/108000 [00:08<01:37, 1041.59it/s]  6%|▋         | 6873/108000 [00:08<01:42, 987.07it/s]   6%|▋         | 6973/108000 [00:08<01:48, 935.07it/s]  7%|▋         | 7068/108000 [00:08<01:48, 926.22it/s]  7%|▋         | 7170/108000 [00:08<01:46, 946.72it/s]  7%|▋         | 7266/108000 [00:08<02:19, 723.35it/s]  7%|▋         | 7347/108000 [00:08<02:43, 614.02it/s]  7%|▋         | 7416/108000 [00:09<03:03, 549.36it/s]  7%|▋         | 7477/108000 [00:09<03:18, 505.15it/s]  7%|▋         | 7532/108000 [00:09<03:42, 451.84it/s]  7%|▋         | 7581/108000 [00:09<03:45, 445.00it/s]  7%|▋         | 7628/108000 [00:09<03:58, 420.00it/s]  7%|▋         | 7686/108000 [00:09<03:42, 450.29it/s]  7%|▋         | 7733/108000 [00:09<03:53, 429.13it/s]  7%|▋         | 7780/108000 [00:10<03:52, 431.67it/s]  7%|▋         | 7824/108000 [00:10<04:19, 385.51it/s]  7%|▋         | 7874/108000 [00:10<04:02, 412.74it/s]  7%|▋         | 7917/108000 [00:10<04:09, 401.87it/s]  7%|▋         | 7959/108000 [00:10<04:07, 403.94it/s]  7%|▋         | 8009/108000 [00:10<03:58, 419.72it/s]  7%|▋         | 8052/108000 [00:10<04:10, 399.71it/s]  7%|▋         | 8093/108000 [00:10<04:18, 386.56it/s]  8%|▊         | 8132/108000 [00:10<04:33, 364.76it/s]  8%|▊         | 8175/108000 [00:11<04:21, 381.94it/s]  8%|▊         | 8214/108000 [00:11<04:25, 375.20it/s]  8%|▊         | 8262/108000 [00:11<04:16, 388.93it/s]  8%|▊         | 8311/108000 [00:11<04:12, 394.27it/s]  8%|▊         | 8351/108000 [00:11<04:28, 371.77it/s]  8%|▊         | 8404/108000 [00:11<04:02, 411.53it/s]  8%|▊         | 8446/108000 [00:11<04:42, 352.32it/s]  8%|▊         | 8489/108000 [00:11<04:28, 370.74it/s]  8%|▊         | 8533/108000 [00:11<04:16, 387.09it/s]  8%|▊         | 8573/108000 [00:12<04:15, 389.66it/s]  8%|▊         | 8613/108000 [00:12<04:14, 390.40it/s]  8%|▊         | 8653/108000 [00:12<04:36, 359.58it/s]  8%|▊         | 8704/108000 [00:12<04:08, 399.36it/s]  8%|▊         | 8745/108000 [00:12<04:21, 379.25it/s]  8%|▊         | 8784/108000 [00:12<04:20, 380.90it/s]  8%|▊         | 8823/108000 [00:12<04:27, 370.15it/s]  8%|▊         | 8870/108000 [00:12<04:09, 397.82it/s]  8%|▊         | 8921/108000 [00:12<04:11, 394.21it/s]  8%|▊         | 8972/108000 [00:13<03:54, 422.11it/s]  8%|▊         | 9015/108000 [00:13<03:58, 415.80it/s]  8%|▊         | 9057/108000 [00:13<03:58, 415.23it/s]  8%|▊         | 9099/108000 [00:13<04:07, 399.27it/s]  8%|▊         | 9142/108000 [00:13<04:06, 400.25it/s]  9%|▊         | 9183/108000 [00:13<04:23, 374.48it/s]  9%|▊         | 9221/108000 [00:13<04:30, 364.59it/s]  9%|▊         | 9258/108000 [00:13<04:37, 355.96it/s]  9%|▊         | 9294/108000 [00:13<04:36, 356.86it/s]  9%|▊         | 9332/108000 [00:14<04:41, 349.91it/s]  9%|▊         | 9372/108000 [00:14<04:38, 354.71it/s]  9%|▊         | 9431/108000 [00:14<03:58, 413.48it/s]  9%|▉         | 9473/108000 [00:14<04:00, 410.03it/s]  9%|▉         | 9515/108000 [00:14<04:19, 379.30it/s]  9%|▉         | 9570/108000 [00:14<03:53, 421.77it/s]  9%|▉         | 9621/108000 [00:14<03:43, 440.14it/s]  9%|▉         | 9717/108000 [00:14<02:49, 581.47it/s]  9%|▉         | 9790/108000 [00:14<02:37, 623.61it/s]  9%|▉         | 9881/108000 [00:15<02:19, 703.39it/s]  9%|▉         | 9991/108000 [00:15<02:00, 814.15it/s]  9%|▉         | 10080/108000 [00:15<02:00, 809.72it/s]  9%|▉         | 10171/108000 [00:15<01:56, 838.23it/s]  9%|▉         | 10256/108000 [00:15<02:03, 791.36it/s] 10%|▉         | 10337/108000 [00:15<02:03, 793.27it/s] 10%|▉         | 10417/108000 [00:15<02:03, 787.58it/s] 10%|▉         | 10527/108000 [00:15<01:51, 877.36it/s] 10%|▉         | 10621/108000 [00:15<01:49, 888.84it/s] 10%|▉         | 10711/108000 [00:15<01:52, 864.97it/s] 10%|█         | 10809/108000 [00:16<01:48, 897.92it/s] 10%|█         | 10900/108000 [00:16<01:53, 857.77it/s] 10%|█         | 10994/108000 [00:16<01:50, 880.02it/s] 10%|█         | 11083/108000 [00:16<01:49, 882.03it/s] 10%|█         | 11172/108000 [00:16<01:50, 879.55it/s] 10%|█         | 11261/108000 [00:16<02:05, 771.67it/s] 11%|█         | 11355/108000 [00:16<01:58, 812.60it/s] 11%|█         | 11451/108000 [00:16<01:55, 835.31it/s] 11%|█         | 11567/108000 [00:16<01:44, 925.32it/s] 11%|█         | 11662/108000 [00:17<01:47, 900.25it/s] 11%|█         | 11754/108000 [00:17<01:46, 901.75it/s] 11%|█         | 11876/108000 [00:17<01:37, 981.54it/s] 11%|█         | 11975/108000 [00:17<01:51, 859.01it/s] 11%|█         | 12065/108000 [00:17<02:06, 758.57it/s] 11%|█         | 12145/108000 [00:17<02:30, 635.13it/s] 11%|█▏        | 12214/108000 [00:17<02:45, 579.05it/s] 11%|█▏        | 12286/108000 [00:18<02:40, 596.87it/s] 11%|█▏        | 12369/108000 [00:18<02:29, 641.03it/s] 12%|█▏        | 12437/108000 [00:18<02:30, 633.66it/s] 12%|█▏        | 12503/108000 [00:18<02:36, 609.02it/s] 12%|█▏        | 12566/108000 [00:18<02:47, 568.61it/s] 12%|█▏        | 12625/108000 [00:18<02:56, 541.88it/s] 12%|█▏        | 12691/108000 [00:18<02:50, 559.63it/s] 12%|█▏        | 12748/108000 [00:18<02:55, 542.25it/s] 12%|█▏        | 12803/108000 [00:18<02:56, 538.84it/s] 12%|█▏        | 12869/108000 [00:19<02:47, 568.38it/s] 12%|█▏        | 12931/108000 [00:19<02:43, 579.91it/s] 12%|█▏        | 12990/108000 [00:19<02:59, 529.49it/s] 12%|█▏        | 13046/108000 [00:19<03:01, 523.36it/s] 12%|█▏        | 13115/108000 [00:19<02:47, 568.15it/s] 12%|█▏        | 13173/108000 [00:19<02:53, 547.11it/s] 12%|█▏        | 13256/108000 [00:19<02:34, 614.25it/s] 12%|█▏        | 13319/108000 [00:19<02:35, 608.98it/s] 12%|█▏        | 13396/108000 [00:19<02:25, 652.08it/s] 12%|█▏        | 13462/108000 [00:20<02:31, 624.11it/s] 13%|█▎        | 13525/108000 [00:20<02:37, 599.89it/s] 13%|█▎        | 13586/108000 [00:20<02:39, 592.70it/s] 13%|█▎        | 13657/108000 [00:20<02:34, 608.89it/s] 13%|█▎        | 13722/108000 [00:20<02:32, 617.18it/s] 13%|█▎        | 13801/108000 [00:20<02:24, 650.24it/s] 13%|█▎        | 13872/108000 [00:20<02:21, 667.08it/s] 13%|█▎        | 13939/108000 [00:20<02:35, 604.82it/s] 13%|█▎        | 14003/108000 [00:20<02:38, 591.98it/s] 13%|█▎        | 14068/108000 [00:21<02:35, 605.36it/s] 13%|█▎        | 14147/108000 [00:21<02:27, 634.33it/s] 13%|█▎        | 14211/108000 [00:21<02:40, 584.23it/s] 13%|█▎        | 14271/108000 [00:21<02:40, 582.96it/s] 13%|█▎        | 14344/108000 [00:21<02:33, 610.64it/s] 13%|█▎        | 14425/108000 [00:21<02:21, 662.03it/s] 13%|█▎        | 14499/108000 [00:21<02:18, 673.06it/s] 14%|█▎        | 14582/108000 [00:21<02:10, 716.88it/s] 14%|█▎        | 14655/108000 [00:21<02:12, 705.64it/s] 14%|█▎        | 14726/108000 [00:22<02:13, 697.17it/s] 14%|█▎        | 14806/108000 [00:22<02:08, 725.99it/s] 14%|█▍        | 14879/108000 [00:22<02:10, 713.42it/s] 14%|█▍        | 14965/108000 [00:22<02:03, 755.71it/s] 14%|█▍        | 15041/108000 [00:22<02:06, 734.62it/s] 14%|█▍        | 15127/108000 [00:22<02:00, 769.81it/s] 14%|█▍        | 15217/108000 [00:22<01:54, 807.28it/s] 14%|█▍        | 15299/108000 [00:22<01:59, 776.45it/s] 14%|█▍        | 15396/108000 [00:22<01:51, 828.96it/s] 14%|█▍        | 15494/108000 [00:22<01:46, 872.22it/s] 14%|█▍        | 15582/108000 [00:23<01:47, 855.93it/s] 15%|█▍        | 15670/108000 [00:23<01:47, 862.84it/s] 15%|█▍        | 15766/108000 [00:23<01:44, 880.83it/s] 15%|█▍        | 15855/108000 [00:23<01:52, 819.92it/s] 15%|█▍        | 15942/108000 [00:23<01:50, 829.91it/s] 15%|█▍        | 16051/108000 [00:23<01:43, 887.12it/s] 15%|█▍        | 16169/108000 [00:23<01:34, 970.06it/s] 15%|█▌        | 16267/108000 [00:23<01:43, 884.50it/s] 15%|█▌        | 16358/108000 [00:23<01:43, 889.04it/s] 15%|█▌        | 16449/108000 [00:24<01:46, 861.19it/s] 15%|█▌        | 16555/108000 [00:24<01:40, 914.40it/s] 15%|█▌        | 16648/108000 [00:24<01:46, 855.96it/s] 15%|█▌        | 16735/108000 [00:24<01:51, 819.33it/s] 16%|█▌        | 16818/108000 [00:24<01:58, 770.39it/s] 16%|█▌        | 16897/108000 [00:24<02:12, 689.57it/s] 16%|█▌        | 16977/108000 [00:24<02:08, 709.05it/s] 16%|█▌        | 17050/108000 [00:24<02:19, 651.65it/s] 16%|█▌        | 17117/108000 [00:25<02:23, 634.76it/s] 16%|█▌        | 17182/108000 [00:25<02:35, 584.55it/s] 16%|█▌        | 17242/108000 [00:25<02:45, 547.74it/s] 16%|█▌        | 17298/108000 [00:25<02:51, 528.16it/s] 16%|█▌        | 17352/108000 [00:25<03:10, 475.07it/s] 16%|█▌        | 17401/108000 [00:25<03:09, 478.22it/s] 16%|█▌        | 17450/108000 [00:25<03:10, 476.32it/s] 16%|█▌        | 17499/108000 [00:25<03:17, 459.00it/s] 16%|█▋        | 17559/108000 [00:25<03:07, 483.38it/s] 16%|█▋        | 17608/108000 [00:26<03:18, 454.67it/s] 16%|█▋        | 17654/108000 [00:26<03:18, 454.37it/s] 16%|█▋        | 17715/108000 [00:26<03:05, 485.75it/s] 16%|█▋        | 17774/108000 [00:26<02:56, 511.84it/s] 17%|█▋        | 17827/108000 [00:26<02:57, 508.67it/s] 17%|█▋        | 17879/108000 [00:26<03:02, 494.14it/s] 17%|█▋        | 17929/108000 [00:26<03:04, 487.39it/s] 17%|█▋        | 17982/108000 [00:26<03:00, 497.60it/s] 17%|█▋        | 18037/108000 [00:26<03:00, 497.22it/s] 17%|█▋        | 18087/108000 [00:27<03:02, 493.31it/s] 17%|█▋        | 18137/108000 [00:27<03:05, 485.33it/s] 17%|█▋        | 18186/108000 [00:27<03:14, 462.85it/s] 17%|█▋        | 18233/108000 [00:27<03:20, 448.55it/s] 17%|█▋        | 18295/108000 [00:27<03:02, 490.54it/s] 17%|█▋        | 18348/108000 [00:27<02:58, 501.21it/s] 17%|█▋        | 18402/108000 [00:27<02:57, 504.86it/s] 17%|█▋        | 18453/108000 [00:27<03:04, 484.82it/s] 17%|█▋        | 18502/108000 [00:27<03:08, 474.79it/s] 17%|█▋        | 18560/108000 [00:28<03:01, 493.01it/s] 17%|█▋        | 18610/108000 [00:28<03:13, 463.15it/s] 17%|█▋        | 18666/108000 [00:28<03:10, 469.52it/s] 17%|█▋        | 18718/108000 [00:28<03:12, 463.07it/s] 17%|█▋        | 18771/108000 [00:28<03:05, 480.94it/s] 17%|█▋        | 18829/108000 [00:28<02:55, 508.60it/s] 17%|█▋        | 18881/108000 [00:28<03:00, 495.09it/s] 18%|█▊        | 18937/108000 [00:28<02:57, 502.35it/s] 18%|█▊        | 18996/108000 [00:28<02:52, 516.71it/s] 18%|█▊        | 19048/108000 [00:29<02:54, 510.45it/s] 18%|█▊        | 19102/108000 [00:29<02:51, 517.57it/s] 18%|█▊        | 19154/108000 [00:29<03:06, 476.97it/s] 18%|█▊        | 19205/108000 [00:29<03:05, 479.80it/s] 18%|█▊        | 19266/108000 [00:29<02:53, 510.23it/s] 18%|█▊        | 19346/108000 [00:29<02:30, 589.66it/s] 18%|█▊        | 19426/108000 [00:29<02:16, 650.05it/s] 18%|█▊        | 19522/108000 [00:29<01:59, 737.42it/s] 18%|█▊        | 19601/108000 [00:29<01:57, 751.38it/s] 18%|█▊        | 19677/108000 [00:29<02:02, 722.90it/s] 18%|█▊        | 19750/108000 [00:30<02:04, 708.65it/s] 18%|█▊        | 19846/108000 [00:30<01:56, 757.97it/s] 18%|█▊        | 19926/108000 [00:30<01:54, 769.52it/s] 19%|█▊        | 20006/108000 [00:30<01:54, 770.00it/s] 19%|█▊        | 20087/108000 [00:30<01:53, 775.58it/s] 19%|█▊        | 20169/108000 [00:30<01:52, 778.43it/s] 19%|█▊        | 20247/108000 [00:30<01:53, 770.63it/s] 19%|█▉        | 20333/108000 [00:30<01:51, 787.52it/s] 19%|█▉        | 20434/108000 [00:30<01:45, 833.02it/s] 19%|█▉        | 20518/108000 [00:31<01:51, 786.66it/s] 19%|█▉        | 20598/108000 [00:31<01:58, 735.16it/s] 19%|█▉        | 20673/108000 [00:31<02:05, 693.11it/s] 19%|█▉        | 20757/108000 [00:31<02:00, 723.34it/s] 19%|█▉        | 20850/108000 [00:31<01:52, 775.46it/s] 19%|█▉        | 20929/108000 [00:31<02:03, 704.09it/s] 19%|█▉        | 21002/108000 [00:31<02:05, 693.07it/s] 20%|█▉        | 21084/108000 [00:31<02:00, 720.49it/s] 20%|█▉        | 21165/108000 [00:31<01:58, 734.55it/s] 20%|█▉        | 21246/108000 [00:32<01:55, 751.89it/s] 20%|█▉        | 21322/108000 [00:32<01:58, 732.23it/s] 20%|█▉        | 21396/108000 [00:32<01:59, 722.94it/s] 20%|█▉        | 21469/108000 [00:32<02:10, 661.06it/s] 20%|█▉        | 21544/108000 [00:32<02:06, 684.02it/s] 20%|██        | 21614/108000 [00:32<02:16, 634.54it/s] 20%|██        | 21679/108000 [00:32<02:27, 586.33it/s] 20%|██        | 21739/108000 [00:32<02:26, 588.73it/s] 20%|██        | 21799/108000 [00:32<02:26, 587.57it/s] 20%|██        | 21873/108000 [00:33<02:17, 626.32it/s] 20%|██        | 21937/108000 [00:33<02:28, 578.13it/s] 20%|██        | 21996/108000 [00:33<02:43, 526.57it/s] 20%|██        | 22075/108000 [00:33<02:24, 594.32it/s] 21%|██        | 22162/108000 [00:33<02:08, 666.41it/s] 21%|██        | 22231/108000 [00:33<02:19, 614.38it/s] 21%|██        | 22303/108000 [00:33<02:15, 634.12it/s] 21%|██        | 22374/108000 [00:33<02:10, 654.60it/s] 21%|██        | 22442/108000 [00:34<02:10, 653.99it/s] 21%|██        | 22514/108000 [00:34<02:09, 658.79it/s] 21%|██        | 22592/108000 [00:34<02:03, 692.94it/s] 21%|██        | 22667/108000 [00:34<02:01, 702.49it/s] 21%|██        | 22738/108000 [00:34<02:10, 650.96it/s] 21%|██        | 22805/108000 [00:34<02:19, 609.36it/s] 21%|██        | 22867/108000 [00:34<02:26, 582.22it/s] 21%|██        | 22926/108000 [00:34<02:29, 568.29it/s] 21%|██▏       | 22984/108000 [00:34<02:30, 566.21it/s] 21%|██▏       | 23070/108000 [00:35<02:11, 645.08it/s] 21%|██▏       | 23136/108000 [00:35<02:22, 595.77it/s] 21%|██▏       | 23203/108000 [00:35<02:19, 606.32it/s] 22%|██▏       | 23274/108000 [00:35<02:13, 634.20it/s] 22%|██▏       | 23343/108000 [00:35<02:12, 641.32it/s] 22%|██▏       | 23408/108000 [00:35<02:12, 640.41it/s] 22%|██▏       | 23476/108000 [00:35<02:15, 625.09it/s] 22%|██▏       | 23539/108000 [00:35<02:27, 572.48it/s] 22%|██▏       | 23605/108000 [00:35<02:23, 589.29it/s] 22%|██▏       | 23689/108000 [00:36<02:08, 653.73it/s] 22%|██▏       | 23756/108000 [00:36<02:17, 613.82it/s] 22%|██▏       | 23819/108000 [00:36<02:16, 617.95it/s] 22%|██▏       | 23882/108000 [00:36<02:21, 595.97it/s] 22%|██▏       | 23945/108000 [00:36<02:20, 597.08it/s] 22%|██▏       | 24006/108000 [00:36<02:25, 578.30it/s] 22%|██▏       | 24068/108000 [00:36<02:25, 575.54it/s] 22%|██▏       | 24126/108000 [00:36<02:41, 519.99it/s] 22%|██▏       | 24180/108000 [00:36<02:40, 521.90it/s] 22%|██▏       | 24234/108000 [00:37<02:41, 518.58it/s] 23%|██▎       | 24305/108000 [00:37<02:26, 570.93it/s] 23%|██▎       | 24363/108000 [00:37<02:32, 546.79it/s] 23%|██▎       | 24419/108000 [00:37<02:32, 547.13it/s] 23%|██▎       | 24484/108000 [00:37<02:28, 563.19it/s] 23%|██▎       | 24548/108000 [00:37<02:26, 569.55it/s] 23%|██▎       | 24606/108000 [00:37<02:38, 525.11it/s] 23%|██▎       | 24660/108000 [00:37<02:53, 481.52it/s] 23%|██▎       | 24712/108000 [00:37<02:50, 488.78it/s] 23%|██▎       | 24780/108000 [00:38<02:36, 532.04it/s] 23%|██▎       | 24840/108000 [00:38<02:31, 550.59it/s] 23%|██▎       | 24896/108000 [00:38<02:48, 494.07it/s] 23%|██▎       | 24949/108000 [00:38<02:44, 503.37it/s] 23%|██▎       | 25003/108000 [00:38<02:43, 508.06it/s] 23%|██▎       | 25066/108000 [00:38<02:35, 533.18it/s] 23%|██▎       | 25120/108000 [00:38<02:42, 508.56it/s] 23%|██▎       | 25183/108000 [00:38<02:36, 529.76it/s] 23%|██▎       | 25249/108000 [00:38<02:26, 565.70it/s] 23%|██▎       | 25307/108000 [00:39<02:49, 487.08it/s] 23%|██▎       | 25367/108000 [00:39<02:42, 507.87it/s] 24%|██▎       | 25420/108000 [00:39<02:48, 489.77it/s] 24%|██▎       | 25480/108000 [00:39<02:44, 500.97it/s] 24%|██▎       | 25538/108000 [00:39<02:43, 504.47it/s] 24%|██▎       | 25603/108000 [00:39<02:35, 529.95it/s] 24%|██▍       | 25657/108000 [00:39<02:37, 523.52it/s] 24%|██▍       | 25730/108000 [00:39<02:23, 573.78it/s] 24%|██▍       | 25788/108000 [00:40<02:40, 510.93it/s] 24%|██▍       | 25857/108000 [00:40<02:29, 549.66it/s] 24%|██▍       | 25914/108000 [00:40<02:30, 544.67it/s] 24%|██▍       | 25985/108000 [00:40<02:21, 579.48it/s] 24%|██▍       | 26044/108000 [00:40<02:42, 505.28it/s] 24%|██▍       | 26099/108000 [00:40<02:42, 503.96it/s] 24%|██▍       | 26151/108000 [00:40<02:58, 458.35it/s] 24%|██▍       | 26199/108000 [00:40<03:10, 430.42it/s] 24%|██▍       | 26259/108000 [00:40<02:55, 466.20it/s] 24%|██▍       | 26317/108000 [00:41<02:48, 484.88it/s] 24%|██▍       | 26387/108000 [00:41<02:33, 531.95it/s] 24%|██▍       | 26458/108000 [00:41<02:21, 574.74it/s] 25%|██▍       | 26543/108000 [00:41<02:05, 649.00it/s] 25%|██▍       | 26654/108000 [00:41<01:45, 771.09it/s] 25%|██▍       | 26743/108000 [00:41<01:42, 794.38it/s] 25%|██▍       | 26849/108000 [00:41<01:33, 863.91it/s] 25%|██▍       | 26937/108000 [00:41<01:33, 865.22it/s] 25%|██▌       | 27061/108000 [00:41<01:24, 959.73it/s] 25%|██▌       | 27158/108000 [00:42<01:26, 930.98it/s] 25%|██▌       | 27252/108000 [00:42<01:29, 905.22it/s] 25%|██▌       | 27343/108000 [00:42<01:30, 893.93it/s] 25%|██▌       | 27433/108000 [00:42<01:34, 856.06it/s] 25%|██▌       | 27519/108000 [00:42<01:37, 828.50it/s] 26%|██▌       | 27623/108000 [00:42<01:31, 881.05it/s] 26%|██▌       | 27712/108000 [00:42<01:32, 866.96it/s] 26%|██▌       | 27824/108000 [00:42<01:26, 928.32it/s] 26%|██▌       | 27918/108000 [00:42<01:30, 884.02it/s] 26%|██▌       | 28013/108000 [00:42<01:29, 897.06it/s] 26%|██▌       | 28104/108000 [00:43<01:33, 853.80it/s] 26%|██▌       | 28199/108000 [00:43<01:31, 869.75it/s] 26%|██▌       | 28287/108000 [00:43<01:32, 864.49it/s] 26%|██▋       | 28374/108000 [00:43<01:36, 827.36it/s] 26%|██▋       | 28458/108000 [00:43<01:37, 818.58it/s] 26%|██▋       | 28541/108000 [00:43<01:45, 754.85it/s] 27%|██▋       | 28646/108000 [00:43<01:35, 831.26it/s] 27%|██▋       | 28744/108000 [00:43<01:31, 864.86it/s] 27%|██▋       | 28832/108000 [00:43<01:34, 837.97it/s] 27%|██▋       | 28917/108000 [00:44<01:42, 771.91it/s] 27%|██▋       | 28996/108000 [00:44<01:46, 740.28it/s] 27%|██▋       | 29072/108000 [00:44<01:53, 696.84it/s] 27%|██▋       | 29144/108000 [00:44<01:53, 694.88it/s] 27%|██▋       | 29215/108000 [00:44<01:53, 695.63it/s] 27%|██▋       | 29291/108000 [00:44<01:50, 711.38it/s] 27%|██▋       | 29391/108000 [00:44<01:39, 788.61it/s] 27%|██▋       | 29471/108000 [00:44<01:42, 767.99it/s] 27%|██▋       | 29549/108000 [00:44<01:42, 766.54it/s] 27%|██▋       | 29633/108000 [00:45<01:41, 772.69it/s] 28%|██▊       | 29711/108000 [00:45<01:55, 679.75it/s] 28%|██▊       | 29781/108000 [00:45<01:58, 659.65it/s] 28%|██▊       | 29854/108000 [00:45<01:55, 677.21it/s] 28%|██▊       | 29928/108000 [00:45<01:52, 691.17it/s] 28%|██▊       | 29999/108000 [00:45<01:55, 672.51it/s] 28%|██▊       | 30067/108000 [00:45<01:56, 670.00it/s] 28%|██▊       | 30135/108000 [00:45<02:05, 620.75it/s] 28%|██▊       | 30198/108000 [00:46<02:05, 621.45it/s] 28%|██▊       | 30261/108000 [00:46<02:09, 599.87it/s] 28%|██▊       | 30322/108000 [00:46<02:09, 601.78it/s] 28%|██▊       | 30383/108000 [00:46<02:14, 576.97it/s] 28%|██▊       | 30454/108000 [00:46<02:08, 605.78it/s] 28%|██▊       | 30562/108000 [00:46<01:44, 738.09it/s] 28%|██▊       | 30637/108000 [00:46<02:12, 582.66it/s] 28%|██▊       | 30713/108000 [00:46<02:03, 624.30it/s] 29%|██▊       | 30782/108000 [00:46<02:00, 641.12it/s] 29%|██▊       | 30850/108000 [00:47<02:02, 627.87it/s] 29%|██▊       | 30941/108000 [00:47<01:51, 692.42it/s] 29%|██▊       | 31019/108000 [00:47<01:47, 715.99it/s] 29%|██▉       | 31093/108000 [00:47<01:47, 717.43it/s] 29%|██▉       | 31166/108000 [00:47<01:55, 663.07it/s] 29%|██▉       | 31234/108000 [00:47<01:56, 657.49it/s] 29%|██▉       | 31307/108000 [00:47<01:55, 665.72it/s] 29%|██▉       | 31375/108000 [00:47<02:06, 605.12it/s] 29%|██▉       | 31437/108000 [00:47<02:19, 548.76it/s] 29%|██▉       | 31517/108000 [00:48<02:06, 606.05it/s] 29%|██▉       | 31580/108000 [00:48<02:13, 571.25it/s] 29%|██▉       | 31649/108000 [00:48<02:12, 576.78it/s] 29%|██▉       | 31711/108000 [00:48<02:10, 583.20it/s] 29%|██▉       | 31775/108000 [00:48<02:07, 596.43it/s] 29%|██▉       | 31836/108000 [00:48<02:11, 577.63it/s] 30%|██▉       | 31900/108000 [00:48<02:07, 594.63it/s] 30%|██▉       | 31960/108000 [00:48<02:08, 593.28it/s] 30%|██▉       | 32021/108000 [00:48<02:07, 596.79it/s] 30%|██▉       | 32081/108000 [00:49<02:09, 586.95it/s] 30%|██▉       | 32140/108000 [00:49<02:12, 571.83it/s] 30%|██▉       | 32223/108000 [00:49<01:58, 637.02it/s] 30%|██▉       | 32301/108000 [00:49<01:56, 649.23it/s] 30%|██▉       | 32378/108000 [00:49<02:00, 626.34it/s] 30%|███       | 32441/108000 [00:49<02:02, 618.29it/s] 30%|███       | 32507/108000 [00:49<02:00, 628.41it/s] 30%|███       | 32571/108000 [00:49<02:02, 615.41it/s] 30%|███       | 32633/108000 [00:49<02:02, 613.48it/s] 30%|███       | 32695/108000 [00:50<02:09, 582.97it/s] 30%|███       | 32768/108000 [00:50<02:03, 609.85it/s] 30%|███       | 32830/108000 [00:50<02:08, 584.51it/s] 30%|███       | 32889/108000 [00:50<02:11, 570.95it/s] 31%|███       | 32965/108000 [00:50<02:01, 617.50it/s] 31%|███       | 33028/108000 [00:50<02:02, 609.75it/s] 31%|███       | 33102/108000 [00:50<01:56, 641.75it/s] 31%|███       | 33177/108000 [00:50<01:52, 664.41it/s] 31%|███       | 33244/108000 [00:50<02:02, 611.07it/s] 31%|███       | 33306/108000 [00:51<02:04, 598.80it/s] 31%|███       | 33367/108000 [00:51<02:07, 585.18it/s] 31%|███       | 33426/108000 [00:51<02:09, 576.02it/s] 31%|███       | 33487/108000 [00:51<02:07, 585.17it/s] 31%|███       | 33546/108000 [00:51<02:14, 553.67it/s] 31%|███       | 33609/108000 [00:51<02:12, 562.18it/s] 31%|███       | 33666/108000 [00:51<02:31, 490.01it/s] 31%|███       | 33717/108000 [00:51<02:53, 429.32it/s] 31%|███▏      | 33763/108000 [00:52<03:15, 379.10it/s] 31%|███▏      | 33804/108000 [00:52<03:23, 364.28it/s] 31%|███▏      | 33849/108000 [00:52<03:15, 379.97it/s] 31%|███▏      | 33889/108000 [00:52<03:56, 312.86it/s] 31%|███▏      | 33925/108000 [00:52<03:51, 320.37it/s] 31%|███▏      | 33975/108000 [00:52<03:29, 353.88it/s] 31%|███▏      | 34013/108000 [00:52<03:57, 311.15it/s] 32%|███▏      | 34047/108000 [00:53<04:07, 299.19it/s] 32%|███▏      | 34099/108000 [00:53<03:32, 347.24it/s] 32%|███▏      | 34136/108000 [00:53<03:38, 337.88it/s] 32%|███▏      | 34171/108000 [00:53<03:50, 320.96it/s] 32%|███▏      | 34206/108000 [00:53<03:49, 322.16it/s] 32%|███▏      | 34239/108000 [00:53<04:00, 306.16it/s] 32%|███▏      | 34272/108000 [00:53<03:56, 312.05it/s] 32%|███▏      | 34312/108000 [00:53<03:41, 332.34it/s] 32%|███▏      | 34346/108000 [00:53<04:17, 286.48it/s] 32%|███▏      | 34404/108000 [00:54<03:23, 360.83it/s] 32%|███▏      | 34443/108000 [00:54<03:52, 316.69it/s] 32%|███▏      | 34503/108000 [00:54<03:15, 376.89it/s] 32%|███▏      | 34544/108000 [00:54<03:39, 335.09it/s] 32%|███▏      | 34588/108000 [00:54<03:23, 360.26it/s] 32%|███▏      | 34627/108000 [00:54<03:44, 327.52it/s] 32%|███▏      | 34664/108000 [00:54<03:40, 333.09it/s] 32%|███▏      | 34699/108000 [00:54<03:42, 328.97it/s] 32%|███▏      | 34739/108000 [00:55<03:33, 342.61it/s] 32%|███▏      | 34775/108000 [00:55<03:32, 345.18it/s] 32%|███▏      | 34819/108000 [00:55<03:17, 371.29it/s] 32%|███▏      | 34857/108000 [00:55<03:16, 372.00it/s] 32%|███▏      | 34895/108000 [00:55<03:23, 359.15it/s] 32%|███▏      | 34934/108000 [00:55<03:23, 359.46it/s] 32%|███▏      | 34971/108000 [00:55<03:36, 336.64it/s] 32%|███▏      | 35017/108000 [00:55<03:22, 361.00it/s] 32%|███▏      | 35054/108000 [00:55<03:39, 332.79it/s] 32%|███▏      | 35095/108000 [00:56<03:28, 350.46it/s] 33%|███▎      | 35136/108000 [00:56<03:38, 333.58it/s] 33%|███▎      | 35173/108000 [00:56<03:40, 330.99it/s] 33%|███▎      | 35207/108000 [00:56<03:39, 332.13it/s] 33%|███▎      | 35249/108000 [00:56<03:26, 352.17it/s] 33%|███▎      | 35288/108000 [00:56<03:24, 356.27it/s] 33%|███▎      | 35324/108000 [00:56<03:49, 316.71it/s] 33%|███▎      | 35359/108000 [00:56<03:43, 324.61it/s] 33%|███▎      | 35393/108000 [00:56<03:45, 322.10it/s] 33%|███▎      | 35429/108000 [00:57<03:42, 326.74it/s] 33%|███▎      | 35471/108000 [00:57<03:27, 349.91it/s] 33%|███▎      | 35508/108000 [00:57<03:23, 355.47it/s] 33%|███▎      | 35544/108000 [00:57<03:41, 327.70it/s] 33%|███▎      | 35578/108000 [00:57<03:47, 318.29it/s] 33%|███▎      | 35611/108000 [00:57<04:10, 289.12it/s] 33%|███▎      | 35652/108000 [00:57<03:47, 318.70it/s] 33%|███▎      | 35687/108000 [00:57<03:41, 327.01it/s] 33%|███▎      | 35724/108000 [00:57<03:33, 338.36it/s] 33%|███▎      | 35759/108000 [00:58<03:57, 304.50it/s] 33%|███▎      | 35791/108000 [00:58<03:57, 304.55it/s] 33%|███▎      | 35830/108000 [00:58<04:04, 295.36it/s] 33%|███▎      | 35881/108000 [00:58<03:26, 349.96it/s] 33%|███▎      | 35918/108000 [00:58<03:34, 336.53it/s] 33%|███▎      | 35965/108000 [00:58<03:17, 365.19it/s] 33%|███▎      | 36003/108000 [00:58<03:29, 343.53it/s] 33%|███▎      | 36061/108000 [00:58<03:01, 396.74it/s] 33%|███▎      | 36133/108000 [00:59<02:29, 480.83it/s] 34%|███▎      | 36197/108000 [00:59<02:17, 523.48it/s] 34%|███▎      | 36259/108000 [00:59<02:11, 544.68it/s] 34%|███▎      | 36329/108000 [00:59<02:01, 588.24it/s] 34%|███▎      | 36395/108000 [00:59<01:59, 599.79it/s] 34%|███▍      | 36456/108000 [00:59<01:59, 600.63it/s] 34%|███▍      | 36539/108000 [00:59<01:47, 664.85it/s] 34%|███▍      | 36606/108000 [00:59<01:52, 634.07it/s] 34%|███▍      | 36689/108000 [00:59<01:45, 674.76it/s] 34%|███▍      | 36763/108000 [00:59<01:45, 674.74it/s] 34%|███▍      | 36831/108000 [01:00<01:50, 643.01it/s] 34%|███▍      | 36908/108000 [01:00<01:46, 666.28it/s] 34%|███▍      | 36987/108000 [01:00<01:41, 700.93it/s] 34%|███▍      | 37058/108000 [01:00<01:50, 640.75it/s] 34%|███▍      | 37130/108000 [01:00<01:47, 657.56it/s] 34%|███▍      | 37197/108000 [01:00<01:52, 628.49it/s] 35%|███▍      | 37301/108000 [01:00<01:37, 724.27it/s] 35%|███▍      | 37400/108000 [01:00<01:29, 788.20it/s] 35%|███▍      | 37490/108000 [01:00<01:28, 797.24it/s] 35%|███▍      | 37571/108000 [01:01<01:39, 710.84it/s] 35%|███▍      | 37645/108000 [01:01<01:46, 662.77it/s] 35%|███▍      | 37713/108000 [01:01<01:56, 603.46it/s] 35%|███▌      | 37801/108000 [01:01<01:45, 667.62it/s] 35%|███▌      | 37871/108000 [01:01<02:07, 549.49it/s] 35%|███▌      | 37931/108000 [01:01<02:04, 561.06it/s] 35%|███▌      | 37991/108000 [01:01<02:07, 550.74it/s] 35%|███▌      | 38049/108000 [01:02<02:09, 538.11it/s] 35%|███▌      | 38107/108000 [01:02<02:08, 542.55it/s] 35%|███▌      | 38174/108000 [01:02<02:01, 573.90it/s] 35%|███▌      | 38233/108000 [01:02<02:04, 558.20it/s] 35%|███▌      | 38299/108000 [01:02<01:59, 584.26it/s] 36%|███▌      | 38359/108000 [01:02<02:21, 493.66it/s] 36%|███▌      | 38415/108000 [01:02<02:25, 478.28it/s] 36%|███▌      | 38465/108000 [01:02<02:37, 440.49it/s] 36%|███▌      | 38511/108000 [01:02<02:41, 430.49it/s] 36%|███▌      | 38556/108000 [01:03<03:12, 361.20it/s] 36%|███▌      | 38595/108000 [01:03<03:28, 332.25it/s] 36%|███▌      | 38632/108000 [01:03<03:27, 334.64it/s] 36%|███▌      | 38667/108000 [01:03<03:46, 305.45it/s] 36%|███▌      | 38699/108000 [01:03<03:52, 298.60it/s] 36%|███▌      | 38732/108000 [01:03<03:50, 300.15it/s] 36%|███▌      | 38779/108000 [01:03<03:24, 337.89it/s] 36%|███▌      | 38828/108000 [01:03<03:05, 373.64it/s] 36%|███▌      | 38867/108000 [01:04<03:24, 337.44it/s] 36%|███▌      | 38903/108000 [01:04<03:32, 325.93it/s] 36%|███▌      | 38943/108000 [01:04<03:23, 338.80it/s] 36%|███▌      | 38978/108000 [01:04<03:25, 336.24it/s] 36%|███▌      | 39020/108000 [01:04<03:14, 354.67it/s] 36%|███▌      | 39056/108000 [01:04<03:22, 341.15it/s] 36%|███▌      | 39091/108000 [01:04<03:39, 313.80it/s] 36%|███▌      | 39123/108000 [01:04<03:47, 302.58it/s] 36%|███▋      | 39179/108000 [01:05<03:10, 362.06it/s] 36%|███▋      | 39218/108000 [01:05<03:11, 360.09it/s] 36%|███▋      | 39255/108000 [01:05<03:22, 339.50it/s] 36%|███▋      | 39290/108000 [01:05<03:36, 317.97it/s] 36%|███▋      | 39323/108000 [01:05<03:36, 316.51it/s] 36%|███▋      | 39361/108000 [01:05<03:27, 331.42it/s] 36%|███▋      | 39395/108000 [01:05<03:31, 324.84it/s] 37%|███▋      | 39431/108000 [01:05<03:29, 327.01it/s] 37%|███▋      | 39464/108000 [01:05<03:46, 302.34it/s] 37%|███▋      | 39505/108000 [01:06<03:31, 324.54it/s] 37%|███▋      | 39544/108000 [01:06<03:20, 340.92it/s] 37%|███▋      | 39579/108000 [01:06<03:46, 302.23it/s] 37%|███▋      | 39613/108000 [01:06<03:41, 308.58it/s] 37%|███▋      | 39645/108000 [01:06<04:15, 267.87it/s] 37%|███▋      | 39697/108000 [01:06<03:29, 326.71it/s] 37%|███▋      | 39732/108000 [01:06<03:32, 321.26it/s] 37%|███▋      | 39766/108000 [01:06<03:36, 315.05it/s] 37%|███▋      | 39799/108000 [01:07<03:52, 292.72it/s] 37%|███▋      | 39830/108000 [01:07<03:49, 297.14it/s] 37%|███▋      | 39875/108000 [01:07<03:27, 328.21it/s] 37%|███▋      | 39909/108000 [01:07<03:25, 331.32it/s] 37%|███▋      | 39943/108000 [01:07<03:36, 314.47it/s] 37%|███▋      | 39975/108000 [01:07<04:09, 272.53it/s] 37%|███▋      | 40025/108000 [01:07<03:28, 326.60it/s] 37%|███▋      | 40072/108000 [01:07<03:07, 362.27it/s] 37%|███▋      | 40110/108000 [01:07<03:10, 356.52it/s] 37%|███▋      | 40147/108000 [01:08<03:43, 304.26it/s] 37%|███▋      | 40180/108000 [01:08<03:38, 310.64it/s] 37%|███▋      | 40240/108000 [01:08<03:00, 375.48it/s] 37%|███▋      | 40279/108000 [01:08<03:17, 343.44it/s] 37%|███▋      | 40315/108000 [01:08<03:34, 315.09it/s] 37%|███▋      | 40360/108000 [01:08<03:21, 335.25it/s] 37%|███▋      | 40395/108000 [01:08<03:32, 317.62it/s] 37%|███▋      | 40428/108000 [01:09<03:57, 285.04it/s] 37%|███▋      | 40459/108000 [01:09<03:52, 290.76it/s] 38%|███▊      | 40505/108000 [01:09<03:27, 325.12it/s] 38%|███▊      | 40545/108000 [01:09<03:23, 332.04it/s] 38%|███▊      | 40585/108000 [01:09<03:15, 344.74it/s] 38%|███▊      | 40620/108000 [01:09<03:33, 314.99it/s] 38%|███▊      | 40659/108000 [01:09<03:22, 332.83it/s] 38%|███▊      | 40693/108000 [01:09<03:43, 300.57it/s] 38%|███▊      | 40736/108000 [01:09<03:32, 316.22it/s] 38%|███▊      | 40780/108000 [01:10<03:15, 344.63it/s] 38%|███▊      | 40827/108000 [01:10<03:02, 367.35it/s] 38%|███▊      | 40905/108000 [01:10<02:23, 466.49it/s] 38%|███▊      | 40971/108000 [01:10<02:09, 516.25it/s] 38%|███▊      | 41024/108000 [01:10<02:09, 517.33it/s] 38%|███▊      | 41091/108000 [01:10<02:02, 547.18it/s] 38%|███▊      | 41189/108000 [01:10<01:40, 666.24it/s] 38%|███▊      | 41275/108000 [01:10<01:33, 716.63it/s] 38%|███▊      | 41348/108000 [01:10<01:35, 696.09it/s] 38%|███▊      | 41461/108000 [01:11<01:22, 805.57it/s] 38%|███▊      | 41543/108000 [01:11<01:42, 649.70it/s] 39%|███▊      | 41637/108000 [01:11<01:32, 718.29it/s] 39%|███▊      | 41721/108000 [01:11<01:28, 749.76it/s] 39%|███▊      | 41800/108000 [01:11<01:30, 731.28it/s] 39%|███▉      | 41876/108000 [01:11<01:33, 704.28it/s] 39%|███▉      | 41959/108000 [01:11<01:30, 727.77it/s] 39%|███▉      | 42034/108000 [01:11<01:33, 703.39it/s] 39%|███▉      | 42106/108000 [01:11<01:36, 682.70it/s] 39%|███▉      | 42176/108000 [01:12<01:40, 655.46it/s] 39%|███▉      | 42264/108000 [01:12<01:32, 710.52it/s] 39%|███▉      | 42340/108000 [01:12<01:30, 724.04it/s] 39%|███▉      | 42414/108000 [01:12<01:41, 648.31it/s] 39%|███▉      | 42491/108000 [01:12<01:36, 680.34it/s] 39%|███▉      | 42561/108000 [01:12<01:49, 599.99it/s] 39%|███▉      | 42643/108000 [01:12<01:40, 651.70it/s] 40%|███▉      | 42725/108000 [01:12<01:34, 687.58it/s] 40%|███▉      | 42808/108000 [01:13<01:31, 710.65it/s] 40%|███▉      | 42881/108000 [01:13<01:32, 707.43it/s] 40%|███▉      | 42958/108000 [01:13<01:30, 721.25it/s] 40%|███▉      | 43031/108000 [01:13<01:29, 722.11it/s] 40%|███▉      | 43104/108000 [01:13<01:44, 619.19it/s] 40%|███▉      | 43178/108000 [01:13<01:40, 648.09it/s] 40%|████      | 43246/108000 [01:13<01:39, 650.04it/s] 40%|████      | 43313/108000 [01:13<01:38, 653.97it/s] 40%|████      | 43381/108000 [01:13<01:37, 660.77it/s] 40%|████      | 43475/108000 [01:13<01:27, 739.95it/s] 40%|████      | 43550/108000 [01:14<01:30, 712.81it/s] 40%|████      | 43623/108000 [01:14<01:30, 709.61it/s] 40%|████      | 43696/108000 [01:14<01:30, 712.82it/s] 41%|████      | 43768/108000 [01:14<01:32, 697.24it/s] 41%|████      | 43839/108000 [01:14<01:32, 695.51it/s] 41%|████      | 43909/108000 [01:14<01:36, 664.12it/s] 41%|████      | 43982/108000 [01:14<01:33, 682.70it/s] 41%|████      | 44051/108000 [01:14<01:37, 653.36it/s] 41%|████      | 44117/108000 [01:14<01:39, 644.93it/s] 41%|████      | 44193/108000 [01:15<01:35, 671.57it/s] 41%|████      | 44272/108000 [01:15<01:30, 703.70it/s] 41%|████      | 44344/108000 [01:15<01:31, 698.61it/s] 41%|████      | 44444/108000 [01:15<01:21, 783.35it/s] 41%|████      | 44531/108000 [01:15<01:19, 796.45it/s] 41%|████▏     | 44619/108000 [01:15<01:17, 819.26it/s] 41%|████▏     | 44702/108000 [01:15<01:24, 753.22it/s] 41%|████▏     | 44781/108000 [01:15<01:23, 756.27it/s] 42%|████▏     | 44858/108000 [01:15<01:24, 746.50it/s] 42%|████▏     | 44934/108000 [01:16<01:26, 733.14it/s] 42%|████▏     | 45022/108000 [01:16<01:23, 757.60it/s] 42%|████▏     | 45107/108000 [01:16<01:21, 768.30it/s] 42%|████▏     | 45185/108000 [01:16<01:26, 727.14it/s] 42%|████▏     | 45259/108000 [01:16<01:35, 659.73it/s] 42%|████▏     | 45347/108000 [01:16<01:45, 591.54it/s] 42%|████▏     | 45423/108000 [01:16<01:39, 631.26it/s] 42%|████▏     | 45489/108000 [01:16<01:41, 615.98it/s] 42%|████▏     | 45553/108000 [01:17<01:53, 549.09it/s] 42%|████▏     | 45623/108000 [01:17<01:48, 576.12it/s] 42%|████▏     | 45683/108000 [01:17<01:52, 554.04it/s] 42%|████▏     | 45740/108000 [01:17<02:02, 509.39it/s] 42%|████▏     | 45806/108000 [01:17<01:54, 544.89it/s] 42%|████▏     | 45866/108000 [01:17<01:51, 555.43it/s] 43%|████▎     | 45930/108000 [01:17<01:47, 577.97it/s] 43%|████▎     | 45989/108000 [01:17<01:54, 543.21it/s] 43%|████▎     | 46053/108000 [01:17<01:49, 564.56it/s] 43%|████▎     | 46111/108000 [01:18<01:49, 567.43it/s] 43%|████▎     | 46173/108000 [01:18<01:48, 571.90it/s] 43%|████▎     | 46253/108000 [01:18<01:39, 621.30it/s] 43%|████▎     | 46322/108000 [01:18<01:38, 626.45it/s] 43%|████▎     | 46385/108000 [01:18<01:40, 611.79it/s] 43%|████▎     | 46463/108000 [01:18<01:34, 654.25it/s] 43%|████▎     | 46561/108000 [01:18<01:22, 741.68it/s] 43%|████▎     | 46636/108000 [01:18<01:26, 711.22it/s] 43%|████▎     | 46708/108000 [01:18<01:28, 695.59it/s] 43%|████▎     | 46791/108000 [01:18<01:23, 733.56it/s] 43%|████▎     | 46865/108000 [01:19<01:34, 650.36it/s] 43%|████▎     | 46941/108000 [01:19<01:30, 677.07it/s] 44%|████▎     | 47011/108000 [01:19<01:37, 627.95it/s] 44%|████▎     | 47095/108000 [01:19<01:30, 670.34it/s] 44%|████▎     | 47164/108000 [01:19<01:33, 650.51it/s] 44%|████▎     | 47243/108000 [01:19<01:29, 681.84it/s] 44%|████▍     | 47313/108000 [01:19<01:29, 676.16it/s] 44%|████▍     | 47382/108000 [01:19<01:35, 635.38it/s] 44%|████▍     | 47447/108000 [01:20<01:36, 629.00it/s] 44%|████▍     | 47511/108000 [01:20<01:39, 606.67it/s] 44%|████▍     | 47577/108000 [01:20<01:37, 616.85it/s] 44%|████▍     | 47644/108000 [01:20<01:36, 623.76it/s] 44%|████▍     | 47719/108000 [01:20<01:31, 655.47it/s] 44%|████▍     | 47807/108000 [01:20<01:25, 703.98it/s] 44%|████▍     | 47878/108000 [01:20<01:31, 658.04it/s] 44%|████▍     | 47945/108000 [01:20<01:34, 637.40it/s] 44%|████▍     | 48025/108000 [01:20<01:28, 679.88it/s] 45%|████▍     | 48094/108000 [01:21<01:42, 586.37it/s] 45%|████▍     | 48156/108000 [01:21<01:42, 584.16it/s] 45%|████▍     | 48217/108000 [01:21<01:43, 577.16it/s] 45%|████▍     | 48276/108000 [01:21<01:44, 569.96it/s] 45%|████▍     | 48334/108000 [01:21<01:49, 544.82it/s] 45%|████▍     | 48413/108000 [01:21<01:37, 610.11it/s] 45%|████▍     | 48476/108000 [01:21<01:43, 575.91it/s] 45%|████▍     | 48535/108000 [01:21<01:50, 540.57it/s] 45%|████▍     | 48594/108000 [01:21<01:49, 541.23it/s] 45%|████▌     | 48655/108000 [01:22<01:47, 553.01it/s] 45%|████▌     | 48711/108000 [01:22<01:49, 542.26it/s] 45%|████▌     | 48766/108000 [01:22<01:51, 529.13it/s] 45%|████▌     | 48827/108000 [01:22<01:50, 533.56it/s] 45%|████▌     | 48881/108000 [01:22<01:51, 532.32it/s] 45%|████▌     | 48940/108000 [01:22<01:51, 530.97it/s] 45%|████▌     | 49002/108000 [01:22<01:49, 539.85it/s] 45%|████▌     | 49057/108000 [01:22<01:50, 531.25it/s] 45%|████▌     | 49111/108000 [01:22<01:52, 524.56it/s] 46%|████▌     | 49164/108000 [01:23<01:55, 510.48it/s] 46%|████▌     | 49219/108000 [01:23<01:54, 511.28it/s] 46%|████▌     | 49274/108000 [01:23<01:52, 520.51it/s] 46%|████▌     | 49328/108000 [01:23<01:54, 513.90it/s] 46%|████▌     | 49380/108000 [01:23<01:55, 509.70it/s] 46%|████▌     | 49445/108000 [01:23<01:48, 541.30it/s] 46%|████▌     | 49500/108000 [01:23<01:50, 529.66it/s] 46%|████▌     | 49554/108000 [01:23<01:50, 529.38it/s] 46%|████▌     | 49614/108000 [01:23<01:46, 549.49it/s] 46%|████▌     | 49696/108000 [01:24<01:35, 610.11it/s] 46%|████▌     | 49757/108000 [01:24<01:37, 596.40it/s] 46%|████▌     | 49817/108000 [01:24<01:45, 550.43it/s] 46%|████▌     | 49877/108000 [01:24<01:43, 563.26it/s] 46%|████▋     | 49952/108000 [01:24<01:34, 612.36it/s] 46%|████▋     | 50014/108000 [01:24<01:38, 589.06it/s] 46%|████▋     | 50074/108000 [01:24<01:47, 538.06it/s] 46%|████▋     | 50153/108000 [01:24<01:36, 601.52it/s] 46%|████▋     | 50215/108000 [01:24<01:37, 592.81it/s] 47%|████▋     | 50276/108000 [01:25<01:46, 542.82it/s] 47%|████▋     | 50332/108000 [01:25<01:45, 545.44it/s] 47%|████▋     | 50388/108000 [01:25<01:57, 490.48it/s] 47%|████▋     | 50443/108000 [01:25<01:53, 505.70it/s] 47%|████▋     | 50529/108000 [01:25<01:36, 592.81it/s] 47%|████▋     | 50592/108000 [01:25<01:35, 602.37it/s] 47%|████▋     | 50654/108000 [01:25<01:42, 562.03it/s] 47%|████▋     | 50712/108000 [01:25<01:49, 524.95it/s] 47%|████▋     | 50784/108000 [01:25<01:39, 574.00it/s] 47%|████▋     | 50847/108000 [01:26<01:39, 576.29it/s] 47%|████▋     | 50921/108000 [01:26<01:34, 606.57it/s] 47%|████▋     | 50996/108000 [01:26<01:28, 642.85it/s] 47%|████▋     | 51066/108000 [01:26<01:27, 649.62it/s] 47%|████▋     | 51145/108000 [01:26<01:29, 632.01it/s] 47%|████▋     | 51209/108000 [01:26<01:36, 590.08it/s] 47%|████▋     | 51279/108000 [01:26<01:31, 618.09it/s] 48%|████▊     | 51342/108000 [01:26<01:39, 566.59it/s] 48%|████▊     | 51419/108000 [01:26<01:31, 619.32it/s] 48%|████▊     | 51483/108000 [01:27<01:42, 550.00it/s] 48%|████▊     | 51546/108000 [01:27<01:39, 568.48it/s] 48%|████▊     | 51612/108000 [01:27<01:35, 591.49it/s] 48%|████▊     | 51675/108000 [01:27<01:33, 599.43it/s] 48%|████▊     | 51738/108000 [01:27<01:32, 607.56it/s] 48%|████▊     | 51800/108000 [01:27<01:32, 610.55it/s] 48%|████▊     | 51862/108000 [01:27<01:34, 596.58it/s] 48%|████▊     | 51931/108000 [01:27<01:30, 620.36it/s] 48%|████▊     | 52004/108000 [01:27<01:27, 638.59it/s] 48%|████▊     | 52087/108000 [01:28<01:21, 686.10it/s] 48%|████▊     | 52156/108000 [01:28<01:35, 582.51it/s] 48%|████▊     | 52217/108000 [01:28<01:35, 584.62it/s] 48%|████▊     | 52289/108000 [01:28<01:31, 609.42it/s] 48%|████▊     | 52352/108000 [01:28<01:37, 569.75it/s] 49%|████▊     | 52414/108000 [01:28<01:35, 579.65it/s] 49%|████▊     | 52474/108000 [01:28<01:37, 570.83it/s] 49%|████▊     | 52555/108000 [01:28<01:29, 620.71it/s] 49%|████▊     | 52631/108000 [01:28<01:24, 659.00it/s] 49%|████▉     | 52711/108000 [01:29<01:19, 698.69it/s] 49%|████▉     | 52782/108000 [01:29<01:27, 630.94it/s] 49%|████▉     | 52847/108000 [01:29<01:40, 547.18it/s] 49%|████▉     | 52905/108000 [01:29<01:58, 465.39it/s] 49%|████▉     | 52956/108000 [01:29<02:15, 405.27it/s] 49%|████▉     | 53002/108000 [01:29<02:13, 412.97it/s] 49%|████▉     | 53046/108000 [01:29<02:20, 392.39it/s] 49%|████▉     | 53089/108000 [01:30<02:17, 397.93it/s] 49%|████▉     | 53131/108000 [01:30<02:41, 340.06it/s] 49%|████▉     | 53169/108000 [01:30<02:40, 340.58it/s] 49%|████▉     | 53205/108000 [01:30<02:43, 334.94it/s] 49%|████▉     | 53243/108000 [01:30<02:40, 341.28it/s] 49%|████▉     | 53278/108000 [01:30<03:13, 283.51it/s] 49%|████▉     | 53331/108000 [01:30<02:45, 331.12it/s] 49%|████▉     | 53367/108000 [01:30<02:42, 335.88it/s] 49%|████▉     | 53403/108000 [01:31<02:43, 333.49it/s] 49%|████▉     | 53438/108000 [01:31<02:50, 320.91it/s] 50%|████▉     | 53477/108000 [01:31<02:42, 334.64it/s] 50%|████▉     | 53512/108000 [01:31<03:15, 278.57it/s] 50%|████▉     | 53556/108000 [01:31<03:33, 255.01it/s] 50%|████▉     | 53602/108000 [01:31<03:06, 291.62it/s] 50%|████▉     | 53634/108000 [01:31<03:27, 262.11it/s] 50%|████▉     | 53674/108000 [01:32<03:12, 281.91it/s] 50%|████▉     | 53704/108000 [01:32<03:22, 268.75it/s] 50%|████▉     | 53759/108000 [01:32<02:41, 335.26it/s] 50%|████▉     | 53795/108000 [01:32<02:50, 317.00it/s] 50%|████▉     | 53829/108000 [01:32<02:54, 310.99it/s] 50%|████▉     | 53866/108000 [01:32<02:53, 311.77it/s] 50%|████▉     | 53898/108000 [01:32<02:53, 311.89it/s] 50%|████▉     | 53930/108000 [01:32<02:55, 308.86it/s] 50%|████▉     | 53962/108000 [01:32<03:02, 296.68it/s] 50%|█████     | 54003/108000 [01:33<02:50, 317.63it/s] 50%|█████     | 54050/108000 [01:33<02:33, 352.58it/s] 50%|█████     | 54086/108000 [01:33<02:35, 346.91it/s] 50%|█████     | 54121/108000 [01:33<02:38, 340.86it/s] 50%|█████     | 54156/108000 [01:33<02:36, 343.27it/s] 50%|█████     | 54191/108000 [01:33<02:42, 330.66it/s] 50%|█████     | 54230/108000 [01:33<02:38, 340.24it/s] 50%|█████     | 54265/108000 [01:33<02:53, 310.52it/s] 50%|█████     | 54305/108000 [01:33<02:40, 333.57it/s] 50%|█████     | 54339/108000 [01:34<02:44, 326.62it/s] 50%|█████     | 54389/108000 [01:34<02:27, 363.10it/s] 50%|█████     | 54426/108000 [01:34<02:42, 330.27it/s] 50%|█████     | 54467/108000 [01:34<02:34, 346.94it/s] 50%|█████     | 54503/108000 [01:34<02:35, 345.06it/s] 51%|█████     | 54548/108000 [01:34<02:24, 371.15it/s] 51%|█████     | 54586/108000 [01:34<02:24, 369.72it/s] 51%|█████     | 54624/108000 [01:34<02:29, 356.42it/s] 51%|█████     | 54660/108000 [01:35<02:52, 310.10it/s] 51%|█████     | 54693/108000 [01:35<02:53, 307.72it/s] 51%|█████     | 54725/108000 [01:35<03:00, 294.59it/s] 51%|█████     | 54760/108000 [01:35<02:52, 308.54it/s] 51%|█████     | 54803/108000 [01:35<02:39, 332.80it/s] 51%|█████     | 54837/108000 [01:35<02:45, 320.94it/s] 51%|█████     | 54892/108000 [01:35<02:18, 383.36it/s] 51%|█████     | 54932/108000 [01:35<02:38, 334.69it/s] 51%|█████     | 54973/108000 [01:35<02:31, 351.07it/s] 51%|█████     | 55010/108000 [01:36<02:34, 342.54it/s] 51%|█████     | 55046/108000 [01:36<02:47, 315.70it/s] 51%|█████     | 55079/108000 [01:36<02:48, 314.07it/s] 51%|█████     | 55123/108000 [01:36<02:40, 329.04it/s] 51%|█████     | 55159/108000 [01:36<02:38, 332.71it/s] 51%|█████     | 55193/108000 [01:36<02:41, 327.91it/s] 51%|█████     | 55226/108000 [01:36<02:54, 303.17it/s] 51%|█████     | 55275/108000 [01:36<02:33, 342.75it/s] 51%|█████     | 55310/108000 [01:37<02:43, 321.98it/s] 51%|█████     | 55348/108000 [01:37<02:36, 336.82it/s] 51%|█████▏    | 55385/108000 [01:37<02:37, 333.97it/s] 51%|█████▏    | 55419/108000 [01:37<02:41, 325.13it/s] 51%|█████▏    | 55452/108000 [01:37<02:55, 299.99it/s] 51%|█████▏    | 55487/108000 [01:37<02:48, 310.78it/s] 51%|█████▏    | 55519/108000 [01:37<03:08, 277.75it/s] 51%|█████▏    | 55554/108000 [01:37<02:59, 292.32it/s] 51%|█████▏    | 55598/108000 [01:37<02:41, 323.62it/s] 52%|█████▏    | 55632/108000 [01:38<02:42, 322.98it/s] 52%|█████▏    | 55665/108000 [01:38<02:52, 303.97it/s] 52%|█████▏    | 55696/108000 [01:38<02:53, 300.60it/s] 52%|█████▏    | 55737/108000 [01:38<02:51, 304.13it/s] 52%|█████▏    | 55769/108000 [01:38<02:53, 301.16it/s] 52%|█████▏    | 55800/108000 [01:38<03:00, 288.67it/s] 52%|█████▏    | 55829/108000 [01:38<03:13, 269.12it/s] 52%|█████▏    | 55874/108000 [01:38<02:48, 309.04it/s] 52%|█████▏    | 55906/108000 [01:39<03:05, 280.99it/s] 52%|█████▏    | 55953/108000 [01:39<02:40, 324.50it/s] 52%|█████▏    | 55988/108000 [01:39<02:40, 323.10it/s] 52%|█████▏    | 56021/108000 [01:39<02:40, 323.57it/s] 52%|█████▏    | 56054/108000 [01:39<03:03, 282.71it/s] 52%|█████▏    | 56084/108000 [01:39<03:19, 259.67it/s] 52%|█████▏    | 56140/108000 [01:39<02:40, 323.72it/s] 52%|█████▏    | 56174/108000 [01:39<02:46, 310.97it/s] 52%|█████▏    | 56221/108000 [01:39<02:28, 349.78it/s] 52%|█████▏    | 56258/108000 [01:40<02:47, 308.68it/s] 52%|█████▏    | 56304/108000 [01:40<02:31, 342.05it/s] 52%|█████▏    | 56340/108000 [01:40<02:39, 324.18it/s] 52%|█████▏    | 56374/108000 [01:40<02:55, 294.35it/s] 52%|█████▏    | 56406/108000 [01:40<02:54, 296.16it/s] 52%|█████▏    | 56437/108000 [01:40<02:54, 294.74it/s] 52%|█████▏    | 56468/108000 [01:40<03:01, 283.81it/s] 52%|█████▏    | 56511/108000 [01:40<02:45, 311.24it/s] 52%|█████▏    | 56543/108000 [01:41<03:04, 279.54it/s] 52%|█████▏    | 56588/108000 [01:41<02:39, 321.72it/s] 52%|█████▏    | 56622/108000 [01:41<02:51, 298.80it/s] 52%|█████▏    | 56659/108000 [01:41<02:46, 308.94it/s] 52%|█████▏    | 56691/108000 [01:41<02:52, 298.12it/s] 53%|█████▎    | 56722/108000 [01:41<03:06, 275.46it/s] 53%|█████▎    | 56765/108000 [01:41<02:45, 310.10it/s] 53%|█████▎    | 56798/108000 [01:41<02:43, 313.22it/s] 53%|█████▎    | 56844/108000 [01:42<02:29, 341.73it/s] 53%|█████▎    | 56879/108000 [01:42<02:52, 297.09it/s] 53%|█████▎    | 56921/108000 [01:42<02:37, 323.29it/s] 53%|█████▎    | 56955/108000 [01:42<02:41, 316.45it/s] 53%|█████▎    | 56988/108000 [01:42<03:02, 279.89it/s] 53%|█████▎    | 57019/108000 [01:42<02:57, 287.37it/s] 53%|█████▎    | 57068/108000 [01:42<02:32, 334.80it/s] 53%|█████▎    | 57103/108000 [01:42<02:40, 316.61it/s] 53%|█████▎    | 57136/108000 [01:43<03:00, 281.36it/s] 53%|█████▎    | 57175/108000 [01:43<02:50, 298.11it/s] 53%|█████▎    | 57227/108000 [01:43<02:30, 337.84it/s] 53%|█████▎    | 57262/108000 [01:43<02:46, 303.89it/s] 53%|█████▎    | 57308/108000 [01:43<02:30, 336.56it/s] 53%|█████▎    | 57343/108000 [01:43<02:48, 301.09it/s] 53%|█████▎    | 57397/108000 [01:43<02:23, 353.41it/s] 53%|█████▎    | 57435/108000 [01:43<02:34, 327.84it/s] 53%|█████▎    | 57470/108000 [01:44<02:35, 324.69it/s] 53%|█████▎    | 57506/108000 [01:44<02:31, 332.58it/s] 53%|█████▎    | 57548/108000 [01:44<02:23, 352.32it/s] 53%|█████▎    | 57584/108000 [01:44<02:30, 334.49it/s] 53%|█████▎    | 57622/108000 [01:44<02:27, 342.70it/s] 53%|█████▎    | 57707/108000 [01:44<01:44, 481.21it/s] 53%|█████▎    | 57777/108000 [01:44<01:34, 534.02it/s] 54%|█████▎    | 57865/108000 [01:44<01:19, 629.95it/s] 54%|█████▎    | 57930/108000 [01:44<01:28, 563.25it/s] 54%|█████▎    | 58010/108000 [01:45<01:22, 609.41it/s] 54%|█████▍    | 58094/108000 [01:45<01:16, 649.79it/s] 54%|█████▍    | 58166/108000 [01:45<01:15, 656.33it/s] 54%|█████▍    | 58233/108000 [01:45<01:17, 644.71it/s] 54%|█████▍    | 58299/108000 [01:45<01:21, 613.27it/s] 54%|█████▍    | 58379/108000 [01:45<01:15, 660.72it/s] 54%|█████▍    | 58464/108000 [01:45<01:11, 697.41it/s] 54%|█████▍    | 58555/108000 [01:45<01:06, 743.73it/s] 54%|█████▍    | 58635/108000 [01:45<01:06, 741.32it/s] 54%|█████▍    | 58710/108000 [01:45<01:06, 737.20it/s] 54%|█████▍    | 58784/108000 [01:46<01:15, 650.29it/s] 55%|█████▍    | 58867/108000 [01:46<01:10, 694.24it/s] 55%|█████▍    | 58945/108000 [01:46<01:09, 707.07it/s] 55%|█████▍    | 59018/108000 [01:46<01:11, 682.25it/s] 55%|█████▍    | 59096/108000 [01:46<01:10, 691.83it/s] 55%|█████▍    | 59166/108000 [01:46<01:38, 495.39it/s] 55%|█████▍    | 59224/108000 [01:46<01:36, 505.59it/s] 55%|█████▍    | 59281/108000 [01:47<01:36, 505.99it/s] 55%|█████▍    | 59336/108000 [01:47<01:35, 510.00it/s] 55%|█████▍    | 59394/108000 [01:47<01:32, 525.98it/s] 55%|█████▌    | 59484/108000 [01:47<01:20, 604.02it/s] 55%|█████▌    | 59547/108000 [01:47<01:27, 553.13it/s] 55%|█████▌    | 59623/108000 [01:47<01:21, 592.82it/s] 55%|█████▌    | 59700/108000 [01:47<01:17, 626.02it/s] 55%|█████▌    | 59764/108000 [01:47<01:16, 628.17it/s] 55%|█████▌    | 59863/108000 [01:47<01:06, 724.39it/s] 56%|█████▌    | 59941/108000 [01:48<01:06, 719.84it/s] 56%|█████▌    | 60014/108000 [01:48<01:08, 696.95it/s] 56%|█████▌    | 60085/108000 [01:48<01:09, 693.73it/s] 56%|█████▌    | 60155/108000 [01:48<01:14, 639.34it/s] 56%|█████▌    | 60230/108000 [01:48<01:11, 669.05it/s] 56%|█████▌    | 60298/108000 [01:48<01:16, 621.98it/s] 56%|█████▌    | 60382/108000 [01:48<01:10, 672.03it/s] 56%|█████▌    | 60453/108000 [01:48<01:10, 672.51it/s] 56%|█████▌    | 60522/108000 [01:48<01:11, 667.84it/s] 56%|█████▌    | 60601/108000 [01:49<01:08, 692.50it/s] 56%|█████▌    | 60671/108000 [01:49<01:13, 641.93it/s] 56%|█████▌    | 60737/108000 [01:49<01:16, 620.11it/s] 56%|█████▋    | 60800/108000 [01:49<01:17, 612.37it/s] 56%|█████▋    | 60862/108000 [01:49<01:19, 589.25it/s] 56%|█████▋    | 60942/108000 [01:49<01:12, 644.86it/s] 56%|█████▋    | 61013/108000 [01:49<01:11, 660.55it/s] 57%|█████▋    | 61080/108000 [01:49<01:17, 608.61it/s] 57%|█████▋    | 61147/108000 [01:49<01:15, 622.32it/s] 57%|█████▋    | 61211/108000 [01:50<01:18, 594.71it/s] 57%|█████▋    | 61292/108000 [01:50<01:12, 644.17it/s] 57%|█████▋    | 61364/108000 [01:50<01:11, 656.53it/s] 57%|█████▋    | 61431/108000 [01:50<01:10, 658.94it/s] 57%|█████▋    | 61498/108000 [01:50<01:16, 609.34it/s] 57%|█████▋    | 61571/108000 [01:50<01:13, 633.02it/s] 57%|█████▋    | 61636/108000 [01:50<01:21, 568.95it/s] 57%|█████▋    | 61720/108000 [01:50<01:12, 634.78it/s] 57%|█████▋    | 61786/108000 [01:50<01:19, 579.11it/s] 57%|█████▋    | 61846/108000 [01:51<01:26, 531.29it/s] 57%|█████▋    | 61921/108000 [01:51<01:20, 573.05it/s] 57%|█████▋    | 61986/108000 [01:51<01:17, 589.98it/s] 57%|█████▋    | 62048/108000 [01:51<01:16, 597.70it/s] 58%|█████▊    | 62117/108000 [01:51<01:13, 623.15it/s] 58%|█████▊    | 62181/108000 [01:51<01:13, 621.49it/s] 58%|█████▊    | 62261/108000 [01:51<01:09, 662.67it/s] 58%|█████▊    | 62328/108000 [01:51<01:10, 650.83it/s] 58%|█████▊    | 62399/108000 [01:51<01:09, 656.12it/s] 58%|█████▊    | 62465/108000 [01:52<01:21, 557.76it/s] 58%|█████▊    | 62524/108000 [01:52<01:26, 527.37it/s] 58%|█████▊    | 62579/108000 [01:52<01:37, 467.56it/s] 58%|█████▊    | 62628/108000 [01:52<01:39, 454.65it/s] 58%|█████▊    | 62675/108000 [01:52<01:46, 426.33it/s] 58%|█████▊    | 62719/108000 [01:52<01:52, 403.85it/s] 58%|█████▊    | 62766/108000 [01:52<01:48, 415.91it/s] 58%|█████▊    | 62818/108000 [01:52<01:47, 421.17it/s] 58%|█████▊    | 62861/108000 [01:53<01:47, 419.94it/s] 58%|█████▊    | 62913/108000 [01:53<01:42, 438.83it/s] 58%|█████▊    | 62959/108000 [01:53<01:44, 431.41it/s] 58%|█████▊    | 63003/108000 [01:53<01:47, 417.60it/s] 58%|█████▊    | 63045/108000 [01:53<01:53, 394.96it/s] 58%|█████▊    | 63097/108000 [01:53<01:44, 427.82it/s] 58%|█████▊    | 63141/108000 [01:53<01:55, 387.81it/s] 59%|█████▊    | 63196/108000 [01:53<01:46, 419.52it/s] 59%|█████▊    | 63246/108000 [01:53<01:43, 434.12it/s] 59%|█████▊    | 63291/108000 [01:54<01:48, 411.83it/s] 59%|█████▊    | 63337/108000 [01:54<01:46, 418.35it/s] 59%|█████▊    | 63385/108000 [01:54<01:45, 424.90it/s] 59%|█████▊    | 63428/108000 [01:54<01:44, 425.74it/s] 59%|█████▉    | 63491/108000 [01:54<01:32, 483.55it/s] 59%|█████▉    | 63540/108000 [01:54<01:40, 443.83it/s] 59%|█████▉    | 63588/108000 [01:54<01:40, 443.12it/s] 59%|█████▉    | 63639/108000 [01:54<01:36, 461.57it/s] 59%|█████▉    | 63686/108000 [01:54<01:38, 448.05it/s] 59%|█████▉    | 63732/108000 [01:55<01:55, 382.44it/s] 59%|█████▉    | 63785/108000 [01:55<01:47, 410.08it/s] 59%|█████▉    | 63828/108000 [01:55<01:53, 389.92it/s] 59%|█████▉    | 63869/108000 [01:55<01:55, 381.56it/s] 59%|█████▉    | 63929/108000 [01:55<01:40, 437.13it/s] 59%|█████▉    | 63974/108000 [01:55<01:45, 417.65it/s] 59%|█████▉    | 64025/108000 [01:55<01:39, 441.85it/s] 59%|█████▉    | 64079/108000 [01:55<01:33, 468.77it/s] 59%|█████▉    | 64127/108000 [01:56<01:42, 428.85it/s] 59%|█████▉    | 64178/108000 [01:56<01:38, 445.23it/s] 59%|█████▉    | 64224/108000 [01:56<01:39, 440.18it/s] 60%|█████▉    | 64269/108000 [01:56<01:56, 374.81it/s] 60%|█████▉    | 64317/108000 [01:56<01:51, 391.34it/s] 60%|█████▉    | 64372/108000 [01:56<01:41, 428.24it/s] 60%|█████▉    | 64418/108000 [01:56<01:39, 435.98it/s] 60%|█████▉    | 64466/108000 [01:56<01:40, 434.97it/s] 60%|█████▉    | 64511/108000 [01:56<01:41, 430.25it/s] 60%|█████▉    | 64555/108000 [01:57<01:44, 414.11it/s] 60%|█████▉    | 64597/108000 [01:57<01:51, 388.15it/s] 60%|█████▉    | 64637/108000 [01:57<01:57, 368.58it/s] 60%|█████▉    | 64678/108000 [01:57<01:55, 374.95it/s] 60%|█████▉    | 64729/108000 [01:57<01:45, 410.23it/s] 60%|█████▉    | 64771/108000 [01:57<01:45, 409.83it/s] 60%|██████    | 64820/108000 [01:57<01:39, 432.08it/s] 60%|██████    | 64864/108000 [01:57<01:43, 416.88it/s] 60%|██████    | 64913/108000 [01:57<01:40, 430.05it/s] 60%|██████    | 64980/108000 [01:58<01:27, 489.15it/s] 60%|██████    | 65030/108000 [01:58<01:29, 480.77it/s] 60%|██████    | 65083/108000 [01:58<01:27, 490.76it/s] 60%|██████    | 65156/108000 [01:58<01:17, 555.48it/s] 60%|██████    | 65212/108000 [01:58<01:20, 532.96it/s] 60%|██████    | 65280/108000 [01:58<01:16, 561.99it/s] 60%|██████    | 65337/108000 [01:58<01:17, 552.32it/s] 61%|██████    | 65393/108000 [01:58<01:21, 522.38it/s] 61%|██████    | 65446/108000 [01:58<01:21, 522.83it/s] 61%|██████    | 65518/108000 [01:59<01:16, 552.36it/s] 61%|██████    | 65574/108000 [01:59<01:21, 518.84it/s] 61%|██████    | 65627/108000 [01:59<01:23, 508.24it/s] 61%|██████    | 65678/108000 [01:59<01:25, 497.03it/s] 61%|██████    | 65740/108000 [01:59<01:21, 520.65it/s] 61%|██████    | 65795/108000 [01:59<01:21, 516.88it/s] 61%|██████    | 65847/108000 [01:59<01:28, 474.10it/s] 61%|██████    | 65895/108000 [01:59<01:30, 467.06it/s] 61%|██████    | 65955/108000 [01:59<01:24, 497.47it/s] 61%|██████    | 66019/108000 [02:00<01:18, 533.36it/s] 61%|██████    | 66080/108000 [02:00<01:15, 554.54it/s] 61%|██████    | 66136/108000 [02:00<01:21, 514.31it/s] 61%|██████▏   | 66191/108000 [02:00<01:20, 519.96it/s] 61%|██████▏   | 66260/108000 [02:00<01:16, 546.01it/s] 61%|██████▏   | 66315/108000 [02:00<01:16, 544.09it/s] 61%|██████▏   | 66371/108000 [02:00<01:16, 544.67it/s] 62%|██████▏   | 66426/108000 [02:00<01:20, 516.68it/s] 62%|██████▏   | 66491/108000 [02:00<01:16, 539.12it/s] 62%|██████▏   | 66558/108000 [02:01<01:13, 560.93it/s] 62%|██████▏   | 66615/108000 [02:01<01:13, 559.90it/s] 62%|██████▏   | 66672/108000 [02:01<01:18, 528.27it/s] 62%|██████▏   | 66730/108000 [02:01<01:17, 535.09it/s] 62%|██████▏   | 66784/108000 [02:01<01:29, 461.62it/s] 62%|██████▏   | 66832/108000 [02:01<01:51, 370.65it/s] 62%|██████▏   | 66900/108000 [02:01<01:33, 440.25it/s] 62%|██████▏   | 66949/108000 [02:01<01:37, 419.44it/s] 62%|██████▏   | 67001/108000 [02:02<01:33, 437.38it/s] 62%|██████▏   | 67052/108000 [02:02<01:30, 452.79it/s] 62%|██████▏   | 67100/108000 [02:02<01:29, 455.19it/s] 62%|██████▏   | 67148/108000 [02:02<01:29, 458.93it/s] 62%|██████▏   | 67204/108000 [02:02<01:25, 477.70it/s] 62%|██████▏   | 67265/108000 [02:02<01:20, 505.43it/s] 62%|██████▏   | 67338/108000 [02:02<01:11, 568.66it/s] 62%|██████▏   | 67396/108000 [02:02<01:12, 562.40it/s] 62%|██████▏   | 67453/108000 [02:02<01:12, 563.15it/s] 63%|██████▎   | 67511/108000 [02:03<01:11, 567.71it/s] 63%|██████▎   | 67591/108000 [02:03<01:03, 634.76it/s] 63%|██████▎   | 67660/108000 [02:03<01:02, 650.29it/s] 63%|██████▎   | 67726/108000 [02:03<01:07, 597.67it/s] 63%|██████▎   | 67787/108000 [02:03<01:09, 577.74it/s] 63%|██████▎   | 67868/108000 [02:03<01:04, 625.45it/s] 63%|██████▎   | 67932/108000 [02:03<01:04, 622.08it/s] 63%|██████▎   | 67995/108000 [02:03<01:09, 573.32it/s] 63%|██████▎   | 68054/108000 [02:03<01:10, 569.20it/s] 63%|██████▎   | 68129/108000 [02:04<01:05, 612.55it/s] 63%|██████▎   | 68191/108000 [02:04<01:08, 580.80it/s] 63%|██████▎   | 68250/108000 [02:04<01:08, 579.26it/s] 63%|██████▎   | 68309/108000 [02:04<01:12, 551.17it/s] 63%|██████▎   | 68381/108000 [02:04<01:06, 596.56it/s] 63%|██████▎   | 68457/108000 [02:04<01:02, 634.87it/s] 63%|██████▎   | 68530/108000 [02:04<00:59, 661.16it/s] 64%|██████▎   | 68597/108000 [02:04<00:59, 662.15it/s] 64%|██████▎   | 68664/108000 [02:04<01:06, 592.71it/s] 64%|██████▎   | 68727/108000 [02:05<01:05, 601.24it/s] 64%|██████▎   | 68789/108000 [02:05<01:04, 604.58it/s] 64%|██████▍   | 68851/108000 [02:05<01:04, 608.88it/s] 64%|██████▍   | 68917/108000 [02:05<01:02, 620.88it/s] 64%|██████▍   | 69009/108000 [02:05<00:56, 695.15it/s] 64%|██████▍   | 69079/108000 [02:05<01:00, 644.15it/s] 64%|██████▍   | 69151/108000 [02:05<00:59, 653.95it/s] 64%|██████▍   | 69224/108000 [02:05<00:57, 669.39it/s] 64%|██████▍   | 69307/108000 [02:05<00:54, 706.23it/s] 64%|██████▍   | 69387/108000 [02:05<00:53, 724.47it/s] 64%|██████▍   | 69460/108000 [02:06<00:59, 653.09it/s] 64%|██████▍   | 69547/108000 [02:06<00:54, 709.80it/s] 64%|██████▍   | 69620/108000 [02:06<00:54, 702.58it/s] 65%|██████▍   | 69692/108000 [02:06<01:05, 582.20it/s] 65%|██████▍   | 69755/108000 [02:06<01:11, 535.85it/s] 65%|██████▍   | 69824/108000 [02:06<01:06, 571.38it/s] 65%|██████▍   | 69893/108000 [02:06<01:03, 598.30it/s] 65%|██████▍   | 69956/108000 [02:06<01:06, 572.94it/s] 65%|██████▍   | 70016/108000 [02:07<01:05, 577.75it/s] 65%|██████▍   | 70086/108000 [02:07<01:03, 595.61it/s] 65%|██████▍   | 70147/108000 [02:07<01:04, 586.63it/s] 65%|██████▌   | 70207/108000 [02:07<01:15, 501.02it/s] 65%|██████▌   | 70260/108000 [02:07<01:16, 491.85it/s] 65%|██████▌   | 70326/108000 [02:07<01:10, 534.47it/s] 65%|██████▌   | 70386/108000 [02:07<01:08, 551.94it/s] 65%|██████▌   | 70443/108000 [02:07<01:15, 494.64it/s] 65%|██████▌   | 70522/108000 [02:08<01:06, 563.52it/s] 65%|██████▌   | 70581/108000 [02:08<01:05, 570.53it/s] 65%|██████▌   | 70640/108000 [02:08<01:07, 552.65it/s] 65%|██████▌   | 70697/108000 [02:08<01:07, 553.17it/s] 66%|██████▌   | 70754/108000 [02:08<01:08, 543.01it/s] 66%|██████▌   | 70809/108000 [02:08<01:14, 501.61it/s] 66%|██████▌   | 70864/108000 [02:08<01:12, 513.37it/s] 66%|██████▌   | 70917/108000 [02:08<01:13, 504.06it/s] 66%|██████▌   | 70976/108000 [02:08<01:11, 515.33it/s] 66%|██████▌   | 71028/108000 [02:08<01:14, 496.20it/s] 66%|██████▌   | 71083/108000 [02:09<01:14, 495.28it/s] 66%|██████▌   | 71145/108000 [02:09<01:09, 527.78it/s] 66%|██████▌   | 71207/108000 [02:09<01:06, 553.38it/s] 66%|██████▌   | 71263/108000 [02:09<01:06, 551.41it/s] 66%|██████▌   | 71319/108000 [02:09<01:11, 513.65it/s] 66%|██████▌   | 71392/108000 [02:09<01:08, 533.42it/s] 66%|██████▌   | 71453/108000 [02:09<01:05, 553.78it/s] 66%|██████▌   | 71513/108000 [02:09<01:05, 557.60it/s] 66%|██████▋   | 71577/108000 [02:09<01:03, 569.80it/s] 66%|██████▋   | 71647/108000 [02:10<01:00, 597.86it/s] 66%|██████▋   | 71708/108000 [02:10<01:03, 572.91it/s] 66%|██████▋   | 71775/108000 [02:10<01:02, 581.11it/s] 67%|██████▋   | 71839/108000 [02:10<01:01, 590.75it/s] 67%|██████▋   | 71899/108000 [02:10<01:02, 574.24it/s] 67%|██████▋   | 71987/108000 [02:10<00:56, 641.41it/s] 67%|██████▋   | 72052/108000 [02:10<01:03, 569.30it/s] 67%|██████▋   | 72111/108000 [02:10<01:04, 558.52it/s] 67%|██████▋   | 72168/108000 [02:11<01:08, 526.65it/s] 67%|██████▋   | 72222/108000 [02:11<01:08, 520.79it/s] 67%|██████▋   | 72275/108000 [02:11<01:10, 503.48it/s] 67%|██████▋   | 72332/108000 [02:11<01:09, 510.28it/s] 67%|██████▋   | 72385/108000 [02:11<01:09, 515.51it/s] 67%|██████▋   | 72437/108000 [02:11<01:13, 485.57it/s] 67%|██████▋   | 72486/108000 [02:11<01:25, 416.96it/s] 67%|██████▋   | 72537/108000 [02:11<01:20, 439.68it/s] 67%|██████▋   | 72596/108000 [02:11<01:14, 476.62it/s] 67%|██████▋   | 72666/108000 [02:12<01:07, 526.70it/s] 67%|██████▋   | 72731/108000 [02:12<01:03, 559.02it/s] 67%|██████▋   | 72789/108000 [02:12<01:09, 508.63it/s] 67%|██████▋   | 72842/108000 [02:12<01:13, 479.26it/s] 67%|██████▋   | 72893/108000 [02:12<01:12, 481.62it/s] 68%|██████▊   | 72943/108000 [02:12<01:12, 483.57it/s] 68%|██████▊   | 72993/108000 [02:12<01:16, 458.47it/s] 68%|██████▊   | 73040/108000 [02:12<01:20, 435.33it/s] 68%|██████▊   | 73085/108000 [02:13<01:29, 390.26it/s] 68%|██████▊   | 73127/108000 [02:13<01:28, 393.35it/s] 68%|██████▊   | 73168/108000 [02:13<01:32, 375.01it/s] 68%|██████▊   | 73212/108000 [02:13<01:30, 385.43it/s] 68%|██████▊   | 73289/108000 [02:13<01:11, 487.50it/s] 68%|██████▊   | 73340/108000 [02:13<01:25, 403.35it/s] 68%|██████▊   | 73394/108000 [02:13<01:19, 434.62it/s] 68%|██████▊   | 73441/108000 [02:13<01:19, 436.39it/s] 68%|██████▊   | 73502/108000 [02:13<01:12, 476.68it/s] 68%|██████▊   | 73552/108000 [02:14<01:16, 449.04it/s] 68%|██████▊   | 73613/108000 [02:14<01:10, 487.51it/s] 68%|██████▊   | 73673/108000 [02:14<01:07, 508.92it/s] 68%|██████▊   | 73733/108000 [02:14<01:05, 524.00it/s] 68%|██████▊   | 73787/108000 [02:14<01:10, 485.59it/s] 68%|██████▊   | 73844/108000 [02:14<01:07, 503.10it/s] 68%|██████▊   | 73897/108000 [02:14<01:06, 510.25it/s] 68%|██████▊   | 73949/108000 [02:14<01:08, 499.36it/s] 69%|██████▊   | 74000/108000 [02:14<01:14, 457.47it/s] 69%|██████▊   | 74058/108000 [02:15<01:09, 489.31it/s] 69%|██████▊   | 74112/108000 [02:15<01:08, 492.23it/s] 69%|██████▊   | 74199/108000 [02:15<00:56, 596.67it/s] 69%|██████▉   | 74260/108000 [02:15<00:58, 573.83it/s] 69%|██████▉   | 74329/108000 [02:15<00:56, 593.00it/s] 69%|██████▉   | 74390/108000 [02:15<01:04, 521.27it/s] 69%|██████▉   | 74445/108000 [02:15<01:08, 491.20it/s] 69%|██████▉   | 74496/108000 [02:15<01:14, 447.46it/s] 69%|██████▉   | 74554/108000 [02:16<01:10, 477.12it/s] 69%|██████▉   | 74604/108000 [02:16<01:18, 426.82it/s] 69%|██████▉   | 74649/108000 [02:16<01:25, 388.25it/s] 69%|██████▉   | 74690/108000 [02:16<01:28, 378.51it/s] 69%|██████▉   | 74729/108000 [02:16<01:29, 370.26it/s] 69%|██████▉   | 74767/108000 [02:16<01:41, 325.87it/s] 69%|██████▉   | 74818/108000 [02:16<01:29, 370.49it/s] 69%|██████▉   | 74857/108000 [02:16<01:32, 358.54it/s] 69%|██████▉   | 74895/108000 [02:17<01:53, 292.80it/s] 69%|██████▉   | 74951/108000 [02:17<01:35, 345.48it/s] 69%|██████▉   | 74989/108000 [02:17<01:39, 332.58it/s] 69%|██████▉   | 75032/108000 [02:17<01:33, 350.98it/s] 70%|██████▉   | 75071/108000 [02:17<01:31, 359.89it/s] 70%|██████▉   | 75109/108000 [02:17<01:31, 360.32it/s] 70%|██████▉   | 75146/108000 [02:17<01:33, 349.56it/s] 70%|██████▉   | 75182/108000 [02:17<01:39, 328.94it/s] 70%|██████▉   | 75216/108000 [02:18<01:44, 314.01it/s] 70%|██████▉   | 75254/108000 [02:18<01:39, 328.41it/s] 70%|██████▉   | 75296/108000 [02:18<01:33, 350.21it/s] 70%|██████▉   | 75332/108000 [02:18<01:33, 349.53it/s] 70%|██████▉   | 75380/108000 [02:18<01:24, 384.10it/s] 70%|██████▉   | 75419/108000 [02:18<01:32, 352.03it/s] 70%|██████▉   | 75465/108000 [02:18<01:25, 379.29it/s] 70%|██████▉   | 75504/108000 [02:18<01:27, 372.77it/s] 70%|██████▉   | 75543/108000 [02:18<01:26, 377.40it/s] 70%|██████▉   | 75582/108000 [02:19<01:30, 358.70it/s] 70%|███████   | 75619/108000 [02:19<01:30, 358.79it/s] 70%|███████   | 75668/108000 [02:19<01:26, 375.01it/s] 70%|███████   | 75713/108000 [02:19<01:22, 393.71it/s] 70%|███████   | 75753/108000 [02:19<01:26, 373.46it/s] 70%|███████   | 75795/108000 [02:19<01:27, 369.13it/s] 70%|███████   | 75833/108000 [02:19<01:31, 350.38it/s] 70%|███████   | 75898/108000 [02:19<01:16, 420.53it/s] 70%|███████   | 75941/108000 [02:19<01:18, 408.76it/s] 70%|███████   | 75983/108000 [02:20<01:23, 382.75it/s] 70%|███████   | 76022/108000 [02:20<01:32, 344.72it/s] 70%|███████   | 76063/108000 [02:20<01:28, 360.58it/s] 70%|███████   | 76100/108000 [02:20<01:30, 351.08it/s] 70%|███████   | 76137/108000 [02:20<01:29, 356.10it/s] 71%|███████   | 76174/108000 [02:20<01:35, 332.24it/s] 71%|███████   | 76221/108000 [02:20<01:27, 361.82it/s] 71%|███████   | 76259/108000 [02:20<01:27, 361.61it/s] 71%|███████   | 76297/108000 [02:20<01:28, 356.45it/s] 71%|███████   | 76337/108000 [02:21<01:31, 346.41it/s] 71%|███████   | 76380/108000 [02:21<01:25, 368.25it/s] 71%|███████   | 76434/108000 [02:21<01:16, 415.06it/s] 71%|███████   | 76477/108000 [02:21<01:24, 374.57it/s] 71%|███████   | 76517/108000 [02:21<01:23, 376.88it/s] 71%|███████   | 76556/108000 [02:21<01:24, 373.61it/s] 71%|███████   | 76595/108000 [02:21<01:24, 372.12it/s] 71%|███████   | 76633/108000 [02:21<01:28, 355.55it/s] 71%|███████   | 76682/108000 [02:21<01:20, 389.89it/s] 71%|███████   | 76722/108000 [02:22<01:20, 389.36it/s] 71%|███████   | 76762/108000 [02:22<01:32, 338.83it/s] 71%|███████   | 76827/108000 [02:22<01:16, 408.96it/s] 71%|███████   | 76885/108000 [02:22<01:08, 452.12it/s] 71%|███████▏  | 76951/108000 [02:22<01:01, 508.41it/s] 71%|███████▏  | 77004/108000 [02:22<01:01, 508.09it/s] 71%|███████▏  | 77066/108000 [02:22<00:57, 533.61it/s] 71%|███████▏  | 77131/108000 [02:22<00:54, 561.76it/s] 71%|███████▏  | 77194/108000 [02:22<00:54, 566.86it/s] 72%|███████▏  | 77252/108000 [02:23<00:59, 517.45it/s] 72%|███████▏  | 77330/108000 [02:23<00:52, 585.61it/s] 72%|███████▏  | 77390/108000 [02:23<00:55, 549.16it/s] 72%|███████▏  | 77463/108000 [02:23<00:51, 597.41it/s] 72%|███████▏  | 77525/108000 [02:23<00:56, 536.48it/s] 72%|███████▏  | 77596/108000 [02:23<00:52, 581.63it/s] 72%|███████▏  | 77666/108000 [02:23<00:49, 613.63it/s] 72%|███████▏  | 77730/108000 [02:23<00:50, 598.89it/s] 72%|███████▏  | 77792/108000 [02:24<00:54, 555.89it/s] 72%|███████▏  | 77859/108000 [02:24<00:51, 584.49it/s] 72%|███████▏  | 77920/108000 [02:24<00:50, 590.14it/s] 72%|███████▏  | 77980/108000 [02:24<00:52, 570.59it/s] 72%|███████▏  | 78038/108000 [02:24<00:53, 558.98it/s] 72%|███████▏  | 78109/108000 [02:24<00:50, 591.91it/s] 72%|███████▏  | 78169/108000 [02:24<00:56, 530.81it/s] 72%|███████▏  | 78239/108000 [02:24<00:51, 574.12it/s] 73%|███████▎  | 78319/108000 [02:24<00:48, 613.67it/s] 73%|███████▎  | 78382/108000 [02:24<00:47, 617.70it/s] 73%|███████▎  | 78445/108000 [02:25<00:49, 602.99it/s] 73%|███████▎  | 78506/108000 [02:25<00:48, 603.07it/s] 73%|███████▎  | 78567/108000 [02:25<00:54, 542.35it/s] 73%|███████▎  | 78625/108000 [02:25<00:53, 550.07it/s] 73%|███████▎  | 78681/108000 [02:25<00:53, 543.13it/s] 73%|███████▎  | 78742/108000 [02:25<00:52, 557.94it/s] 73%|███████▎  | 78799/108000 [02:25<00:52, 554.24it/s] 73%|███████▎  | 78871/108000 [02:25<00:48, 594.48it/s] 73%|███████▎  | 78931/108000 [02:25<00:50, 575.52it/s] 73%|███████▎  | 78989/108000 [02:26<00:52, 554.16it/s] 73%|███████▎  | 79048/108000 [02:26<00:51, 564.10it/s] 73%|███████▎  | 79105/108000 [02:26<00:55, 516.65it/s] 73%|███████▎  | 79162/108000 [02:26<00:54, 529.58it/s] 73%|███████▎  | 79217/108000 [02:26<00:54, 531.55it/s] 73%|███████▎  | 79271/108000 [02:26<01:05, 435.95it/s] 73%|███████▎  | 79318/108000 [02:26<01:06, 429.95it/s] 73%|███████▎  | 79365/108000 [02:26<01:06, 433.78it/s] 74%|███████▎  | 79421/108000 [02:27<01:02, 460.26it/s] 74%|███████▎  | 79469/108000 [02:27<01:06, 431.51it/s] 74%|███████▎  | 79532/108000 [02:27<00:59, 479.92it/s] 74%|███████▎  | 79582/108000 [02:27<00:59, 474.66it/s] 74%|███████▎  | 79631/108000 [02:27<01:08, 414.27it/s] 74%|███████▍  | 79675/108000 [02:27<01:11, 398.94it/s] 74%|███████▍  | 79723/108000 [02:27<01:08, 412.10it/s] 74%|███████▍  | 79766/108000 [02:27<01:09, 405.17it/s] 74%|███████▍  | 79808/108000 [02:27<01:12, 388.54it/s] 74%|███████▍  | 79861/108000 [02:28<01:09, 407.41it/s] 74%|███████▍  | 79903/108000 [02:28<01:14, 378.78it/s] 74%|███████▍  | 79947/108000 [02:28<01:14, 375.66it/s] 74%|███████▍  | 80006/108000 [02:28<01:05, 427.06it/s] 74%|███████▍  | 80058/108000 [02:28<01:02, 448.82it/s] 74%|███████▍  | 80104/108000 [02:28<01:15, 371.00it/s] 74%|███████▍  | 80157/108000 [02:28<01:08, 408.99it/s] 74%|███████▍  | 80209/108000 [02:28<01:04, 432.02it/s] 74%|███████▍  | 80268/108000 [02:29<01:02, 443.22it/s] 74%|███████▍  | 80314/108000 [02:29<01:03, 433.98it/s] 74%|███████▍  | 80368/108000 [02:29<01:01, 447.82it/s] 74%|███████▍  | 80414/108000 [02:29<01:04, 424.44it/s] 74%|███████▍  | 80458/108000 [02:29<01:06, 416.45it/s] 75%|███████▍  | 80501/108000 [02:29<01:06, 414.40it/s] 75%|███████▍  | 80543/108000 [02:29<01:09, 395.89it/s] 75%|███████▍  | 80602/108000 [02:29<01:01, 444.67it/s] 75%|███████▍  | 80647/108000 [02:29<01:01, 444.43it/s] 75%|███████▍  | 80692/108000 [02:30<01:05, 417.67it/s] 75%|███████▍  | 80735/108000 [02:30<01:06, 409.85it/s] 75%|███████▍  | 80777/108000 [02:30<01:09, 389.51it/s] 75%|███████▍  | 80819/108000 [02:30<01:09, 390.58it/s] 75%|███████▍  | 80860/108000 [02:30<01:08, 395.52it/s] 75%|███████▍  | 80900/108000 [02:30<01:08, 394.33it/s] 75%|███████▍  | 80940/108000 [02:30<01:13, 368.39it/s] 75%|███████▍  | 80985/108000 [02:30<01:11, 379.64it/s] 75%|███████▌  | 81051/108000 [02:30<01:01, 439.68it/s] 75%|███████▌  | 81096/108000 [02:31<01:08, 394.52it/s] 75%|███████▌  | 81137/108000 [02:31<01:09, 386.54it/s] 75%|███████▌  | 81207/108000 [02:31<00:57, 463.37it/s] 75%|███████▌  | 81255/108000 [02:31<01:01, 431.55it/s] 75%|███████▌  | 81305/108000 [02:31<01:20, 331.33it/s] 75%|███████▌  | 81355/108000 [02:31<01:15, 352.00it/s] 75%|███████▌  | 81402/108000 [02:31<01:10, 377.59it/s] 75%|███████▌  | 81448/108000 [02:32<01:06, 396.48it/s] 75%|███████▌  | 81491/108000 [02:32<01:10, 376.63it/s] 75%|███████▌  | 81531/108000 [02:32<01:11, 371.16it/s] 76%|███████▌  | 81570/108000 [02:32<01:12, 366.09it/s] 76%|███████▌  | 81608/108000 [02:32<01:18, 337.90it/s] 76%|███████▌  | 81647/108000 [02:32<01:19, 330.14it/s] 76%|███████▌  | 81681/108000 [02:32<01:22, 320.47it/s] 76%|███████▌  | 81717/108000 [02:32<01:21, 324.11it/s] 76%|███████▌  | 81762/108000 [02:32<01:16, 344.55it/s] 76%|███████▌  | 81807/108000 [02:33<01:13, 355.99it/s] 76%|███████▌  | 81846/108000 [02:33<01:12, 361.36it/s] 76%|███████▌  | 81893/108000 [02:33<01:09, 374.81it/s] 76%|███████▌  | 81931/108000 [02:33<01:13, 354.62it/s] 76%|███████▌  | 81967/108000 [02:33<01:16, 341.42it/s] 76%|███████▌  | 82002/108000 [02:33<01:17, 335.57it/s] 76%|███████▌  | 82036/108000 [02:33<01:32, 281.16it/s] 76%|███████▌  | 82075/108000 [02:33<01:24, 307.25it/s] 76%|███████▌  | 82130/108000 [02:34<01:09, 369.72it/s] 76%|███████▌  | 82169/108000 [02:34<01:10, 368.25it/s] 76%|███████▌  | 82208/108000 [02:34<01:14, 346.99it/s] 76%|███████▌  | 82264/108000 [02:34<01:06, 386.79it/s] 76%|███████▌  | 82304/108000 [02:34<01:16, 334.81it/s] 76%|███████▋  | 82352/108000 [02:34<01:10, 366.39it/s] 76%|███████▋  | 82391/108000 [02:34<01:12, 353.17it/s] 76%|███████▋  | 82437/108000 [02:34<01:08, 374.72it/s] 76%|███████▋  | 82476/108000 [02:34<01:08, 374.95it/s] 76%|███████▋  | 82515/108000 [02:35<01:07, 378.76it/s] 76%|███████▋  | 82554/108000 [02:35<01:14, 341.34it/s] 76%|███████▋  | 82590/108000 [02:35<01:14, 342.22it/s] 77%|███████▋  | 82625/108000 [02:35<01:14, 339.68it/s] 77%|███████▋  | 82660/108000 [02:35<01:16, 332.75it/s] 77%|███████▋  | 82706/108000 [02:35<01:11, 351.57it/s] 77%|███████▋  | 82744/108000 [02:35<01:12, 348.79it/s] 77%|███████▋  | 82785/108000 [02:35<01:09, 361.78it/s] 77%|███████▋  | 82822/108000 [02:35<01:10, 357.78it/s] 77%|███████▋  | 82858/108000 [02:36<01:18, 321.77it/s] 77%|███████▋  | 82900/108000 [02:36<01:13, 340.87it/s] 77%|███████▋  | 82945/108000 [02:36<01:08, 364.32it/s] 77%|███████▋  | 82987/108000 [02:36<01:06, 378.92it/s] 77%|███████▋  | 83026/108000 [02:36<01:07, 368.35it/s] 77%|███████▋  | 83064/108000 [02:36<01:17, 323.28it/s] 77%|███████▋  | 83098/108000 [02:36<01:21, 305.74it/s] 77%|███████▋  | 83143/108000 [02:36<01:12, 342.15it/s] 77%|███████▋  | 83184/108000 [02:37<01:10, 354.43it/s] 77%|███████▋  | 83221/108000 [02:37<01:11, 345.34it/s] 77%|███████▋  | 83259/108000 [02:37<01:14, 333.61it/s] 77%|███████▋  | 83293/108000 [02:37<01:15, 327.45it/s] 77%|███████▋  | 83333/108000 [02:37<01:11, 346.62it/s] 77%|███████▋  | 83373/108000 [02:37<01:08, 361.54it/s] 77%|███████▋  | 83410/108000 [02:37<01:11, 342.62it/s] 77%|███████▋  | 83447/108000 [02:37<01:15, 327.06it/s] 77%|███████▋  | 83481/108000 [02:37<01:15, 323.57it/s] 77%|███████▋  | 83528/108000 [02:38<01:08, 358.97it/s] 77%|███████▋  | 83565/108000 [02:38<01:13, 330.57it/s] 77%|███████▋  | 83603/108000 [02:38<01:11, 340.61it/s] 77%|███████▋  | 83638/108000 [02:38<01:11, 339.67it/s] 77%|███████▋  | 83673/108000 [02:38<01:13, 331.12it/s] 78%|███████▊  | 83717/108000 [02:38<01:09, 351.39it/s] 78%|███████▊  | 83756/108000 [02:38<01:08, 352.37it/s] 78%|███████▊  | 83804/108000 [02:38<01:03, 379.32it/s] 78%|███████▊  | 83846/108000 [02:38<01:07, 359.63it/s] 78%|███████▊  | 83883/108000 [02:39<01:14, 322.75it/s] 78%|███████▊  | 83937/108000 [02:39<01:03, 376.95it/s] 78%|███████▊  | 83977/108000 [02:39<01:08, 348.81it/s] 78%|███████▊  | 84014/108000 [02:39<01:17, 309.96it/s] 78%|███████▊  | 84047/108000 [02:39<01:44, 229.86it/s] 78%|███████▊  | 84074/108000 [02:40<02:12, 181.24it/s] 78%|███████▊  | 84096/108000 [02:40<02:31, 158.22it/s] 78%|███████▊  | 84115/108000 [02:40<02:39, 149.52it/s] 78%|███████▊  | 84132/108000 [02:40<02:52, 138.46it/s] 78%|███████▊  | 84147/108000 [02:40<03:01, 131.51it/s] 78%|███████▊  | 84168/108000 [02:40<02:44, 145.03it/s] 78%|███████▊  | 84184/108000 [02:40<02:57, 134.55it/s] 78%|███████▊  | 84202/108000 [02:41<02:44, 144.59it/s] 78%|███████▊  | 84218/108000 [02:41<02:57, 133.90it/s] 78%|███████▊  | 84232/108000 [02:41<02:55, 135.21it/s] 78%|███████▊  | 84246/108000 [02:41<03:17, 120.29it/s] 78%|███████▊  | 84259/108000 [02:41<03:28, 113.62it/s] 78%|███████▊  | 84281/108000 [02:41<02:57, 133.92it/s] 78%|███████▊  | 84295/108000 [02:41<03:14, 121.69it/s] 78%|███████▊  | 84308/108000 [02:41<03:27, 114.01it/s] 78%|███████▊  | 84329/108000 [02:42<02:58, 132.98it/s] 78%|███████▊  | 84344/108000 [02:42<02:56, 133.68it/s] 78%|███████▊  | 84358/108000 [02:42<03:06, 126.46it/s] 78%|███████▊  | 84371/108000 [02:42<03:17, 119.69it/s] 78%|███████▊  | 84388/108000 [02:42<02:58, 131.96it/s] 78%|███████▊  | 84402/108000 [02:42<03:14, 121.54it/s] 78%|███████▊  | 84424/108000 [02:42<02:44, 143.63it/s] 78%|███████▊  | 84439/108000 [02:42<03:14, 121.03it/s] 78%|███████▊  | 84457/108000 [02:43<03:03, 128.09it/s] 78%|███████▊  | 84471/108000 [02:43<03:18, 118.32it/s] 78%|███████▊  | 84489/108000 [02:43<02:57, 132.50it/s] 78%|███████▊  | 84506/108000 [02:43<02:53, 135.76it/s] 78%|███████▊  | 84522/108000 [02:43<03:03, 127.89it/s] 78%|███████▊  | 84536/108000 [02:43<03:00, 130.29it/s] 78%|███████▊  | 84550/108000 [02:43<02:59, 130.91it/s] 78%|███████▊  | 84564/108000 [02:43<03:09, 123.55it/s] 78%|███████▊  | 84577/108000 [02:44<03:18, 117.81it/s] 78%|███████▊  | 84589/108000 [02:44<03:50, 101.68it/s] 78%|███████▊  | 84605/108000 [02:44<03:24, 114.67it/s] 78%|███████▊  | 84618/108000 [02:44<03:29, 111.67it/s] 78%|███████▊  | 84644/108000 [02:44<02:42, 144.00it/s] 78%|███████▊  | 84659/108000 [02:44<02:50, 136.76it/s] 78%|███████▊  | 84674/108000 [02:44<02:54, 134.00it/s] 78%|███████▊  | 84690/108000 [02:44<02:54, 133.86it/s] 78%|███████▊  | 84706/108000 [02:45<02:49, 137.11it/s] 78%|███████▊  | 84724/108000 [02:45<02:37, 147.44it/s] 78%|███████▊  | 84739/108000 [02:45<02:51, 135.72it/s] 78%|███████▊  | 84754/108000 [02:45<02:49, 137.47it/s] 78%|███████▊  | 84768/108000 [02:45<02:53, 134.22it/s] 79%|███████▊  | 84782/108000 [02:45<03:37, 106.95it/s] 79%|███████▊  | 84795/108000 [02:45<03:27, 112.07it/s] 79%|███████▊  | 84809/108000 [02:45<03:17, 117.30it/s] 79%|███████▊  | 84823/108000 [02:45<03:12, 120.51it/s] 79%|███████▊  | 84836/108000 [02:46<03:09, 122.16it/s] 79%|███████▊  | 84850/108000 [02:46<03:05, 125.14it/s] 79%|███████▊  | 84863/108000 [02:46<03:20, 115.62it/s] 79%|███████▊  | 84878/108000 [02:46<03:05, 124.48it/s] 79%|███████▊  | 84892/108000 [02:46<03:03, 126.24it/s] 79%|███████▊  | 84905/108000 [02:46<04:04, 94.63it/s]  79%|███████▊  | 84917/108000 [02:46<03:52, 99.16it/s] 79%|███████▊  | 84928/108000 [02:46<03:47, 101.23it/s] 79%|███████▊  | 84939/108000 [02:47<03:54, 98.19it/s]  79%|███████▊  | 84950/108000 [02:47<04:01, 95.28it/s] 79%|███████▊  | 84967/108000 [02:47<03:25, 112.01it/s] 79%|███████▊  | 84983/108000 [02:47<03:09, 121.46it/s] 79%|███████▊  | 85003/108000 [02:47<02:45, 138.92it/s] 79%|███████▊  | 85018/108000 [02:47<02:56, 130.38it/s] 79%|███████▊  | 85032/108000 [02:47<03:06, 123.00it/s] 79%|███████▊  | 85045/108000 [02:47<03:10, 120.50it/s] 79%|███████▉  | 85062/108000 [02:48<02:55, 130.76it/s] 79%|███████▉  | 85076/108000 [02:48<03:14, 117.74it/s] 79%|███████▉  | 85094/108000 [02:48<02:53, 131.85it/s] 79%|███████▉  | 85108/108000 [02:48<02:59, 127.60it/s] 79%|███████▉  | 85122/108000 [02:48<03:00, 126.50it/s] 79%|███████▉  | 85144/108000 [02:48<02:30, 151.43it/s] 79%|███████▉  | 85160/108000 [02:48<02:55, 130.40it/s] 79%|███████▉  | 85176/108000 [02:48<02:48, 135.17it/s] 79%|███████▉  | 85191/108000 [02:49<02:53, 131.44it/s] 79%|███████▉  | 85208/108000 [02:49<02:44, 138.17it/s] 79%|███████▉  | 85223/108000 [02:49<02:56, 128.97it/s] 79%|███████▉  | 85240/108000 [02:49<02:45, 137.37it/s] 79%|███████▉  | 85255/108000 [02:49<02:58, 127.21it/s] 79%|███████▉  | 85269/108000 [02:49<03:01, 125.48it/s] 79%|███████▉  | 85282/108000 [02:49<03:04, 122.90it/s] 79%|███████▉  | 85295/108000 [02:49<03:02, 124.64it/s] 79%|███████▉  | 85312/108000 [02:49<02:47, 135.29it/s] 79%|███████▉  | 85326/108000 [02:50<03:00, 125.95it/s] 79%|███████▉  | 85341/108000 [02:50<02:51, 132.17it/s] 79%|███████▉  | 85355/108000 [02:50<03:17, 114.46it/s] 79%|███████▉  | 85376/108000 [02:50<02:45, 136.68it/s] 79%|███████▉  | 85395/108000 [02:50<02:39, 141.36it/s] 79%|███████▉  | 85410/108000 [02:50<02:49, 133.13it/s] 79%|███████▉  | 85424/108000 [02:50<03:13, 116.37it/s] 79%|███████▉  | 85444/108000 [02:50<02:47, 134.31it/s] 79%|███████▉  | 85459/108000 [02:51<02:43, 137.90it/s] 79%|███████▉  | 85474/108000 [02:51<02:49, 133.05it/s] 79%|███████▉  | 85492/108000 [02:51<02:38, 141.71it/s] 79%|███████▉  | 85507/108000 [02:51<02:47, 134.45it/s] 79%|███████▉  | 85521/108000 [02:51<02:57, 126.57it/s] 79%|███████▉  | 85536/108000 [02:51<02:56, 127.57it/s] 79%|███████▉  | 85549/108000 [02:51<03:00, 124.21it/s] 79%|███████▉  | 85563/108000 [02:51<02:56, 127.23it/s] 79%|███████▉  | 85580/108000 [02:51<02:44, 136.45it/s] 79%|███████▉  | 85594/108000 [02:52<02:51, 130.62it/s] 79%|███████▉  | 85610/108000 [02:52<02:50, 131.40it/s] 79%|███████▉  | 85624/108000 [02:52<02:55, 127.58it/s] 79%|███████▉  | 85637/108000 [02:52<03:05, 120.34it/s] 79%|███████▉  | 85657/108000 [02:52<02:40, 138.98it/s] 79%|███████▉  | 85672/108000 [02:52<03:06, 119.99it/s] 79%|███████▉  | 85691/108000 [02:52<02:42, 137.07it/s] 79%|███████▉  | 85708/108000 [02:52<02:36, 142.63it/s] 79%|███████▉  | 85723/108000 [02:53<02:48, 131.88it/s] 79%|███████▉  | 85737/108000 [02:53<02:48, 131.80it/s] 79%|███████▉  | 85751/108000 [02:53<03:00, 123.18it/s] 79%|███████▉  | 85764/108000 [02:53<03:16, 113.39it/s] 79%|███████▉  | 85780/108000 [02:53<02:59, 123.90it/s] 79%|███████▉  | 85797/108000 [02:53<02:43, 135.83it/s] 79%|███████▉  | 85814/108000 [02:53<02:33, 144.75it/s] 79%|███████▉  | 85829/108000 [02:53<02:42, 136.46it/s] 79%|███████▉  | 85843/108000 [02:54<02:56, 125.45it/s] 79%|███████▉  | 85856/108000 [02:54<02:57, 124.94it/s] 80%|███████▉  | 85869/108000 [02:54<03:19, 110.86it/s] 80%|███████▉  | 85888/108000 [02:54<02:57, 124.28it/s] 80%|███████▉  | 85901/108000 [02:54<02:59, 123.22it/s] 80%|███████▉  | 85918/108000 [02:54<02:47, 132.06it/s] 80%|███████▉  | 85932/108000 [02:54<03:18, 111.23it/s] 80%|███████▉  | 85947/108000 [02:54<03:07, 117.73it/s] 80%|███████▉  | 85960/108000 [02:55<03:02, 120.80it/s] 80%|███████▉  | 85976/108000 [02:55<02:52, 127.81it/s] 80%|███████▉  | 86002/108000 [02:55<02:20, 156.45it/s] 80%|███████▉  | 86018/108000 [02:55<02:34, 142.03it/s] 80%|███████▉  | 86033/108000 [02:55<02:40, 136.91it/s] 80%|███████▉  | 86047/108000 [02:55<02:43, 133.88it/s] 80%|███████▉  | 86061/108000 [02:55<02:53, 126.19it/s] 80%|███████▉  | 86077/108000 [02:55<02:42, 134.53it/s] 80%|███████▉  | 86091/108000 [02:55<03:01, 120.88it/s] 80%|███████▉  | 86104/108000 [02:56<03:04, 118.83it/s] 80%|███████▉  | 86123/108000 [02:56<02:41, 135.87it/s] 80%|███████▉  | 86137/108000 [02:56<02:45, 132.30it/s] 80%|███████▉  | 86151/108000 [02:56<03:13, 112.74it/s] 80%|███████▉  | 86165/108000 [02:56<03:08, 116.08it/s] 80%|███████▉  | 86178/108000 [02:56<03:25, 106.12it/s] 80%|███████▉  | 86202/108000 [02:56<02:37, 138.08it/s] 80%|███████▉  | 86223/108000 [02:56<02:29, 146.05it/s] 80%|███████▉  | 86239/108000 [02:57<02:28, 146.61it/s] 80%|███████▉  | 86255/108000 [02:57<02:32, 142.60it/s] 80%|███████▉  | 86270/108000 [02:57<02:37, 137.88it/s] 80%|███████▉  | 86285/108000 [02:57<02:40, 135.31it/s] 80%|███████▉  | 86299/108000 [02:57<02:47, 129.48it/s] 80%|███████▉  | 86313/108000 [02:57<03:03, 118.06it/s] 80%|███████▉  | 86333/108000 [02:57<02:41, 133.83it/s] 80%|███████▉  | 86350/108000 [02:57<02:34, 140.28it/s] 80%|███████▉  | 86365/108000 [02:58<02:49, 127.63it/s] 80%|███████▉  | 86380/108000 [02:58<02:42, 132.99it/s] 80%|███████▉  | 86394/108000 [02:58<02:44, 131.24it/s] 80%|████████  | 86445/108000 [02:58<01:32, 232.49it/s] 80%|████████  | 86516/108000 [02:58<00:58, 364.76it/s] 80%|████████  | 86577/108000 [02:58<00:49, 430.20it/s] 80%|████████  | 86633/108000 [02:58<00:45, 467.19it/s] 80%|████████  | 86699/108000 [02:58<00:40, 522.91it/s] 80%|████████  | 86753/108000 [02:58<00:40, 521.21it/s] 80%|████████  | 86806/108000 [02:59<00:41, 504.97it/s] 80%|████████  | 86871/108000 [02:59<00:39, 533.47it/s] 81%|████████  | 86953/108000 [02:59<00:35, 592.55it/s] 81%|████████  | 87013/108000 [02:59<00:37, 555.26it/s] 81%|████████  | 87069/108000 [02:59<00:37, 555.39it/s] 81%|████████  | 87126/108000 [02:59<00:37, 559.22it/s] 81%|████████  | 87183/108000 [02:59<00:41, 507.41it/s] 81%|████████  | 87245/108000 [02:59<00:39, 531.45it/s] 81%|████████  | 87302/108000 [02:59<00:38, 539.44it/s] 81%|████████  | 87391/108000 [02:59<00:32, 636.53it/s] 81%|████████  | 87456/108000 [03:00<00:35, 581.10it/s] 81%|████████  | 87541/108000 [03:00<00:31, 649.42it/s] 81%|████████  | 87608/108000 [03:00<00:32, 619.06it/s] 81%|████████  | 87687/108000 [03:00<00:30, 665.29it/s] 81%|████████▏ | 87755/108000 [03:00<00:30, 666.09it/s] 81%|████████▏ | 87847/108000 [03:00<00:27, 722.95it/s] 81%|████████▏ | 87920/108000 [03:00<00:29, 687.88it/s] 81%|████████▏ | 87990/108000 [03:00<00:29, 685.11it/s] 82%|████████▏ | 88060/108000 [03:01<00:30, 645.26it/s] 82%|████████▏ | 88130/108000 [03:01<00:30, 651.34it/s] 82%|████████▏ | 88204/108000 [03:01<00:29, 665.73it/s] 82%|████████▏ | 88275/108000 [03:01<00:29, 670.72it/s] 82%|████████▏ | 88343/108000 [03:01<00:30, 651.62it/s] 82%|████████▏ | 88409/108000 [03:01<00:30, 643.52it/s] 82%|████████▏ | 88474/108000 [03:01<00:40, 476.49it/s] 82%|████████▏ | 88533/108000 [03:01<00:38, 502.56it/s] 82%|████████▏ | 88600/108000 [03:01<00:36, 530.34it/s] 82%|████████▏ | 88657/108000 [03:02<00:38, 500.57it/s] 82%|████████▏ | 88726/108000 [03:02<00:35, 548.02it/s] 82%|████████▏ | 88791/108000 [03:02<00:34, 564.51it/s] 82%|████████▏ | 88850/108000 [03:02<00:39, 484.17it/s] 82%|████████▏ | 88909/108000 [03:02<00:37, 509.02it/s] 82%|████████▏ | 88963/108000 [03:02<00:43, 437.95it/s] 82%|████████▏ | 89011/108000 [03:02<00:45, 413.80it/s] 82%|████████▏ | 89055/108000 [03:02<00:45, 418.38it/s] 82%|████████▏ | 89099/108000 [03:03<00:46, 406.19it/s] 83%|████████▎ | 89146/108000 [03:03<00:44, 422.50it/s] 83%|████████▎ | 89217/108000 [03:03<00:38, 489.93it/s] 83%|████████▎ | 89268/108000 [03:03<00:41, 453.18it/s] 83%|████████▎ | 89322/108000 [03:03<00:39, 471.34it/s] 83%|████████▎ | 89379/108000 [03:03<00:37, 498.04it/s] 83%|████████▎ | 89430/108000 [03:03<00:39, 469.98it/s] 83%|████████▎ | 89478/108000 [03:03<00:39, 468.47it/s] 83%|████████▎ | 89526/108000 [03:03<00:40, 452.73it/s] 83%|████████▎ | 89588/108000 [03:04<00:37, 496.43it/s] 83%|████████▎ | 89639/108000 [03:04<00:38, 476.12it/s] 83%|████████▎ | 89692/108000 [03:04<00:37, 486.73it/s] 83%|████████▎ | 89742/108000 [03:04<00:40, 452.18it/s] 83%|████████▎ | 89788/108000 [03:04<00:41, 443.99it/s] 83%|████████▎ | 89846/108000 [03:04<00:37, 481.26it/s] 83%|████████▎ | 89895/108000 [03:04<00:39, 460.74it/s] 83%|████████▎ | 89951/108000 [03:04<00:37, 480.72it/s] 83%|████████▎ | 90000/108000 [03:05<00:40, 445.49it/s] 83%|████████▎ | 90046/108000 [03:05<00:42, 419.20it/s] 83%|████████▎ | 90096/108000 [03:05<00:43, 409.62it/s] 83%|████████▎ | 90161/108000 [03:05<00:38, 469.31it/s] 84%|████████▎ | 90210/108000 [03:05<00:40, 435.03it/s] 84%|████████▎ | 90275/108000 [03:05<00:36, 481.30it/s] 84%|████████▎ | 90325/108000 [03:05<00:42, 412.68it/s] 84%|████████▎ | 90374/108000 [03:05<00:41, 421.81it/s] 84%|████████▎ | 90422/108000 [03:05<00:40, 435.03it/s] 84%|████████▍ | 90467/108000 [03:06<00:42, 410.93it/s] 84%|████████▍ | 90514/108000 [03:06<00:42, 414.88it/s] 84%|████████▍ | 90583/108000 [03:06<00:35, 488.05it/s] 84%|████████▍ | 90634/108000 [03:06<00:36, 470.71it/s] 84%|████████▍ | 90683/108000 [03:06<00:37, 460.94it/s] 84%|████████▍ | 90730/108000 [03:06<00:38, 449.68it/s] 84%|████████▍ | 90776/108000 [03:06<00:38, 444.64it/s] 84%|████████▍ | 90821/108000 [03:06<00:39, 435.17it/s] 84%|████████▍ | 90865/108000 [03:06<00:39, 434.57it/s] 84%|████████▍ | 90909/108000 [03:07<00:39, 432.06it/s] 84%|████████▍ | 90953/108000 [03:07<00:40, 422.07it/s] 84%|████████▍ | 90998/108000 [03:07<00:40, 422.00it/s] 84%|████████▍ | 91049/108000 [03:07<00:38, 437.80it/s] 84%|████████▍ | 91098/108000 [03:07<00:37, 445.14it/s] 84%|████████▍ | 91143/108000 [03:07<00:37, 445.18it/s] 84%|████████▍ | 91203/108000 [03:07<00:34, 484.80it/s] 84%|████████▍ | 91252/108000 [03:07<00:37, 451.60it/s] 85%|████████▍ | 91306/108000 [03:07<00:35, 476.08it/s] 85%|████████▍ | 91362/108000 [03:08<00:34, 477.15it/s] 85%|████████▍ | 91437/108000 [03:08<00:30, 548.25it/s] 85%|████████▍ | 91509/108000 [03:08<00:27, 596.90it/s] 85%|████████▍ | 91579/108000 [03:08<00:26, 623.13it/s] 85%|████████▍ | 91642/108000 [03:08<00:27, 596.23it/s] 85%|████████▍ | 91711/108000 [03:08<00:26, 622.23it/s] 85%|████████▍ | 91784/108000 [03:08<00:25, 638.11it/s] 85%|████████▌ | 91849/108000 [03:08<00:27, 596.66it/s] 85%|████████▌ | 91920/108000 [03:08<00:26, 618.24it/s] 85%|████████▌ | 91983/108000 [03:09<00:28, 570.50it/s] 85%|████████▌ | 92057/108000 [03:09<00:26, 605.13it/s] 85%|████████▌ | 92119/108000 [03:09<00:27, 588.09it/s] 85%|████████▌ | 92179/108000 [03:09<00:28, 558.19it/s] 85%|████████▌ | 92238/108000 [03:09<00:28, 560.76it/s] 85%|████████▌ | 92302/108000 [03:09<00:26, 581.58it/s] 86%|████████▌ | 92361/108000 [03:09<00:27, 563.59it/s] 86%|████████▌ | 92418/108000 [03:09<00:28, 553.26it/s] 86%|████████▌ | 92485/108000 [03:09<00:26, 585.08it/s] 86%|████████▌ | 92544/108000 [03:10<00:29, 520.52it/s] 86%|████████▌ | 92598/108000 [03:10<00:29, 517.05it/s] 86%|████████▌ | 92669/108000 [03:10<00:27, 562.27it/s] 86%|████████▌ | 92727/108000 [03:10<00:27, 560.19it/s] 86%|████████▌ | 92784/108000 [03:10<00:28, 539.76it/s] 86%|████████▌ | 92871/108000 [03:10<00:24, 629.63it/s] 86%|████████▌ | 92935/108000 [03:10<00:24, 624.24it/s] 86%|████████▌ | 92999/108000 [03:10<00:25, 595.89it/s] 86%|████████▌ | 93075/108000 [03:10<00:23, 640.13it/s] 86%|████████▌ | 93140/108000 [03:11<00:24, 611.27it/s] 86%|████████▋ | 93208/108000 [03:11<00:23, 628.81it/s] 86%|████████▋ | 93296/108000 [03:11<00:21, 698.89it/s] 86%|████████▋ | 93367/108000 [03:11<00:21, 685.70it/s] 87%|████████▋ | 93437/108000 [03:11<00:23, 631.19it/s] 87%|████████▋ | 93511/108000 [03:11<00:21, 660.64it/s] 87%|████████▋ | 93579/108000 [03:11<00:24, 597.17it/s] 87%|████████▋ | 93649/108000 [03:11<00:23, 610.63it/s] 87%|████████▋ | 93712/108000 [03:11<00:26, 536.94it/s] 87%|████████▋ | 93791/108000 [03:12<00:23, 595.19it/s] 87%|████████▋ | 93854/108000 [03:12<00:24, 585.95it/s] 87%|████████▋ | 93915/108000 [03:12<00:26, 530.07it/s] 87%|████████▋ | 93980/108000 [03:12<00:25, 549.89it/s] 87%|████████▋ | 94037/108000 [03:12<00:25, 537.18it/s] 87%|████████▋ | 94108/108000 [03:12<00:23, 583.21it/s] 87%|████████▋ | 94168/108000 [03:12<00:24, 558.19it/s] 87%|████████▋ | 94227/108000 [03:12<00:24, 563.52it/s] 87%|████████▋ | 94301/108000 [03:13<00:22, 600.73it/s] 87%|████████▋ | 94362/108000 [03:13<00:22, 596.60it/s] 87%|████████▋ | 94423/108000 [03:13<00:24, 565.22it/s] 87%|████████▋ | 94481/108000 [03:13<00:24, 546.88it/s] 88%|████████▊ | 94537/108000 [03:13<00:26, 513.11it/s] 88%|████████▊ | 94594/108000 [03:13<00:26, 515.38it/s] 88%|████████▊ | 94650/108000 [03:13<00:26, 509.77it/s] 88%|████████▊ | 94703/108000 [03:13<00:25, 511.48it/s] 88%|████████▊ | 94770/108000 [03:13<00:25, 528.53it/s] 88%|████████▊ | 94831/108000 [03:14<00:24, 542.49it/s] 88%|████████▊ | 94899/108000 [03:14<00:22, 578.80it/s] 88%|████████▊ | 94958/108000 [03:14<00:25, 513.10it/s] 88%|████████▊ | 95035/108000 [03:14<00:22, 578.80it/s] 88%|████████▊ | 95095/108000 [03:14<00:24, 528.74it/s] 88%|████████▊ | 95150/108000 [03:14<00:24, 533.58it/s] 88%|████████▊ | 95211/108000 [03:14<00:23, 554.22it/s] 88%|████████▊ | 95268/108000 [03:14<00:23, 541.72it/s] 88%|████████▊ | 95324/108000 [03:14<00:25, 501.20it/s] 88%|████████▊ | 95396/108000 [03:15<00:22, 551.68it/s] 88%|████████▊ | 95456/108000 [03:15<00:22, 557.26it/s] 88%|████████▊ | 95513/108000 [03:15<00:23, 526.50it/s] 88%|████████▊ | 95567/108000 [03:15<00:26, 473.93it/s] 89%|████████▊ | 95624/108000 [03:15<00:25, 476.91it/s] 89%|████████▊ | 95677/108000 [03:15<00:25, 481.49it/s] 89%|████████▊ | 95732/108000 [03:15<00:24, 495.13it/s] 89%|████████▊ | 95783/108000 [03:15<00:26, 468.42it/s] 89%|████████▊ | 95842/108000 [03:15<00:25, 486.11it/s] 89%|████████▉ | 95903/108000 [03:16<00:23, 515.55it/s] 89%|████████▉ | 95963/108000 [03:16<00:22, 536.65it/s] 89%|████████▉ | 96028/108000 [03:16<00:21, 564.24it/s] 89%|████████▉ | 96085/108000 [03:16<00:21, 555.08it/s] 89%|████████▉ | 96141/108000 [03:16<00:21, 549.13it/s] 89%|████████▉ | 96197/108000 [03:16<00:32, 359.41it/s] 89%|████████▉ | 96253/108000 [03:16<00:29, 391.57it/s] 89%|████████▉ | 96312/108000 [03:17<00:26, 433.38it/s] 89%|████████▉ | 96388/108000 [03:17<00:22, 512.90it/s] 89%|████████▉ | 96446/108000 [03:17<00:22, 518.49it/s] 89%|████████▉ | 96503/108000 [03:17<00:22, 502.81it/s] 89%|████████▉ | 96557/108000 [03:17<00:22, 510.01it/s] 89%|████████▉ | 96611/108000 [03:17<00:23, 486.96it/s] 90%|████████▉ | 96662/108000 [03:17<00:23, 485.52it/s] 90%|████████▉ | 96712/108000 [03:17<00:24, 470.29it/s] 90%|████████▉ | 96760/108000 [03:17<00:23, 472.36it/s] 90%|████████▉ | 96833/108000 [03:17<00:20, 535.16it/s] 90%|████████▉ | 96892/108000 [03:18<00:20, 550.63it/s] 90%|████████▉ | 96948/108000 [03:18<00:20, 534.89it/s] 90%|████████▉ | 97012/108000 [03:18<00:19, 562.93it/s] 90%|████████▉ | 97069/108000 [03:18<00:21, 513.06it/s] 90%|████████▉ | 97122/108000 [03:18<00:21, 505.56it/s] 90%|████████▉ | 97174/108000 [03:18<00:21, 508.25it/s] 90%|█████████ | 97253/108000 [03:18<00:18, 571.33it/s] 90%|█████████ | 97311/108000 [03:18<00:19, 561.75it/s] 90%|█████████ | 97368/108000 [03:19<00:20, 506.41it/s] 90%|█████████ | 97423/108000 [03:19<00:20, 514.75it/s] 90%|█████████ | 97476/108000 [03:19<00:21, 497.95it/s] 90%|█████████ | 97547/108000 [03:19<00:19, 549.18it/s] 90%|█████████ | 97603/108000 [03:19<00:22, 458.82it/s] 90%|█████████ | 97683/108000 [03:19<00:19, 541.32it/s] 91%|█████████ | 97741/108000 [03:19<00:19, 517.67it/s] 91%|█████████ | 97806/108000 [03:19<00:18, 551.18it/s] 91%|█████████ | 97864/108000 [03:19<00:20, 497.54it/s] 91%|█████████ | 97917/108000 [03:20<00:20, 501.32it/s] 91%|█████████ | 97969/108000 [03:20<00:20, 478.69it/s] 91%|█████████ | 98031/108000 [03:20<00:19, 504.34it/s] 91%|█████████ | 98083/108000 [03:20<00:20, 472.97it/s] 91%|█████████ | 98141/108000 [03:20<00:19, 494.49it/s] 91%|█████████ | 98193/108000 [03:20<00:19, 499.66it/s] 91%|█████████ | 98250/108000 [03:20<00:19, 508.06it/s] 91%|█████████ | 98302/108000 [03:20<00:20, 476.84it/s] 91%|█████████ | 98361/108000 [03:20<00:19, 505.28it/s] 91%|█████████ | 98413/108000 [03:21<00:19, 499.74it/s] 91%|█████████ | 98464/108000 [03:21<00:20, 461.59it/s] 91%|█████████ | 98516/108000 [03:21<00:19, 476.41it/s] 91%|█████████▏| 98565/108000 [03:21<00:21, 432.62it/s] 91%|█████████▏| 98625/108000 [03:21<00:19, 473.24it/s] 91%|█████████▏| 98674/108000 [03:21<00:20, 461.20it/s] 91%|█████████▏| 98721/108000 [03:21<00:20, 449.61it/s] 91%|█████████▏| 98773/108000 [03:21<00:20, 459.06it/s] 92%|█████████▏| 98829/108000 [03:22<00:18, 486.33it/s] 92%|█████████▏| 98879/108000 [03:22<00:20, 446.62it/s] 92%|█████████▏| 98932/108000 [03:22<00:19, 463.30it/s] 92%|█████████▏| 98980/108000 [03:22<00:20, 439.84it/s] 92%|█████████▏| 99028/108000 [03:22<00:20, 435.16it/s] 92%|█████████▏| 99076/108000 [03:22<00:20, 435.78it/s] 92%|█████████▏| 99136/108000 [03:22<00:18, 477.95it/s] 92%|█████████▏| 99185/108000 [03:22<00:18, 474.01it/s] 92%|█████████▏| 99234/108000 [03:22<00:19, 444.55it/s] 92%|█████████▏| 99280/108000 [03:23<00:20, 428.53it/s] 92%|█████████▏| 99325/108000 [03:23<00:20, 432.76it/s] 92%|█████████▏| 99392/108000 [03:23<00:18, 473.90it/s] 92%|█████████▏| 99440/108000 [03:23<00:18, 474.64it/s] 92%|█████████▏| 99491/108000 [03:23<00:18, 471.31it/s] 92%|█████████▏| 99543/108000 [03:23<00:17, 484.98it/s] 92%|█████████▏| 99592/108000 [03:23<00:19, 437.33it/s] 92%|█████████▏| 99656/108000 [03:23<00:17, 490.56it/s] 92%|█████████▏| 99707/108000 [03:23<00:17, 473.75it/s] 92%|█████████▏| 99756/108000 [03:24<00:17, 465.67it/s] 92%|█████████▏| 99804/108000 [03:24<00:18, 437.97it/s] 92%|█████████▏| 99854/108000 [03:24<00:18, 446.27it/s] 93%|█████████▎| 99906/108000 [03:24<00:17, 452.66it/s] 93%|█████████▎| 99953/108000 [03:24<00:17, 453.72it/s] 93%|█████████▎| 100008/108000 [03:24<00:16, 474.62it/s] 93%|█████████▎| 100056/108000 [03:24<00:16, 474.02it/s] 93%|█████████▎| 100104/108000 [03:24<00:17, 441.01it/s] 93%|█████████▎| 100176/108000 [03:24<00:15, 496.46it/s] 93%|█████████▎| 100228/108000 [03:25<00:15, 489.83it/s] 93%|█████████▎| 100293/108000 [03:25<00:14, 531.18it/s] 93%|█████████▎| 100347/108000 [03:25<00:14, 524.13it/s] 93%|█████████▎| 100400/108000 [03:25<00:16, 460.32it/s] 93%|█████████▎| 100469/108000 [03:25<00:14, 508.62it/s] 93%|█████████▎| 100522/108000 [03:25<00:15, 495.25it/s] 93%|█████████▎| 100573/108000 [03:25<00:15, 490.02it/s] 93%|█████████▎| 100623/108000 [03:25<00:16, 435.27it/s] 93%|█████████▎| 100683/108000 [03:25<00:15, 474.46it/s] 93%|█████████▎| 100737/108000 [03:26<00:14, 486.28it/s] 93%|█████████▎| 100787/108000 [03:26<00:15, 464.64it/s] 93%|█████████▎| 100843/108000 [03:26<00:14, 477.61it/s] 93%|█████████▎| 100918/108000 [03:26<00:13, 543.09it/s] 94%|█████████▎| 101003/108000 [03:26<00:11, 625.63it/s] 94%|█████████▎| 101075/108000 [03:26<00:10, 640.00it/s] 94%|█████████▎| 101143/108000 [03:26<00:10, 644.60it/s] 94%|█████████▎| 101241/108000 [03:26<00:09, 729.80it/s] 94%|█████████▍| 101321/108000 [03:26<00:08, 742.50it/s] 94%|█████████▍| 101404/108000 [03:27<00:08, 767.71it/s] 94%|█████████▍| 101483/108000 [03:27<00:08, 766.22it/s] 94%|█████████▍| 101560/108000 [03:27<00:09, 702.10it/s] 94%|█████████▍| 101632/108000 [03:27<00:09, 686.98it/s] 94%|█████████▍| 101702/108000 [03:27<00:09, 669.44it/s] 94%|█████████▍| 101791/108000 [03:27<00:08, 722.63it/s] 94%|█████████▍| 101864/108000 [03:27<00:09, 659.39it/s] 94%|█████████▍| 101934/108000 [03:27<00:09, 664.49it/s] 94%|█████████▍| 102002/108000 [03:27<00:09, 647.06it/s] 95%|█████████▍| 102094/108000 [03:28<00:08, 709.15it/s] 95%|█████████▍| 102173/108000 [03:28<00:08, 727.87it/s] 95%|█████████▍| 102247/108000 [03:28<00:08, 706.20it/s] 95%|█████████▍| 102319/108000 [03:28<00:08, 689.16it/s] 95%|█████████▍| 102389/108000 [03:28<00:08, 690.56it/s] 95%|█████████▍| 102479/108000 [03:28<00:07, 750.02it/s] 95%|█████████▍| 102555/108000 [03:28<00:08, 667.62it/s] 95%|█████████▌| 102655/108000 [03:28<00:07, 738.89it/s] 95%|█████████▌| 102731/108000 [03:28<00:07, 711.63it/s] 95%|█████████▌| 102805/108000 [03:29<00:07, 715.73it/s] 95%|█████████▌| 102878/108000 [03:29<00:07, 678.12it/s] 95%|█████████▌| 102959/108000 [03:29<00:07, 702.38it/s] 95%|█████████▌| 103030/108000 [03:29<00:07, 695.02it/s] 95%|█████████▌| 103100/108000 [03:29<00:07, 692.67it/s] 96%|█████████▌| 103170/108000 [03:29<00:07, 673.36it/s] 96%|█████████▌| 103238/108000 [03:29<00:08, 593.72it/s] 96%|█████████▌| 103300/108000 [03:29<00:09, 502.47it/s] 96%|█████████▌| 103354/108000 [03:30<00:11, 404.63it/s] 96%|█████████▌| 103400/108000 [03:30<00:11, 406.51it/s] 96%|█████████▌| 103452/108000 [03:30<00:10, 427.42it/s] 96%|█████████▌| 103498/108000 [03:30<00:12, 365.67it/s] 96%|█████████▌| 103543/108000 [03:30<00:11, 379.89it/s] 96%|█████████▌| 103584/108000 [03:30<00:11, 384.73it/s] 96%|█████████▌| 103625/108000 [03:30<00:12, 358.54it/s] 96%|█████████▌| 103670/108000 [03:30<00:11, 378.77it/s] 96%|█████████▌| 103716/108000 [03:31<00:10, 390.59it/s] 96%|█████████▌| 103757/108000 [03:31<00:11, 378.74it/s] 96%|█████████▌| 103801/108000 [03:31<00:10, 386.81it/s] 96%|█████████▌| 103841/108000 [03:31<00:11, 375.58it/s] 96%|█████████▌| 103882/108000 [03:31<00:10, 384.11it/s] 96%|█████████▌| 103921/108000 [03:31<00:15, 258.78it/s] 96%|█████████▋| 103964/108000 [03:31<00:13, 294.27it/s] 96%|█████████▋| 103999/108000 [03:32<00:13, 286.77it/s] 96%|█████████▋| 104033/108000 [03:32<00:13, 298.45it/s] 96%|█████████▋| 104067/108000 [03:32<00:13, 301.88it/s] 96%|█████████▋| 104111/108000 [03:32<00:11, 331.81it/s] 96%|█████████▋| 104160/108000 [03:32<00:10, 373.25it/s] 96%|█████████▋| 104200/108000 [03:32<00:11, 332.84it/s] 97%|█████████▋| 104240/108000 [03:32<00:10, 349.84it/s] 97%|█████████▋| 104277/108000 [03:32<00:10, 344.69it/s] 97%|█████████▋| 104313/108000 [03:32<00:10, 347.68it/s] 97%|█████████▋| 104368/108000 [03:33<00:09, 401.65it/s] 97%|█████████▋| 104410/108000 [03:33<00:09, 388.13it/s] 97%|█████████▋| 104450/108000 [03:33<00:09, 382.79it/s] 97%|█████████▋| 104489/108000 [03:33<00:09, 379.00it/s] 97%|█████████▋| 104528/108000 [03:33<00:09, 356.27it/s] 97%|█████████▋| 104565/108000 [03:33<00:10, 340.85it/s] 97%|█████████▋| 104600/108000 [03:33<00:10, 330.58it/s] 97%|█████████▋| 104635/108000 [03:33<00:10, 321.25it/s] 97%|█████████▋| 104674/108000 [03:33<00:10, 331.27it/s] 97%|█████████▋| 104713/108000 [03:34<00:09, 345.48it/s] 97%|█████████▋| 104750/108000 [03:34<00:09, 348.84it/s] 97%|█████████▋| 104806/108000 [03:34<00:07, 401.47it/s] 97%|█████████▋| 104847/108000 [03:34<00:08, 377.85it/s] 97%|█████████▋| 104886/108000 [03:34<00:08, 357.40it/s] 97%|█████████▋| 104928/108000 [03:34<00:08, 359.62it/s] 97%|█████████▋| 104972/108000 [03:34<00:08, 373.48it/s] 97%|█████████▋| 105026/108000 [03:34<00:07, 417.45it/s] 97%|█████████▋| 105069/108000 [03:34<00:07, 383.84it/s] 97%|█████████▋| 105109/108000 [03:35<00:08, 347.95it/s] 97%|█████████▋| 105157/108000 [03:35<00:07, 374.72it/s] 97%|█████████▋| 105196/108000 [03:35<00:07, 375.56it/s] 97%|█████████▋| 105235/108000 [03:35<00:07, 375.45it/s] 97%|█████████▋| 105274/108000 [03:35<00:07, 352.07it/s] 98%|█████████▊| 105310/108000 [03:35<00:07, 347.05it/s] 98%|█████████▊| 105346/108000 [03:35<00:07, 331.76it/s] 98%|█████████▊| 105395/108000 [03:35<00:07, 366.64it/s] 98%|█████████▊| 105441/108000 [03:35<00:06, 381.49it/s] 98%|█████████▊| 105480/108000 [03:36<00:06, 380.36it/s] 98%|█████████▊| 105519/108000 [03:36<00:07, 340.44it/s] 98%|█████████▊| 105567/108000 [03:36<00:06, 368.25it/s] 98%|█████████▊| 105605/108000 [03:36<00:06, 369.63it/s] 98%|█████████▊| 105675/108000 [03:36<00:05, 459.47it/s] 98%|█████████▊| 105728/108000 [03:36<00:04, 474.25it/s] 98%|█████████▊| 105792/108000 [03:36<00:04, 507.07it/s] 98%|█████████▊| 105856/108000 [03:36<00:03, 539.03it/s] 98%|█████████▊| 105922/108000 [03:36<00:03, 572.66it/s] 98%|█████████▊| 105993/108000 [03:37<00:03, 608.22it/s] 98%|█████████▊| 106055/108000 [03:37<00:03, 576.77it/s] 98%|█████████▊| 106116/108000 [03:37<00:03, 580.66it/s] 98%|█████████▊| 106196/108000 [03:37<00:02, 628.95it/s] 98%|█████████▊| 106261/108000 [03:37<00:02, 624.65it/s] 98%|█████████▊| 106324/108000 [03:37<00:02, 614.50it/s] 99%|█████████▊| 106391/108000 [03:37<00:02, 630.33it/s] 99%|█████████▊| 106468/108000 [03:37<00:02, 666.92it/s] 99%|█████████▊| 106542/108000 [03:37<00:02, 655.57it/s] 99%|█████████▊| 106626/108000 [03:38<00:01, 697.87it/s] 99%|█████████▉| 106699/108000 [03:38<00:01, 688.60it/s] 99%|█████████▉| 106769/108000 [03:38<00:01, 651.80it/s] 99%|█████████▉| 106835/108000 [03:38<00:01, 634.73it/s] 99%|█████████▉| 106912/108000 [03:38<00:01, 669.03it/s] 99%|█████████▉| 106980/108000 [03:38<00:01, 607.00it/s] 99%|█████████▉| 107047/108000 [03:38<00:01, 613.81it/s] 99%|█████████▉| 107125/108000 [03:38<00:01, 642.35it/s] 99%|█████████▉| 107197/108000 [03:38<00:01, 649.15it/s] 99%|█████████▉| 107263/108000 [03:39<00:01, 647.70it/s] 99%|█████████▉| 107329/108000 [03:39<00:01, 627.70it/s] 99%|█████████▉| 107393/108000 [03:39<00:00, 622.65it/s] 99%|█████████▉| 107456/108000 [03:39<00:00, 598.30it/s]100%|█████████▉| 107545/108000 [03:39<00:00, 668.36it/s]100%|█████████▉| 107613/108000 [03:39<00:00, 628.56it/s]100%|█████████▉| 107681/108000 [03:39<00:00, 642.44it/s]100%|█████████▉| 107746/108000 [03:39<00:00, 591.47it/s]100%|█████████▉| 107836/108000 [03:39<00:00, 656.50it/s]100%|█████████▉| 107903/108000 [03:40<00:00, 635.65it/s]100%|█████████▉| 107968/108000 [03:40<00:00, 637.63it/s]100%|██████████| 108000/108000 [03:40<00:00, 490.50it/s]
aug_train process done: X = (108000, 3, 2, 2000), y = (108000,)

Size Analysis:
--------------
Total raw size: 9.66 GB
Estimated compressed size: 4.83 GB
Overhead: 1.50 KB

Size per array:
X: 9.66 GB
y: 843.75 KB
finished gen taf script for aug_train
starting gen taf script for aug_valid
  0%|          | 0/13500 [00:00<?, ?it/s]  1%|          | 106/13500 [00:00<00:12, 1059.88it/s]  2%|▏         | 212/13500 [00:00<00:22, 595.89it/s]   2%|▏         | 283/13500 [00:00<00:26, 492.82it/s]  3%|▎         | 339/13500 [00:00<00:29, 448.41it/s]  3%|▎         | 388/13500 [00:00<00:37, 348.52it/s]  3%|▎         | 427/13500 [00:01<00:39, 327.15it/s]  3%|▎         | 462/13500 [00:01<00:42, 308.26it/s]  4%|▎         | 504/13500 [00:01<00:39, 331.07it/s]  4%|▍         | 539/13500 [00:01<00:40, 320.64it/s]  4%|▍         | 578/13500 [00:01<00:38, 336.89it/s]  5%|▍         | 624/13500 [00:01<00:35, 367.32it/s]  5%|▌         | 685/13500 [00:01<00:29, 428.47it/s]  6%|▌         | 745/13500 [00:01<00:26, 472.91it/s]  6%|▌         | 818/13500 [00:01<00:23, 539.86it/s]  7%|▋         | 893/13500 [00:02<00:21, 593.09it/s]  7%|▋         | 954/13500 [00:02<00:22, 565.44it/s]  7%|▋         | 1012/13500 [00:02<00:27, 454.20it/s]  8%|▊         | 1062/13500 [00:02<00:27, 459.57it/s]  8%|▊         | 1111/13500 [00:02<00:27, 456.14it/s]  9%|▊         | 1159/13500 [00:02<00:30, 401.49it/s]  9%|▉         | 1216/13500 [00:02<00:27, 440.35it/s]  9%|▉         | 1263/13500 [00:02<00:27, 440.67it/s] 10%|▉         | 1348/13500 [00:03<00:22, 547.63it/s] 11%|█         | 1437/13500 [00:03<00:18, 641.71it/s] 11%|█         | 1507/13500 [00:03<00:18, 651.45it/s] 12%|█▏        | 1603/13500 [00:03<00:16, 739.11it/s] 13%|█▎        | 1691/13500 [00:03<00:15, 776.85it/s] 13%|█▎        | 1770/13500 [00:03<00:16, 711.64it/s] 14%|█▎        | 1844/13500 [00:03<00:16, 714.76it/s] 14%|█▍        | 1932/13500 [00:03<00:15, 749.92it/s] 15%|█▍        | 2018/13500 [00:03<00:14, 768.56it/s] 16%|█▌        | 2110/13500 [00:03<00:14, 804.30it/s] 16%|█▌        | 2192/13500 [00:04<00:17, 652.45it/s] 17%|█▋        | 2263/13500 [00:04<00:18, 623.82it/s] 17%|█▋        | 2329/13500 [00:04<00:19, 561.55it/s] 18%|█▊        | 2389/13500 [00:04<00:20, 551.16it/s] 18%|█▊        | 2448/13500 [00:04<00:19, 555.66it/s] 19%|█▊        | 2518/13500 [00:04<00:18, 591.78it/s] 19%|█▉        | 2592/13500 [00:04<00:17, 631.44it/s] 20%|█▉        | 2684/13500 [00:04<00:15, 707.57it/s] 21%|██        | 2776/13500 [00:05<00:13, 767.58it/s] 21%|██        | 2855/13500 [00:05<00:14, 715.34it/s] 22%|██▏       | 2929/13500 [00:05<00:16, 658.56it/s] 22%|██▏       | 2997/13500 [00:05<00:17, 615.32it/s] 23%|██▎       | 3061/13500 [00:05<00:19, 530.44it/s] 23%|██▎       | 3117/13500 [00:05<00:20, 496.18it/s] 23%|██▎       | 3170/13500 [00:05<00:20, 501.06it/s] 24%|██▍       | 3224/13500 [00:05<00:20, 494.29it/s] 24%|██▍       | 3299/13500 [00:06<00:18, 552.09it/s] 25%|██▌       | 3395/13500 [00:06<00:15, 660.68it/s] 26%|██▌       | 3474/13500 [00:06<00:14, 696.06it/s] 27%|██▋       | 3578/13500 [00:06<00:12, 779.80it/s] 27%|██▋       | 3670/13500 [00:06<00:12, 811.39it/s] 28%|██▊       | 3777/13500 [00:06<00:11, 883.82it/s] 29%|██▊       | 3867/13500 [00:06<00:11, 812.47it/s] 29%|██▉       | 3951/13500 [00:06<00:12, 766.45it/s] 30%|██▉       | 4030/13500 [00:06<00:13, 722.04it/s] 30%|███       | 4104/13500 [00:07<00:13, 700.80it/s] 31%|███       | 4175/13500 [00:07<00:14, 655.80it/s] 31%|███▏      | 4242/13500 [00:07<00:14, 622.81it/s] 32%|███▏      | 4305/13500 [00:07<00:18, 507.04it/s] 32%|███▏      | 4360/13500 [00:07<00:19, 457.34it/s] 33%|███▎      | 4409/13500 [00:07<00:23, 383.79it/s] 33%|███▎      | 4451/13500 [00:07<00:23, 383.10it/s] 33%|███▎      | 4504/13500 [00:08<00:21, 413.59it/s] 34%|███▍      | 4561/13500 [00:08<00:20, 446.86it/s] 34%|███▍      | 4637/13500 [00:08<00:16, 525.14it/s] 35%|███▍      | 4712/13500 [00:08<00:15, 583.64it/s] 35%|███▌      | 4782/13500 [00:08<00:14, 615.63it/s] 36%|███▌      | 4846/13500 [00:08<00:16, 535.70it/s] 36%|███▋      | 4903/13500 [00:08<00:19, 434.59it/s] 37%|███▋      | 4952/13500 [00:08<00:21, 405.59it/s] 37%|███▋      | 4996/13500 [00:09<00:22, 371.62it/s] 37%|███▋      | 5036/13500 [00:09<00:23, 353.38it/s] 38%|███▊      | 5073/13500 [00:09<00:23, 354.57it/s] 38%|███▊      | 5110/13500 [00:09<00:23, 353.59it/s] 39%|███▊      | 5200/13500 [00:09<00:16, 494.82it/s] 39%|███▉      | 5274/13500 [00:09<00:14, 560.88it/s] 40%|███▉      | 5333/13500 [00:09<00:14, 545.13it/s] 40%|████      | 5404/13500 [00:09<00:13, 588.10it/s] 41%|████      | 5474/13500 [00:09<00:13, 614.93it/s] 41%|████      | 5563/13500 [00:10<00:11, 685.81it/s] 42%|████▏     | 5634/13500 [00:10<00:11, 690.65it/s] 42%|████▏     | 5712/13500 [00:10<00:11, 706.62it/s] 43%|████▎     | 5784/13500 [00:10<00:11, 669.37it/s] 43%|████▎     | 5852/13500 [00:10<00:11, 648.42it/s] 44%|████▍     | 5927/13500 [00:10<00:11, 671.37it/s] 44%|████▍     | 5995/13500 [00:10<00:11, 669.74it/s] 45%|████▍     | 6063/13500 [00:10<00:11, 634.23it/s] 45%|████▌     | 6127/13500 [00:11<00:13, 539.79it/s] 46%|████▌     | 6197/13500 [00:11<00:12, 580.14it/s] 46%|████▋     | 6259/13500 [00:11<00:13, 555.14it/s] 47%|████▋     | 6317/13500 [00:11<00:12, 559.84it/s] 47%|████▋     | 6375/13500 [00:11<00:12, 564.07it/s] 48%|████▊     | 6451/13500 [00:11<00:11, 597.82it/s] 48%|████▊     | 6526/13500 [00:11<00:11, 627.68it/s] 49%|████▉     | 6590/13500 [00:11<00:11, 616.39it/s] 49%|████▉     | 6652/13500 [00:11<00:12, 531.65it/s] 50%|████▉     | 6708/13500 [00:12<00:14, 468.27it/s] 50%|█████     | 6758/13500 [00:12<00:16, 398.74it/s] 50%|█████     | 6801/13500 [00:12<00:16, 403.61it/s] 51%|█████     | 6844/13500 [00:12<00:16, 398.10it/s] 51%|█████     | 6886/13500 [00:12<00:18, 355.72it/s] 51%|█████▏    | 6924/13500 [00:12<00:20, 320.22it/s] 52%|█████▏    | 6958/13500 [00:12<00:20, 320.37it/s] 52%|█████▏    | 6991/13500 [00:13<00:20, 310.86it/s] 52%|█████▏    | 7023/13500 [00:13<00:21, 297.61it/s] 52%|█████▏    | 7068/13500 [00:13<00:19, 329.08it/s] 53%|█████▎    | 7106/13500 [00:13<00:19, 332.60it/s] 53%|█████▎    | 7140/13500 [00:13<00:20, 306.97it/s] 53%|█████▎    | 7173/13500 [00:13<00:21, 292.71it/s] 54%|█████▎    | 7242/13500 [00:13<00:15, 393.07it/s] 54%|█████▍    | 7297/13500 [00:13<00:14, 435.06it/s] 55%|█████▍    | 7379/13500 [00:13<00:11, 531.75it/s] 55%|█████▌    | 7436/13500 [00:14<00:11, 542.39it/s] 56%|█████▌    | 7495/13500 [00:14<00:10, 550.61it/s] 56%|█████▌    | 7551/13500 [00:14<00:10, 551.01it/s] 56%|█████▋    | 7607/13500 [00:14<00:11, 532.89it/s] 57%|█████▋    | 7695/13500 [00:14<00:09, 623.05it/s] 57%|█████▋    | 7758/13500 [00:14<00:09, 623.37it/s] 58%|█████▊    | 7821/13500 [00:14<00:10, 552.63it/s] 58%|█████▊    | 7878/13500 [00:14<00:10, 516.47it/s] 59%|█████▉    | 7932/13500 [00:14<00:11, 488.27it/s] 59%|█████▉    | 7982/13500 [00:15<00:12, 458.80it/s] 59%|█████▉    | 8030/13500 [00:15<00:11, 462.10it/s] 60%|█████▉    | 8077/13500 [00:15<00:11, 462.52it/s] 60%|██████    | 8130/13500 [00:15<00:11, 478.29it/s] 61%|██████    | 8182/13500 [00:15<00:10, 487.94it/s] 61%|██████    | 8235/13500 [00:15<00:10, 494.75it/s] 62%|██████▏   | 8309/13500 [00:15<00:09, 560.69it/s] 62%|██████▏   | 8366/13500 [00:15<00:09, 556.81it/s] 62%|██████▏   | 8423/13500 [00:15<00:09, 542.77it/s] 63%|██████▎   | 8478/13500 [00:16<00:10, 495.95it/s] 63%|██████▎   | 8539/13500 [00:16<00:09, 508.44it/s] 64%|██████▍   | 8611/13500 [00:16<00:08, 565.91it/s] 64%|██████▍   | 8692/13500 [00:16<00:07, 619.50it/s] 65%|██████▍   | 8755/13500 [00:16<00:07, 610.37it/s] 65%|██████▌   | 8817/13500 [00:16<00:07, 598.54it/s] 66%|██████▌   | 8878/13500 [00:16<00:08, 566.24it/s] 66%|██████▌   | 8936/13500 [00:16<00:08, 534.72it/s] 67%|██████▋   | 9007/13500 [00:16<00:07, 563.28it/s] 67%|██████▋   | 9064/13500 [00:17<00:08, 503.49it/s] 68%|██████▊   | 9129/13500 [00:17<00:08, 534.32it/s] 68%|██████▊   | 9192/13500 [00:17<00:07, 553.36it/s] 69%|██████▊   | 9249/13500 [00:17<00:08, 501.73it/s] 69%|██████▉   | 9301/13500 [00:17<00:08, 472.32it/s] 69%|██████▉   | 9350/13500 [00:17<00:09, 445.42it/s] 70%|██████▉   | 9396/13500 [00:17<00:09, 422.35it/s] 70%|██████▉   | 9439/13500 [00:17<00:09, 416.23it/s] 70%|███████   | 9481/13500 [00:18<00:10, 399.26it/s] 71%|███████   | 9526/13500 [00:18<00:09, 408.28it/s] 71%|███████   | 9574/13500 [00:18<00:09, 427.53it/s] 71%|███████   | 9618/13500 [00:18<00:10, 361.00it/s] 72%|███████▏  | 9689/13500 [00:18<00:08, 427.35it/s] 72%|███████▏  | 9744/13500 [00:18<00:08, 455.98it/s] 73%|███████▎  | 9813/13500 [00:18<00:07, 509.79it/s] 73%|███████▎  | 9873/13500 [00:18<00:06, 529.36it/s] 74%|███████▎  | 9930/13500 [00:18<00:06, 531.97it/s] 74%|███████▍  | 9985/13500 [00:19<00:07, 485.83it/s] 74%|███████▍  | 10039/13500 [00:19<00:07, 484.54it/s] 75%|███████▍  | 10089/13500 [00:19<00:07, 463.65it/s] 75%|███████▌  | 10137/13500 [00:19<00:07, 441.84it/s] 75%|███████▌  | 10188/13500 [00:19<00:07, 446.57it/s] 76%|███████▌  | 10234/13500 [00:19<00:08, 369.05it/s] 76%|███████▋  | 10296/13500 [00:19<00:07, 425.05it/s] 77%|███████▋  | 10342/13500 [00:20<00:08, 370.54it/s] 77%|███████▋  | 10385/13500 [00:20<00:08, 381.55it/s] 77%|███████▋  | 10426/13500 [00:20<00:08, 365.11it/s] 78%|███████▊  | 10478/13500 [00:20<00:07, 398.75it/s] 78%|███████▊  | 10520/13500 [00:20<00:10, 290.42it/s] 78%|███████▊  | 10555/13500 [00:20<00:13, 225.82it/s] 78%|███████▊  | 10583/13500 [00:21<00:15, 188.98it/s] 79%|███████▊  | 10607/13500 [00:21<00:16, 173.12it/s] 79%|███████▊  | 10628/13500 [00:21<00:17, 168.83it/s] 79%|███████▉  | 10647/13500 [00:21<00:17, 162.12it/s] 79%|███████▉  | 10665/13500 [00:21<00:18, 153.14it/s] 79%|███████▉  | 10681/13500 [00:21<00:19, 145.00it/s] 79%|███████▉  | 10696/13500 [00:21<00:19, 145.78it/s] 79%|███████▉  | 10711/13500 [00:22<00:19, 144.66it/s] 79%|███████▉  | 10727/13500 [00:22<00:18, 146.75it/s] 80%|███████▉  | 10742/13500 [00:22<00:19, 143.01it/s] 80%|███████▉  | 10757/13500 [00:22<00:19, 139.37it/s] 80%|███████▉  | 10771/13500 [00:22<00:20, 130.70it/s] 80%|███████▉  | 10785/13500 [00:22<00:21, 127.95it/s] 80%|████████  | 10816/13500 [00:22<00:15, 172.36it/s] 81%|████████  | 10874/13500 [00:22<00:09, 282.19it/s] 81%|████████  | 10955/13500 [00:22<00:06, 422.87it/s] 82%|████████▏ | 11021/13500 [00:23<00:05, 489.16it/s] 82%|████████▏ | 11079/13500 [00:23<00:04, 500.85it/s] 82%|████████▏ | 11131/13500 [00:23<00:04, 494.45it/s] 83%|████████▎ | 11197/13500 [00:23<00:04, 540.22it/s] 83%|████████▎ | 11252/13500 [00:23<00:04, 493.58it/s] 84%|████████▍ | 11307/13500 [00:23<00:04, 508.82it/s] 84%|████████▍ | 11363/13500 [00:23<00:04, 494.97it/s] 85%|████████▍ | 11414/13500 [00:23<00:04, 468.95it/s] 85%|████████▌ | 11484/13500 [00:23<00:03, 531.15it/s] 85%|████████▌ | 11539/13500 [00:24<00:03, 524.02it/s] 86%|████████▌ | 11606/13500 [00:24<00:03, 548.01it/s] 87%|████████▋ | 11678/13500 [00:24<00:03, 569.28it/s] 87%|████████▋ | 11736/13500 [00:24<00:03, 569.11it/s] 87%|████████▋ | 11794/13500 [00:24<00:03, 550.70it/s] 88%|████████▊ | 11851/13500 [00:24<00:02, 553.31it/s] 88%|████████▊ | 11927/13500 [00:24<00:02, 579.72it/s] 89%|████████▉ | 11985/13500 [00:24<00:02, 511.75it/s] 89%|████████▉ | 12059/13500 [00:24<00:02, 561.23it/s] 90%|████████▉ | 12117/13500 [00:25<00:02, 491.52it/s] 90%|█████████ | 12181/13500 [00:25<00:02, 507.60it/s] 91%|█████████ | 12239/13500 [00:25<00:02, 525.75it/s] 91%|█████████ | 12305/13500 [00:25<00:02, 531.23it/s] 92%|█████████▏| 12360/13500 [00:25<00:02, 492.83it/s] 92%|█████████▏| 12411/13500 [00:25<00:02, 482.33it/s] 92%|█████████▏| 12460/13500 [00:25<00:02, 479.44it/s] 93%|█████████▎| 12509/13500 [00:25<00:02, 430.68it/s] 93%|█████████▎| 12568/13500 [00:26<00:02, 462.33it/s] 93%|█████████▎| 12617/13500 [00:26<00:01, 467.23it/s] 94%|█████████▍| 12698/13500 [00:26<00:01, 559.24it/s] 95%|█████████▍| 12771/13500 [00:26<00:01, 601.28it/s] 95%|█████████▌| 12856/13500 [00:26<00:00, 667.59it/s] 96%|█████████▌| 12924/13500 [00:26<00:00, 597.81it/s] 96%|█████████▌| 12986/13500 [00:26<00:00, 534.46it/s] 97%|█████████▋| 13042/13500 [00:26<00:01, 426.89it/s] 97%|█████████▋| 13090/13500 [00:27<00:00, 422.45it/s] 97%|█████████▋| 13136/13500 [00:27<00:00, 398.24it/s] 98%|█████████▊| 13186/13500 [00:27<00:00, 413.48it/s] 98%|█████████▊| 13236/13500 [00:27<00:00, 429.20it/s] 99%|█████████▊| 13317/13500 [00:27<00:00, 522.91it/s] 99%|█████████▉| 13382/13500 [00:27<00:00, 556.95it/s]100%|█████████▉| 13448/13500 [00:27<00:00, 575.43it/s]100%|██████████| 13500/13500 [00:27<00:00, 486.31it/s]
aug_valid process done: X = (13500, 3, 2, 2000), y = (13500,)

Size Analysis:
--------------
Total raw size: 1.21 GB
Estimated compressed size: 618.03 MB
Overhead: 1.50 KB

Size per array:
X: 1.21 GB
y: 105.47 KB
finished gen taf script for aug_valid
starting gen taf script for test
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 46/4500 [00:00<00:10, 428.76it/s]  2%|▏         | 89/4500 [00:00<00:11, 382.91it/s]  3%|▎         | 131/4500 [00:00<00:11, 375.35it/s]  4%|▍         | 169/4500 [00:00<00:12, 351.43it/s]  5%|▍         | 205/4500 [00:00<00:12, 336.02it/s]  5%|▌         | 239/4500 [00:00<00:13, 323.41it/s]  6%|▌         | 277/4500 [00:00<00:12, 338.53it/s]  7%|▋         | 312/4500 [00:00<00:13, 318.79it/s]  8%|▊         | 345/4500 [00:01<00:15, 270.56it/s]  8%|▊         | 374/4500 [00:01<00:17, 231.72it/s]  9%|▉         | 399/4500 [00:01<00:17, 228.24it/s] 10%|▉         | 429/4500 [00:01<00:16, 245.05it/s] 10%|█         | 460/4500 [00:01<00:15, 259.42it/s] 11%|█         | 487/4500 [00:01<00:15, 255.68it/s] 11%|█▏        | 514/4500 [00:01<00:15, 256.99it/s] 12%|█▏        | 541/4500 [00:01<00:16, 239.52it/s] 13%|█▎        | 568/4500 [00:02<00:16, 241.99it/s] 13%|█▎        | 593/4500 [00:02<00:18, 213.82it/s] 14%|█▍        | 629/4500 [00:02<00:15, 246.89it/s] 15%|█▍        | 657/4500 [00:02<00:15, 246.07it/s] 15%|█▌        | 692/4500 [00:02<00:14, 266.39it/s] 16%|█▌        | 720/4500 [00:02<00:14, 252.07it/s] 17%|█▋        | 746/4500 [00:02<00:15, 243.41it/s] 17%|█▋        | 779/4500 [00:02<00:14, 255.19it/s] 18%|█▊        | 809/4500 [00:02<00:14, 259.36it/s] 20%|█▉        | 878/4500 [00:03<00:10, 360.78it/s] 21%|██        | 933/4500 [00:03<00:08, 410.61it/s] 22%|██▏       | 985/4500 [00:03<00:08, 434.80it/s] 23%|██▎       | 1030/4500 [00:03<00:08, 425.40it/s] 24%|██▍       | 1073/4500 [00:03<00:08, 393.62it/s] 25%|██▍       | 1118/4500 [00:03<00:08, 408.55it/s] 27%|██▋       | 1207/4500 [00:03<00:06, 518.16it/s] 28%|██▊       | 1259/4500 [00:03<00:06, 516.49it/s] 29%|██▉       | 1311/4500 [00:03<00:06, 498.93it/s] 31%|███       | 1373/4500 [00:04<00:05, 526.91it/s] 32%|███▏      | 1426/4500 [00:04<00:07, 425.05it/s] 33%|███▎      | 1472/4500 [00:04<00:08, 338.02it/s] 34%|███▎      | 1516/4500 [00:04<00:08, 352.97it/s] 35%|███▍      | 1561/4500 [00:04<00:07, 370.98it/s] 36%|███▌      | 1607/4500 [00:04<00:07, 389.79it/s] 37%|███▋      | 1649/4500 [00:05<00:08, 317.11it/s] 37%|███▋      | 1685/4500 [00:05<00:09, 288.44it/s] 38%|███▊      | 1721/4500 [00:05<00:09, 304.06it/s] 39%|███▉      | 1754/4500 [00:05<00:09, 303.11it/s] 40%|████      | 1815/4500 [00:05<00:07, 374.81it/s] 41%|████▏     | 1857/4500 [00:05<00:06, 379.69it/s] 42%|████▏     | 1906/4500 [00:05<00:06, 402.30it/s] 44%|████▍     | 1974/4500 [00:05<00:05, 462.97it/s] 45%|████▌     | 2031/4500 [00:05<00:05, 475.60it/s] 46%|████▌     | 2080/4500 [00:06<00:05, 446.46it/s] 47%|████▋     | 2131/4500 [00:06<00:05, 455.37it/s] 48%|████▊     | 2178/4500 [00:06<00:05, 438.86it/s] 49%|████▉     | 2223/4500 [00:06<00:06, 357.37it/s] 50%|█████     | 2262/4500 [00:06<00:06, 324.14it/s] 51%|█████     | 2297/4500 [00:06<00:07, 289.48it/s] 52%|█████▏    | 2328/4500 [00:06<00:07, 282.97it/s] 52%|█████▏    | 2358/4500 [00:07<00:08, 262.62it/s] 53%|█████▎    | 2386/4500 [00:07<00:08, 241.30it/s] 54%|█████▍    | 2430/4500 [00:07<00:07, 285.23it/s] 55%|█████▍    | 2474/4500 [00:07<00:06, 314.92it/s] 56%|█████▌    | 2522/4500 [00:07<00:05, 354.18it/s] 57%|█████▋    | 2569/4500 [00:07<00:05, 375.98it/s] 58%|█████▊    | 2620/4500 [00:07<00:04, 393.54it/s] 59%|█████▉    | 2661/4500 [00:07<00:04, 390.98it/s] 60%|██████    | 2701/4500 [00:07<00:04, 382.74it/s] 61%|██████    | 2740/4500 [00:08<00:04, 369.85it/s] 62%|██████▏   | 2778/4500 [00:08<00:04, 360.45it/s] 63%|██████▎   | 2821/4500 [00:08<00:04, 377.74it/s] 64%|██████▎   | 2862/4500 [00:08<00:04, 383.36it/s] 65%|██████▍   | 2915/4500 [00:08<00:04, 392.90it/s] 66%|██████▌   | 2955/4500 [00:08<00:04, 381.31it/s] 67%|██████▋   | 2994/4500 [00:08<00:03, 376.93it/s] 68%|██████▊   | 3041/4500 [00:08<00:03, 396.63it/s] 68%|██████▊   | 3081/4500 [00:08<00:03, 372.80it/s] 69%|██████▉   | 3119/4500 [00:09<00:03, 350.24it/s] 70%|███████   | 3155/4500 [00:09<00:04, 307.41it/s] 71%|███████   | 3187/4500 [00:09<00:04, 276.28it/s] 72%|███████▏  | 3236/4500 [00:09<00:03, 322.87it/s] 73%|███████▎  | 3273/4500 [00:09<00:03, 328.55it/s] 74%|███████▎  | 3312/4500 [00:09<00:03, 338.02it/s] 74%|███████▍  | 3347/4500 [00:09<00:03, 292.36it/s] 75%|███████▌  | 3394/4500 [00:09<00:03, 331.28it/s] 76%|███████▌  | 3429/4500 [00:10<00:03, 319.60it/s] 77%|███████▋  | 3463/4500 [00:10<00:03, 312.72it/s] 78%|███████▊  | 3496/4500 [00:10<00:04, 225.33it/s] 78%|███████▊  | 3523/4500 [00:10<00:06, 157.01it/s] 79%|███████▉  | 3544/4500 [00:10<00:05, 164.75it/s] 79%|███████▉  | 3565/4500 [00:11<00:05, 160.87it/s] 80%|███████▉  | 3584/4500 [00:11<00:06, 133.29it/s] 80%|████████  | 3620/4500 [00:11<00:05, 175.15it/s] 81%|████████▏ | 3658/4500 [00:11<00:03, 213.62it/s] 83%|████████▎ | 3715/4500 [00:11<00:02, 293.31it/s] 83%|████████▎ | 3750/4500 [00:11<00:02, 280.16it/s] 84%|████████▍ | 3789/4500 [00:11<00:02, 297.56it/s] 85%|████████▌ | 3840/4500 [00:11<00:01, 340.25it/s] 86%|████████▌ | 3881/4500 [00:12<00:01, 358.12it/s] 87%|████████▋ | 3927/4500 [00:12<00:01, 385.33it/s] 88%|████████▊ | 3979/4500 [00:12<00:01, 420.04it/s] 89%|████████▉ | 4023/4500 [00:12<00:01, 417.18it/s] 90%|█████████ | 4066/4500 [00:12<00:01, 394.43it/s] 91%|█████████▏| 4107/4500 [00:12<00:01, 379.03it/s] 92%|█████████▏| 4146/4500 [00:12<00:00, 360.78it/s] 93%|█████████▎| 4183/4500 [00:12<00:01, 290.58it/s] 94%|█████████▍| 4234/4500 [00:13<00:00, 341.01it/s] 95%|█████████▌| 4290/4500 [00:13<00:00, 389.51it/s] 96%|█████████▋| 4332/4500 [00:13<00:00, 329.87it/s] 97%|█████████▋| 4369/4500 [00:13<00:00, 290.58it/s] 98%|█████████▊| 4408/4500 [00:13<00:00, 312.30it/s] 99%|█████████▊| 4442/4500 [00:13<00:00, 311.04it/s]100%|██████████| 4500/4500 [00:13<00:00, 327.83it/s]
test process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test
starting gen taf script for test_neglected
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 81/10000 [00:00<00:12, 777.63it/s]  2%|▏         | 159/10000 [00:00<00:25, 388.22it/s]  2%|▏         | 208/10000 [00:00<00:29, 334.37it/s]  2%|▏         | 247/10000 [00:00<00:30, 319.73it/s]  3%|▎         | 282/10000 [00:00<00:33, 287.51it/s]  3%|▎         | 314/10000 [00:00<00:33, 288.20it/s]  4%|▎         | 352/10000 [00:01<00:32, 297.30it/s]  4%|▍         | 390/10000 [00:01<00:30, 317.96it/s]  5%|▍         | 453/10000 [00:01<00:24, 394.40it/s]  5%|▌         | 501/10000 [00:01<00:22, 417.39it/s]  6%|▌         | 571/10000 [00:01<00:19, 491.14it/s]  6%|▌         | 622/10000 [00:01<00:19, 470.73it/s]  7%|▋         | 696/10000 [00:01<00:17, 545.20it/s]  8%|▊         | 753/10000 [00:01<00:16, 546.03it/s]  8%|▊         | 811/10000 [00:01<00:17, 536.56it/s]  9%|▊         | 866/10000 [00:02<00:18, 500.59it/s]  9%|▉         | 917/10000 [00:02<00:21, 425.22it/s] 10%|▉         | 970/10000 [00:02<00:20, 446.46it/s] 10%|█         | 1017/10000 [00:02<00:23, 379.57it/s] 11%|█         | 1058/10000 [00:02<00:26, 331.99it/s] 11%|█         | 1094/10000 [00:02<00:27, 326.98it/s] 11%|█▏        | 1129/10000 [00:02<00:30, 294.22it/s] 12%|█▏        | 1168/10000 [00:03<00:28, 309.05it/s] 12%|█▏        | 1217/10000 [00:03<00:25, 347.75it/s] 13%|█▎        | 1292/10000 [00:03<00:19, 449.97it/s] 14%|█▎        | 1360/10000 [00:03<00:16, 509.32it/s] 14%|█▍        | 1414/10000 [00:03<00:22, 385.10it/s] 15%|█▍        | 1459/10000 [00:03<00:26, 323.89it/s] 15%|█▍        | 1497/10000 [00:04<00:33, 251.09it/s] 15%|█▌        | 1528/10000 [00:04<00:33, 252.26it/s] 16%|█▌        | 1558/10000 [00:04<00:35, 236.30it/s] 16%|█▌        | 1585/10000 [00:04<00:40, 207.77it/s] 16%|█▌        | 1619/10000 [00:04<00:36, 229.11it/s] 17%|█▋        | 1677/10000 [00:04<00:27, 305.60it/s] 17%|█▋        | 1742/10000 [00:04<00:22, 371.30it/s] 18%|█▊        | 1810/10000 [00:04<00:18, 439.99it/s] 19%|█▉        | 1899/10000 [00:05<00:14, 551.73it/s] 20%|█▉        | 1988/10000 [00:05<00:12, 637.31it/s] 21%|██        | 2056/10000 [00:05<00:14, 560.12it/s] 21%|██        | 2117/10000 [00:05<00:15, 517.28it/s] 22%|██▏       | 2173/10000 [00:05<00:16, 469.63it/s] 22%|██▏       | 2223/10000 [00:05<00:16, 458.42it/s] 23%|██▎       | 2271/10000 [00:05<00:20, 368.90it/s] 23%|██▎       | 2312/10000 [00:06<00:25, 303.30it/s] 24%|██▎       | 2350/10000 [00:06<00:24, 314.32it/s] 24%|██▍       | 2385/10000 [00:06<00:25, 303.06it/s] 24%|██▍       | 2422/10000 [00:06<00:24, 315.05it/s] 25%|██▍       | 2477/10000 [00:06<00:20, 368.12it/s] 25%|██▌       | 2528/10000 [00:06<00:18, 398.11it/s] 26%|██▌       | 2570/10000 [00:06<00:19, 390.96it/s] 26%|██▌       | 2611/10000 [00:06<00:18, 391.93it/s] 27%|██▋       | 2652/10000 [00:07<00:24, 304.33it/s] 27%|██▋       | 2686/10000 [00:07<00:30, 243.06it/s] 27%|██▋       | 2715/10000 [00:07<00:33, 218.81it/s] 27%|██▋       | 2740/10000 [00:07<00:34, 207.58it/s] 28%|██▊       | 2763/10000 [00:07<00:36, 197.87it/s] 28%|██▊       | 2784/10000 [00:08<00:44, 160.72it/s] 28%|██▊       | 2845/10000 [00:08<00:28, 248.38it/s] 29%|██▉       | 2890/10000 [00:08<00:24, 287.27it/s] 29%|██▉       | 2940/10000 [00:08<00:21, 333.36it/s] 30%|███       | 3008/10000 [00:08<00:16, 411.99it/s] 31%|███       | 3054/10000 [00:08<00:20, 345.96it/s] 31%|███       | 3094/10000 [00:08<00:22, 305.61it/s] 31%|███▏      | 3129/10000 [00:08<00:23, 289.10it/s] 32%|███▏      | 3161/10000 [00:09<00:26, 254.08it/s] 32%|███▏      | 3208/10000 [00:09<00:23, 294.29it/s] 33%|███▎      | 3268/10000 [00:09<00:18, 364.43it/s] 33%|███▎      | 3337/10000 [00:09<00:15, 439.71it/s] 34%|███▍      | 3412/10000 [00:09<00:12, 519.82it/s] 35%|███▍      | 3468/10000 [00:09<00:14, 459.14it/s] 35%|███▌      | 3518/10000 [00:09<00:15, 421.31it/s] 36%|███▌      | 3567/10000 [00:09<00:14, 436.81it/s] 36%|███▌      | 3614/10000 [00:10<00:14, 432.91it/s] 37%|███▋      | 3665/10000 [00:10<00:14, 451.49it/s] 37%|███▋      | 3726/10000 [00:10<00:13, 474.99it/s] 38%|███▊      | 3787/10000 [00:10<00:12, 509.25it/s] 38%|███▊      | 3839/10000 [00:10<00:12, 504.17it/s] 39%|███▉      | 3891/10000 [00:10<00:13, 452.90it/s] 39%|███▉      | 3938/10000 [00:10<00:15, 389.31it/s] 40%|███▉      | 3980/10000 [00:10<00:16, 356.07it/s] 40%|████      | 4038/10000 [00:11<00:14, 407.94it/s] 41%|████      | 4089/10000 [00:11<00:13, 430.59it/s] 42%|████▏     | 4193/10000 [00:11<00:09, 584.81it/s] 43%|████▎     | 4255/10000 [00:11<00:09, 582.83it/s] 43%|████▎     | 4316/10000 [00:11<00:10, 527.72it/s] 44%|████▍     | 4380/10000 [00:11<00:10, 536.88it/s] 44%|████▍     | 4436/10000 [00:11<00:12, 439.65it/s] 45%|████▍     | 4484/10000 [00:11<00:14, 373.19it/s] 45%|████▌     | 4526/10000 [00:12<00:17, 314.50it/s] 46%|████▌     | 4562/10000 [00:12<00:19, 284.38it/s] 46%|████▌     | 4595/10000 [00:12<00:18, 292.94it/s] 46%|████▋     | 4627/10000 [00:12<00:20, 258.11it/s] 47%|████▋     | 4675/10000 [00:12<00:17, 300.79it/s] 47%|████▋     | 4708/10000 [00:12<00:18, 293.62it/s] 47%|████▋     | 4740/10000 [00:12<00:18, 286.99it/s] 48%|████▊     | 4776/10000 [00:13<00:17, 304.06it/s] 48%|████▊     | 4808/10000 [00:13<00:18, 279.53it/s] 48%|████▊     | 4837/10000 [00:13<00:20, 252.26it/s] 49%|████▊     | 4864/10000 [00:13<00:20, 248.77it/s] 49%|████▉     | 4890/10000 [00:13<00:21, 233.95it/s] 49%|████▉     | 4914/10000 [00:13<00:22, 221.63it/s] 49%|████▉     | 4937/10000 [00:13<00:25, 200.27it/s] 50%|████▉     | 4970/10000 [00:13<00:21, 229.45it/s] 50%|████▉     | 4994/10000 [00:14<00:21, 229.43it/s] 50%|█████     | 5033/10000 [00:14<00:18, 270.26it/s] 51%|█████     | 5092/10000 [00:14<00:14, 347.04it/s] 52%|█████▏    | 5157/10000 [00:14<00:11, 418.89it/s] 52%|█████▏    | 5200/10000 [00:14<00:11, 400.64it/s] 52%|█████▏    | 5241/10000 [00:14<00:13, 340.99it/s] 53%|█████▎    | 5277/10000 [00:14<00:15, 297.84it/s] 53%|█████▎    | 5309/10000 [00:14<00:16, 284.73it/s] 53%|█████▎    | 5339/10000 [00:15<00:18, 250.42it/s] 54%|█████▎    | 5367/10000 [00:15<00:18, 254.64it/s] 54%|█████▍    | 5394/10000 [00:15<00:18, 251.31it/s] 54%|█████▍    | 5434/10000 [00:15<00:16, 277.63it/s] 55%|█████▍    | 5483/10000 [00:15<00:14, 321.35it/s] 55%|█████▌    | 5521/10000 [00:15<00:13, 331.71it/s] 56%|█████▌    | 5557/10000 [00:15<00:13, 339.33it/s] 56%|█████▌    | 5593/10000 [00:15<00:12, 344.50it/s] 57%|█████▋    | 5661/10000 [00:15<00:10, 431.31it/s] 57%|█████▋    | 5705/10000 [00:16<00:09, 430.52it/s] 58%|█████▊    | 5760/10000 [00:16<00:09, 457.42it/s] 58%|█████▊    | 5806/10000 [00:16<00:10, 392.26it/s] 58%|█████▊    | 5850/10000 [00:16<00:10, 400.83it/s] 59%|█████▉    | 5892/10000 [00:16<00:11, 368.97it/s] 59%|█████▉    | 5931/10000 [00:16<00:11, 339.17it/s] 60%|█████▉    | 5967/10000 [00:16<00:12, 313.56it/s] 60%|██████    | 6002/10000 [00:16<00:12, 310.72it/s] 61%|██████    | 6053/10000 [00:17<00:11, 358.65it/s] 61%|██████    | 6098/10000 [00:17<00:10, 381.29it/s] 62%|██████▏   | 6154/10000 [00:17<00:09, 426.38it/s] 62%|██████▏   | 6198/10000 [00:17<00:09, 381.32it/s] 62%|██████▏   | 6238/10000 [00:17<00:11, 340.34it/s] 63%|██████▎   | 6274/10000 [00:17<00:14, 256.82it/s] 63%|██████▎   | 6319/10000 [00:17<00:12, 294.21it/s] 64%|██████▎   | 6353/10000 [00:18<00:14, 250.34it/s] 64%|██████▍   | 6382/10000 [00:18<00:14, 243.33it/s] 64%|██████▍   | 6410/10000 [00:18<00:14, 250.17it/s] 64%|██████▍   | 6437/10000 [00:18<00:14, 245.67it/s] 65%|██████▍   | 6463/10000 [00:18<00:15, 224.51it/s] 65%|██████▍   | 6494/10000 [00:18<00:14, 242.53it/s] 65%|██████▌   | 6520/10000 [00:18<00:14, 236.74it/s] 66%|██████▌   | 6558/10000 [00:18<00:12, 266.04it/s] 66%|██████▌   | 6586/10000 [00:19<00:13, 252.53it/s] 66%|██████▌   | 6617/10000 [00:19<00:12, 266.57it/s] 67%|██████▋   | 6656/10000 [00:19<00:11, 280.54it/s] 67%|██████▋   | 6685/10000 [00:19<00:12, 257.49it/s] 67%|██████▋   | 6729/10000 [00:19<00:11, 296.99it/s] 68%|██████▊   | 6760/10000 [00:19<00:11, 293.34it/s] 68%|██████▊   | 6790/10000 [00:19<00:11, 274.88it/s] 68%|██████▊   | 6831/10000 [00:19<00:10, 306.02it/s] 69%|██████▉   | 6878/10000 [00:20<00:08, 348.86it/s] 69%|██████▉   | 6933/10000 [00:20<00:07, 398.87it/s] 70%|██████▉   | 6989/10000 [00:20<00:06, 443.95it/s] 70%|███████   | 7035/10000 [00:20<00:06, 431.49it/s] 71%|███████   | 7087/10000 [00:20<00:06, 445.48it/s] 71%|███████▏  | 7132/10000 [00:20<00:06, 429.47it/s] 72%|███████▏  | 7181/10000 [00:20<00:06, 444.63it/s] 72%|███████▏  | 7227/10000 [00:20<00:06, 440.66it/s] 73%|███████▎  | 7285/10000 [00:20<00:05, 469.77it/s] 74%|███████▎  | 7359/10000 [00:20<00:04, 534.34it/s] 74%|███████▍  | 7413/10000 [00:21<00:05, 440.55it/s] 75%|███████▍  | 7460/10000 [00:21<00:05, 442.63it/s] 75%|███████▌  | 7527/10000 [00:21<00:05, 484.37it/s] 76%|███████▌  | 7577/10000 [00:21<00:05, 465.70it/s] 76%|███████▋  | 7625/10000 [00:21<00:05, 420.94it/s] 77%|███████▋  | 7669/10000 [00:21<00:06, 376.38it/s] 77%|███████▋  | 7709/10000 [00:21<00:06, 376.69it/s] 77%|███████▋  | 7748/10000 [00:22<00:06, 350.56it/s] 78%|███████▊  | 7784/10000 [00:22<00:07, 314.36it/s] 78%|███████▊  | 7824/10000 [00:22<00:06, 332.50it/s] 79%|███████▉  | 7913/10000 [00:22<00:04, 463.04it/s] 80%|███████▉  | 7978/10000 [00:22<00:03, 507.22it/s] 81%|████████  | 8059/10000 [00:22<00:03, 579.41it/s] 81%|████████  | 8119/10000 [00:22<00:03, 543.94it/s] 82%|████████▏ | 8181/10000 [00:22<00:03, 559.56it/s] 82%|████████▏ | 8239/10000 [00:23<00:03, 455.03it/s] 83%|████████▎ | 8289/10000 [00:23<00:04, 378.72it/s] 83%|████████▎ | 8332/10000 [00:23<00:04, 353.49it/s] 84%|████████▎ | 8371/10000 [00:23<00:05, 307.65it/s] 84%|████████▍ | 8405/10000 [00:23<00:05, 299.12it/s] 84%|████████▍ | 8437/10000 [00:23<00:05, 297.94it/s] 85%|████████▍ | 8474/10000 [00:23<00:04, 313.46it/s] 85%|████████▌ | 8517/10000 [00:23<00:04, 341.10it/s] 86%|████████▌ | 8553/10000 [00:24<00:04, 335.42it/s] 86%|████████▌ | 8588/10000 [00:24<00:04, 298.80it/s] 87%|████████▋ | 8656/10000 [00:24<00:03, 382.38it/s] 87%|████████▋ | 8714/10000 [00:24<00:03, 413.65it/s] 88%|████████▊ | 8782/10000 [00:24<00:02, 481.49it/s] 88%|████████▊ | 8843/10000 [00:24<00:02, 515.95it/s] 89%|████████▉ | 8924/10000 [00:24<00:01, 590.13it/s] 90%|█████████ | 9000/10000 [00:24<00:01, 637.60it/s] 91%|█████████ | 9066/10000 [00:24<00:01, 639.53it/s] 91%|█████████▏| 9131/10000 [00:25<00:01, 570.31it/s] 92%|█████████▏| 9190/10000 [00:25<00:01, 517.55it/s] 92%|█████████▏| 9244/10000 [00:25<00:01, 464.48it/s] 93%|█████████▎| 9293/10000 [00:25<00:01, 372.12it/s] 93%|█████████▎| 9335/10000 [00:25<00:01, 376.62it/s] 94%|█████████▍| 9376/10000 [00:25<00:02, 296.06it/s] 94%|█████████▍| 9415/10000 [00:26<00:01, 315.28it/s] 95%|█████████▍| 9451/10000 [00:26<00:01, 288.53it/s] 95%|█████████▍| 9490/10000 [00:26<00:01, 304.63it/s] 95%|█████████▌| 9523/10000 [00:26<00:01, 304.67it/s] 96%|█████████▌| 9556/10000 [00:26<00:01, 302.56it/s] 96%|█████████▌| 9594/10000 [00:26<00:01, 322.25it/s] 96%|█████████▋| 9628/10000 [00:26<00:01, 285.62it/s] 97%|█████████▋| 9678/10000 [00:26<00:00, 337.48it/s] 97%|█████████▋| 9717/10000 [00:27<00:00, 346.81it/s] 98%|█████████▊| 9762/10000 [00:27<00:00, 374.68it/s] 98%|█████████▊| 9801/10000 [00:27<00:00, 339.73it/s] 99%|█████████▊| 9860/10000 [00:27<00:00, 404.62it/s] 99%|█████████▉| 9944/10000 [00:27<00:00, 522.26it/s]100%|██████████| 10000/10000 [00:27<00:00, 363.25it/s]
test_neglected process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Train: X=torch.Size([108000, 3, 2, 2000]), y=torch.Size([108000])
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
num_classes: 45
No pre-trained model
Loss for training is SupConLoss
torch.Size([256, 3, 2, 2000])
epoch: 0
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:02<14:24,  2.06s/it]going through batches for holmes training:   1%|          | 3/421 [00:02<04:07,  1.69it/s]going through batches for holmes training:   1%|          | 5/421 [00:02<02:14,  3.08it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:02<01:29,  4.63it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:02<01:05,  6.25it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:02<00:52,  7.84it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:02<00:43,  9.33it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:03<00:38, 10.63it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:03<00:34, 11.67it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:03<00:32, 12.50it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:03<00:30, 13.15it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:03<00:29, 13.63it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:03<00:28, 14.01it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:03<00:27, 14.27it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:03<00:27, 14.46it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:04<00:26, 14.60it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:04<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:04<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:04<00:25, 14.85it/s]going through batches for holmes training:  10%|█         | 43/421 [00:04<00:25, 14.85it/s]going through batches for holmes training:  11%|█         | 45/421 [00:05<00:25, 14.86it/s]going through batches for holmes training:  11%|█         | 47/421 [00:05<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:05<00:25, 14.87it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:05<00:24, 14.87it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:05<00:24, 14.88it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:05<00:24, 14.89it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:05<00:24, 14.91it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:05<00:24, 14.90it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:06<00:24, 14.90it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:06<00:24, 14.90it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:06<00:23, 14.90it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:06<00:23, 14.91it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:06<00:23, 14.92it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:06<00:23, 14.91it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:06<00:23, 14.91it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:07<00:23, 14.91it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:07<00:23, 14.91it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:07<00:22, 14.91it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:07<00:22, 14.91it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:07<00:22, 14.92it/s]going through batches for holmes training:  20%|██        | 85/421 [00:07<00:22, 14.92it/s]going through batches for holmes training:  21%|██        | 87/421 [00:07<00:22, 14.92it/s]going through batches for holmes training:  21%|██        | 89/421 [00:07<00:22, 14.89it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:08<00:22, 14.88it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:08<00:22, 14.89it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:08<00:21, 14.90it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:08<00:21, 14.92it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:08<00:21, 14.92it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:08<00:21, 14.91it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:08<00:21, 14.91it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:09<00:21, 14.91it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:09<00:21, 14.90it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:09<00:20, 14.90it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:09<00:20, 14.91it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:09<00:20, 14.90it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:09<00:20, 14.90it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:09<00:20, 14.89it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:10<00:20, 14.89it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:10<00:20, 14.89it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:10<00:20, 14.88it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:10<00:19, 14.88it/s]going through batches for holmes training:  30%|███       | 127/421 [00:10<00:19, 14.90it/s]going through batches for holmes training:  31%|███       | 129/421 [00:10<00:19, 14.93it/s]going through batches for holmes training:  31%|███       | 131/421 [00:10<00:19, 14.93it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:10<00:19, 14.93it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:11<00:19, 14.91it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:11<00:19, 14.91it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:11<00:18, 14.91it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:11<00:18, 14.90it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:11<00:18, 14.90it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:11<00:18, 14.90it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:11<00:18, 14.92it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:12<00:18, 14.91it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:12<00:18, 14.94it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:12<00:17, 14.93it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:12<00:17, 14.92it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:12<00:17, 14.94it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:12<00:17, 14.93it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:12<00:17, 14.91it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.91it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:13<00:18, 13.78it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:13<00:18, 14.04it/s]going through batches for holmes training:  40%|████      | 169/421 [00:13<00:17, 14.27it/s]going through batches for holmes training:  41%|████      | 171/421 [00:13<00:17, 14.45it/s]going through batches for holmes training:  41%|████      | 173/421 [00:13<00:17, 14.57it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:13<00:16, 14.65it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:14<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:14<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:14<00:16, 14.84it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:14<00:15, 14.88it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:14<00:15, 14.90it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:15<00:15, 14.89it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:15<00:15, 14.89it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:15<00:15, 14.90it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:15<00:14, 14.90it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:15<00:14, 14.92it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:15<00:14, 14.91it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:15<00:14, 14.93it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.92it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:16<00:14, 14.91it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:16<00:14, 14.89it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:16<00:13, 14.90it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:17<00:13, 14.92it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:17<00:13, 14.93it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:17<00:12, 14.93it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:17<00:12, 14.93it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:17<00:12, 14.92it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:17<00:12, 14.92it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:17<00:12, 14.93it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.92it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:18<00:12, 14.92it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:18<00:12, 14.89it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:18<00:11, 14.90it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.90it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:19<00:11, 14.90it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:19<00:11, 14.90it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:19<00:11, 14.90it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:19<00:10, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:20<00:10, 14.90it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:20<00:10, 14.89it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:20<00:09, 14.90it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:20<00:09, 14.91it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:20<00:09, 14.90it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:21<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:21<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:21<00:09, 14.88it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:21<00:08, 14.90it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:21<00:08, 14.91it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:21<00:08, 14.90it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.89it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.90it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:22<00:08, 14.90it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:22<00:08, 14.89it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:22<00:07, 14.90it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:22<00:07, 14.90it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:22<00:07, 14.90it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:22<00:07, 14.90it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.89it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:23<00:07, 14.90it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:23<00:07, 14.88it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:23<00:06, 14.87it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:23<00:06, 14.89it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:23<00:06, 14.88it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:23<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:24<00:06, 14.88it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:24<00:06, 14.88it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:24<00:06, 14.89it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:24<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:24<00:05, 14.90it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.89it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:25<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:25<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:26<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:26<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:26<00:04, 14.91it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.91it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.90it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:27<00:03, 14.89it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:27<00:03, 14.89it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:27<00:02, 14.91it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:27<00:02, 14.91it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:27<00:02, 14.89it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:28<00:02, 14.15it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:28<00:02, 14.31it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:28<00:02, 14.41it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:28<00:01, 14.52it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:28<00:01, 14.61it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:29<00:01, 14.75it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:29<00:01, 14.67it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:29<00:01, 14.77it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:29<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:29<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:29<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.91it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.93it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:30<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:30<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:30<00:00, 14.93it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:30<00:00, 13.86it/s]
epoch 0: train_loss = 4.041
0: {'Accuracy': 0.8831, 'Precision': 0.8857, 'Recall': 0.8831, 'F1-score': 0.8836}
epoch: 1
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:38,  1.05it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.38it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.59it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.61it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.29it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.65it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.78it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.63it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.27it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:30, 13.29it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 13.96it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.21it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.53it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.83it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.80it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.81it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.80it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.80it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.34it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.44it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.53it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.57it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.63it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.80it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.82it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.81it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.81it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 1: train_loss = 2.757
1: {'Accuracy': 0.9144, 'Precision': 0.9165, 'Recall': 0.9144, 'F1-score': 0.915}
epoch: 2
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:44,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.32it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.49it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.39it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.11it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.49it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.61it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.48it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.11it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.60it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.90it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.12it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.26it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.52it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.72it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.63it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.63it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.67it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.58it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.61it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.63it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.62it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.58it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.59it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.60it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.60it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.62it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.62it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.58it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.57it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.60it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.61it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:22, 14.62it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.64it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.55it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.52it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.56it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.61it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.64it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.64it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.60it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.58it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.59it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.58it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.60it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.64it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.59it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.57it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.54it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.52it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.56it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.60it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.62it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.63it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:19, 14.62it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.64it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.63it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.66it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.67it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.67it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.67it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.67it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.66it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.68it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.68it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.62it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.68it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.71it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.57it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.70it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.61it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.81it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.22it/s]
epoch 2: train_loss = 2.461
2: {'Accuracy': 0.9264, 'Precision': 0.9282, 'Recall': 0.9264, 'F1-score': 0.9269}
epoch: 3
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:11,  1.35it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:00,  3.47it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.68it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.66it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.38it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.80it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.91it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.73it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.35it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.82it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.18it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.70it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.85it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.86it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.85it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.85it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.86it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.60it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.62it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.63it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.67it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.81it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.88it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.90it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.87it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.79it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.70it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.63it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.64it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.62it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.56it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.61it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.62it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.63it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.53it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.59it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.63it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.64it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.64it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.67it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.69it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.57it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.80it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.38it/s]
epoch 3: train_loss = 2.324
3: {'Accuracy': 0.93, 'Precision': 0.9325, 'Recall': 0.93, 'F1-score': 0.9308}
epoch: 4
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:31,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:02,  3.43it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.65it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.61it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.31it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.73it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.85it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.71it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.32it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.76it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.11it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.31it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.46it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.58it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.84it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.87it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.87it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.86it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.88it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.88it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.87it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.89it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.89it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.13it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.30it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.45it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.55it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.62it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.66it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.69it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.76it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.59it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.61it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.71it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.71it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.70it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.66it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.71it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.71it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.72it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.47it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.56it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.58it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.64it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 4: train_loss = 2.244
4: {'Accuracy': 0.9347, 'Precision': 0.9371, 'Recall': 0.9347, 'F1-score': 0.9354}
epoch: 5
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:03,  1.01s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:10,  3.21it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:17,  5.36it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.35it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.00it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.43it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.59it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.47it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.12it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.55it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.90it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.15it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.34it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.45it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.56it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.61it/s]going through batches for holmes training:  11%|█         | 45/421 [00:04<00:25, 14.60it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.56it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.62it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.77it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.72it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.70it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.71it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.62it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.80it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.82it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.25it/s]
epoch 5: train_loss = 2.198
5: {'Accuracy': 0.9359, 'Precision': 0.9379, 'Recall': 0.9359, 'F1-score': 0.9365}
epoch: 6
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:57,  1.01it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:09,  3.22it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:17,  5.39it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.36it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.00it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.46it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.60it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.50it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.16it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.63it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.00it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.20it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.36it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.55it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.67it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.63it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.68it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.64it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.68it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.79it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.80it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.80it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:17, 13.96it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.21it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.33it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:16, 14.43it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.54it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.61it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.64it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.74it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.74it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.77it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 13.69it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 13.90it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.17it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.37it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.51it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.59it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.65it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.69it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.72it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.25it/s]
epoch 6: train_loss = 2.16
6: {'Accuracy': 0.9384, 'Precision': 0.9401, 'Recall': 0.9384, 'F1-score': 0.939}
epoch: 7
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:42,  1.23it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:50,  3.77it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:08,  6.09it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:51,  8.09it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:42,  9.73it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 11.03it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.08it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.87it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.43it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.86it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.16it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.35it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.56it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.60it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:27, 13.68it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:27, 13.98it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:26, 14.20it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:26, 14.35it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.47it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.54it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.60it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.67it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.69it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.68it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.73it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.65it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.66it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.72it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.71it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.77it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 7: train_loss = 2.125
7: {'Accuracy': 0.9425, 'Precision': 0.9451, 'Recall': 0.9425, 'F1-score': 0.9434}
epoch: 8
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:41,  1.23it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:51,  3.75it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:09,  6.03it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:51,  8.06it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:42,  9.72it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 11.06it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.09it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.84it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.41it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.79it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.10it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.33it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.56it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.71it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.71it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.73it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:21, 14.06it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:21, 14.26it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.39it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.48it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.57it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.62it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.64it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.67it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.68it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.66it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.66it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.66it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.72it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.75it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.67it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.68it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.65it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.68it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.66it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.70it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.62it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.80it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.31it/s]
epoch 8: train_loss = 2.093
8: {'Accuracy': 0.9427, 'Precision': 0.9445, 'Recall': 0.9427, 'F1-score': 0.9433}
epoch: 9
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:30,  1.08it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:02,  3.42it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.65it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.58it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.29it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.69it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.80it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.66it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.23it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.23it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.50it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.57it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.53it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.56it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.53it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.53it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.57it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.77it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.80it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.79it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.78it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.78it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:16, 13.68it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:16, 13.99it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.22it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.38it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:15, 14.50it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.58it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.64it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.63it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.66it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.74it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.79it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.79it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.79it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.78it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.79it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.85it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.30it/s]
epoch 9: train_loss = 2.074
9: {'Accuracy': 0.9444, 'Precision': 0.9464, 'Recall': 0.9444, 'F1-score': 0.945}
epoch: 10
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:31,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:02,  3.41it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.65it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.65it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.33it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.75it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.84it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.64it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.28it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.72it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.05it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.45it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.57it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.78it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.65it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.62it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.59it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:26, 14.01it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.23it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:25, 14.38it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:25, 14.42it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.49it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.56it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.64it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.80it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.58it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:23, 14.58it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.61it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.64it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.68it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.71it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.71it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.66it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.76it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.76it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.80it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.78it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.77it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.77it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.59it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.61it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.54it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.58it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.63it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.65it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.68it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.69it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.71it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.71it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.72it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.28it/s]
epoch 10: train_loss = 2.058
10: {'Accuracy': 0.9446, 'Precision': 0.946, 'Recall': 0.9446, 'F1-score': 0.9451}
epoch: 11
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:38,  1.06it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.38it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.58it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.60it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.29it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.68it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.82it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.68it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.35it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.82it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.39it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.54it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.63it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.76it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.81it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.84it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.61it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.62it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.88it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.82it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.89it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.14it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:20, 14.22it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:20, 14.25it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.39it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.50it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.60it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.85it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.89it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.86it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.86it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.88it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.87it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.85it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.90it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.90it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.90it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.87it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.89it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.89it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.90it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.91it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.80it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.80it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.83it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.89it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.88it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.91it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.92it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:05, 13.69it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 13.97it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.16it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.36it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.50it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.61it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.95it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 11: train_loss = 2.042
11: {'Accuracy': 0.9442, 'Precision': 0.946, 'Recall': 0.9442, 'F1-score': 0.9448}
epoch: 12
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:39,  1.05it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:04,  3.36it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.57it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.53it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.25it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.62it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.73it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.58it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.17it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.98it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.20it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.39it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.50it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.55it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.60it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.59it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.61it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.70it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.67it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.68it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.59it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.58it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.58it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.63it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.88it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.72it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.67it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.66it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.65it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.39it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.49it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.58it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.63it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.66it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.69it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.64it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.65it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.63it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.62it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.62it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.69it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.69it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.66it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.63it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.65it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.64it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.64it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.63it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.55it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.52it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.57it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.61it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.61it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.63it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.66it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.65it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.61it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.65it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.68it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.58it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.55it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.58it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.58it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.58it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.63it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.66it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.66it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.66it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.64it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.62it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.65it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.65it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.66it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.69it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.69it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.59it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.61it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.62it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.63it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.62it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.66it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.67it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.61it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.63it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.56it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.84it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.23it/s]
epoch 12: train_loss = 2.031
12: {'Accuracy': 0.9452, 'Precision': 0.9466, 'Recall': 0.9452, 'F1-score': 0.9456}
epoch: 13
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:36,  1.06it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.39it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.63it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.63it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.27it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.68it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.81it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.68it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.32it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.80it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.10it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.33it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.46it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.57it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.78it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.80it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.58it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.58it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.64it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.66it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.64it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.66it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.70it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.67it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.59it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:23, 14.59it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.62it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.69it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.60it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.61it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.64it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.66it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.63it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.61it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.64it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.66it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.66it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.65it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.64it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.56it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.54it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.52it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.56it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.63it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.73it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.67it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.64it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.67it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.66it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.57it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:17, 14.55it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.53it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.55it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.63it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.67it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.63it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.59it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:16, 14.62it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.64it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.64it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.64it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.67it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.63it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.60it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.63it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.60it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.62it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.62it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.59it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.58it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.62it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.68it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.66it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.61it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.62it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.64it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.65it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.63it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.68it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.68it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.64it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.63it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.61it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.62it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.66it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.66it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.71it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.66it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.72it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.61it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.77it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.77it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.23it/s]
epoch 13: train_loss = 2.015
13: {'Accuracy': 0.9461, 'Precision': 0.9478, 'Recall': 0.9461, 'F1-score': 0.9466}
epoch: 14
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:11,  1.13it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<01:57,  3.56it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:11,  5.80it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:52,  7.83it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.53it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.85it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.93it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.76it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.39it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.86it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.16it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.35it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.59it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.87it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.78it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.66it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.62it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.60it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:20, 14.09it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.26it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:19, 14.33it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:19, 14.46it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.56it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.64it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.77it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.77it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.62it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.63it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.68it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.72it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.63it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.64it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.64it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.65it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.62it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.66it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.59it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.59it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.61it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.64it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.62it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.31it/s]
epoch 14: train_loss = 1.997
14: {'Accuracy': 0.9459, 'Precision': 0.9471, 'Recall': 0.9459, 'F1-score': 0.9462}
epoch: 15
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:28,  1.08it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:01,  3.43it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.66it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.65it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.33it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.73it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.82it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.67it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.29it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.06it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.53it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.75it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.77it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.77it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.76it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.79it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.80it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.78it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.80it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.80it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.78it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.63it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.62it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.68it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.68it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.68it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.71it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.79it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.82it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.31it/s]
epoch 15: train_loss = 1.992
15: {'Accuracy': 0.9453, 'Precision': 0.9462, 'Recall': 0.9453, 'F1-score': 0.9455}
epoch: 16
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:42,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:04,  3.35it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.57it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.52it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.23it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.62it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.75it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.62it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.27it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.76it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.08it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.30it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.45it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.55it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.84it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.83it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.81it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.85it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.81it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.81it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.82it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.81it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.93it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.95it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.95it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.95it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.36it/s]
epoch 16: train_loss = 1.98
16: {'Accuracy': 0.9466, 'Precision': 0.9479, 'Recall': 0.9466, 'F1-score': 0.947}
epoch: 17
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:28,  1.28it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:50,  3.80it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:07,  6.14it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:50,  8.12it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:42,  9.77it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:36, 11.09it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.13it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.91it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:29, 13.50it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:28, 13.91it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.21it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.43it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.55it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.73it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:02<00:26, 14.78it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.79it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.80it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.80it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.78it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:14<00:14, 14.91it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:16<00:12, 14.89it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.92it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.90it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.88it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.89it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.89it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.90it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.90it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.90it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.86it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.78it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.90it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:28<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.94it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.44it/s]
epoch 17: train_loss = 1.97
17: {'Accuracy': 0.9476, 'Precision': 0.9491, 'Recall': 0.9476, 'F1-score': 0.948}
epoch: 18
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:23,  1.09it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:00,  3.48it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:12,  5.71it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.69it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.35it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.72it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.83it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.66it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.25it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.71it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.98it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.17it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.32it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.43it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.53it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.76it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.86it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.78it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.83it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.61it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.66it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.78it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.85it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.83it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.83it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.86it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.84it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.63it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.64it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.62it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.66it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.70it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.60it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.63it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.58it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.62it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.67it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.68it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.68it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.58it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.31it/s]
epoch 18: train_loss = 1.958
18: {'Accuracy': 0.9452, 'Precision': 0.9462, 'Recall': 0.9452, 'F1-score': 0.9455}
epoch: 19
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:31,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:02,  3.42it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.67it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.68it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.32it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.73it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.86it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.70it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.33it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.80it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.10it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.30it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.45it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.57it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.77it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.80it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:23, 14.15it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.35it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.49it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:22, 14.55it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.61it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.67it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.86it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.81it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.81it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.84it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.82it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.37it/s]
epoch 19: train_loss = 1.951
19: {'Accuracy': 0.9467, 'Precision': 0.9476, 'Recall': 0.9467, 'F1-score': 0.9469}
epoch: 20
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:45,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.32it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.50it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.47it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.18it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.59it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.65it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.45it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.08it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.59it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.95it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.18it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.33it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.41it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:27, 14.46it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.53it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.57it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.57it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.53it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.54it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.62it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.66it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.63it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.63it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.67it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.67it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.65it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.64it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.58it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:23, 14.55it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.57it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.56it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.61it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.64it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.63it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.62it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:22, 14.59it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.64it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.62it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.62it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.61it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.60it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.62it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.65it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.69it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.64it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.59it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.60it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.62it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.63it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.62it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.58it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.59it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:19, 14.61it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.64it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.66it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.68it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.68it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.65it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.67it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.66it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.66it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:18, 13.47it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:18, 13.81it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:17, 14.03it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:17, 14.10it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:17, 14.28it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.30it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.41it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.51it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.57it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:16, 14.59it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.54it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.60it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.60it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.63it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.65it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.65it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.66it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.66it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.65it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.61it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:14, 14.54it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.56it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:16<00:13, 14.61it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.61it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.61it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.62it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.63it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.68it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.66it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.67it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.68it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.68it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.62it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:19<00:10, 14.62it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.62it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.66it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.66it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.68it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.69it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.68it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.64it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.62it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.61it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.56it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.59it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.60it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:22<00:07, 14.57it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.59it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.62it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.62it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.56it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:07, 14.56it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.60it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.62it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.63it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.64it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.65it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.67it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:24<00:05, 14.65it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.66it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.65it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.61it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.64it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:25<00:04, 14.63it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.62it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.63it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.62it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.61it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.62it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:26<00:03, 14.65it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.63it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.65it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.68it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:27<00:02, 14.62it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.62it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.64it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.68it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.66it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.57it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.62it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.63it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.67it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:29<00:00, 14.72it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.82it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.85it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.17it/s]
epoch 20: train_loss = 1.941
20: {'Accuracy': 0.945, 'Precision': 0.9461, 'Recall': 0.945, 'F1-score': 0.9453}
epoch: 21
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:15,  1.04s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:14,  3.10it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:19,  5.23it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:57,  7.21it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:46,  8.93it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.38it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.56it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.48it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.18it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:29, 13.51it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:28, 13.86it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:28, 14.07it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:27, 14.23it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:27, 14.35it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.46it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.53it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.56it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.57it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.62it/s]going through batches for holmes training:  11%|█         | 45/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.64it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:05<00:24, 14.67it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.67it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 89/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.70it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.72it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.65it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.80it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 13.78it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.10it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:12, 14.32it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.47it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.57it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.87it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.87it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.85it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.87it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.87it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.89it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.88it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.88it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.86it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.87it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.90it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.27it/s]
epoch 21: train_loss = 1.933
21: {'Accuracy': 0.9456, 'Precision': 0.9468, 'Recall': 0.9456, 'F1-score': 0.946}
epoch: 22
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:45,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.31it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.50it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.46it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.19it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.56it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.69it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.56it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.71it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.01it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.24it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.53it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.65it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.90it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.88it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.84it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.86it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.86it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.87it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.88it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.89it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.89it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.89it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.89it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.84it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.86it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.90it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.88it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.91it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.37it/s]
epoch 22: train_loss = 1.922
22: {'Accuracy': 0.946, 'Precision': 0.9472, 'Recall': 0.946, 'F1-score': 0.9464}
epoch: 23
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:43,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.31it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.52it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.52it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.22it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.65it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.78it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.65it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.29it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.76it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.36it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.50it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.84it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.77it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.78it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.81it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.83it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.81it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.82it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.90it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.91it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.91it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.90it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.90it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.90it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.90it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.90it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 13.99it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.28it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.47it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.59it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 23: train_loss = 1.915
23: {'Accuracy': 0.9448, 'Precision': 0.9464, 'Recall': 0.9448, 'F1-score': 0.9453}
epoch: 24
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:24,  1.09it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:00,  3.48it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:12,  5.72it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.68it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.38it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.77it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.87it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.66it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.25it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.06it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.40it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.60it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.61it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.68it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.69it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.66it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.73it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.71it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.68it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.72it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.76it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.76it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.79it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.78it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.77it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.79it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.81it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.81it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.32it/s]
epoch 24: train_loss = 1.91
24: {'Accuracy': 0.9464, 'Precision': 0.9472, 'Recall': 0.9464, 'F1-score': 0.9466}
epoch: 25
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:30,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:01,  3.43it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.66it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.66it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.29it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.67it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.76it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.62it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.25it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.96it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.17it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.32it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.46it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.55it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.67it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.91it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.90it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.90it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.88it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.90it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.92it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.90it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.64it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.71it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.87it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.89it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:17, 14.90it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.90it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.89it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.87it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.87it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.92it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.92it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:15, 14.92it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.92it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.91it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.90it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.90it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.90it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.91it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.91it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.91it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.91it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.90it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.89it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.88it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.89it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.90it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.92it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.91it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.90it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.90it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.90it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.91it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:08, 14.91it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.90it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.89it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.91it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.92it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.90it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.90it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.90it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.87it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.91it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.92it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.91it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.91it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.90it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.90it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.15it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.37it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.54it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.65it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.86it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.86it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.91it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.92it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.91it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.90it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.90it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.90it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.91it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.92it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.90it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.90it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.89it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.92it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.92it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.90it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.91it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.83it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.93it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.39it/s]
epoch 25: train_loss = 1.907
25: {'Accuracy': 0.9453, 'Precision': 0.9465, 'Recall': 0.9453, 'F1-score': 0.9456}
epoch: 26
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:24,  1.09it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:00,  3.46it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:12,  5.71it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.66it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.38it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.79it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.88it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.69it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.26it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.74it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.05it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.26it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.39it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.84it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.82it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.43it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.54it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.65it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.76it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.76it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.80it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.81it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.83it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.36it/s]
epoch 26: train_loss = 1.897
26: {'Accuracy': 0.9449, 'Precision': 0.9462, 'Recall': 0.9449, 'F1-score': 0.9453}
epoch: 27
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:31,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:02,  3.42it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.65it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.68it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.31it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.70it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.82it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.67it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.32it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.80it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.34it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.78it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:25, 14.13it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:25, 14.32it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.47it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.58it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.79it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.81it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.87it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:10, 13.97it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.23it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.41it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.55it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:09, 14.65it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.86it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.83it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.86it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.90it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.88it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.84it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.90it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.96it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.96it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.36it/s]
epoch 27: train_loss = 1.888
27: {'Accuracy': 0.9463, 'Precision': 0.9474, 'Recall': 0.9463, 'F1-score': 0.9466}
epoch: 28
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:46,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.32it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.51it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.46it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.13it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.55it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.68it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.56it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.22it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.55it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.88it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.90it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.90it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.89it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.90it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.82it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.90it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.90it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.89it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.90it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.89it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.88it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.88it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.89it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.91it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.89it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.89it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.89it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.90it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:17, 14.89it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.89it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.90it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.90it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.90it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.91it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.92it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.92it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.93it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.89it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.92it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.89it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:15, 14.89it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.91it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.89it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.89it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.89it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.90it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.91it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.92it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.90it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.90it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.91it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.89it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.88it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.89it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.89it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.89it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.90it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.90it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.90it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.89it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.90it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.89it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.90it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.90it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.91it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.90it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.89it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.90it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.92it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.91it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.89it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.94it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.94it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.94it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.95it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.94it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.39it/s]
epoch 28: train_loss = 1.886
28: {'Accuracy': 0.9451, 'Precision': 0.9459, 'Recall': 0.9451, 'F1-score': 0.9453}
epoch: 29
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:41,  1.05it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.34it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.55it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.52it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.23it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.66it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.80it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.68it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.33it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.78it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.63it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.70it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.81it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.75it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.77it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.65it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.67it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.66it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.64it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.65it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.65it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.63it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.65it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.66it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.66it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.65it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.67it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.67it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.64it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.65it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.64it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.60it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.64it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.69it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.70it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.70it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.61it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.53it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.56it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.58it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.61it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.64it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.65it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.63it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.63it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.62it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.66it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.67it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.67it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.64it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.62it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.65it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.62it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.61it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.60it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.55it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.59it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.61it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.60it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.53it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.58it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.62it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.63it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.65it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.65it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.67it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.68it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.67it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.62it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.63it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.56it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.61it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.62it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.59it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.61it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.64it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.67it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.68it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.69it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.67it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.67it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.66it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.66it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.63it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.60it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:09, 14.57it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.61it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.67it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.65it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.60it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.63it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.64it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.66it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.69it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.72it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.72it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.67it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.71it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.65it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.62it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.62it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.64it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.68it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.64it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.70it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.61it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.61it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.63it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.61it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.57it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.56it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.59it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.59it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.62it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.63it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.61it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.60it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.62it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.65it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.66it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.66it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.56it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.84it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.22it/s]
epoch 29: train_loss = 1.883
29: {'Accuracy': 0.9456, 'Precision': 0.9465, 'Recall': 0.9456, 'F1-score': 0.9459}
epoch: 30
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:39,  1.05it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.37it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.61it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.59it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.30it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.72it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.85it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.70it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.34it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.81it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.36it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.60it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.84it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.87it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.87it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.88it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.88it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.69it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.68it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.68it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.68it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.71it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.77it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.71it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.66it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.60it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.67it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.66it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.64it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.59it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.62it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.57it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.58it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.61it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.62it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.62it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.63it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.64it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.62it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.63it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.65it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.66it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.66it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.68it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.67it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.67it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.65it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.66it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.66it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.63it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.51it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.50it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.55it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.60it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.62it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.63it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.65it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.59it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.61it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.58it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.61it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.62it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.64it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.65it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.66it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.63it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.62it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.67it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.67it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.67it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.61it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.61it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.63it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.61it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.59it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.62it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.64it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.57it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.58it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.56it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.60it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.59it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.59it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.59it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.64it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.65it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.66it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.68it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.70it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.71it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.60it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.61it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.61it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.62it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.62it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.63it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.61it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.64it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.67it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.65it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.58it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.62it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.67it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.64it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.69it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.53it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.84it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.25it/s]
epoch 30: train_loss = 1.876
30: {'Accuracy': 0.9448, 'Precision': 0.9456, 'Recall': 0.9448, 'F1-score': 0.945}
epoch: 31
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:20,  1.10it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:01,  3.45it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:12,  5.70it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.73it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.41it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.80it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.91it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.76it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.38it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.78it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.12it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.58it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.78it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.84it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.85it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.86it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.85it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.88it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.88it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.90it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.90it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.89it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.85it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.23it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.38it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.46it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.55it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.63it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.67it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.87it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.89it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.88it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 13.77it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.04it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.24it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.39it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.52it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.62it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.93it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.94it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.94it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.37it/s]
epoch 31: train_loss = 1.874
31: {'Accuracy': 0.9481, 'Precision': 0.949, 'Recall': 0.9481, 'F1-score': 0.9484}
epoch: 32
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:49,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.30it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.50it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.49it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.12it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.52it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.66it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.54it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.17it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.62it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.00it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.25it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.57it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.82it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.85it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.86it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.88it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.80it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.89it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.88it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.87it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.89it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.88it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:14, 13.62it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:13, 13.94it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:13, 14.13it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.32it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.50it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.59it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.85it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.87it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.68it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.78it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.79it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 32: train_loss = 1.867
32: {'Accuracy': 0.9445, 'Precision': 0.9454, 'Recall': 0.9445, 'F1-score': 0.9447}
epoch: 33
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:24,  1.09it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:01,  3.45it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.69it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.72it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.45it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.84it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.94it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.73it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.37it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.83it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.11it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.36it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.50it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.85it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:24, 13.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:23, 14.02it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:23, 14.21it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.39it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.52it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.56it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.59it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:22, 14.60it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.62it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.67it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.70it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.69it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.70it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.73it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.70it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.63it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.66it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.78it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.55it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.59it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.65it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.67it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.66it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.66it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.65it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.68it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.58it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.59it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.54it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.56it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.59it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.62it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.61it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.59it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.62it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.66it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.66it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.67it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.67it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.69it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.71it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.69it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.60it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.59it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.62it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:08, 13.85it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:08, 14.08it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.26it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.32it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.46it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.55it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.61it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.69it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.65it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.67it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.80it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.25it/s]
epoch 33: train_loss = 1.859
33: {'Accuracy': 0.9454, 'Precision': 0.9464, 'Recall': 0.9454, 'F1-score': 0.9457}
epoch: 34
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:54,  1.01it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:08,  3.27it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.45it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.37it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.10it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.54it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.70it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.55it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.20it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.69it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.24it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.39it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.51it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.58it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.61it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.80it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.68it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.68it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.66it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.65it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.65it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.66it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.66it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.64it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.64it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.66it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:22, 14.62it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.63it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.59it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.60it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.61it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.60it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.59it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.59it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.62it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.62it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.60it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.60it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.59it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.63it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.59it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.60it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.66it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.73it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.33it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:18, 14.31it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:18, 14.43it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.52it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.55it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.62it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.64it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.81it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.81it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.83it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.71it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.85it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.27it/s]
epoch 34: train_loss = 1.858
34: {'Accuracy': 0.9461, 'Precision': 0.9468, 'Recall': 0.9461, 'F1-score': 0.9463}
epoch: 35
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:29,  1.07s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:16,  3.05it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:20,  5.16it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:58,  7.08it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:46,  8.82it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:40, 10.24it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.40it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:02<00:32, 12.35it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:31, 13.02it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.55it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.93it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.18it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.50it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 45/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.75it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.66it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.61it/s]going through batches for holmes training:  21%|██        | 89/421 [00:07<00:22, 14.61it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:10<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.62it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.66it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.64it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.77it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.59it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.64it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.82it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.82it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.82it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.83it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.71it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.85it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.85it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.24it/s]
epoch 35: train_loss = 1.849
35: {'Accuracy': 0.9457, 'Precision': 0.9466, 'Recall': 0.9457, 'F1-score': 0.946}
epoch: 36
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:43,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.34it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.54it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.55it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.25it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.65it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.77it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.63it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.29it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.08it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.30it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.59it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.83it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.89it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.89it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.87it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:23, 14.31it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.45it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.57it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.63it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.68it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.77it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.85it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.85it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.86it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 13.74it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.05it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.28it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:07, 14.46it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.56it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 36: train_loss = 1.845
36: {'Accuracy': 0.9467, 'Precision': 0.9475, 'Recall': 0.9467, 'F1-score': 0.9469}
epoch: 37
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:34,  1.06it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.39it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.63it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.62it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.27it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.70it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.82it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.67it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.33it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.75it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.11it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.32it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.85it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.89it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.89it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.87it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.87it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.88it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.88it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.86it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.83it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.87it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.87it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.88it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.86it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 13.79it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.09it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.30it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.47it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.45it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.58it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.87it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.37it/s]
epoch 37: train_loss = 1.847
37: {'Accuracy': 0.9474, 'Precision': 0.9485, 'Recall': 0.9474, 'F1-score': 0.9478}
epoch: 38
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:07,  1.02s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:11,  3.19it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:18,  5.33it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.32it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.06it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.41it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.58it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.48it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.19it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.69it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.03it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.25it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.57it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.70it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.70it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.66it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.78it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.72it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.60it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.58it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.63it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.70it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.73it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.67it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.67it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.76it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.68it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.68it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.63it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.67it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.61it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.63it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.64it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.65it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.65it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.58it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.60it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.62it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.63it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.62it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:06, 14.64it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.66it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.65it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.68it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.64it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.54it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.54it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.57it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.61it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.65it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.64it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.64it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.67it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.70it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.72it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.68it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.69it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.69it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.66it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.68it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.68it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.59it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.53it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.55it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.60it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.63it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.49it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.80it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.22it/s]
epoch 38: train_loss = 1.837
38: {'Accuracy': 0.9447, 'Precision': 0.9455, 'Recall': 0.9447, 'F1-score': 0.9449}
epoch: 39
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:51,  1.02it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:07,  3.27it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.47it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.48it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.19it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.63it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.74it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.56it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.24it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.74it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.11it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.32it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.58it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.78it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.84it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.86it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.86it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.87it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.87it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.85it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.89it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.87it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.83it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.77it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:22, 13.82it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:22, 14.12it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.33it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.49it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.59it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.58it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.62it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.64it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.69it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.77it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.80it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.66it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.64it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.60it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.63it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.83it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.84it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.84it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.85it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.85it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.86it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.87it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.45it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.57it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:06, 14.63it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.82it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.32it/s]
epoch 39: train_loss = 1.834
39: {'Accuracy': 0.9464, 'Precision': 0.9474, 'Recall': 0.9464, 'F1-score': 0.9467}
epoch: 40
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:31,  1.27it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:48,  3.86it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:07,  6.16it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:50,  8.18it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:41,  9.85it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:36, 11.19it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.22it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.96it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:29, 13.51it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:28, 13.92it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.21it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.53it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:02<00:26, 14.74it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.63it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.79it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.77it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:07<00:21, 14.77it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.70it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.67it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:17, 13.50it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:16, 13.83it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:16, 14.05it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:16, 14.24it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.35it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.47it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.57it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.62it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.62it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.65it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.65it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.69it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.72it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.79it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.72it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.76it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.70it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.59it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.64it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.79it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.20it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.36it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.50it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.59it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.68it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.71it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 40: train_loss = 1.836
40: {'Accuracy': 0.9436, 'Precision': 0.9443, 'Recall': 0.9436, 'F1-score': 0.9437}
epoch: 41
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:57,  1.01it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:08,  3.25it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.42it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.41it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.05it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.50it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.65it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.54it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.67it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.00it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.23it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.54it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:26, 14.25it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:26, 14.43it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.51it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.62it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.68it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.72it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.80it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.80it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.77it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.81it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.76it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.79it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.81it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.80it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.30it/s]
epoch 41: train_loss = 1.83
41: {'Accuracy': 0.9465, 'Precision': 0.9474, 'Recall': 0.9465, 'F1-score': 0.9468}
epoch: 42
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:43,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.34it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.48it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.48it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.20it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.58it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.70it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.56it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.20it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.68it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.01it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.22it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.56it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.71it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:21, 13.93it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:21, 14.18it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.35it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.42it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.48it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.56it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.63it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.67it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.70it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.64it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.67it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.77it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.69it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.69it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.68it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.64it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.68it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.71it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.65it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.68it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.65it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.66it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.70it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.72it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.72it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.62it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.83it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.25it/s]
epoch 42: train_loss = 1.826
42: {'Accuracy': 0.9449, 'Precision': 0.9461, 'Recall': 0.9449, 'F1-score': 0.9453}
epoch: 43
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:48,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.31it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.50it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.46it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.18it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.58it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.72it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.60it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.68it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.03it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.26it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.55it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.83it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.80it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.80it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.78it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.80it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.80it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.77it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.81it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.18it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.36it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:15, 14.51it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.59it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.66it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.82it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.81it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.82it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.82it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.77it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.81it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.81it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.44it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.32it/s]
epoch 43: train_loss = 1.825
43: {'Accuracy': 0.9473, 'Precision': 0.9479, 'Recall': 0.9473, 'F1-score': 0.9474}
epoch: 44
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:07,  1.02s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:11,  3.18it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:18,  5.28it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.27it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  8.98it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.43it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.59it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.49it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.16it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.65it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.26it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.58it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.77it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.85it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.79it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.87it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.84it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.87it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.86it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.83it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.83it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.82it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.56it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.71it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.83it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.84it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.32it/s]
epoch 44: train_loss = 1.818
44: {'Accuracy': 0.9443, 'Precision': 0.9452, 'Recall': 0.9443, 'F1-score': 0.9445}
epoch: 45
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:43,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.31it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.51it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.47it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.20it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.60it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.74it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.61it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.26it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.75it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.09it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.32it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.58it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.65it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.77it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.78it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.81it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.84it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.85it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.82it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.83it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.83it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.88it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 13.93it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.15it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:04, 14.29it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.45it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.56it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.90it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 45: train_loss = 1.814
45: {'Accuracy': 0.9475, 'Precision': 0.9484, 'Recall': 0.9475, 'F1-score': 0.9477}
epoch: 46
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:51,  1.02it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:07,  3.28it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.46it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.40it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.12it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.54it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.70it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.59it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.26it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.09it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.31it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.46it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.66it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.69it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.71it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.68it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.69it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.65it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.66it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.67it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.66it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.60it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.61it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.72it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.76it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.65it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.68it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.70it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.70it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.52it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.59it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.67it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.80it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.71it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.62it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.71it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.70it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.78it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.79it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.26it/s]
epoch 46: train_loss = 1.813
46: {'Accuracy': 0.9444, 'Precision': 0.9457, 'Recall': 0.9444, 'F1-score': 0.9447}
epoch: 47
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:41,  1.23it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:49,  3.80it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:07,  6.15it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:50,  8.18it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:41,  9.84it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:36, 11.14it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.16it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.94it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:29, 13.52it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:28, 13.92it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.21it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.70it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:02<00:26, 14.78it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.85it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:24, 14.34it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.44it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.49it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.59it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.66it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.86it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.85it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.82it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.81it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.02it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.21it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.36it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.49it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.60it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.90it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.91it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.41it/s]
epoch 47: train_loss = 1.812
47: {'Accuracy': 0.9461, 'Precision': 0.9468, 'Recall': 0.9461, 'F1-score': 0.9463}
epoch: 48
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:54,  1.01it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:08,  3.26it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.43it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.43it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.09it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.51it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.66it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.50it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.11it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.57it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.93it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.19it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.55it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.68it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.64it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.71it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.75it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.66it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.43it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.49it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.56it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.61it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.62it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.67it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.72it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.67it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.66it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.56it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.57it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.62it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.67it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.71it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.77it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.70it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.70it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.71it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.66it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.63it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.72it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.57it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.57it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.59it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.64it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.67it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.71it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.72it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.86it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.24it/s]
epoch 48: train_loss = 1.805
48: {'Accuracy': 0.946, 'Precision': 0.9465, 'Recall': 0.946, 'F1-score': 0.9461}
epoch: 49
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:52,  1.12s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:23,  2.92it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:23,  4.96it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<01:00,  6.88it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:47,  8.62it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:40, 10.04it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:36, 11.28it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:02<00:33, 12.25it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:31, 13.00it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.52it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.88it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.12it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.32it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  11%|█         | 45/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.75it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.77it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  21%|██        | 89/421 [00:07<00:22, 14.87it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.87it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.86it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.84it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.89it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.85it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.77it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.48it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.53it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:13, 14.51it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.58it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.63it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.78it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.77it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.76it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.76it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.78it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.79it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.79it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.50it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.66it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.82it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.23it/s]
epoch 49: train_loss = 1.809
49: {'Accuracy': 0.9476, 'Precision': 0.9485, 'Recall': 0.9476, 'F1-score': 0.9478}
epoch: 50
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:46,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.32it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.48it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.48it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.16it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.58it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.71it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.55it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.17it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.64it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.01it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.25it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.58it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.68it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.70it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.69it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.68it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.71it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.73it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.53it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.55it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.52it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:18, 14.54it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.60it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.63it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.71it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.72it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.71it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.67it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:08, 13.71it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.00it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.21it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.35it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.47it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.55it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.63it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.70it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.70it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.71it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.69it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.71it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.80it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.24it/s]
epoch 50: train_loss = 1.805
50: {'Accuracy': 0.9447, 'Precision': 0.9455, 'Recall': 0.9447, 'F1-score': 0.9449}
epoch: 51
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:51,  1.02it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:07,  3.27it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.48it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.49it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.21it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.61it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.69it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.58it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.26it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.74it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.09it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.33it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.74it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.65it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.58it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.64it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.65it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.63it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.63it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.67it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.69it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.69it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.71it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.66it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.66it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.66it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.66it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.65it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.65it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.66it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.64it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.67it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.65it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.78it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.67it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.60it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.60it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.74it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.81it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.71it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.64it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.67it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.65it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.74it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.64it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.69it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.70it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.67it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.70it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.68it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.69it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.65it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.49it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.46it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.44it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:04, 14.50it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.55it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.59it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.57it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.58it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.61it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 13.94it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.12it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.31it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.45it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.52it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.59it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.62it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.60it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.63it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.57it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.61it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.65it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.69it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.78it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.23it/s]
epoch 51: train_loss = 1.797
51: {'Accuracy': 0.946, 'Precision': 0.9467, 'Recall': 0.946, 'F1-score': 0.9462}
epoch: 52
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:13,  1.12it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<01:57,  3.56it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:11,  5.86it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:52,  7.86it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.56it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.92it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 12.00it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.83it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.45it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:28, 13.88it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.58it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.87it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.83it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.88it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.89it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.89it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.91it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.90it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.90it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.91it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.90it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.89it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.89it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.89it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.90it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.88it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.89it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.89it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.88it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.89it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.90it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.90it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.90it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.92it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.91it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.90it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.89it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.85it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.87it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.89it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.89it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.89it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.90it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.90it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.89it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.89it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.52it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.61it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.88it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.87it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.87it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.90it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.89it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.88it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.90it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.89it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.92it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.42it/s]
epoch 52: train_loss = 1.801
52: {'Accuracy': 0.9477, 'Precision': 0.9485, 'Recall': 0.9477, 'F1-score': 0.9479}
epoch: 53
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:27,  1.08it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:01,  3.44it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.69it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.68it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.35it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.73it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.83it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.68it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.33it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.80it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.34it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.60it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.85it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.87it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.89it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.89it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.89it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.89it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.88it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.86it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:22, 14.50it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.55it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.58it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.61it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.69it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.90it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.90it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.87it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.88it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.88it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.86it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.89it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.88it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.85it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.88it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.89it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.89it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.89it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.86it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.87it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.89it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.88it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.38it/s]
epoch 53: train_loss = 1.798
53: {'Accuracy': 0.9465, 'Precision': 0.9472, 'Recall': 0.9465, 'F1-score': 0.9466}
epoch: 54
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:40,  1.24it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:50,  3.78it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:08,  6.11it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:50,  8.16it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:42,  9.79it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:36, 11.13it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.17it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.95it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:29, 13.53it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:28, 13.91it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.21it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.71it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:02<00:26, 14.78it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.78it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.82it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.85it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.83it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:04<00:24, 14.72it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.77it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.79it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.68it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.73it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.59it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.56it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.61it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.68it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:19, 14.60it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.62it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.67it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.66it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.08it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.24it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:16, 14.35it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:16, 14.40it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.45it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.53it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.64it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.71it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.76it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.77it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.81it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.76it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.69it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.67it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.67it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.70it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.67it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.62it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.66it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.61it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.57it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.62it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.66it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.69it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.71it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.65it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.70it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.74it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.80it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 54: train_loss = 1.791
54: {'Accuracy': 0.9447, 'Precision': 0.9457, 'Recall': 0.9447, 'F1-score': 0.9449}
epoch: 55
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:42,  1.04it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.34it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.54it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.50it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.18it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.60it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.71it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.57it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.66it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.04it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.22it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.56it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.65it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.63it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.62it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.76it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.73it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.73it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.76it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.77it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.76it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.74it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.72it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.74it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.75it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.74it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.68it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.63it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.68it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.71it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.78it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.79it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.83it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.83it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.27it/s]
epoch 55: train_loss = 1.793
55: {'Accuracy': 0.9447, 'Precision': 0.9454, 'Recall': 0.9447, 'F1-score': 0.9449}
epoch: 56
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:05,  1.01s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:11,  3.19it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:18,  5.33it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.29it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.01it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.37it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.50it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.38it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.07it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.55it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.95it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.15it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.29it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.54it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.54it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.56it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.61it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.58it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.54it/s]going through batches for holmes training:  11%|█         | 45/421 [00:04<00:25, 14.59it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.60it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.64it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:25, 14.63it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.64it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.66it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.67it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.70it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.68it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.69it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.59it/s]going through batches for holmes training:  21%|██        | 89/421 [00:07<00:22, 14.57it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.61it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.60it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.61it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.63it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:22, 14.59it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.58it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.61it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.66it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.70it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.68it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.69it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:22, 13.77it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:21, 14.04it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:21, 14.22it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.31it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.42it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.51it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.51it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.54it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.56it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:10<00:19, 14.55it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.59it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.61it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.65it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:11<00:18, 14.67it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.66it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.63it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.65it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.67it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.67it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.67it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.66it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.66it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.68it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.65it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.62it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.58it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.62it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.66it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.63it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.65it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.63it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.58it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.57it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.60it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.60it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.55it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.60it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.63it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.64it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.63it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.65it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.58it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.61it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.63it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.68it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.54it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.56it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.59it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.63it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.62it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.58it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.61it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.60it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:22<00:07, 14.62it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.61it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.64it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:06, 14.60it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.60it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.60it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:24<00:05, 14.62it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.63it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.64it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.65it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.64it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:25<00:04, 14.61it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.64it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.70it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.67it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.64it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.68it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.68it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:27<00:02, 14.68it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.69it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.69it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.67it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.52it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.65it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.65it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:29<00:00, 14.68it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.70it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.72it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.16it/s]
epoch 56: train_loss = 1.792
56: {'Accuracy': 0.9455, 'Precision': 0.9468, 'Recall': 0.9455, 'F1-score': 0.9458}
epoch: 57
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:02,  1.01s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:10,  3.20it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:17,  5.35it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.35it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.01it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.46it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.63it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.54it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.21it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.71it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.23it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.41it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.54it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.63it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.79it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.70it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.78it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.80it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.78it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.80it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.71it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.66it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.74it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.72it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.70it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.80it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.62it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.69it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.70it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.83it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.79it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.78it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.75it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.78it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.80it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.71it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.73it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.78it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.79it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.63it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.11it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.22it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.35it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.42it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.53it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.58it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.26it/s]
epoch 57: train_loss = 1.791
57: {'Accuracy': 0.9458, 'Precision': 0.9464, 'Recall': 0.9458, 'F1-score': 0.9458}
epoch: 58
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:36,  1.06it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.38it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.57it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.56it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.26it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.65it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.77it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.61it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.69it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.42it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.53it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.72it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.87it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.83it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.88it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.83it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.85it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.82it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:11, 13.70it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.02it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.26it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:10, 14.43it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.56it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.65it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.85it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 58: train_loss = 1.787
58: {'Accuracy': 0.9433, 'Precision': 0.9441, 'Recall': 0.9433, 'F1-score': 0.9435}
epoch: 59
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:07,  1.14it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<01:55,  3.61it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:10,  5.89it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:52,  7.90it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.53it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.89it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.97it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.79it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.41it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.84it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.12it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.35it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.60it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.80it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.84it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.86it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.82it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.80it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.79it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.79it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.79it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.80it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.80it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.79it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.77it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.79it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.80it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.78it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.79it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.90it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.91it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.38it/s]
epoch 59: train_loss = 1.782
59: {'Accuracy': 0.9467, 'Precision': 0.9473, 'Recall': 0.9467, 'F1-score': 0.9469}
epoch: 60
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:41,  1.05it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:04,  3.35it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.53it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.51it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.24it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.59it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.72it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.60it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.24it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.72it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.02it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.23it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.41it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.54it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.67it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.68it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.67it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.76it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.72it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.76it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.67it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.21it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.36it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.48it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.59it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.65it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.76it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.77it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.82it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.81it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.83it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.82it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.81it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.87it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.88it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.87it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.86it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.89it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.71it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.31it/s]
epoch 60: train_loss = 1.781
60: {'Accuracy': 0.9453, 'Precision': 0.9462, 'Recall': 0.9453, 'F1-score': 0.9456}
epoch: 61
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:59,  1.00it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:09,  3.23it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:17,  5.38it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.38it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.11it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.53it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.67it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.52it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.19it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.70it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.07it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.84it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.85it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.22it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.39it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:24, 14.53it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.64it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.70it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.77it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.88it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.87it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.85it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.81it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.85it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.85it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.84it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.86it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.87it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.87it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.85it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.85it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.84it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.84it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.85it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.86it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.86it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.85it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.84it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.80it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.90it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 61: train_loss = 1.78
61: {'Accuracy': 0.9456, 'Precision': 0.9462, 'Recall': 0.9456, 'F1-score': 0.9457}
epoch: 62
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:56,  1.01it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:08,  3.25it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.41it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.36it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.10it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.55it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.70it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.59it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.23it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.10it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.31it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.45it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.54it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.83it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.86it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.86it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.87it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.87it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.89it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.89it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.88it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.80it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.80it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.83it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.50it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.63it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.77it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.85it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.85it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.88it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.88it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.88it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.84it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.87it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.88it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.90it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.89it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.84it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.84it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.86it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.88it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.88it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.83it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.81it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.88it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.88it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.79it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.91it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 62: train_loss = 1.776
62: {'Accuracy': 0.9453, 'Precision': 0.9462, 'Recall': 0.9453, 'F1-score': 0.9455}
epoch: 63
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:31,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:04,  3.35it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.55it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.55it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.18it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.59it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.71it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.58it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.65it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.01it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.21it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.35it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:27, 14.51it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.57it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.58it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.69it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.72it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.71it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.66it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.68it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.63it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.64it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.73it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.66it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.60it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.63it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.64it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.69it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.70it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.78it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.76it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.75it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.73it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.72it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.65it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.66it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.66it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.66it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.63it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.61it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.65it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:14, 13.82it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.04it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.25it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.35it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:13, 14.40it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.46it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.53it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.57it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.56it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.61it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.53it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.48it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.52it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.57it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.63it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.64it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.62it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.64it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.62it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.61it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.60it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.66it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.79it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.80it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.83it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.81it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.80it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.81it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.78it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.80it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.84it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.82it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.74it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.74it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.81it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.77it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.24it/s]
epoch 63: train_loss = 1.779
63: {'Accuracy': 0.9465, 'Precision': 0.9473, 'Recall': 0.9465, 'F1-score': 0.9467}
epoch: 64
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:23,  1.10it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:00,  3.47it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:12,  5.72it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.71it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.38it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.78it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.87it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.67it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.27it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.74it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.05it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.24it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.37it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.46it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.56it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.59it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:26, 14.60it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.63it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.61it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.62it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.68it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.68it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.70it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.68it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.63it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:24, 14.58it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.60it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.53it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.49it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.54it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.61it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.67it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.69it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.70it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.73it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.72it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.71it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.68it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.69it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.73it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.72it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.73it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.70it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.75it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.71it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.70it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.75it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.74it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.71it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.70it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.72it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.80it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.81it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.27it/s]
epoch 64: train_loss = 1.772
64: {'Accuracy': 0.9461, 'Precision': 0.9467, 'Recall': 0.9461, 'F1-score': 0.9462}
epoch: 65
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:52,  1.02it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:07,  3.27it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.45it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.42it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.11it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.51it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.68it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.55it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.19it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.68it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.01it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.25it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.40it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.53it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.63it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.67it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.78it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.77it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.72it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.69it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.68it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.73it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.71it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.79it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.71it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.64it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.60it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.71it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.70it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.67it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.62it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.59it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.61it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.68it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.65it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.65it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.60it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.62it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.65it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.65it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.66it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.67it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.68it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.68it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.70it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.71it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.69it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.67it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.66it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.68it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.68it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.68it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.68it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.63it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.59it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.55it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.53it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.62it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.64it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.63it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.67it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.79it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.69it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.72it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.77it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.80it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.79it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.79it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.47it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.53it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:07, 14.57it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.60it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.63it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.65it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.61it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.63it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.62it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:06, 14.64it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.65it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.72it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.70it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.65it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.67it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.64it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.63it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.65it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.70it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.36it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.48it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.55it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.59it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.64it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.63it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.64it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.67it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.66it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.53it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.59it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.66it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.75it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.22it/s]
epoch 65: train_loss = 1.772
65: {'Accuracy': 0.945, 'Precision': 0.9456, 'Recall': 0.945, 'F1-score': 0.9451}
epoch: 66
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:02,  1.01s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:10,  3.21it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:18,  5.33it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.32it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.05it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.49it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.65it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.51it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.20it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.69it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.03it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.45it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.58it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.76it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.53it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:24, 14.26it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:24, 14.37it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:24, 14.41it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.48it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.58it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.62it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.68it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.81it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.78it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.75it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.78it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.76it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.76it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.79it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.79it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.79it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.89it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.87it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.88it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.87it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.90it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.89it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.88it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.90it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.91it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.85it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.86it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.90it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.87it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.87it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.89it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.90it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.91it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.91it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.91it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.92it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.91it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.90it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.88it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.90it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.89it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.89it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:08, 14.89it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.88it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.90it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.90it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.90it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.89it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.89it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.87it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.88it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.88it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.89it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.92it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.91it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.90it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.91it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.91it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.90it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.86it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.89it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.89it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.88it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.83it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.85it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.80it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.79it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.81it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 66: train_loss = 1.777
66: {'Accuracy': 0.9475, 'Precision': 0.9482, 'Recall': 0.9475, 'F1-score': 0.9477}
epoch: 67
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:04,  1.15it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<01:58,  3.54it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:11,  5.82it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:53,  7.76it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:43,  9.47it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.87it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.98it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.81it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.40it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.81it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.14it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.27it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.43it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.48it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.58it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.66it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.73it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.74it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.65it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.65it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.65it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.73it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.78it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.72it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.75it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.77it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.77it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.79it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.77it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.67it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.81it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.82it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.78it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.75it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.76it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.72it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.73it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.76it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.61it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.61it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.61it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.75it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.79it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.80it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.77it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.76it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.80it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.75it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.69it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.63it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.66it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.66it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.68it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.69it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.68it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.68it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.67it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.60it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.57it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.57it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.59it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.61it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.61it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.63it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.64it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.79it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.79it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.76it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.77it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.80it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.74it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.78it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.80it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.59it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.67it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.64it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.62it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.66it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.30it/s]
epoch 67: train_loss = 1.77
67: {'Accuracy': 0.9454, 'Precision': 0.9461, 'Recall': 0.9454, 'F1-score': 0.9456}
epoch: 68
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:34,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.40it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.61it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.57it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.29it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.63it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.76it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.62it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.28it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.76it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.04it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.28it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.59it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.58it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.64it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.68it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.71it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.73it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.70it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.72it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.71it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.70it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.74it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.77it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.77it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.78it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.76it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.73it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.74it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.79it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.80it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.72it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.76it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.77it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.80it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.68it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.36it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.44it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.54it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.58it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.62it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.65it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.68it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.71it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.75it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.77it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.78it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.79it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.69it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.67it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.77it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.80it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.79it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.80it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.77it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.74it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.76it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.73it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.68it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.81it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.77it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.72it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.72it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.77it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.78it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.79it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.77it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.79it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.64it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.61it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.65it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.67it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.78it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.76it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.24it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.35it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.43it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.49it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.58it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.64it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.65it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.68it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.63it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.67it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.70it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.77it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.80it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.83it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.84it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.82it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.27it/s]
epoch 68: train_loss = 1.771
68: {'Accuracy': 0.9446, 'Precision': 0.9453, 'Recall': 0.9446, 'F1-score': 0.9447}
epoch: 69
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:01<07:00,  1.00s/it]going through batches for holmes training:   1%|          | 3/421 [00:01<02:09,  3.22it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:17,  5.39it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:56,  7.34it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:46,  8.93it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.32it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.47it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.38it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.10it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.62it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.98it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.24it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.41it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.65it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.83it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.86it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.86it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.87it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.88it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.87it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.84it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.67it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.70it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.79it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.68it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.62it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.72it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.64it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.64it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.62it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.65it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.66it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.68it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.70it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.68it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.69it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.70it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.70it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.69it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.68it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.70it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.72it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.71it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.57it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.57it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.61it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.63it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.61it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.63it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:15, 14.62it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.69it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.69it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.70it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.75it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.74it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.75it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:13, 14.32it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:13, 14.44it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.56it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.61it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.68it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.71it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.71it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.71it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.73it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.73it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.74it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.73it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.74it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.75it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.72it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.71it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.66it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.64it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.67it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.69it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.73it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.68it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.73it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.73it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.77it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.63it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.71it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.71it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.23it/s]
epoch 69: train_loss = 1.769
69: {'Accuracy': 0.9449, 'Precision': 0.9456, 'Recall': 0.9449, 'F1-score': 0.9451}
epoch: 70
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:56,  1.18it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:54,  3.64it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:10,  5.89it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:52,  7.92it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:42,  9.58it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.95it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.02it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.83it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.43it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.82it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.15it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.38it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.52it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.71it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.73it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.72it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.74it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.72it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.70it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.71it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.72it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.64it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.62it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.64it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.66it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.72it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.71it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.65it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.61it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.66it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.65it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.62it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.66it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.73it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.70it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.68it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.68it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.68it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.77it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.74it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.65it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.66it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.46it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.53it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.59it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.67it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.71it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.74it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.72it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.73it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.75it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.77it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.74it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.71it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.72it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.74it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.73it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.71it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.74it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.75it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.76it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.78it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.73it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.75it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.75it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.75it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.66it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.67it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.70it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.64it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.62it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.64it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.74it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.77it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.69it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.76it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.75it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.76it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.77it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.79it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.77it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.76it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.78it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.62it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.62it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.68it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.65it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.70it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.74it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.82it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.74it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.66it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.66it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.68it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.67it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.65it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.77it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.76it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.78it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.87it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.88it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.78it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.86it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.87it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.88it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.87it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.34it/s]
epoch 70: train_loss = 1.771
70: {'Accuracy': 0.9441, 'Precision': 0.945, 'Recall': 0.9441, 'F1-score': 0.9443}
epoch: 71
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:49,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:06,  3.30it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:15,  5.48it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.43it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.17it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.60it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.75it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.64it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.25it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.75it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.12it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.34it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.51it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.63it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.70it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.77it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.79it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.81it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.66it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.68it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.62it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.67it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.86it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:22, 14.89it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.88it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.87it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.76it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.65it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.69it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.74it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.81it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.78it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.38it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.42it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.46it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:17, 14.54it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.59it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.62it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.56it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.57it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.60it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.64it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.69it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.74it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.74it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.73it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.74it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.78it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.70it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.72it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.70it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.70it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.73it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.71it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.72it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.71it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.72it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.73it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.64it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.65it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.66it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.72it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.74it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.75it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.73it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.75it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.60it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.59it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.57it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.59it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.60it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.60it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.62it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.66it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.71it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.74it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.73it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.76it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.74it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.77it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.76it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.78it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.77it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.77it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.76it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.75it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.74it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.71it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.71it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.74it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.58it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.65it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.69it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.71it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.73it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.27it/s]
epoch 71: train_loss = 1.765
71: {'Accuracy': 0.9457, 'Precision': 0.9464, 'Recall': 0.9457, 'F1-score': 0.9459}
epoch: 72
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:48,  1.03it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:07,  3.28it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.47it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.48it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.20it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.60it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.72it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.58it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.24it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.07it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 13.90it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:28, 14.13it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.29it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:27, 14.41it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.51it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.61it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.67it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.70it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.76it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.73it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.74it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.77it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.77it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.76it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.77it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.76it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.75it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.73it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.75it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.76it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.78it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.81it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.86it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.87it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.85it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.89it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.89it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.88it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.86it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.84it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.84it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.85it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.21it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:12, 14.36it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.44it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.51it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.60it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.66it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.79it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.80it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.81it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.82it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.86it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.86it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.87it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.67it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.67it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.62it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.64it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.71it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.74it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.73it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.76it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.77it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.75it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.73it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.75it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.74it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.75it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.58it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.65it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.64it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.66it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.64it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.69it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.72it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.64it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.69it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.75it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.72it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.74it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.75it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.29it/s]
epoch 72: train_loss = 1.766
72: {'Accuracy': 0.9453, 'Precision': 0.9463, 'Recall': 0.9453, 'F1-score': 0.9456}
epoch: 73
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:41,  1.05it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:04,  3.35it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.56it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.56it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.25it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.60it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.74it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.61it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.27it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.75it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.07it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.30it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.44it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.55it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.74it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.82it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.76it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.79it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.79it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.78it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.81it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.79it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.79it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.74it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:22, 14.43it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.47it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.52it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.59it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.68it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.72it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.76it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.84it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.83it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.86it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.81it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.83it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.82it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.81it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.82it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.84it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.83it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.85it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.85it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.82it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.84it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.83it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.85it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.82it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 13.94it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.17it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.34it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.46it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:06, 14.54it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.61it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.76it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.78it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.83it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.82it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.83it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.86it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.84it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.84it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.71it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.84it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.85it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.90it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 73: train_loss = 1.76
73: {'Accuracy': 0.9462, 'Precision': 0.9468, 'Recall': 0.9462, 'F1-score': 0.9463}
epoch: 74
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:35,  1.06it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:02,  3.41it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.65it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.64it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.31it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.68it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.80it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.65it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.30it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.74it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.06it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.29it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.43it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.55it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.62it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.69it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.77it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.84it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.75it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.74it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.80it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.80it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.81it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.78it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.76it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.74it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.73it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.72it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.69it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.71it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.71it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.72it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.75it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.77it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.75it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.73it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.70it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.69it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.66it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.67it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.70it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.69it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.71it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.74it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.75it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.74it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.72it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.69it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.67it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.54it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.53it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.60it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.62it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.60it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.64it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.67it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.70it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.68it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.69it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.71it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.73it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.74it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.72it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.76it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.33it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.46it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.53it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:16, 14.59it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.63it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.66it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.65it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.67it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.68it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.72it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.71it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.73it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.73it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.69it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.67it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.68it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.63it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.64it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.63it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.60it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.72it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.71it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.70it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.67it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.70it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.73it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.72it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.64it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.67it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.66it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.70it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.71it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.72it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.70it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.69it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.66it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.68it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.70it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.69it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.68it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.64it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.69it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.72it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.71it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.67it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.70it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.73it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.70it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.70it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.72it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.74it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.72it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.71it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.71it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.71it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.66it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.71it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.70it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.71it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.72it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.74it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.75it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.73it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.71it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.68it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.66it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.69it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.68it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.71it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.72it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.69it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.72it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.76it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.76it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.75it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.74it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 13.63it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 13.78it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.04it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.19it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.31it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.42it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.49it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.57it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.63it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.66it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.71it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.24it/s]
epoch 74: train_loss = 1.761
74: {'Accuracy': 0.9436, 'Precision': 0.9446, 'Recall': 0.9436, 'F1-score': 0.9438}
epoch: 75
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<05:18,  1.32it/s]going through batches for holmes training:   1%|          | 3/421 [00:00<01:45,  3.97it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:05,  6.38it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:49,  8.33it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:41,  9.97it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:36, 11.25it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.29it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.94it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:29, 13.49it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:01<00:28, 13.89it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.18it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.41it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.56it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:26, 14.63it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.68it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:02<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.69it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.65it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:27, 13.64it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:27, 13.93it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:26, 14.11it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:26, 14.27it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.42it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.53it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.61it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.69it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.75it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.78it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.81it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.83it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:05<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.81it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.82it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.80it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.85it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.80it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.82it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.82it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.84it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.84it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.77it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.79it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.78it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.80it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.75it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.76it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.78it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:14<00:14, 14.79it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.81it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.80it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.83it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.83it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.83it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.82it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.83it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:17<00:11, 14.84it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.82it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.81it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:11, 14.31it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.46it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.56it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.63it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.68it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.73it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.78it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.80it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.82it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.84it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:19<00:09, 14.83it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.82it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.81it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.79it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.77it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.78it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.80it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.81it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.82it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.83it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.84it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:22<00:06, 14.83it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.81it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.80it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.82it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.81it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.83it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.84it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.82it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:24<00:04, 14.80it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.79it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.79it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.83it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.84it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.85it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.80it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.79it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.76it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.81it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.87it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.90it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.41it/s]
epoch 75: train_loss = 1.757
75: {'Accuracy': 0.9446, 'Precision': 0.9455, 'Recall': 0.9446, 'F1-score': 0.9449}
epoch: 76
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:53,  1.02it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:08,  3.26it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:16,  5.42it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:55,  7.41it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:45,  9.08it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:39, 10.47it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:35, 11.62it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.50it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.17it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.64it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 13.96it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:28, 14.18it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.33it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.47it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.55it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:03<00:26, 14.62it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.58it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.59it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.63it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.68it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.66it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.65it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.67it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.69it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:25, 14.70it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.65it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:25, 14.64it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.65it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.68it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.69it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.66it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.61it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:24, 14.63it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:24, 14.64it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.65it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.62it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:06<00:23, 14.61it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.65it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.68it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:23, 14.64it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:23, 14.64it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.63it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.67it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.68it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.65it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:22, 14.66it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:22, 14.68it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.70it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.66it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.62it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:08<00:21, 14.61it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.65it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:21, 14.63it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:21, 14.58it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.58it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.60it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:09<00:21, 13.83it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:21, 13.99it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:21, 14.13it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:20, 14.28it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:20, 14.41it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:20, 14.42it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:20, 14.48it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:10<00:19, 14.49it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:10<00:19, 14.52it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.57it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.62it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:19, 14.63it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.64it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.65it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.69it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:11<00:18, 14.69it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.65it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.62it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:18, 14.64it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:18, 14.63it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.63it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.59it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:12<00:17, 14.55it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.58it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.62it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:17, 14.57it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:17, 14.54it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:17, 14.54it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.59it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:13<00:16, 14.63it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:13<00:16, 14.66it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.64it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.62it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:16, 14.65it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.72it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.70it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:14<00:15, 14.64it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.66it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.69it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:15, 14.71it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.68it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.58it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.60it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:15<00:14, 14.59it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:15<00:14, 14.59it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.64it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.61it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:14, 14.62it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.71it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.71it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.72it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.67it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.63it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:17<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.67it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.64it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.62it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.64it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.64it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.67it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:18<00:11, 14.63it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:18<00:11, 14.60it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.60it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.62it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.64it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.62it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.63it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:19<00:10, 14.64it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:19<00:10, 14.67it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.69it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.66it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:10, 14.57it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.50it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.55it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:20<00:09, 14.60it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.61it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.62it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.64it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:09, 14.64it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.62it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.63it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:21<00:08, 14.62it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:21<00:08, 14.64it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.65it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.65it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.66it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.67it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.68it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.64it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.65it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.59it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.60it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.62it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:23<00:06, 14.62it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:23<00:06, 14.61it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.63it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.65it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.69it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:06, 13.67it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:24<00:05, 13.98it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:24<00:05, 14.19it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.34it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.44it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.51it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.57it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.58it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:25<00:04, 14.56it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:25<00:04, 14.57it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.60it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.63it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.66it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.64it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.61it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:26<00:03, 14.61it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:26<00:03, 14.60it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.59it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.59it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.62it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.63it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.67it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.70it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.69it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.70it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.70it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.67it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:28<00:01, 14.54it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:28<00:01, 14.56it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.59it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.48it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.56it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.61it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.65it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:29<00:00, 14.67it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:29<00:00, 14.70it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.73it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.74it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.15it/s]
epoch 76: train_loss = 1.757
76: {'Accuracy': 0.9441, 'Precision': 0.9451, 'Recall': 0.9441, 'F1-score': 0.9443}
epoch: 77
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:07,  1.14it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<01:56,  3.60it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:11,  5.84it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:52,  7.87it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:42,  9.59it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:37, 10.97it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:33, 12.03it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.79it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:01<00:30, 13.41it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.85it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.18it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.36it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.49it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.58it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.72it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.66it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.71it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.75it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.77it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.80it/s]going through batches for holmes training:  11%|█         | 47/421 [00:03<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.79it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.80it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.82it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.80it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.81it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.79it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.86it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:06<00:22, 14.77it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.80it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.85it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.85it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.86it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.86it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.87it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.89it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.90it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.85it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.84it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:11<00:17, 14.86it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.88it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.85it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.86it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.87it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.79it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.81it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.85it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.84it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.85it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.89it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:15<00:13, 14.86it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.87it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.88it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.87it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:16<00:12, 14.86it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:11, 14.87it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.86it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:17<00:11, 14.85it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.84it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.83it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.85it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:18<00:10, 14.86it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.86it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.86it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.87it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.84it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.83it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.83it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.87it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.85it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:20<00:08, 14.84it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.85it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.86it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.88it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:21<00:07, 14.87it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.88it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.85it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.88it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:22<00:06, 14.87it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.88it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.88it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.90it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.89it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.86it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.85it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:23<00:05, 14.84it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.87it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:04, 14.87it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.85it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:24<00:04, 14.88it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:24<00:04, 14.86it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.85it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.85it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:25<00:03, 14.86it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.89it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.90it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.88it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.84it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.86it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:26<00:02, 14.87it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.87it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.85it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.86it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.73it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.78it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.91it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:28<00:00, 14.92it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.93it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.92it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.41it/s]
epoch 77: train_loss = 1.755
77: {'Accuracy': 0.9468, 'Precision': 0.948, 'Recall': 0.9468, 'F1-score': 0.9471}
epoch: 78
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:33,  1.07it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:03,  3.39it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:13,  5.62it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.61it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.33it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.73it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.84it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:31, 12.69it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.31it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.73it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.10it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.30it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.43it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.55it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.64it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.71it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.75it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.78it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.79it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.80it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:25, 14.42it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:25, 14.55it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.63it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.71it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.74it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:24, 14.75it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.76it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.78it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.80it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.82it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.80it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.85it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.85it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.86it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.83it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.86it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.87it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.88it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.90it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.87it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.85it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.86it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.88it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.87it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.86it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.85it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.84it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.87it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.88it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.87it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.87it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.88it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.86it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.88it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.87it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.88it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.85it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.86it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.83it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.85it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.84it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.85it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.86it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.87it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.87it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.87it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.73it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.67it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.66it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.66it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.68it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:13, 14.69it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.70it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.69it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.65it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.67it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.69it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:12, 14.66it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.68it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.69it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.66it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.66it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.67it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.63it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:11, 14.65it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.66it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.53it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.49it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.55it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.58it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.61it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.63it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.65it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.64it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.68it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.67it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.58it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:09, 14.61it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.63it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.64it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.65it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.67it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.68it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.67it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.66it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.60it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.59it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.64it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.69it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.69it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.68it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.65it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.66it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.70it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:23<00:06, 14.69it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.70it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.68it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.67it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.68it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.67it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.66it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.66it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.69it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.68it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.69it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.68it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.69it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.70it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.72it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:26<00:03, 14.72it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.70it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.70it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:03, 14.58it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.61it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.63it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.65it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.69it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.71it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.68it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.65it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.62it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.62it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:28<00:01, 14.62it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.53it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.60it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.66it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.73it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.74it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:29<00:00, 14.76it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.79it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.77it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.76it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.29it/s]
epoch 78: train_loss = 1.755
78: {'Accuracy': 0.947, 'Precision': 0.9478, 'Recall': 0.947, 'F1-score': 0.9472}
epoch: 79
going through batches for holmes training:   0%|          | 0/421 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/421 [00:00<06:37,  1.06it/s]going through batches for holmes training:   1%|          | 3/421 [00:01<02:05,  3.34it/s]going through batches for holmes training:   1%|          | 5/421 [00:01<01:14,  5.55it/s]going through batches for holmes training:   2%|▏         | 7/421 [00:01<00:54,  7.56it/s]going through batches for holmes training:   2%|▏         | 9/421 [00:01<00:44,  9.27it/s]going through batches for holmes training:   3%|▎         | 11/421 [00:01<00:38, 10.65it/s]going through batches for holmes training:   3%|▎         | 13/421 [00:01<00:34, 11.75it/s]going through batches for holmes training:   4%|▎         | 15/421 [00:01<00:32, 12.56it/s]going through batches for holmes training:   4%|▍         | 17/421 [00:02<00:30, 13.22it/s]going through batches for holmes training:   5%|▍         | 19/421 [00:02<00:29, 13.70it/s]going through batches for holmes training:   5%|▍         | 21/421 [00:02<00:28, 14.03it/s]going through batches for holmes training:   5%|▌         | 23/421 [00:02<00:27, 14.26it/s]going through batches for holmes training:   6%|▌         | 25/421 [00:02<00:27, 14.40it/s]going through batches for holmes training:   6%|▋         | 27/421 [00:02<00:27, 14.53it/s]going through batches for holmes training:   7%|▋         | 29/421 [00:02<00:26, 14.61it/s]going through batches for holmes training:   7%|▋         | 31/421 [00:02<00:26, 14.67it/s]going through batches for holmes training:   8%|▊         | 33/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   8%|▊         | 35/421 [00:03<00:26, 14.70it/s]going through batches for holmes training:   9%|▉         | 37/421 [00:03<00:26, 14.73it/s]going through batches for holmes training:   9%|▉         | 39/421 [00:03<00:25, 14.72it/s]going through batches for holmes training:  10%|▉         | 41/421 [00:03<00:25, 14.74it/s]going through batches for holmes training:  10%|█         | 43/421 [00:03<00:25, 14.76it/s]going through batches for holmes training:  11%|█         | 45/421 [00:03<00:25, 14.79it/s]going through batches for holmes training:  11%|█         | 47/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 49/421 [00:04<00:25, 14.81it/s]going through batches for holmes training:  12%|█▏        | 51/421 [00:04<00:24, 14.81it/s]going through batches for holmes training:  13%|█▎        | 53/421 [00:04<00:24, 14.82it/s]going through batches for holmes training:  13%|█▎        | 55/421 [00:04<00:24, 14.83it/s]going through batches for holmes training:  14%|█▎        | 57/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 59/421 [00:04<00:24, 14.85it/s]going through batches for holmes training:  14%|█▍        | 61/421 [00:05<00:24, 14.84it/s]going through batches for holmes training:  15%|█▍        | 63/421 [00:05<00:24, 14.84it/s]going through batches for holmes training:  15%|█▌        | 65/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  16%|█▌        | 67/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  16%|█▋        | 69/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  17%|█▋        | 71/421 [00:05<00:23, 14.83it/s]going through batches for holmes training:  17%|█▋        | 73/421 [00:05<00:23, 14.84it/s]going through batches for holmes training:  18%|█▊        | 75/421 [00:05<00:23, 14.85it/s]going through batches for holmes training:  18%|█▊        | 77/421 [00:06<00:23, 14.85it/s]going through batches for holmes training:  19%|█▉        | 79/421 [00:06<00:23, 14.84it/s]going through batches for holmes training:  19%|█▉        | 81/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  20%|█▉        | 83/421 [00:06<00:22, 14.82it/s]going through batches for holmes training:  20%|██        | 85/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 87/421 [00:06<00:22, 14.84it/s]going through batches for holmes training:  21%|██        | 89/421 [00:06<00:22, 14.83it/s]going through batches for holmes training:  22%|██▏       | 91/421 [00:07<00:22, 14.84it/s]going through batches for holmes training:  22%|██▏       | 93/421 [00:07<00:22, 14.83it/s]going through batches for holmes training:  23%|██▎       | 95/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  23%|██▎       | 97/421 [00:07<00:21, 14.83it/s]going through batches for holmes training:  24%|██▎       | 99/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▍       | 101/421 [00:07<00:21, 14.82it/s]going through batches for holmes training:  24%|██▍       | 103/421 [00:07<00:21, 14.84it/s]going through batches for holmes training:  25%|██▍       | 105/421 [00:07<00:21, 14.81it/s]going through batches for holmes training:  25%|██▌       | 107/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▌       | 109/421 [00:08<00:21, 14.82it/s]going through batches for holmes training:  26%|██▋       | 111/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 113/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  27%|██▋       | 115/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 117/421 [00:08<00:20, 14.84it/s]going through batches for holmes training:  28%|██▊       | 119/421 [00:08<00:20, 14.83it/s]going through batches for holmes training:  29%|██▊       | 121/421 [00:09<00:20, 14.83it/s]going through batches for holmes training:  29%|██▉       | 123/421 [00:09<00:20, 14.82it/s]going through batches for holmes training:  30%|██▉       | 125/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  30%|███       | 127/421 [00:09<00:19, 14.84it/s]going through batches for holmes training:  31%|███       | 129/421 [00:09<00:19, 14.83it/s]going through batches for holmes training:  31%|███       | 131/421 [00:09<00:19, 14.82it/s]going through batches for holmes training:  32%|███▏      | 133/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  32%|███▏      | 135/421 [00:09<00:19, 14.81it/s]going through batches for holmes training:  33%|███▎      | 137/421 [00:10<00:19, 14.84it/s]going through batches for holmes training:  33%|███▎      | 139/421 [00:10<00:19, 14.82it/s]going through batches for holmes training:  33%|███▎      | 141/421 [00:10<00:18, 14.83it/s]going through batches for holmes training:  34%|███▍      | 143/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  34%|███▍      | 145/421 [00:10<00:18, 14.84it/s]going through batches for holmes training:  35%|███▍      | 147/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  35%|███▌      | 149/421 [00:10<00:18, 14.82it/s]going through batches for holmes training:  36%|███▌      | 151/421 [00:11<00:18, 14.80it/s]going through batches for holmes training:  36%|███▋      | 153/421 [00:11<00:18, 14.83it/s]going through batches for holmes training:  37%|███▋      | 155/421 [00:11<00:17, 14.82it/s]going through batches for holmes training:  37%|███▋      | 157/421 [00:11<00:17, 14.80it/s]going through batches for holmes training:  38%|███▊      | 159/421 [00:11<00:17, 14.81it/s]going through batches for holmes training:  38%|███▊      | 161/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▊      | 163/421 [00:11<00:17, 14.83it/s]going through batches for holmes training:  39%|███▉      | 165/421 [00:12<00:17, 14.84it/s]going through batches for holmes training:  40%|███▉      | 167/421 [00:12<00:17, 14.86it/s]going through batches for holmes training:  40%|████      | 169/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 171/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  41%|████      | 173/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  42%|████▏     | 175/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  42%|████▏     | 177/421 [00:12<00:16, 14.84it/s]going through batches for holmes training:  43%|████▎     | 179/421 [00:12<00:16, 14.83it/s]going through batches for holmes training:  43%|████▎     | 181/421 [00:13<00:16, 14.82it/s]going through batches for holmes training:  43%|████▎     | 183/421 [00:13<00:16, 14.81it/s]going through batches for holmes training:  44%|████▍     | 185/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  44%|████▍     | 187/421 [00:13<00:15, 14.80it/s]going through batches for holmes training:  45%|████▍     | 189/421 [00:13<00:15, 14.78it/s]going through batches for holmes training:  45%|████▌     | 191/421 [00:13<00:15, 14.81it/s]going through batches for holmes training:  46%|████▌     | 193/421 [00:13<00:15, 14.82it/s]going through batches for holmes training:  46%|████▋     | 195/421 [00:14<00:15, 14.83it/s]going through batches for holmes training:  47%|████▋     | 197/421 [00:14<00:15, 14.86it/s]going through batches for holmes training:  47%|████▋     | 199/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  48%|████▊     | 201/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  48%|████▊     | 203/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  49%|████▊     | 205/421 [00:14<00:14, 14.84it/s]going through batches for holmes training:  49%|████▉     | 207/421 [00:14<00:14, 14.83it/s]going through batches for holmes training:  50%|████▉     | 209/421 [00:14<00:14, 14.82it/s]going through batches for holmes training:  50%|█████     | 211/421 [00:15<00:14, 14.82it/s]going through batches for holmes training:  51%|█████     | 213/421 [00:15<00:14, 14.81it/s]going through batches for holmes training:  51%|█████     | 215/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 217/421 [00:15<00:13, 14.82it/s]going through batches for holmes training:  52%|█████▏    | 219/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  52%|█████▏    | 221/421 [00:15<00:13, 14.81it/s]going through batches for holmes training:  53%|█████▎    | 223/421 [00:15<00:13, 14.78it/s]going through batches for holmes training:  53%|█████▎    | 225/421 [00:16<00:13, 14.78it/s]going through batches for holmes training:  54%|█████▍    | 227/421 [00:16<00:13, 14.79it/s]going through batches for holmes training:  54%|█████▍    | 229/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  55%|█████▍    | 231/421 [00:16<00:12, 14.79it/s]going through batches for holmes training:  55%|█████▌    | 233/421 [00:16<00:12, 14.78it/s]going through batches for holmes training:  56%|█████▌    | 235/421 [00:16<00:12, 14.81it/s]going through batches for holmes training:  56%|█████▋    | 237/421 [00:16<00:12, 14.82it/s]going through batches for holmes training:  57%|█████▋    | 239/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  57%|█████▋    | 241/421 [00:17<00:12, 14.81it/s]going through batches for holmes training:  58%|█████▊    | 243/421 [00:17<00:12, 14.82it/s]going through batches for holmes training:  58%|█████▊    | 245/421 [00:17<00:11, 14.81it/s]going through batches for holmes training:  59%|█████▊    | 247/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  59%|█████▉    | 249/421 [00:17<00:11, 14.80it/s]going through batches for holmes training:  60%|█████▉    | 251/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  60%|██████    | 253/421 [00:17<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 255/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  61%|██████    | 257/421 [00:18<00:11, 14.78it/s]going through batches for holmes training:  62%|██████▏   | 259/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 261/421 [00:18<00:10, 14.77it/s]going through batches for holmes training:  62%|██████▏   | 263/421 [00:18<00:10, 14.76it/s]going through batches for holmes training:  63%|██████▎   | 265/421 [00:18<00:10, 14.74it/s]going through batches for holmes training:  63%|██████▎   | 267/421 [00:18<00:10, 14.75it/s]going through batches for holmes training:  64%|██████▍   | 269/421 [00:19<00:10, 14.76it/s]going through batches for holmes training:  64%|██████▍   | 271/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▍   | 273/421 [00:19<00:10, 14.75it/s]going through batches for holmes training:  65%|██████▌   | 275/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  66%|██████▌   | 277/421 [00:19<00:09, 14.77it/s]going through batches for holmes training:  66%|██████▋   | 279/421 [00:19<00:09, 14.76it/s]going through batches for holmes training:  67%|██████▋   | 281/421 [00:19<00:09, 14.75it/s]going through batches for holmes training:  67%|██████▋   | 283/421 [00:19<00:09, 14.74it/s]going through batches for holmes training:  68%|██████▊   | 285/421 [00:20<00:09, 14.76it/s]going through batches for holmes training:  68%|██████▊   | 287/421 [00:20<00:09, 14.78it/s]going through batches for holmes training:  69%|██████▊   | 289/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  69%|██████▉   | 291/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  70%|██████▉   | 293/421 [00:20<00:08, 14.77it/s]going through batches for holmes training:  70%|███████   | 295/421 [00:20<00:08, 14.78it/s]going through batches for holmes training:  71%|███████   | 297/421 [00:20<00:08, 14.76it/s]going through batches for holmes training:  71%|███████   | 299/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  71%|███████▏  | 301/421 [00:21<00:08, 14.76it/s]going through batches for holmes training:  72%|███████▏  | 303/421 [00:21<00:08, 14.75it/s]going through batches for holmes training:  72%|███████▏  | 305/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  73%|███████▎  | 307/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  73%|███████▎  | 309/421 [00:21<00:07, 14.75it/s]going through batches for holmes training:  74%|███████▍  | 311/421 [00:21<00:07, 14.76it/s]going through batches for holmes training:  74%|███████▍  | 313/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  75%|███████▍  | 315/421 [00:22<00:07, 14.76it/s]going through batches for holmes training:  75%|███████▌  | 317/421 [00:22<00:07, 14.77it/s]going through batches for holmes training:  76%|███████▌  | 319/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  76%|███████▌  | 321/421 [00:22<00:06, 14.77it/s]going through batches for holmes training:  77%|███████▋  | 323/421 [00:22<00:06, 14.76it/s]going through batches for holmes training:  77%|███████▋  | 325/421 [00:22<00:06, 14.73it/s]going through batches for holmes training:  78%|███████▊  | 327/421 [00:22<00:06, 14.71it/s]going through batches for holmes training:  78%|███████▊  | 329/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▊  | 331/421 [00:23<00:06, 14.72it/s]going through batches for holmes training:  79%|███████▉  | 333/421 [00:23<00:05, 14.71it/s]going through batches for holmes training:  80%|███████▉  | 335/421 [00:23<00:05, 14.72it/s]going through batches for holmes training:  80%|████████  | 337/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 339/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████  | 341/421 [00:23<00:05, 14.75it/s]going through batches for holmes training:  81%|████████▏ | 343/421 [00:24<00:05, 14.75it/s]going through batches for holmes training:  82%|████████▏ | 345/421 [00:24<00:05, 14.73it/s]going through batches for holmes training:  82%|████████▏ | 347/421 [00:24<00:05, 14.77it/s]going through batches for holmes training:  83%|████████▎ | 349/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  83%|████████▎ | 351/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  84%|████████▍ | 353/421 [00:24<00:04, 14.79it/s]going through batches for holmes training:  84%|████████▍ | 355/421 [00:24<00:04, 14.81it/s]going through batches for holmes training:  85%|████████▍ | 357/421 [00:25<00:04, 14.84it/s]going through batches for holmes training:  85%|████████▌ | 359/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  86%|████████▌ | 361/421 [00:25<00:04, 14.81it/s]going through batches for holmes training:  86%|████████▌ | 363/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 365/421 [00:25<00:03, 14.80it/s]going through batches for holmes training:  87%|████████▋ | 367/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 369/421 [00:25<00:03, 14.81it/s]going through batches for holmes training:  88%|████████▊ | 371/421 [00:25<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▊ | 373/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  89%|████████▉ | 375/421 [00:26<00:03, 14.82it/s]going through batches for holmes training:  90%|████████▉ | 377/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 379/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  90%|█████████ | 381/421 [00:26<00:02, 14.82it/s]going through batches for holmes training:  91%|█████████ | 383/421 [00:26<00:02, 14.81it/s]going through batches for holmes training:  91%|█████████▏| 385/421 [00:26<00:02, 14.83it/s]going through batches for holmes training:  92%|█████████▏| 387/421 [00:27<00:02, 14.82it/s]going through batches for holmes training:  92%|█████████▏| 389/421 [00:27<00:02, 14.81it/s]going through batches for holmes training:  93%|█████████▎| 391/421 [00:27<00:02, 14.83it/s]going through batches for holmes training:  93%|█████████▎| 393/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  94%|█████████▍| 395/421 [00:27<00:01, 14.85it/s]going through batches for holmes training:  94%|█████████▍| 397/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▍| 399/421 [00:27<00:01, 14.83it/s]going through batches for holmes training:  95%|█████████▌| 401/421 [00:27<00:01, 14.82it/s]going through batches for holmes training:  96%|█████████▌| 403/421 [00:28<00:01, 14.68it/s]going through batches for holmes training:  96%|█████████▌| 405/421 [00:28<00:01, 14.75it/s]going through batches for holmes training:  97%|█████████▋| 407/421 [00:28<00:00, 14.79it/s]going through batches for holmes training:  97%|█████████▋| 409/421 [00:28<00:00, 14.82it/s]going through batches for holmes training:  98%|█████████▊| 411/421 [00:28<00:00, 14.83it/s]going through batches for holmes training:  98%|█████████▊| 413/421 [00:28<00:00, 14.86it/s]going through batches for holmes training:  99%|█████████▊| 415/421 [00:28<00:00, 14.89it/s]going through batches for holmes training:  99%|█████████▉| 417/421 [00:29<00:00, 14.89it/s]going through batches for holmes training: 100%|█████████▉| 419/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.88it/s]going through batches for holmes training: 100%|██████████| 421/421 [00:29<00:00, 14.33it/s]
epoch 79: train_loss = 1.756
79: {'Accuracy': 0.946, 'Precision': 0.9469, 'Recall': 0.946, 'F1-score': 0.9462}
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
num_classes: 45
Generate ./checkpoints/Tik_Tok_removed_50_43/Holmes/spatial_distribution.npz done
script for gen early traffic started
creating test set for p = 10
Generating the page loaded 10% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 35%|███▍      | 1562/4500 [00:00<00:00, 15614.62it/s] 70%|███████   | 3158/4500 [00:00<00:00, 15814.28it/s]100%|██████████| 4500/4500 [00:00<00:00, 15870.86it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 11
Generating the page loaded 11% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 45%|████▌     | 2031/4500 [00:00<00:00, 20305.52it/s] 90%|█████████ | 4062/4500 [00:00<00:00, 17574.10it/s]100%|██████████| 4500/4500 [00:00<00:00, 17669.42it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 12
Generating the page loaded 12% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 47%|████▋     | 2132/4500 [00:00<00:00, 21313.31it/s] 95%|█████████▍| 4264/4500 [00:00<00:00, 18079.66it/s]100%|██████████| 4500/4500 [00:00<00:00, 18387.83it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 13
Generating the page loaded 13% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2745/4500 [00:00<00:00, 27448.52it/s]100%|██████████| 4500/4500 [00:00<00:00, 21756.69it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 14
Generating the page loaded 14% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2755/4500 [00:00<00:00, 27531.84it/s]100%|██████████| 4500/4500 [00:00<00:00, 21793.45it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 15
Generating the page loaded 15% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 56%|█████▋    | 2533/4500 [00:00<00:00, 25318.49it/s]100%|██████████| 4500/4500 [00:00<00:00, 20018.10it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 16
Generating the page loaded 16% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 51%|█████     | 2287/4500 [00:00<00:00, 22862.06it/s]100%|██████████| 4500/4500 [00:00<00:00, 19057.80it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 17
Generating the page loaded 17% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2742/4500 [00:00<00:00, 27408.85it/s]100%|██████████| 4500/4500 [00:00<00:00, 21389.23it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 18
Generating the page loaded 18% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2735/4500 [00:00<00:00, 27342.40it/s]100%|██████████| 4500/4500 [00:00<00:00, 21408.27it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 19
Generating the page loaded 19% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 48%|████▊     | 2163/4500 [00:00<00:00, 21624.14it/s] 96%|█████████▌| 4326/4500 [00:00<00:00, 18593.54it/s]100%|██████████| 4500/4500 [00:00<00:00, 18853.50it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 20
Generating the page loaded 20% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 58%|█████▊    | 2622/4500 [00:00<00:00, 26214.96it/s]100%|██████████| 4500/4500 [00:00<00:00, 20678.62it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 21
Generating the page loaded 21% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2738/4500 [00:00<00:00, 27375.78it/s]100%|██████████| 4500/4500 [00:00<00:00, 21379.68it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 22
Generating the page loaded 22% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2749/4500 [00:00<00:00, 27487.86it/s]100%|██████████| 4500/4500 [00:00<00:00, 21776.93it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 23
Generating the page loaded 23% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|██████    | 2721/4500 [00:00<00:00, 27205.29it/s]100%|██████████| 4500/4500 [00:00<00:00, 20627.88it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 24
Generating the page loaded 24% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2723/4500 [00:00<00:00, 27225.68it/s]100%|██████████| 4500/4500 [00:00<00:00, 21508.47it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 25
Generating the page loaded 25% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|██████    | 2714/4500 [00:00<00:00, 27136.60it/s]100%|██████████| 4500/4500 [00:00<00:00, 21277.23it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 26
Generating the page loaded 26% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2732/4500 [00:00<00:00, 27302.97it/s]100%|██████████| 4500/4500 [00:00<00:00, 21751.33it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 27
Generating the page loaded 27% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2723/4500 [00:00<00:00, 27218.93it/s]100%|██████████| 4500/4500 [00:00<00:00, 21638.24it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 28
Generating the page loaded 28% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 46%|████▌     | 2061/4500 [00:00<00:00, 20603.39it/s] 92%|█████████▏| 4122/4500 [00:00<00:00, 18478.72it/s]100%|██████████| 4500/4500 [00:00<00:00, 18509.73it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 29
Generating the page loaded 29% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2734/4500 [00:00<00:00, 27335.46it/s]100%|██████████| 4500/4500 [00:00<00:00, 22001.46it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 30
Generating the page loaded 30% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2747/4500 [00:00<00:00, 27453.66it/s]100%|██████████| 4500/4500 [00:00<00:00, 22163.65it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 31
Generating the page loaded 31% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 58%|█████▊    | 2594/4500 [00:00<00:00, 25937.18it/s]100%|██████████| 4500/4500 [00:00<00:00, 21123.35it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 32
Generating the page loaded 32% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2738/4500 [00:00<00:00, 27371.48it/s]100%|██████████| 4500/4500 [00:00<00:00, 22051.35it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 33
Generating the page loaded 33% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2741/4500 [00:00<00:00, 27404.02it/s]100%|██████████| 4500/4500 [00:00<00:00, 22077.19it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 34
Generating the page loaded 34% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2729/4500 [00:00<00:00, 27275.26it/s]100%|██████████| 4500/4500 [00:00<00:00, 21976.22it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 35
Generating the page loaded 35% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2740/4500 [00:00<00:00, 27399.37it/s]100%|██████████| 4500/4500 [00:00<00:00, 22166.36it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 36
Generating the page loaded 36% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2747/4500 [00:00<00:00, 27459.55it/s]100%|██████████| 4500/4500 [00:00<00:00, 22075.13it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 37
Generating the page loaded 37% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2739/4500 [00:00<00:00, 27387.35it/s]100%|██████████| 4500/4500 [00:00<00:00, 22080.17it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 38
Generating the page loaded 38% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2749/4500 [00:00<00:00, 27477.78it/s]100%|██████████| 4500/4500 [00:00<00:00, 22152.70it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 39
Generating the page loaded 39% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2729/4500 [00:00<00:00, 27267.34it/s]100%|██████████| 4500/4500 [00:00<00:00, 21984.26it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 40
Generating the page loaded 40% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2729/4500 [00:00<00:00, 27279.75it/s]100%|██████████| 4500/4500 [00:00<00:00, 22022.33it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 41
Generating the page loaded 41% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2724/4500 [00:00<00:00, 27238.21it/s]100%|██████████| 4500/4500 [00:00<00:00, 21959.22it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 42
Generating the page loaded 42% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2749/4500 [00:00<00:00, 27483.54it/s]100%|██████████| 4500/4500 [00:00<00:00, 22267.46it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 43
Generating the page loaded 43% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2728/4500 [00:00<00:00, 27264.94it/s]100%|██████████| 4500/4500 [00:00<00:00, 22018.17it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 44
Generating the page loaded 44% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2727/4500 [00:00<00:00, 27258.20it/s]100%|██████████| 4500/4500 [00:00<00:00, 22127.85it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 45
Generating the page loaded 45% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2728/4500 [00:00<00:00, 27276.58it/s]100%|██████████| 4500/4500 [00:00<00:00, 22125.77it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 46
Generating the page loaded 46% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2725/4500 [00:00<00:00, 27245.48it/s]100%|██████████| 4500/4500 [00:00<00:00, 21918.98it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 47
Generating the page loaded 47% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 46%|████▋     | 2091/4500 [00:00<00:00, 20902.84it/s] 93%|█████████▎| 4182/4500 [00:00<00:00, 18764.11it/s]100%|██████████| 4500/4500 [00:00<00:00, 18896.78it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 48
Generating the page loaded 48% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2744/4500 [00:00<00:00, 27432.64it/s]100%|██████████| 4500/4500 [00:00<00:00, 22157.80it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 49
Generating the page loaded 49% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2724/4500 [00:00<00:00, 27236.32it/s]100%|██████████| 4500/4500 [00:00<00:00, 22056.07it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 50
Generating the page loaded 50% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 61%|██████    | 2733/4500 [00:00<00:00, 27317.59it/s]100%|██████████| 4500/4500 [00:00<00:00, 22139.14it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 51
Generating the page loaded 51% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|██████    | 2714/4500 [00:00<00:00, 27132.85it/s]100%|██████████| 4500/4500 [00:00<00:00, 21854.21it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 52
Generating the page loaded 52% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 57%|█████▋    | 2580/4500 [00:00<00:00, 25795.97it/s]100%|██████████| 4500/4500 [00:00<00:00, 20262.16it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 53
Generating the page loaded 53% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2656/4500 [00:00<00:00, 26552.43it/s]100%|██████████| 4500/4500 [00:00<00:00, 20200.49it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 54
Generating the page loaded 54% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2663/4500 [00:00<00:00, 26619.43it/s]100%|██████████| 4500/4500 [00:00<00:00, 20658.27it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 55
Generating the page loaded 55% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2686/4500 [00:00<00:00, 26857.14it/s]100%|██████████| 4500/4500 [00:00<00:00, 21239.61it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 56
Generating the page loaded 56% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|██████    | 2704/4500 [00:00<00:00, 27031.13it/s]100%|██████████| 4500/4500 [00:00<00:00, 21551.94it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 57
Generating the page loaded 57% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2689/4500 [00:00<00:00, 26886.63it/s]100%|██████████| 4500/4500 [00:00<00:00, 21101.62it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 58
Generating the page loaded 58% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2689/4500 [00:00<00:00, 26879.39it/s]100%|██████████| 4500/4500 [00:00<00:00, 21425.28it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 59
Generating the page loaded 59% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2691/4500 [00:00<00:00, 26899.44it/s]100%|██████████| 4500/4500 [00:00<00:00, 21456.22it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 60
Generating the page loaded 60% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2678/4500 [00:00<00:00, 26774.22it/s]100%|██████████| 4500/4500 [00:00<00:00, 21303.69it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 61
Generating the page loaded 61% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2691/4500 [00:00<00:00, 26901.24it/s]100%|██████████| 4500/4500 [00:00<00:00, 20674.27it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 62
Generating the page loaded 62% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2669/4500 [00:00<00:00, 26688.50it/s]100%|██████████| 4500/4500 [00:00<00:00, 20858.14it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 63
Generating the page loaded 63% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2678/4500 [00:00<00:00, 26771.66it/s]100%|██████████| 4500/4500 [00:00<00:00, 21044.64it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 64
Generating the page loaded 64% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2682/4500 [00:00<00:00, 26809.42it/s]100%|██████████| 4500/4500 [00:00<00:00, 20919.99it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 65
Generating the page loaded 65% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2660/4500 [00:00<00:00, 26596.47it/s]100%|██████████| 4500/4500 [00:00<00:00, 21157.61it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 66
Generating the page loaded 66% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2672/4500 [00:00<00:00, 26710.86it/s]100%|██████████| 4500/4500 [00:00<00:00, 21192.82it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 67
Generating the page loaded 67% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2684/4500 [00:00<00:00, 26834.01it/s]100%|██████████| 4500/4500 [00:00<00:00, 21344.84it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 68
Generating the page loaded 68% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2690/4500 [00:00<00:00, 26898.74it/s]100%|██████████| 4500/4500 [00:00<00:00, 21252.00it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 69
Generating the page loaded 69% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2693/4500 [00:00<00:00, 26918.41it/s]100%|██████████| 4500/4500 [00:00<00:00, 21343.32it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 70
Generating the page loaded 70% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2666/4500 [00:00<00:00, 26654.56it/s]100%|██████████| 4500/4500 [00:00<00:00, 21162.19it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 71
Generating the page loaded 71% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2669/4500 [00:00<00:00, 26689.13it/s]100%|██████████| 4500/4500 [00:00<00:00, 21095.73it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 72
Generating the page loaded 72% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2670/4500 [00:00<00:00, 26696.97it/s]100%|██████████| 4500/4500 [00:00<00:00, 21079.52it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 73
Generating the page loaded 73% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 45%|████▍     | 2024/4500 [00:00<00:00, 20235.00it/s] 90%|████████▉ | 4048/4500 [00:00<00:00, 17646.17it/s]100%|██████████| 4500/4500 [00:00<00:00, 17621.10it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 74
Generating the page loaded 74% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2653/4500 [00:00<00:00, 26524.21it/s]100%|██████████| 4500/4500 [00:00<00:00, 20673.18it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 75
Generating the page loaded 75% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2675/4500 [00:00<00:00, 26744.92it/s]100%|██████████| 4500/4500 [00:00<00:00, 21078.34it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 76
Generating the page loaded 76% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2671/4500 [00:00<00:00, 26699.14it/s]100%|██████████| 4500/4500 [00:00<00:00, 21119.10it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 77
Generating the page loaded 77% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2679/4500 [00:00<00:00, 26783.90it/s]100%|██████████| 4500/4500 [00:00<00:00, 21006.60it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 78
Generating the page loaded 78% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2663/4500 [00:00<00:00, 26626.72it/s]100%|██████████| 4500/4500 [00:00<00:00, 20822.87it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 79
Generating the page loaded 79% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2671/4500 [00:00<00:00, 26692.78it/s]100%|██████████| 4500/4500 [00:00<00:00, 20991.25it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 80
Generating the page loaded 80% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2661/4500 [00:00<00:00, 26600.96it/s]100%|██████████| 4500/4500 [00:00<00:00, 20652.64it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 81
Generating the page loaded 81% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2680/4500 [00:00<00:00, 26798.62it/s]100%|██████████| 4500/4500 [00:00<00:00, 21114.25it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 82
Generating the page loaded 82% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2657/4500 [00:00<00:00, 26564.52it/s]100%|██████████| 4500/4500 [00:00<00:00, 20858.40it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 83
Generating the page loaded 83% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 56%|█████▌    | 2527/4500 [00:00<00:00, 25265.02it/s]100%|██████████| 4500/4500 [00:00<00:00, 20312.12it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 84
Generating the page loaded 84% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2662/4500 [00:00<00:00, 26611.46it/s]100%|██████████| 4500/4500 [00:00<00:00, 21172.11it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 85
Generating the page loaded 85% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2691/4500 [00:00<00:00, 26904.70it/s]100%|██████████| 4500/4500 [00:00<00:00, 21423.34it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 86
Generating the page loaded 86% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2687/4500 [00:00<00:00, 26858.12it/s]100%|██████████| 4500/4500 [00:00<00:00, 21039.67it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 87
Generating the page loaded 87% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2654/4500 [00:00<00:00, 26524.22it/s]100%|██████████| 4500/4500 [00:00<00:00, 20676.26it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 88
Generating the page loaded 88% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2673/4500 [00:00<00:00, 26727.03it/s]100%|██████████| 4500/4500 [00:00<00:00, 21139.15it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 89
Generating the page loaded 89% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2692/4500 [00:00<00:00, 26910.34it/s]100%|██████████| 4500/4500 [00:00<00:00, 21241.88it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 90
Generating the page loaded 90% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2669/4500 [00:00<00:00, 26686.34it/s]100%|██████████| 4500/4500 [00:00<00:00, 20718.16it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 91
Generating the page loaded 91% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2649/4500 [00:00<00:00, 26482.01it/s]100%|██████████| 4500/4500 [00:00<00:00, 20788.03it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 92
Generating the page loaded 92% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2682/4500 [00:00<00:00, 26816.32it/s]100%|██████████| 4500/4500 [00:00<00:00, 21318.97it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 93
Generating the page loaded 93% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2682/4500 [00:00<00:00, 26807.75it/s]100%|██████████| 4500/4500 [00:00<00:00, 21418.79it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 94
Generating the page loaded 94% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2689/4500 [00:00<00:00, 26889.32it/s]100%|██████████| 4500/4500 [00:00<00:00, 21357.67it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 95
Generating the page loaded 95% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|██████    | 2706/4500 [00:00<00:00, 27054.80it/s]100%|██████████| 4500/4500 [00:00<00:00, 21013.31it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 96
Generating the page loaded 96% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2679/4500 [00:00<00:00, 26783.96it/s]100%|██████████| 4500/4500 [00:00<00:00, 21060.94it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 97
Generating the page loaded 97% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2672/4500 [00:00<00:00, 26714.68it/s]100%|██████████| 4500/4500 [00:00<00:00, 21175.34it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 98
Generating the page loaded 98% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 60%|█████▉    | 2691/4500 [00:00<00:00, 26895.15it/s]100%|██████████| 4500/4500 [00:00<00:00, 21181.95it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 99
Generating the page loaded 99% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2677/4500 [00:00<00:00, 26757.14it/s]100%|██████████| 4500/4500 [00:00<00:00, 21250.71it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
creating test set for p = 100
Generating the page loaded 100% of traffic
  0%|          | 0/4500 [00:00<?, ?it/s] 59%|█████▉    | 2673/4500 [00:00<00:00, 26715.57it/s]100%|██████████| 4500/4500 [00:00<00:00, 20639.93it/s]
Shape: X = (4500, 10000), y = (4500,)

Size Analysis:
--------------
Total raw size: 343.36 MB
Estimated compressed size: 171.68 MB
Overhead: 1.50 KB

Size per array:
X: 343.32 MB
y: 35.16 KB
script for gen early traffic started
script for gen early traffic started
creating test set for p = 10
Generating the page loaded 10% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 16%|█▌        | 1611/10000 [00:00<00:00, 16102.49it/s] 33%|███▎      | 3302/10000 [00:00<00:00, 16572.63it/s] 50%|████▉     | 4992/10000 [00:00<00:00, 16719.68it/s] 67%|██████▋   | 6681/10000 [00:00<00:00, 16783.25it/s] 84%|████████▍ | 8397/10000 [00:00<00:00, 16914.19it/s]100%|██████████| 10000/10000 [00:00<00:00, 16867.80it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 11
Generating the page loaded 11% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 21%|██        | 2090/10000 [00:00<00:00, 20889.71it/s] 42%|████▏     | 4182/10000 [00:00<00:00, 20904.19it/s] 63%|██████▎   | 6273/10000 [00:00<00:00, 20713.14it/s] 83%|████████▎ | 8345/10000 [00:00<00:00, 19360.53it/s]100%|██████████| 10000/10000 [00:00<00:00, 19419.44it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 12
Generating the page loaded 12% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 31%|███       | 3073/10000 [00:00<00:00, 30720.29it/s] 62%|██████▏   | 6155/10000 [00:00<00:00, 30774.08it/s] 92%|█████████▏| 9233/10000 [00:00<00:00, 23806.07it/s]100%|██████████| 10000/10000 [00:00<00:00, 24481.16it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 13
Generating the page loaded 13% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 22%|██▏       | 2173/10000 [00:00<00:00, 21728.05it/s] 43%|████▎     | 4346/10000 [00:00<00:00, 21288.55it/s] 65%|██████▍   | 6476/10000 [00:00<00:00, 20917.02it/s] 86%|████████▌ | 8569/10000 [00:00<00:00, 19493.20it/s]100%|██████████| 10000/10000 [00:00<00:00, 19702.93it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 14
Generating the page loaded 14% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 31%|███       | 3058/10000 [00:00<00:00, 30573.03it/s] 61%|██████    | 6121/10000 [00:00<00:00, 30605.31it/s] 92%|█████████▏| 9182/10000 [00:00<00:00, 23846.50it/s]100%|██████████| 10000/10000 [00:00<00:00, 24416.05it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 15
Generating the page loaded 15% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 24%|██▍       | 2444/10000 [00:00<00:00, 24435.60it/s] 49%|████▉     | 4888/10000 [00:00<00:00, 23205.74it/s] 72%|███████▏  | 7213/10000 [00:00<00:00, 22834.90it/s] 95%|█████████▍| 9499/10000 [00:00<00:00, 20484.73it/s]100%|██████████| 10000/10000 [00:00<00:00, 21214.20it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 16
Generating the page loaded 16% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2877/10000 [00:00<00:00, 28762.83it/s] 59%|█████▊    | 5865/10000 [00:00<00:00, 29414.95it/s] 88%|████████▊ | 8807/10000 [00:00<00:00, 22969.40it/s]100%|██████████| 10000/10000 [00:00<00:00, 23296.42it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 17
Generating the page loaded 17% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 24%|██▎       | 2360/10000 [00:00<00:00, 23594.51it/s] 51%|█████▏    | 5145/10000 [00:00<00:00, 26095.54it/s] 78%|███████▊  | 7755/10000 [00:00<00:00, 24002.17it/s]100%|██████████| 10000/10000 [00:00<00:00, 22397.60it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 18
Generating the page loaded 18% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▊       | 2863/10000 [00:00<00:00, 28621.43it/s] 58%|█████▊    | 5847/10000 [00:00<00:00, 29333.60it/s] 88%|████████▊ | 8781/10000 [00:00<00:00, 22909.73it/s]100%|██████████| 10000/10000 [00:00<00:00, 23219.45it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 19
Generating the page loaded 19% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3039/10000 [00:00<00:00, 30388.58it/s] 61%|██████    | 6084/10000 [00:00<00:00, 30420.33it/s] 91%|█████████▏| 9127/10000 [00:00<00:00, 23823.98it/s]100%|██████████| 10000/10000 [00:00<00:00, 24324.73it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 20
Generating the page loaded 20% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3033/10000 [00:00<00:00, 30328.37it/s] 61%|██████    | 6076/10000 [00:00<00:00, 30381.39it/s] 91%|█████████ | 9115/10000 [00:00<00:00, 23830.48it/s]100%|██████████| 10000/10000 [00:00<00:00, 24296.48it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 21
Generating the page loaded 21% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 24%|██▎       | 2367/10000 [00:00<00:00, 23664.27it/s] 51%|█████▏    | 5130/10000 [00:00<00:00, 25996.40it/s] 77%|███████▋  | 7730/10000 [00:00<00:00, 24470.51it/s]100%|██████████| 10000/10000 [00:00<00:00, 22557.07it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 22
Generating the page loaded 22% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 28%|██▊       | 2846/10000 [00:00<00:00, 28455.28it/s] 58%|█████▊    | 5821/10000 [00:00<00:00, 29208.69it/s] 87%|████████▋ | 8742/10000 [00:00<00:00, 22852.92it/s]100%|██████████| 10000/10000 [00:00<00:00, 23122.95it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 23
Generating the page loaded 23% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3046/10000 [00:00<00:00, 30450.66it/s] 61%|██████    | 6104/10000 [00:00<00:00, 30523.76it/s] 92%|█████████▏| 9157/10000 [00:00<00:00, 23780.12it/s]100%|██████████| 10000/10000 [00:00<00:00, 24333.27it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 24
Generating the page loaded 24% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2924/10000 [00:00<00:00, 29234.03it/s] 60%|█████▉    | 5970/10000 [00:00<00:00, 29950.15it/s] 90%|████████▉ | 8966/10000 [00:00<00:00, 23816.38it/s]100%|██████████| 10000/10000 [00:00<00:00, 24055.51it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 25
Generating the page loaded 25% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3024/10000 [00:00<00:00, 30237.29it/s] 61%|██████    | 6051/10000 [00:00<00:00, 30253.03it/s] 91%|█████████ | 9077/10000 [00:00<00:00, 23759.36it/s]100%|██████████| 10000/10000 [00:00<00:00, 24188.84it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 26
Generating the page loaded 26% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 23%|██▎       | 2329/10000 [00:00<00:00, 23286.30it/s] 51%|█████     | 5089/10000 [00:00<00:00, 25820.80it/s] 77%|███████▋  | 7672/10000 [00:00<00:00, 24488.62it/s]100%|██████████| 10000/10000 [00:00<00:00, 22451.14it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 27
Generating the page loaded 27% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 27%|██▋       | 2691/10000 [00:00<00:00, 26909.58it/s] 54%|█████▍    | 5382/10000 [00:00<00:00, 23611.89it/s] 78%|███████▊  | 7770/10000 [00:00<00:00, 22429.30it/s]100%|██████████| 10000/10000 [00:00<00:00, 21536.66it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 28
Generating the page loaded 28% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 28%|██▊       | 2847/10000 [00:00<00:00, 28466.97it/s] 58%|█████▊    | 5809/10000 [00:00<00:00, 29144.72it/s] 87%|████████▋ | 8724/10000 [00:00<00:00, 22773.47it/s]100%|██████████| 10000/10000 [00:00<00:00, 23028.66it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 29
Generating the page loaded 29% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3000/10000 [00:00<00:00, 29994.24it/s] 60%|██████    | 6000/10000 [00:00<00:00, 29960.75it/s] 90%|████████▉ | 8997/10000 [00:00<00:00, 23594.04it/s]100%|██████████| 10000/10000 [00:00<00:00, 23961.19it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 30
Generating the page loaded 30% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3010/10000 [00:00<00:00, 30095.08it/s] 60%|██████    | 6046/10000 [00:00<00:00, 30247.74it/s] 91%|█████████ | 9071/10000 [00:00<00:00, 23756.84it/s]100%|██████████| 10000/10000 [00:00<00:00, 24192.87it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 31
Generating the page loaded 31% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3013/10000 [00:00<00:00, 30120.62it/s] 60%|██████    | 6026/10000 [00:00<00:00, 30070.07it/s] 90%|█████████ | 9034/10000 [00:00<00:00, 23706.78it/s]100%|██████████| 10000/10000 [00:00<00:00, 24089.98it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 32
Generating the page loaded 32% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 23%|██▎       | 2274/10000 [00:00<00:00, 22735.63it/s] 50%|█████     | 5039/10000 [00:00<00:00, 25624.64it/s] 76%|███████▌  | 7602/10000 [00:00<00:00, 24489.41it/s]100%|██████████| 10000/10000 [00:00<00:00, 22341.98it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 33
Generating the page loaded 33% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 26%|██▋       | 2626/10000 [00:00<00:00, 26254.39it/s] 53%|█████▎    | 5252/10000 [00:00<00:00, 23414.43it/s] 76%|███████▌  | 7614/10000 [00:00<00:00, 22439.62it/s] 99%|█████████▊| 9869/10000 [00:00<00:00, 20257.72it/s]100%|██████████| 10000/10000 [00:00<00:00, 21314.65it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 34
Generating the page loaded 34% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 28%|██▊       | 2813/10000 [00:00<00:00, 28120.98it/s] 58%|█████▊    | 5796/10000 [00:00<00:00, 29123.55it/s] 87%|████████▋ | 8709/10000 [00:00<00:00, 22698.79it/s]100%|██████████| 10000/10000 [00:00<00:00, 22929.37it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 35
Generating the page loaded 35% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2991/10000 [00:00<00:00, 29907.96it/s] 60%|█████▉    | 5993/10000 [00:00<00:00, 29967.91it/s] 90%|████████▉ | 8990/10000 [00:00<00:00, 23708.59it/s]100%|██████████| 10000/10000 [00:00<00:00, 24030.55it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 36
Generating the page loaded 36% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2979/10000 [00:00<00:00, 29782.64it/s] 60%|█████▉    | 5989/10000 [00:00<00:00, 29963.90it/s] 90%|████████▉ | 8986/10000 [00:00<00:00, 23774.29it/s]100%|██████████| 10000/10000 [00:00<00:00, 24065.02it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 37
Generating the page loaded 37% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2987/10000 [00:00<00:00, 29866.54it/s] 60%|█████▉    | 5974/10000 [00:00<00:00, 29836.50it/s] 90%|████████▉ | 8958/10000 [00:00<00:00, 23661.02it/s]100%|██████████| 10000/10000 [00:00<00:00, 23935.04it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 38
Generating the page loaded 38% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2971/10000 [00:00<00:00, 29701.18it/s] 60%|█████▉    | 5971/10000 [00:00<00:00, 29874.69it/s] 90%|████████▉ | 8959/10000 [00:00<00:00, 23748.84it/s]100%|██████████| 10000/10000 [00:00<00:00, 24006.73it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 39
Generating the page loaded 39% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2996/10000 [00:00<00:00, 29957.24it/s] 60%|██████    | 6007/10000 [00:00<00:00, 30044.33it/s] 90%|█████████ | 9012/10000 [00:00<00:00, 23724.88it/s]100%|██████████| 10000/10000 [00:00<00:00, 24062.37it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 40
Generating the page loaded 40% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2981/10000 [00:00<00:00, 29807.61it/s] 60%|█████▉    | 5973/10000 [00:00<00:00, 29870.76it/s] 90%|████████▉ | 8961/10000 [00:00<00:00, 23689.78it/s]100%|██████████| 10000/10000 [00:00<00:00, 23956.10it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 41
Generating the page loaded 41% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 24%|██▍       | 2391/10000 [00:00<00:00, 23903.58it/s] 51%|█████▏    | 5131/10000 [00:00<00:00, 25957.90it/s] 77%|███████▋  | 7727/10000 [00:00<00:00, 24322.18it/s]100%|██████████| 10000/10000 [00:00<00:00, 22479.30it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 42
Generating the page loaded 42% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 26%|██▌       | 2620/10000 [00:00<00:00, 26194.65it/s] 52%|█████▏    | 5240/10000 [00:00<00:00, 23377.38it/s] 76%|███████▌  | 7598/10000 [00:00<00:00, 22416.62it/s] 98%|█████████▊| 9850/10000 [00:00<00:00, 19624.61it/s]100%|██████████| 10000/10000 [00:00<00:00, 20867.50it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 43
Generating the page loaded 43% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2997/10000 [00:00<00:00, 29960.31it/s] 60%|█████▉    | 5994/10000 [00:00<00:00, 29049.20it/s] 89%|████████▉ | 8901/10000 [00:00<00:00, 22663.57it/s]100%|██████████| 10000/10000 [00:00<00:00, 23187.35it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 44
Generating the page loaded 44% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3016/10000 [00:00<00:00, 30151.11it/s] 60%|██████    | 6041/10000 [00:00<00:00, 30207.01it/s] 91%|█████████ | 9062/10000 [00:00<00:00, 23739.81it/s]100%|██████████| 10000/10000 [00:00<00:00, 24152.70it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 45
Generating the page loaded 45% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3008/10000 [00:00<00:00, 30078.38it/s] 60%|██████    | 6021/10000 [00:00<00:00, 30105.17it/s] 90%|█████████ | 9032/10000 [00:00<00:00, 23616.20it/s]100%|██████████| 10000/10000 [00:00<00:00, 24016.31it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 46
Generating the page loaded 46% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2971/10000 [00:00<00:00, 29702.10it/s] 60%|█████▉    | 5975/10000 [00:00<00:00, 29894.61it/s] 90%|████████▉ | 8965/10000 [00:00<00:00, 23536.11it/s]100%|██████████| 10000/10000 [00:00<00:00, 23856.70it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 47
Generating the page loaded 47% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2991/10000 [00:00<00:00, 29905.11it/s] 60%|█████▉    | 5995/10000 [00:00<00:00, 29983.67it/s] 90%|████████▉ | 8994/10000 [00:00<00:00, 23695.31it/s]100%|██████████| 10000/10000 [00:00<00:00, 24009.75it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 48
Generating the page loaded 48% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 23%|██▎       | 2281/10000 [00:00<00:00, 22805.51it/s] 50%|█████     | 5009/10000 [00:00<00:00, 25432.98it/s] 76%|███████▌  | 7553/10000 [00:00<00:00, 24485.64it/s]100%|██████████| 10000/10000 [00:00<00:00, 22245.86it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 49
Generating the page loaded 49% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2988/10000 [00:00<00:00, 29873.12it/s] 60%|█████▉    | 5982/10000 [00:00<00:00, 29908.66it/s] 90%|████████▉ | 8973/10000 [00:00<00:00, 23657.76it/s]100%|██████████| 10000/10000 [00:00<00:00, 23936.27it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 50
Generating the page loaded 50% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 27%|██▋       | 2668/10000 [00:00<00:00, 26666.74it/s] 53%|█████▎    | 5335/10000 [00:00<00:00, 23586.52it/s] 77%|███████▋  | 7717/10000 [00:00<00:00, 22447.00it/s]100%|█████████▉| 9975/10000 [00:00<00:00, 20257.44it/s]100%|██████████| 10000/10000 [00:00<00:00, 21397.81it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 51
Generating the page loaded 51% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 28%|██▊       | 2793/10000 [00:00<00:00, 27924.23it/s] 57%|█████▋    | 5741/10000 [00:00<00:00, 28833.71it/s] 86%|████████▋ | 8625/10000 [00:00<00:00, 22563.20it/s]100%|██████████| 10000/10000 [00:00<00:00, 22731.03it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 52
Generating the page loaded 52% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2979/10000 [00:00<00:00, 29785.55it/s] 60%|█████▉    | 5959/10000 [00:00<00:00, 29793.36it/s] 89%|████████▉ | 8939/10000 [00:00<00:00, 23660.42it/s]100%|██████████| 10000/10000 [00:00<00:00, 23914.48it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 53
Generating the page loaded 53% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2995/10000 [00:00<00:00, 29941.11it/s] 60%|█████▉    | 5990/10000 [00:00<00:00, 29905.97it/s] 90%|████████▉ | 8981/10000 [00:00<00:00, 23565.87it/s]100%|██████████| 10000/10000 [00:00<00:00, 23885.50it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 54
Generating the page loaded 54% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2966/10000 [00:00<00:00, 29658.05it/s] 59%|█████▉    | 5944/10000 [00:00<00:00, 29724.59it/s] 89%|████████▉ | 8917/10000 [00:00<00:00, 23732.72it/s]100%|██████████| 10000/10000 [00:00<00:00, 23939.03it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 55
Generating the page loaded 55% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2992/10000 [00:00<00:00, 29915.61it/s] 60%|█████▉    | 5984/10000 [00:00<00:00, 29885.73it/s] 90%|████████▉ | 8973/10000 [00:00<00:00, 23652.04it/s]100%|██████████| 10000/10000 [00:00<00:00, 23957.36it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 56
Generating the page loaded 56% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3003/10000 [00:00<00:00, 30027.09it/s] 60%|██████    | 6006/10000 [00:00<00:00, 29356.72it/s] 89%|████████▉ | 8943/10000 [00:00<00:00, 23459.68it/s]100%|██████████| 10000/10000 [00:00<00:00, 23760.72it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 57
Generating the page loaded 57% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|███       | 3000/10000 [00:00<00:00, 29996.67it/s] 60%|██████    | 6000/10000 [00:00<00:00, 29994.02it/s] 90%|█████████ | 9000/10000 [00:00<00:00, 23669.40it/s]100%|██████████| 10000/10000 [00:00<00:00, 24010.15it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 58
Generating the page loaded 58% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2983/10000 [00:00<00:00, 29829.39it/s] 60%|█████▉    | 5976/10000 [00:00<00:00, 29888.00it/s] 90%|████████▉ | 8965/10000 [00:00<00:00, 23712.58it/s]100%|██████████| 10000/10000 [00:00<00:00, 23988.97it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 59
Generating the page loaded 59% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2945/10000 [00:00<00:00, 29441.96it/s] 59%|█████▉    | 5900/10000 [00:00<00:00, 29499.15it/s] 88%|████████▊ | 8850/10000 [00:00<00:00, 23574.49it/s]100%|██████████| 10000/10000 [00:00<00:00, 23711.19it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 60
Generating the page loaded 60% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2970/10000 [00:00<00:00, 29691.39it/s] 60%|█████▉    | 5954/10000 [00:00<00:00, 29774.85it/s] 89%|████████▉ | 8932/10000 [00:00<00:00, 23679.15it/s]100%|██████████| 10000/10000 [00:00<00:00, 23900.41it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 61
Generating the page loaded 61% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2957/10000 [00:00<00:00, 29560.30it/s] 59%|█████▉    | 5936/10000 [00:00<00:00, 29692.63it/s] 89%|████████▉ | 8906/10000 [00:00<00:00, 23566.25it/s]100%|██████████| 10000/10000 [00:00<00:00, 23785.85it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 62
Generating the page loaded 62% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2981/10000 [00:00<00:00, 29804.41it/s] 60%|█████▉    | 5962/10000 [00:00<00:00, 29762.47it/s] 89%|████████▉ | 8939/10000 [00:00<00:00, 22539.44it/s]100%|██████████| 10000/10000 [00:00<00:00, 22969.86it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 63
Generating the page loaded 63% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 22%|██▏       | 2239/10000 [00:00<00:00, 22386.50it/s] 49%|████▉     | 4923/10000 [00:00<00:00, 25004.44it/s] 74%|███████▍  | 7424/10000 [00:00<00:00, 24121.78it/s] 98%|█████████▊| 9840/10000 [00:00<00:00, 20429.03it/s]100%|██████████| 10000/10000 [00:00<00:00, 21520.55it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 64
Generating the page loaded 64% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2969/10000 [00:00<00:00, 29688.19it/s] 60%|█████▉    | 5963/10000 [00:00<00:00, 29830.97it/s] 89%|████████▉ | 8947/10000 [00:00<00:00, 22074.29it/s]100%|██████████| 10000/10000 [00:00<00:00, 22301.42it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 65
Generating the page loaded 65% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 26%|██▌       | 2595/10000 [00:00<00:00, 25949.47it/s] 52%|█████▏    | 5190/10000 [00:00<00:00, 22961.60it/s] 75%|███████▌  | 7509/10000 [00:00<00:00, 22036.41it/s] 97%|█████████▋| 9724/10000 [00:00<00:00, 19674.32it/s]100%|██████████| 10000/10000 [00:00<00:00, 20706.36it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 66
Generating the page loaded 66% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2968/10000 [00:00<00:00, 29673.31it/s] 59%|█████▉    | 5941/10000 [00:00<00:00, 29703.05it/s] 89%|████████▉ | 8912/10000 [00:00<00:00, 23443.56it/s]100%|██████████| 10000/10000 [00:00<00:00, 23691.27it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 67
Generating the page loaded 67% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 28%|██▊       | 2763/10000 [00:00<00:00, 27617.98it/s] 57%|█████▋    | 5715/10000 [00:00<00:00, 28732.88it/s] 86%|████████▌ | 8589/10000 [00:00<00:00, 22333.18it/s]100%|██████████| 10000/10000 [00:00<00:00, 22500.23it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 68
Generating the page loaded 68% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2960/10000 [00:00<00:00, 29595.72it/s] 59%|█████▉    | 5942/10000 [00:00<00:00, 29721.53it/s] 89%|████████▉ | 8915/10000 [00:00<00:00, 23615.75it/s]100%|██████████| 10000/10000 [00:00<00:00, 23831.79it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 69
Generating the page loaded 69% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2965/10000 [00:00<00:00, 29643.03it/s] 59%|█████▉    | 5936/10000 [00:00<00:00, 29677.44it/s] 89%|████████▉ | 8904/10000 [00:00<00:00, 23629.05it/s]100%|██████████| 10000/10000 [00:00<00:00, 23843.44it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 70
Generating the page loaded 70% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2978/10000 [00:00<00:00, 29777.19it/s] 60%|█████▉    | 5970/10000 [00:00<00:00, 29855.93it/s] 90%|████████▉ | 8956/10000 [00:00<00:00, 23665.46it/s]100%|██████████| 10000/10000 [00:00<00:00, 23942.93it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 71
Generating the page loaded 71% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2947/10000 [00:00<00:00, 29462.23it/s] 59%|█████▉    | 5906/10000 [00:00<00:00, 29533.96it/s] 89%|████████▊ | 8860/10000 [00:00<00:00, 23565.67it/s]100%|██████████| 10000/10000 [00:00<00:00, 23731.53it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 72
Generating the page loaded 72% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2950/10000 [00:00<00:00, 29490.40it/s] 59%|█████▉    | 5900/10000 [00:00<00:00, 29402.84it/s] 88%|████████▊ | 8841/10000 [00:00<00:00, 23541.40it/s]100%|██████████| 10000/10000 [00:00<00:00, 23680.52it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 73
Generating the page loaded 73% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2963/10000 [00:00<00:00, 29626.85it/s] 59%|█████▉    | 5926/10000 [00:00<00:00, 28653.23it/s] 88%|████████▊ | 8794/10000 [00:00<00:00, 23354.42it/s]100%|██████████| 10000/10000 [00:00<00:00, 23467.34it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 74
Generating the page loaded 74% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2954/10000 [00:00<00:00, 29536.79it/s] 59%|█████▉    | 5919/10000 [00:00<00:00, 29600.49it/s] 89%|████████▉ | 8880/10000 [00:00<00:00, 23621.79it/s]100%|██████████| 10000/10000 [00:00<00:00, 23801.02it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 75
Generating the page loaded 75% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 23%|██▎       | 2302/10000 [00:00<00:00, 23015.08it/s] 50%|████▉     | 4969/10000 [00:00<00:00, 25159.99it/s] 75%|███████▍  | 7485/10000 [00:00<00:00, 24318.55it/s] 99%|█████████▉| 9921/10000 [00:00<00:00, 20985.72it/s]100%|██████████| 10000/10000 [00:00<00:00, 22040.29it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 76
Generating the page loaded 76% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2945/10000 [00:00<00:00, 29447.99it/s] 59%|█████▉    | 5899/10000 [00:00<00:00, 29497.70it/s] 88%|████████▊ | 8849/10000 [00:00<00:00, 23463.50it/s]100%|██████████| 10000/10000 [00:00<00:00, 23649.27it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 77
Generating the page loaded 77% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2963/10000 [00:00<00:00, 29620.64it/s] 59%|█████▉    | 5937/10000 [00:00<00:00, 29686.86it/s] 89%|████████▉ | 8906/10000 [00:00<00:00, 23608.36it/s]100%|██████████| 10000/10000 [00:00<00:00, 23818.67it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 78
Generating the page loaded 78% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 26%|██▋       | 2631/10000 [00:00<00:00, 26299.68it/s] 53%|█████▎    | 5261/10000 [00:00<00:00, 22953.03it/s] 76%|███████▌  | 7584/10000 [00:00<00:00, 21985.91it/s] 98%|█████████▊| 9797/10000 [00:00<00:00, 19810.69it/s]100%|██████████| 10000/10000 [00:00<00:00, 20874.23it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 79
Generating the page loaded 79% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2928/10000 [00:00<00:00, 29277.86it/s] 59%|█████▊    | 5856/10000 [00:00<00:00, 29256.41it/s] 88%|████████▊ | 8782/10000 [00:00<00:00, 23221.13it/s]100%|██████████| 10000/10000 [00:00<00:00, 23355.93it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 80
Generating the page loaded 80% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 28%|██▊       | 2786/10000 [00:00<00:00, 27849.14it/s] 57%|█████▋    | 5730/10000 [00:00<00:00, 28781.29it/s] 86%|████████▌ | 8609/10000 [00:00<00:00, 22454.17it/s]100%|██████████| 10000/10000 [00:00<00:00, 22635.16it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 81
Generating the page loaded 81% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2951/10000 [00:00<00:00, 29505.17it/s] 59%|█████▉    | 5925/10000 [00:00<00:00, 29638.53it/s] 89%|████████▉ | 8889/10000 [00:00<00:00, 23504.96it/s]100%|██████████| 10000/10000 [00:00<00:00, 23710.38it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 82
Generating the page loaded 82% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2950/10000 [00:00<00:00, 29494.54it/s] 59%|█████▉    | 5921/10000 [00:00<00:00, 29615.56it/s] 89%|████████▉ | 8883/10000 [00:00<00:00, 23600.83it/s]100%|██████████| 10000/10000 [00:00<00:00, 23775.95it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 83
Generating the page loaded 83% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2947/10000 [00:00<00:00, 29461.88it/s] 59%|█████▉    | 5909/10000 [00:00<00:00, 29553.57it/s] 89%|████████▊ | 8865/10000 [00:00<00:00, 23589.19it/s]100%|██████████| 10000/10000 [00:00<00:00, 23742.56it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 84
Generating the page loaded 84% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2956/10000 [00:00<00:00, 29552.91it/s] 59%|█████▉    | 5933/10000 [00:00<00:00, 29677.16it/s] 89%|████████▉ | 8901/10000 [00:00<00:00, 23637.85it/s]100%|██████████| 10000/10000 [00:00<00:00, 23833.03it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 85
Generating the page loaded 85% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2958/10000 [00:00<00:00, 29574.60it/s] 59%|█████▉    | 5922/10000 [00:00<00:00, 29607.15it/s] 89%|████████▉ | 8883/10000 [00:00<00:00, 23590.19it/s]100%|██████████| 10000/10000 [00:00<00:00, 23779.82it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 86
Generating the page loaded 86% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2959/10000 [00:00<00:00, 29584.39it/s] 59%|█████▉    | 5918/10000 [00:00<00:00, 29560.05it/s] 89%|████████▉ | 8875/10000 [00:00<00:00, 23590.40it/s]100%|██████████| 10000/10000 [00:00<00:00, 23757.62it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 87
Generating the page loaded 87% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2926/10000 [00:00<00:00, 29255.28it/s] 59%|█████▊    | 5866/10000 [00:00<00:00, 29339.48it/s] 88%|████████▊ | 8800/10000 [00:00<00:00, 23519.33it/s]100%|██████████| 10000/10000 [00:00<00:00, 23593.41it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 88
Generating the page loaded 88% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 30%|██▉       | 2960/10000 [00:00<00:00, 29592.97it/s] 59%|█████▉    | 5922/10000 [00:00<00:00, 29603.82it/s] 89%|████████▉ | 8883/10000 [00:00<00:00, 23617.40it/s]100%|██████████| 10000/10000 [00:00<00:00, 23816.40it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 89
Generating the page loaded 89% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2907/10000 [00:00<00:00, 29063.10it/s] 58%|█████▊    | 5821/10000 [00:00<00:00, 29102.63it/s] 87%|████████▋ | 8732/10000 [00:00<00:00, 23448.25it/s]100%|██████████| 10000/10000 [00:00<00:00, 23443.09it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 90
Generating the page loaded 90% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2887/10000 [00:00<00:00, 28861.43it/s] 58%|█████▊    | 5804/10000 [00:00<00:00, 29041.26it/s] 87%|████████▋ | 8709/10000 [00:00<00:00, 23438.60it/s]100%|██████████| 10000/10000 [00:00<00:00, 23385.03it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 91
Generating the page loaded 91% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2919/10000 [00:00<00:00, 29181.12it/s] 59%|█████▊    | 5856/10000 [00:00<00:00, 29288.45it/s] 88%|████████▊ | 8785/10000 [00:00<00:00, 23475.04it/s]100%|██████████| 10000/10000 [00:00<00:00, 23548.37it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 92
Generating the page loaded 92% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2912/10000 [00:00<00:00, 29114.47it/s] 58%|█████▊    | 5842/10000 [00:00<00:00, 29217.80it/s] 88%|████████▊ | 8764/10000 [00:00<00:00, 23508.93it/s]100%|██████████| 10000/10000 [00:00<00:00, 23546.65it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 93
Generating the page loaded 93% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2944/10000 [00:00<00:00, 29431.19it/s] 59%|█████▉    | 5895/10000 [00:00<00:00, 29476.81it/s] 88%|████████▊ | 8843/10000 [00:00<00:00, 23536.31it/s]100%|██████████| 10000/10000 [00:00<00:00, 23673.59it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 94
Generating the page loaded 94% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 23%|██▎       | 2337/10000 [00:00<00:00, 23362.17it/s] 50%|█████     | 5046/10000 [00:00<00:00, 25553.86it/s] 76%|███████▌  | 7602/10000 [00:00<00:00, 24273.10it/s]100%|██████████| 10000/10000 [00:00<00:00, 22201.67it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 95
Generating the page loaded 95% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2915/10000 [00:00<00:00, 29148.92it/s] 59%|█████▊    | 5852/10000 [00:00<00:00, 29277.79it/s] 88%|████████▊ | 8780/10000 [00:00<00:00, 23464.45it/s]100%|██████████| 10000/10000 [00:00<00:00, 23525.42it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 96
Generating the page loaded 96% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2929/10000 [00:00<00:00, 29288.42it/s] 59%|█████▊    | 5863/10000 [00:00<00:00, 29312.90it/s] 88%|████████▊ | 8795/10000 [00:00<00:00, 23449.59it/s]100%|██████████| 10000/10000 [00:00<00:00, 23545.71it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 97
Generating the page loaded 97% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 26%|██▌       | 2592/10000 [00:00<00:00, 25914.09it/s] 52%|█████▏    | 5184/10000 [00:00<00:00, 23044.95it/s] 75%|███████▌  | 7510/10000 [00:00<00:00, 22159.45it/s] 97%|█████████▋| 9737/10000 [00:00<00:00, 20015.01it/s]100%|██████████| 10000/10000 [00:00<00:00, 20992.66it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 98
Generating the page loaded 98% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2925/10000 [00:00<00:00, 29244.38it/s] 59%|█████▊    | 5859/10000 [00:00<00:00, 29296.20it/s] 88%|████████▊ | 8789/10000 [00:00<00:00, 23519.87it/s]100%|██████████| 10000/10000 [00:00<00:00, 23596.97it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 99
Generating the page loaded 99% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2943/10000 [00:00<00:00, 29423.22it/s] 59%|█████▉    | 5886/10000 [00:00<00:00, 29353.87it/s] 88%|████████▊ | 8822/10000 [00:00<00:00, 23429.18it/s]100%|██████████| 10000/10000 [00:00<00:00, 23573.17it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
creating test set for p = 100
Generating the page loaded 100% of traffic
  0%|          | 0/10000 [00:00<?, ?it/s] 29%|██▉       | 2936/10000 [00:00<00:00, 29354.64it/s] 59%|█████▉    | 5887/10000 [00:00<00:00, 29441.95it/s] 88%|████████▊ | 8832/10000 [00:00<00:00, 23413.68it/s]100%|██████████| 10000/10000 [00:00<00:00, 23557.93it/s]
Shape: X = (10000, 10000), y = (10000,)

Size Analysis:
--------------
Total raw size: 763.02 MB
Estimated compressed size: 381.51 MB
Overhead: 1.50 KB

Size per array:
X: 762.94 MB
y: 78.12 KB
script for gen early traffic started
starting gen taf script for test_p20
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 92/4500 [00:00<00:04, 886.50it/s]  4%|▍         | 181/4500 [00:00<00:06, 652.04it/s]  6%|▌         | 250/4500 [00:00<00:06, 633.07it/s]  7%|▋         | 315/4500 [00:00<00:06, 619.28it/s]  8%|▊         | 378/4500 [00:00<00:09, 434.30it/s] 10%|▉         | 428/4500 [00:00<00:09, 431.71it/s] 11%|█         | 476/4500 [00:00<00:09, 436.53it/s] 12%|█▏        | 544/4500 [00:01<00:07, 499.40it/s] 13%|█▎        | 598/4500 [00:01<00:07, 492.43it/s] 14%|█▍        | 650/4500 [00:01<00:08, 447.04it/s] 15%|█▌        | 697/4500 [00:01<00:08, 451.04it/s] 17%|█▋        | 744/4500 [00:01<00:09, 412.79it/s] 17%|█▋        | 787/4500 [00:01<00:10, 359.56it/s] 19%|█▊        | 835/4500 [00:01<00:09, 386.41it/s] 20%|█▉        | 891/4500 [00:01<00:08, 429.85it/s] 21%|██        | 939/4500 [00:02<00:08, 441.54it/s] 22%|██▏       | 988/4500 [00:02<00:07, 449.14it/s] 23%|██▎       | 1035/4500 [00:02<00:08, 420.98it/s] 24%|██▍       | 1101/4500 [00:02<00:07, 480.89it/s] 27%|██▋       | 1195/4500 [00:02<00:05, 607.36it/s] 29%|██▉       | 1323/4500 [00:02<00:04, 791.00it/s] 31%|███       | 1405/4500 [00:02<00:03, 783.36it/s] 33%|███▎      | 1485/4500 [00:02<00:04, 685.06it/s] 35%|███▌      | 1576/4500 [00:02<00:03, 741.98it/s] 37%|███▋      | 1654/4500 [00:03<00:04, 682.47it/s] 38%|███▊      | 1725/4500 [00:03<00:04, 676.28it/s] 40%|███▉      | 1795/4500 [00:03<00:04, 612.13it/s] 42%|████▏     | 1909/4500 [00:03<00:03, 746.72it/s] 45%|████▍     | 2019/4500 [00:03<00:02, 835.44it/s] 47%|████▋     | 2107/4500 [00:03<00:03, 761.79it/s] 49%|████▊     | 2192/4500 [00:03<00:02, 782.05it/s] 51%|█████     | 2273/4500 [00:03<00:03, 681.63it/s] 52%|█████▏    | 2346/4500 [00:04<00:03, 664.95it/s] 54%|█████▎    | 2416/4500 [00:04<00:03, 660.40it/s] 56%|█████▌    | 2505/4500 [00:04<00:02, 710.59it/s] 58%|█████▊    | 2599/4500 [00:04<00:02, 762.75it/s] 60%|█████▉    | 2678/4500 [00:04<00:02, 753.60it/s] 61%|██████▏   | 2767/4500 [00:04<00:02, 784.01it/s] 64%|██████▎   | 2864/4500 [00:04<00:01, 826.77it/s] 66%|██████▌   | 2948/4500 [00:04<00:01, 824.19it/s] 67%|██████▋   | 3031/4500 [00:04<00:01, 811.98it/s] 69%|██████▉   | 3113/4500 [00:04<00:01, 776.31it/s] 71%|███████   | 3192/4500 [00:05<00:01, 747.66it/s] 73%|███████▎  | 3295/4500 [00:05<00:01, 805.32it/s] 75%|███████▌  | 3376/4500 [00:05<00:01, 778.16it/s] 77%|███████▋  | 3455/4500 [00:05<00:01, 702.09it/s] 78%|███████▊  | 3527/4500 [00:05<00:01, 606.04it/s] 80%|███████▉  | 3591/4500 [00:05<00:01, 489.02it/s] 83%|████████▎ | 3717/4500 [00:05<00:01, 651.43it/s] 85%|████████▍ | 3807/4500 [00:06<00:00, 707.86it/s] 87%|████████▋ | 3921/4500 [00:06<00:00, 810.69it/s] 91%|█████████ | 4077/4500 [00:06<00:00, 990.27it/s] 93%|█████████▎| 4183/4500 [00:06<00:00, 908.53it/s] 95%|█████████▌| 4280/4500 [00:06<00:00, 895.62it/s] 97%|█████████▋| 4374/4500 [00:06<00:00, 808.30it/s] 99%|█████████▉| 4471/4500 [00:06<00:00, 838.52it/s]100%|██████████| 4500/4500 [00:06<00:00, 666.05it/s]
test_p20 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p20
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p20.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.27it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.10it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.18it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.68it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p20_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p20_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p20_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p20_Holmes_probs.npy
{'Accuracy': 0.636, 'Precision': 0.741, 'Recall': 0.636, 'F1-score': 0.6452}
starting gen taf script for test_p21
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 66/4500 [00:00<00:07, 633.29it/s]  3%|▎         | 130/4500 [00:00<00:07, 568.00it/s]  4%|▍         | 188/4500 [00:00<00:07, 566.33it/s]  6%|▌         | 251/4500 [00:00<00:07, 587.22it/s]  7%|▋         | 310/4500 [00:00<00:08, 506.16it/s]  8%|▊         | 363/4500 [00:00<00:10, 395.86it/s]  9%|▉         | 407/4500 [00:00<00:10, 401.55it/s] 10%|█         | 450/4500 [00:01<00:11, 343.20it/s] 11%|█         | 488/4500 [00:01<00:12, 329.36it/s] 12%|█▏        | 528/4500 [00:01<00:11, 346.19it/s] 13%|█▎        | 565/4500 [00:01<00:11, 343.94it/s] 13%|█▎        | 601/4500 [00:01<00:11, 347.16it/s] 14%|█▍        | 650/4500 [00:01<00:09, 385.57it/s] 16%|█▌        | 702/4500 [00:01<00:08, 422.27it/s] 17%|█▋        | 749/4500 [00:01<00:08, 430.84it/s] 18%|█▊        | 809/4500 [00:01<00:07, 476.50it/s] 20%|█▉        | 882/4500 [00:02<00:06, 543.42it/s] 22%|██▏       | 972/4500 [00:02<00:05, 636.78it/s] 24%|██▍       | 1093/4500 [00:02<00:04, 799.24it/s] 27%|██▋       | 1211/4500 [00:02<00:03, 908.87it/s] 29%|██▉       | 1311/4500 [00:02<00:03, 933.74it/s] 31%|███       | 1405/4500 [00:02<00:03, 881.33it/s] 33%|███▎      | 1495/4500 [00:02<00:03, 853.50it/s] 35%|███▌      | 1588/4500 [00:02<00:03, 874.43it/s] 37%|███▋      | 1677/4500 [00:02<00:04, 691.07it/s] 39%|███▉      | 1762/4500 [00:03<00:03, 724.68it/s] 41%|████▏     | 1866/4500 [00:03<00:03, 800.78it/s] 44%|████▍     | 1978/4500 [00:03<00:02, 885.04it/s] 46%|████▌     | 2077/4500 [00:03<00:02, 899.49it/s] 48%|████▊     | 2175/4500 [00:03<00:02, 918.96it/s] 50%|█████     | 2270/4500 [00:03<00:02, 883.52it/s] 52%|█████▏    | 2361/4500 [00:03<00:02, 750.77it/s] 54%|█████▍    | 2441/4500 [00:03<00:02, 757.19it/s] 57%|█████▋    | 2543/4500 [00:03<00:02, 824.76it/s] 58%|█████▊    | 2629/4500 [00:04<00:02, 801.77it/s] 61%|██████    | 2724/4500 [00:04<00:02, 834.31it/s] 63%|██████▎   | 2832/4500 [00:04<00:01, 901.11it/s] 65%|██████▍   | 2924/4500 [00:04<00:01, 846.83it/s] 67%|██████▋   | 3023/4500 [00:04<00:01, 867.82it/s] 69%|██████▉   | 3112/4500 [00:04<00:01, 850.60it/s] 71%|███████   | 3198/4500 [00:04<00:01, 770.67it/s] 73%|███████▎  | 3298/4500 [00:04<00:01, 808.10it/s] 75%|███████▌  | 3381/4500 [00:04<00:01, 763.62it/s] 77%|███████▋  | 3459/4500 [00:05<00:01, 754.04it/s] 79%|███████▊  | 3536/4500 [00:05<00:01, 600.83it/s] 80%|████████  | 3602/4500 [00:05<00:01, 451.94it/s] 83%|████████▎ | 3721/4500 [00:05<00:01, 592.46it/s] 85%|████████▌ | 3837/4500 [00:05<00:00, 712.81it/s] 88%|████████▊ | 3949/4500 [00:05<00:00, 808.61it/s] 90%|████████▉ | 4042/4500 [00:05<00:00, 760.58it/s] 92%|█████████▏| 4141/4500 [00:06<00:00, 796.61it/s] 94%|█████████▍| 4227/4500 [00:06<00:00, 771.99it/s] 97%|█████████▋| 4349/4500 [00:06<00:00, 887.14it/s] 99%|█████████▉| 4477/4500 [00:06<00:00, 984.45it/s]100%|██████████| 4500/4500 [00:06<00:00, 700.29it/s]
test_p21 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p21
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p21.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.02it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.08it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.27it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.39it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.94it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p21_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p21_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p21_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p21_Holmes_probs.npy
{'Accuracy': 0.6653, 'Precision': 0.7542, 'Recall': 0.6653, 'F1-score': 0.6731}
starting gen taf script for test_p22
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 46/4500 [00:00<00:09, 454.01it/s]  2%|▏         | 96/4500 [00:00<00:09, 473.49it/s]  3%|▎         | 144/4500 [00:00<00:09, 443.62it/s]  4%|▍         | 189/4500 [00:00<00:09, 445.48it/s]  6%|▌         | 249/4500 [00:00<00:08, 486.14it/s]  7%|▋         | 310/4500 [00:00<00:08, 515.43it/s]  8%|▊         | 362/4500 [00:00<00:09, 441.57it/s]  9%|▉         | 408/4500 [00:00<00:11, 370.17it/s] 11%|█         | 477/4500 [00:01<00:09, 443.61it/s] 12%|█▏        | 531/4500 [00:01<00:08, 465.02it/s] 13%|█▎        | 587/4500 [00:01<00:08, 485.52it/s] 14%|█▍        | 640/4500 [00:01<00:07, 496.70it/s] 16%|█▌        | 720/4500 [00:01<00:06, 568.57it/s] 18%|█▊        | 830/4500 [00:01<00:05, 715.72it/s] 21%|██        | 943/4500 [00:01<00:04, 826.07it/s] 23%|██▎       | 1032/4500 [00:01<00:04, 844.10it/s] 25%|██▌       | 1136/4500 [00:01<00:03, 900.84it/s] 28%|██▊       | 1248/4500 [00:01<00:03, 954.81it/s] 30%|███       | 1358/4500 [00:02<00:03, 996.08it/s] 32%|███▏      | 1459/4500 [00:02<00:03, 909.63it/s] 34%|███▍      | 1552/4500 [00:02<00:03, 787.96it/s] 36%|███▋      | 1635/4500 [00:02<00:03, 729.82it/s] 38%|███▊      | 1711/4500 [00:02<00:04, 645.13it/s] 40%|████      | 1808/4500 [00:02<00:03, 722.20it/s] 42%|████▏     | 1908/4500 [00:02<00:03, 791.66it/s] 45%|████▍     | 2018/4500 [00:02<00:02, 873.22it/s] 47%|████▋     | 2135/4500 [00:03<00:02, 954.47it/s] 50%|████▉     | 2234/4500 [00:03<00:02, 865.98it/s] 52%|█████▏    | 2325/4500 [00:03<00:02, 806.31it/s] 54%|█████▎    | 2409/4500 [00:03<00:02, 754.07it/s] 56%|█████▌    | 2528/4500 [00:03<00:02, 864.76it/s] 58%|█████▊    | 2619/4500 [00:03<00:02, 856.57it/s] 60%|██████    | 2708/4500 [00:03<00:02, 798.61it/s] 62%|██████▏   | 2800/4500 [00:03<00:02, 830.20it/s] 64%|██████▍   | 2893/4500 [00:04<00:01, 844.21it/s] 66%|██████▌   | 2979/4500 [00:04<00:01, 847.59it/s] 68%|██████▊   | 3065/4500 [00:04<00:01, 786.25it/s] 70%|██████▉   | 3146/4500 [00:04<00:01, 785.05it/s] 72%|███████▏  | 3226/4500 [00:04<00:01, 732.47it/s] 74%|███████▎  | 3315/4500 [00:04<00:01, 765.12it/s] 75%|███████▌  | 3393/4500 [00:04<00:01, 720.62it/s] 77%|███████▋  | 3467/4500 [00:04<00:01, 721.97it/s] 79%|███████▊  | 3540/4500 [00:05<00:01, 541.61it/s] 80%|████████  | 3601/4500 [00:05<00:01, 468.07it/s] 82%|████████▏ | 3687/4500 [00:05<00:01, 546.11it/s] 83%|████████▎ | 3756/4500 [00:05<00:01, 578.84it/s] 86%|████████▌ | 3874/4500 [00:05<00:00, 716.51it/s] 88%|████████▊ | 3968/4500 [00:05<00:00, 773.92it/s] 91%|█████████ | 4080/4500 [00:05<00:00, 864.16it/s] 93%|█████████▎| 4171/4500 [00:05<00:00, 771.82it/s] 95%|█████████▍| 4253/4500 [00:05<00:00, 773.99it/s] 96%|█████████▋| 4334/4500 [00:06<00:00, 753.50it/s] 98%|█████████▊| 4419/4500 [00:06<00:00, 767.25it/s]100%|██████████| 4500/4500 [00:06<00:00, 716.82it/s]
test_p22 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p22
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p22.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.70it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.88it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.11it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.50it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p22_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p22_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p22_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p22_Holmes_probs.npy
{'Accuracy': 0.692, 'Precision': 0.7619, 'Recall': 0.692, 'F1-score': 0.6976}
starting gen taf script for test_p23
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 96/4500 [00:00<00:04, 934.81it/s]  4%|▍         | 190/4500 [00:00<00:06, 654.00it/s]  6%|▌         | 261/4500 [00:00<00:06, 613.60it/s]  7%|▋         | 325/4500 [00:00<00:08, 509.46it/s]  8%|▊         | 379/4500 [00:00<00:10, 382.67it/s]  9%|▉         | 427/4500 [00:00<00:10, 403.37it/s] 11%|█         | 488/4500 [00:01<00:08, 449.01it/s] 12%|█▏        | 537/4500 [00:01<00:08, 443.97it/s] 13%|█▎        | 585/4500 [00:01<00:09, 429.24it/s] 14%|█▍        | 640/4500 [00:01<00:08, 460.38it/s] 15%|█▌        | 688/4500 [00:01<00:10, 375.02it/s] 16%|█▌        | 729/4500 [00:01<00:12, 304.96it/s] 17%|█▋        | 770/4500 [00:01<00:11, 326.34it/s] 18%|█▊        | 825/4500 [00:01<00:09, 376.73it/s] 19%|█▉        | 874/4500 [00:02<00:09, 397.44it/s] 20%|██        | 917/4500 [00:02<00:09, 385.68it/s] 21%|██▏       | 961/4500 [00:02<00:08, 397.29it/s] 23%|██▎       | 1018/4500 [00:02<00:07, 442.14it/s] 24%|██▎       | 1064/4500 [00:02<00:07, 445.39it/s] 25%|██▍       | 1118/4500 [00:02<00:07, 468.68it/s] 26%|██▋       | 1192/4500 [00:02<00:06, 543.43it/s] 28%|██▊       | 1273/4500 [00:02<00:05, 614.47it/s] 30%|███       | 1354/4500 [00:02<00:04, 667.22it/s] 32%|███▏      | 1442/4500 [00:02<00:04, 711.71it/s] 34%|███▎      | 1514/4500 [00:03<00:04, 645.31it/s] 35%|███▌      | 1591/4500 [00:03<00:04, 677.56it/s] 37%|███▋      | 1660/4500 [00:03<00:04, 590.10it/s] 39%|███▊      | 1741/4500 [00:03<00:04, 641.86it/s] 40%|████      | 1808/4500 [00:03<00:04, 580.41it/s] 42%|████▏     | 1885/4500 [00:03<00:04, 623.30it/s] 45%|████▍     | 2009/4500 [00:03<00:03, 777.51it/s] 47%|████▋     | 2106/4500 [00:03<00:02, 825.06it/s] 49%|████▊     | 2192/4500 [00:04<00:02, 792.93it/s] 51%|█████     | 2274/4500 [00:04<00:02, 750.89it/s] 52%|█████▏    | 2351/4500 [00:04<00:03, 711.66it/s] 54%|█████▍    | 2424/4500 [00:04<00:03, 665.74it/s] 56%|█████▌    | 2516/4500 [00:04<00:02, 731.93it/s] 58%|█████▊    | 2612/4500 [00:04<00:02, 791.99it/s] 60%|█████▉    | 2697/4500 [00:04<00:02, 803.03it/s] 62%|██████▏   | 2792/4500 [00:04<00:02, 842.78it/s] 64%|██████▍   | 2878/4500 [00:04<00:02, 788.87it/s] 66%|██████▌   | 2970/4500 [00:05<00:01, 818.66it/s] 68%|██████▊   | 3054/4500 [00:05<00:01, 791.78it/s] 70%|██████▉   | 3135/4500 [00:05<00:01, 689.14it/s] 71%|███████▏  | 3213/4500 [00:05<00:01, 710.81it/s] 73%|███████▎  | 3293/4500 [00:05<00:01, 732.49it/s] 75%|███████▍  | 3369/4500 [00:05<00:01, 699.34it/s] 76%|███████▋  | 3441/4500 [00:05<00:01, 632.48it/s] 78%|███████▊  | 3507/4500 [00:05<00:01, 563.00it/s] 79%|███████▉  | 3566/4500 [00:06<00:02, 420.48it/s] 81%|████████  | 3627/4500 [00:06<00:01, 457.03it/s] 82%|████████▏ | 3706/4500 [00:06<00:01, 529.89it/s] 84%|████████▍ | 3791/4500 [00:06<00:01, 599.61it/s] 86%|████████▌ | 3873/4500 [00:06<00:00, 655.37it/s] 88%|████████▊ | 3948/4500 [00:06<00:00, 680.43it/s] 90%|████████▉ | 4048/4500 [00:06<00:00, 762.32it/s] 92%|█████████▏| 4128/4500 [00:06<00:00, 680.49it/s] 93%|█████████▎| 4200/4500 [00:07<00:00, 654.31it/s] 95%|█████████▌| 4286/4500 [00:07<00:00, 699.37it/s] 97%|█████████▋| 4359/4500 [00:07<00:00, 683.39it/s] 99%|█████████▉| 4445/4500 [00:07<00:00, 723.94it/s]100%|██████████| 4500/4500 [00:07<00:00, 605.23it/s]
test_p23 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p23
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p23.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.11s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.34it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.21it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.22it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.75it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p23_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p23_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p23_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p23_Holmes_probs.npy
{'Accuracy': 0.7218, 'Precision': 0.7771, 'Recall': 0.7218, 'F1-score': 0.7246}
starting gen taf script for test_p24
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 106/4500 [00:00<00:04, 1019.34it/s]  5%|▍         | 208/4500 [00:00<00:06, 657.90it/s]   6%|▌         | 281/4500 [00:00<00:06, 654.39it/s]  8%|▊         | 351/4500 [00:00<00:09, 450.41it/s]  9%|▉         | 404/4500 [00:00<00:10, 374.74it/s] 10%|█         | 456/4500 [00:00<00:09, 404.45it/s] 11%|█         | 505/4500 [00:01<00:09, 420.55it/s] 13%|█▎        | 566/4500 [00:01<00:08, 466.54it/s] 14%|█▍        | 619/4500 [00:01<00:08, 479.37it/s] 15%|█▌        | 675/4500 [00:01<00:07, 499.97it/s] 16%|█▌        | 728/4500 [00:01<00:07, 502.30it/s] 17%|█▋        | 780/4500 [00:01<00:08, 435.52it/s] 19%|█▊        | 833/4500 [00:01<00:08, 446.62it/s] 20%|██        | 922/4500 [00:01<00:06, 558.63it/s] 23%|██▎       | 1037/4500 [00:01<00:04, 718.79it/s] 26%|██▌       | 1170/4500 [00:02<00:03, 883.10it/s] 28%|██▊       | 1268/4500 [00:02<00:03, 905.43it/s] 30%|███       | 1364/4500 [00:02<00:03, 917.09it/s] 32%|███▏      | 1458/4500 [00:02<00:03, 831.06it/s] 34%|███▍      | 1544/4500 [00:02<00:04, 687.86it/s] 36%|███▌      | 1624/4500 [00:02<00:04, 698.91it/s] 38%|███▊      | 1698/4500 [00:02<00:04, 617.67it/s] 40%|███▉      | 1780/4500 [00:02<00:04, 662.70it/s] 42%|████▏     | 1893/4500 [00:03<00:03, 779.81it/s] 44%|████▍     | 1982/4500 [00:03<00:03, 805.82it/s] 46%|████▌     | 2074/4500 [00:03<00:02, 828.15it/s] 48%|████▊     | 2167/4500 [00:03<00:02, 852.85it/s] 50%|█████     | 2255/4500 [00:03<00:03, 678.53it/s] 52%|█████▏    | 2330/4500 [00:03<00:03, 643.79it/s] 53%|█████▎    | 2400/4500 [00:03<00:03, 621.22it/s] 55%|█████▌    | 2495/4500 [00:03<00:02, 699.70it/s] 57%|█████▋    | 2587/4500 [00:04<00:02, 756.68it/s] 59%|█████▉    | 2673/4500 [00:04<00:02, 766.57it/s] 62%|██████▏   | 2770/4500 [00:04<00:02, 808.09it/s] 64%|██████▎   | 2867/4500 [00:04<00:01, 841.03it/s] 66%|██████▋   | 2992/4500 [00:04<00:01, 956.08it/s] 69%|██████▊   | 3090/4500 [00:04<00:01, 906.52it/s] 71%|███████   | 3183/4500 [00:04<00:01, 823.17it/s] 73%|███████▎  | 3294/4500 [00:04<00:01, 885.08it/s] 75%|███████▌  | 3385/4500 [00:04<00:01, 749.62it/s] 77%|███████▋  | 3465/4500 [00:05<00:01, 693.91it/s] 79%|███████▊  | 3538/4500 [00:05<00:01, 573.74it/s] 80%|████████  | 3601/4500 [00:05<00:02, 424.18it/s] 82%|████████▏ | 3699/4500 [00:05<00:01, 525.54it/s] 84%|████████▍ | 3778/4500 [00:05<00:01, 578.88it/s] 86%|████████▌ | 3876/4500 [00:05<00:00, 670.59it/s] 89%|████████▊ | 3985/4500 [00:05<00:00, 766.31it/s] 90%|█████████ | 4071/4500 [00:06<00:00, 761.61it/s] 92%|█████████▏| 4154/4500 [00:06<00:00, 693.05it/s] 94%|█████████▍| 4229/4500 [00:06<00:00, 664.38it/s] 96%|█████████▋| 4336/4500 [00:06<00:00, 764.85it/s] 98%|█████████▊| 4417/4500 [00:06<00:00, 774.07it/s]100%|██████████| 4500/4500 [00:06<00:00, 677.74it/s]
test_p24 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p24
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p24.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.26it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.07it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.04it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.51it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p24_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p24_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p24_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p24_Holmes_probs.npy
{'Accuracy': 0.754, 'Precision': 0.7992, 'Recall': 0.754, 'F1-score': 0.7556}
starting gen taf script for test_p25
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 58/4500 [00:00<00:08, 552.39it/s]  3%|▎         | 115/4500 [00:00<00:07, 562.20it/s]  4%|▍         | 178/4500 [00:00<00:07, 592.14it/s]  5%|▌         | 246/4500 [00:00<00:06, 622.73it/s]  7%|▋         | 309/4500 [00:00<00:07, 598.67it/s]  8%|▊         | 370/4500 [00:00<00:09, 424.64it/s]  9%|▉         | 419/4500 [00:00<00:11, 362.48it/s] 11%|█         | 476/4500 [00:01<00:09, 409.24it/s] 12%|█▏        | 523/4500 [00:01<00:09, 414.53it/s] 13%|█▎        | 572/4500 [00:01<00:09, 433.67it/s] 14%|█▍        | 639/4500 [00:01<00:07, 489.01it/s] 15%|█▌        | 695/4500 [00:01<00:07, 502.12it/s] 17%|█▋        | 762/4500 [00:01<00:06, 536.05it/s] 20%|█▉        | 881/4500 [00:01<00:05, 713.06it/s] 22%|██▏       | 997/4500 [00:01<00:04, 829.56it/s] 24%|██▍       | 1084/4500 [00:01<00:04, 840.99it/s] 27%|██▋       | 1201/4500 [00:01<00:03, 936.34it/s] 29%|██▉       | 1305/4500 [00:02<00:03, 962.76it/s] 31%|███       | 1403/4500 [00:02<00:03, 843.12it/s] 33%|███▎      | 1491/4500 [00:02<00:04, 711.20it/s] 36%|███▌      | 1598/4500 [00:02<00:03, 794.95it/s] 37%|███▋      | 1684/4500 [00:02<00:04, 677.27it/s] 39%|███▉      | 1761/4500 [00:02<00:04, 684.08it/s] 41%|████▏     | 1866/4500 [00:02<00:03, 768.08it/s] 43%|████▎     | 1948/4500 [00:02<00:03, 764.57it/s] 46%|████▌     | 2068/4500 [00:03<00:02, 873.73it/s] 48%|████▊     | 2168/4500 [00:03<00:02, 892.12it/s] 50%|█████     | 2260/4500 [00:03<00:02, 758.45it/s] 52%|█████▏    | 2341/4500 [00:03<00:02, 721.58it/s] 54%|█████▎    | 2417/4500 [00:03<00:03, 602.03it/s] 56%|█████▌    | 2510/4500 [00:03<00:02, 675.30it/s] 57%|█████▋    | 2584/4500 [00:03<00:02, 689.56it/s] 59%|█████▉    | 2658/4500 [00:03<00:02, 680.99it/s] 61%|██████    | 2730/4500 [00:04<00:02, 681.53it/s] 62%|██████▏   | 2801/4500 [00:04<00:02, 681.81it/s] 64%|██████▍   | 2884/4500 [00:04<00:02, 718.38it/s] 66%|██████▌   | 2964/4500 [00:04<00:02, 734.66it/s] 68%|██████▊   | 3039/4500 [00:04<00:02, 726.66it/s] 69%|██████▉   | 3113/4500 [00:04<00:02, 636.12it/s] 71%|███████   | 3199/4500 [00:04<00:01, 680.15it/s] 73%|███████▎  | 3280/4500 [00:04<00:01, 713.59it/s] 75%|███████▍  | 3354/4500 [00:04<00:01, 693.01it/s] 76%|███████▌  | 3425/4500 [00:05<00:01, 659.34it/s] 78%|███████▊  | 3501/4500 [00:05<00:01, 617.44it/s] 79%|███████▉  | 3565/4500 [00:05<00:02, 436.50it/s] 80%|████████  | 3617/4500 [00:05<00:02, 399.06it/s] 82%|████████▏ | 3704/4500 [00:05<00:01, 494.09it/s] 85%|████████▍ | 3808/4500 [00:05<00:01, 616.55it/s] 86%|████████▋ | 3884/4500 [00:05<00:00, 644.15it/s] 89%|████████▉ | 3995/4500 [00:06<00:00, 738.84it/s] 91%|█████████ | 4090/4500 [00:06<00:00, 784.70it/s] 93%|█████████▎| 4173/4500 [00:06<00:00, 710.35it/s] 94%|█████████▍| 4249/4500 [00:06<00:00, 700.64it/s] 96%|█████████▌| 4329/4500 [00:06<00:00, 707.03it/s] 98%|█████████▊| 4402/4500 [00:06<00:00, 675.84it/s]100%|██████████| 4500/4500 [00:06<00:00, 665.70it/s]
test_p25 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p25
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p25.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.07s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.61it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.58it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.75it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.92it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p25_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p25_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p25_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p25_Holmes_probs.npy
{'Accuracy': 0.7776, 'Precision': 0.8153, 'Recall': 0.7776, 'F1-score': 0.7776}
starting gen taf script for test_p26
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 67/4500 [00:00<00:06, 663.15it/s]  3%|▎         | 134/4500 [00:00<00:08, 529.09it/s]  5%|▍         | 205/4500 [00:00<00:07, 598.81it/s]  6%|▌         | 274/4500 [00:00<00:06, 620.03it/s]  8%|▊         | 338/4500 [00:00<00:08, 491.23it/s]  9%|▊         | 392/4500 [00:00<00:10, 400.34it/s] 10%|▉         | 443/4500 [00:00<00:09, 424.98it/s] 11%|█         | 499/4500 [00:01<00:08, 454.92it/s] 13%|█▎        | 564/4500 [00:01<00:07, 503.37it/s] 14%|█▍        | 625/4500 [00:01<00:07, 527.43it/s] 15%|█▌        | 681/4500 [00:01<00:07, 520.67it/s] 17%|█▋        | 781/4500 [00:01<00:05, 653.00it/s] 20%|██        | 912/4500 [00:01<00:04, 837.48it/s] 23%|██▎       | 1025/4500 [00:01<00:03, 919.60it/s] 25%|██▌       | 1131/4500 [00:01<00:03, 960.09it/s] 29%|██▉       | 1302/4500 [00:01<00:02, 1177.82it/s] 32%|███▏      | 1422/4500 [00:01<00:02, 1042.82it/s] 34%|███▍      | 1531/4500 [00:02<00:03, 785.79it/s]  36%|███▌      | 1622/4500 [00:02<00:03, 773.04it/s] 38%|███▊      | 1708/4500 [00:02<00:04, 637.56it/s] 40%|███▉      | 1784/4500 [00:02<00:04, 659.91it/s] 41%|████▏     | 1858/4500 [00:02<00:03, 670.53it/s] 44%|████▍     | 1970/4500 [00:02<00:03, 772.64it/s] 46%|████▌     | 2060/4500 [00:02<00:03, 804.66it/s] 48%|████▊     | 2145/4500 [00:03<00:02, 812.09it/s] 50%|████▉     | 2230/4500 [00:03<00:02, 791.83it/s] 51%|█████▏    | 2312/4500 [00:03<00:03, 671.43it/s] 53%|█████▎    | 2384/4500 [00:03<00:03, 559.05it/s] 56%|█████▌    | 2498/4500 [00:03<00:02, 688.00it/s] 57%|█████▋    | 2587/4500 [00:03<00:02, 719.11it/s] 59%|█████▉    | 2665/4500 [00:03<00:02, 723.38it/s] 61%|██████    | 2746/4500 [00:03<00:02, 736.18it/s] 63%|██████▎   | 2842/4500 [00:04<00:02, 781.99it/s] 65%|██████▍   | 2923/4500 [00:04<00:02, 767.62it/s] 67%|██████▋   | 3009/4500 [00:04<00:01, 775.41it/s] 69%|██████▊   | 3088/4500 [00:04<00:01, 763.83it/s] 70%|███████   | 3166/4500 [00:04<00:01, 672.27it/s] 72%|███████▏  | 3236/4500 [00:04<00:01, 638.60it/s] 73%|███████▎  | 3306/4500 [00:04<00:01, 650.13it/s] 75%|███████▍  | 3373/4500 [00:04<00:01, 622.74it/s] 76%|███████▋  | 3439/4500 [00:05<00:01, 620.91it/s] 78%|███████▊  | 3502/4500 [00:05<00:01, 593.21it/s] 79%|███████▉  | 3562/4500 [00:05<00:02, 430.07it/s] 80%|████████  | 3612/4500 [00:05<00:02, 402.39it/s] 82%|████████▏ | 3685/4500 [00:05<00:01, 472.48it/s] 84%|████████▎ | 3766/4500 [00:05<00:01, 552.84it/s] 86%|████████▌ | 3854/4500 [00:05<00:01, 631.61it/s] 89%|████████▊ | 3983/4500 [00:05<00:00, 795.26it/s] 90%|█████████ | 4068/4500 [00:06<00:00, 745.68it/s] 92%|█████████▏| 4147/4500 [00:06<00:00, 702.80it/s] 94%|█████████▍| 4221/4500 [00:06<00:00, 693.54it/s] 95%|█████████▌| 4297/4500 [00:06<00:00, 701.62it/s] 97%|█████████▋| 4369/4500 [00:06<00:00, 635.58it/s]100%|██████████| 4500/4500 [00:06<00:00, 678.67it/s]
test_p26 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p26
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p26.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:12,  1.32it/s]evaluating model with Holmes:  11%|█         | 2/18 [00:01<00:07,  2.13it/s]evaluating model with Holmes:  39%|███▉      | 7/18 [00:01<00:01,  9.21it/s]evaluating model with Holmes:  67%|██████▋   | 12/18 [00:01<00:00, 16.07it/s]evaluating model with Holmes:  94%|█████████▍| 17/18 [00:01<00:00, 22.58it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.82it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p26_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p26_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p26_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p26_Holmes_probs.npy
{'Accuracy': 0.8027, 'Precision': 0.8329, 'Recall': 0.8027, 'F1-score': 0.8012}
starting gen taf script for test_p27
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 73/4500 [00:00<00:06, 698.63it/s]  3%|▎         | 143/4500 [00:00<00:07, 550.58it/s]  4%|▍         | 200/4500 [00:00<00:08, 506.02it/s]  6%|▌         | 252/4500 [00:00<00:08, 478.37it/s]  7%|▋         | 301/4500 [00:00<00:08, 479.04it/s]  8%|▊         | 350/4500 [00:00<00:10, 379.55it/s]  9%|▊         | 391/4500 [00:00<00:10, 373.69it/s] 10%|▉         | 438/4500 [00:01<00:10, 391.81it/s] 11%|█         | 487/4500 [00:01<00:09, 416.67it/s] 12%|█▏        | 540/4500 [00:01<00:08, 441.73it/s] 13%|█▎        | 586/4500 [00:01<00:08, 443.15it/s] 14%|█▍        | 632/4500 [00:01<00:09, 419.06it/s] 15%|█▌        | 688/4500 [00:01<00:08, 455.24it/s] 16%|█▋        | 742/4500 [00:01<00:07, 478.98it/s] 18%|█▊        | 791/4500 [00:01<00:08, 445.25it/s] 19%|█▊        | 843/4500 [00:01<00:07, 461.52it/s] 20%|█▉        | 895/4500 [00:01<00:07, 477.25it/s] 22%|██▏       | 970/4500 [00:02<00:06, 547.00it/s] 23%|██▎       | 1049/4500 [00:02<00:05, 615.07it/s] 25%|██▌       | 1129/4500 [00:02<00:05, 664.23it/s] 28%|██▊       | 1255/4500 [00:02<00:03, 836.14it/s] 30%|██▉       | 1342/4500 [00:02<00:03, 842.43it/s] 32%|███▏      | 1427/4500 [00:02<00:03, 783.96it/s] 33%|███▎      | 1507/4500 [00:02<00:04, 676.23it/s] 35%|███▌      | 1588/4500 [00:02<00:04, 705.13it/s] 37%|███▋      | 1662/4500 [00:03<00:04, 599.27it/s] 38%|███▊      | 1727/4500 [00:03<00:04, 588.04it/s] 40%|████      | 1812/4500 [00:03<00:04, 653.05it/s] 42%|████▏     | 1881/4500 [00:03<00:04, 653.39it/s] 44%|████▍     | 1971/4500 [00:03<00:03, 716.59it/s] 46%|████▋     | 2086/4500 [00:03<00:02, 826.95it/s] 48%|████▊     | 2175/4500 [00:03<00:02, 836.19it/s] 50%|█████     | 2261/4500 [00:03<00:02, 760.31it/s] 52%|█████▏    | 2340/4500 [00:03<00:03, 671.82it/s] 54%|█████▎    | 2411/4500 [00:04<00:03, 624.18it/s] 56%|█████▌    | 2513/4500 [00:04<00:02, 714.26it/s] 58%|█████▊    | 2588/4500 [00:04<00:02, 719.79it/s] 59%|█████▉    | 2663/4500 [00:04<00:02, 712.55it/s] 62%|██████▏   | 2786/4500 [00:04<00:02, 852.54it/s] 64%|██████▍   | 2874/4500 [00:04<00:01, 851.89it/s] 66%|██████▌   | 2961/4500 [00:04<00:01, 782.00it/s] 68%|██████▊   | 3042/4500 [00:04<00:02, 728.41it/s] 70%|██████▉   | 3131/4500 [00:04<00:01, 755.69it/s] 71%|███████▏  | 3209/4500 [00:05<00:01, 662.65it/s] 74%|███████▎  | 3309/4500 [00:05<00:01, 736.65it/s] 75%|███████▌  | 3386/4500 [00:05<00:01, 641.30it/s] 77%|███████▋  | 3454/4500 [00:05<00:01, 649.03it/s] 78%|███████▊  | 3522/4500 [00:05<00:01, 518.71it/s] 80%|███████▉  | 3580/4500 [00:05<00:02, 430.33it/s] 81%|████████  | 3629/4500 [00:06<00:02, 427.34it/s] 82%|████████▏ | 3697/4500 [00:06<00:01, 472.11it/s] 84%|████████▎ | 3766/4500 [00:06<00:01, 522.19it/s] 85%|████████▌ | 3847/4500 [00:06<00:01, 591.82it/s] 88%|████████▊ | 3943/4500 [00:06<00:00, 681.54it/s] 90%|████████▉ | 4031/4500 [00:06<00:00, 729.97it/s] 91%|█████████▏| 4108/4500 [00:06<00:00, 734.51it/s] 93%|█████████▎| 4184/4500 [00:06<00:00, 715.16it/s] 95%|█████████▍| 4269/4500 [00:06<00:00, 752.80it/s] 97%|█████████▋| 4346/4500 [00:07<00:00, 686.60it/s] 99%|█████████▊| 4440/4500 [00:07<00:00, 744.70it/s]100%|██████████| 4500/4500 [00:07<00:00, 627.82it/s]
test_p27 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p27
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p27.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:14,  1.16it/s]evaluating model with Holmes:  28%|██▊       | 5/18 [00:00<00:01,  6.50it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 13.43it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 20.15it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.94it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p27_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p27_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p27_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p27_Holmes_probs.npy
{'Accuracy': 0.8236, 'Precision': 0.8474, 'Recall': 0.8236, 'F1-score': 0.8215}
starting gen taf script for test_p28
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 72/4500 [00:00<00:06, 671.81it/s]  3%|▎         | 140/4500 [00:00<00:08, 539.55it/s]  5%|▍         | 208/4500 [00:00<00:07, 593.62it/s]  6%|▌         | 269/4500 [00:00<00:07, 596.33it/s]  7%|▋         | 330/4500 [00:00<00:09, 446.35it/s]  8%|▊         | 380/4500 [00:00<00:12, 331.88it/s]  9%|▉         | 420/4500 [00:01<00:12, 338.93it/s] 11%|█         | 486/4500 [00:01<00:09, 411.18it/s] 12%|█▏        | 537/4500 [00:01<00:09, 433.60it/s] 13%|█▎        | 596/4500 [00:01<00:08, 474.01it/s] 14%|█▍        | 648/4500 [00:01<00:08, 476.44it/s] 16%|█▌        | 706/4500 [00:01<00:07, 500.60it/s] 17%|█▋        | 759/4500 [00:01<00:07, 485.40it/s] 18%|█▊        | 810/4500 [00:01<00:07, 477.95it/s] 19%|█▉        | 866/4500 [00:01<00:07, 499.27it/s] 20%|██        | 919/4500 [00:01<00:07, 500.85it/s] 22%|██▏       | 970/4500 [00:02<00:07, 449.18it/s] 23%|██▎       | 1055/4500 [00:02<00:06, 554.09it/s] 26%|██▌       | 1161/4500 [00:02<00:04, 693.05it/s] 28%|██▊       | 1267/4500 [00:02<00:04, 795.87it/s] 31%|███       | 1391/4500 [00:02<00:03, 914.33it/s] 33%|███▎      | 1485/4500 [00:02<00:04, 705.34it/s] 35%|███▍      | 1565/4500 [00:02<00:04, 723.84it/s] 37%|███▋      | 1644/4500 [00:02<00:04, 649.80it/s] 38%|███▊      | 1715/4500 [00:03<00:04, 583.91it/s] 40%|████      | 1811/4500 [00:03<00:04, 670.92it/s] 42%|████▏     | 1896/4500 [00:03<00:03, 715.38it/s] 45%|████▍     | 2004/4500 [00:03<00:03, 797.72it/s] 47%|████▋     | 2093/4500 [00:03<00:02, 817.01it/s] 49%|████▉     | 2201/4500 [00:03<00:02, 853.96it/s] 51%|█████     | 2289/4500 [00:03<00:03, 706.20it/s] 53%|█████▎    | 2365/4500 [00:03<00:03, 648.43it/s] 54%|█████▍    | 2434/4500 [00:04<00:03, 609.84it/s] 57%|█████▋    | 2563/4500 [00:04<00:02, 770.70it/s] 59%|█████▉    | 2651/4500 [00:04<00:02, 786.57it/s] 61%|██████    | 2734/4500 [00:04<00:02, 789.73it/s] 63%|██████▎   | 2817/4500 [00:04<00:02, 792.16it/s] 65%|██████▍   | 2916/4500 [00:04<00:01, 838.85it/s] 67%|██████▋   | 3002/4500 [00:04<00:01, 794.84it/s] 69%|██████▊   | 3084/4500 [00:04<00:01, 760.16it/s] 70%|███████   | 3162/4500 [00:05<00:02, 629.13it/s] 72%|███████▏  | 3242/4500 [00:05<00:01, 667.52it/s] 74%|███████▍  | 3326/4500 [00:05<00:01, 709.04it/s] 76%|███████▌  | 3401/4500 [00:05<00:01, 622.05it/s] 77%|███████▋  | 3468/4500 [00:05<00:01, 620.90it/s] 79%|███████▊  | 3533/4500 [00:05<00:02, 471.27it/s] 80%|███████▉  | 3587/4500 [00:06<00:02, 348.19it/s] 82%|████████▏ | 3682/4500 [00:06<00:01, 456.68it/s] 83%|████████▎ | 3741/4500 [00:06<00:01, 468.38it/s] 85%|████████▌ | 3827/4500 [00:06<00:01, 547.03it/s] 87%|████████▋ | 3917/4500 [00:06<00:00, 625.70it/s] 89%|████████▉ | 4001/4500 [00:06<00:00, 678.74it/s] 91%|█████████ | 4076/4500 [00:06<00:00, 690.62it/s] 92%|█████████▏| 4150/4500 [00:06<00:00, 632.96it/s] 94%|█████████▍| 4225/4500 [00:06<00:00, 662.00it/s] 96%|█████████▌| 4317/4500 [00:07<00:00, 730.69it/s] 98%|█████████▊| 4394/4500 [00:07<00:00, 667.44it/s]100%|██████████| 4500/4500 [00:07<00:00, 622.12it/s]
test_p28 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p28
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p28.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.05it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.26it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.64it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.09it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.23it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p28_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p28_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p28_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p28_Holmes_probs.npy
{'Accuracy': 0.8389, 'Precision': 0.8576, 'Recall': 0.8389, 'F1-score': 0.8365}
starting gen taf script for test_p29
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 72/4500 [00:00<00:06, 702.86it/s]  3%|▎         | 143/4500 [00:00<00:07, 581.32it/s]  5%|▍         | 203/4500 [00:00<00:08, 530.84it/s]  6%|▌         | 274/4500 [00:00<00:07, 590.23it/s]  7%|▋         | 335/4500 [00:00<00:08, 505.43it/s]  9%|▊         | 388/4500 [00:00<00:08, 478.29it/s] 11%|█         | 490/4500 [00:00<00:06, 626.95it/s] 13%|█▎        | 582/4500 [00:00<00:05, 706.93it/s] 15%|█▌        | 678/4500 [00:01<00:04, 768.51it/s] 17%|█▋        | 758/4500 [00:01<00:05, 681.22it/s] 19%|█▉        | 872/4500 [00:01<00:04, 801.97it/s] 21%|██▏       | 957/4500 [00:01<00:04, 792.13it/s] 23%|██▎       | 1043/4500 [00:01<00:04, 798.17it/s] 25%|██▌       | 1140/4500 [00:01<00:03, 841.58it/s] 28%|██▊       | 1252/4500 [00:01<00:03, 912.97it/s] 30%|███       | 1364/4500 [00:01<00:03, 962.43it/s] 32%|███▏      | 1462/4500 [00:02<00:03, 782.60it/s] 34%|███▍      | 1547/4500 [00:02<00:03, 795.27it/s] 36%|███▌      | 1631/4500 [00:02<00:04, 660.39it/s] 38%|███▊      | 1704/4500 [00:02<00:04, 621.09it/s] 40%|███▉      | 1784/4500 [00:02<00:04, 662.71it/s] 41%|████▏     | 1861/4500 [00:02<00:03, 686.49it/s] 44%|████▍     | 1985/4500 [00:02<00:03, 831.19it/s] 46%|████▋     | 2090/4500 [00:02<00:02, 876.98it/s] 48%|████▊     | 2181/4500 [00:02<00:02, 880.09it/s] 50%|█████     | 2272/4500 [00:03<00:03, 670.23it/s] 52%|█████▏    | 2348/4500 [00:03<00:03, 658.22it/s] 54%|█████▍    | 2420/4500 [00:03<00:03, 632.39it/s] 56%|█████▌    | 2521/4500 [00:03<00:02, 721.45it/s] 58%|█████▊    | 2598/4500 [00:03<00:02, 695.02it/s] 59%|█████▉    | 2671/4500 [00:03<00:02, 646.67it/s] 61%|██████    | 2749/4500 [00:03<00:02, 672.39it/s] 63%|██████▎   | 2825/4500 [00:03<00:02, 688.61it/s] 65%|██████▍   | 2913/4500 [00:04<00:02, 740.55it/s] 66%|██████▋   | 2989/4500 [00:04<00:02, 702.77it/s] 68%|██████▊   | 3061/4500 [00:04<00:02, 670.04it/s] 70%|██████▉   | 3130/4500 [00:04<00:02, 614.44it/s] 71%|███████   | 3195/4500 [00:04<00:02, 614.94it/s] 73%|███████▎  | 3264/4500 [00:04<00:01, 633.00it/s] 74%|███████▍  | 3337/4500 [00:04<00:01, 659.51it/s] 76%|███████▌  | 3404/4500 [00:04<00:01, 594.16it/s] 77%|███████▋  | 3469/4500 [00:05<00:01, 599.68it/s] 78%|███████▊  | 3531/4500 [00:05<00:02, 415.70it/s] 80%|███████▉  | 3581/4500 [00:05<00:02, 317.22it/s] 81%|████████▏ | 3662/4500 [00:05<00:02, 402.56it/s] 83%|████████▎ | 3728/4500 [00:05<00:01, 443.47it/s] 84%|████████▍ | 3796/4500 [00:05<00:01, 494.33it/s] 86%|████████▋ | 3891/4500 [00:05<00:01, 603.13it/s] 88%|████████▊ | 3971/4500 [00:06<00:00, 653.17it/s] 90%|████████▉ | 4048/4500 [00:06<00:00, 671.90it/s] 92%|█████████▏| 4135/4500 [00:06<00:00, 713.89it/s] 94%|█████████▎| 4211/4500 [00:06<00:00, 619.68it/s] 95%|█████████▌| 4295/4500 [00:06<00:00, 670.23it/s] 97%|█████████▋| 4367/4500 [00:06<00:00, 610.54it/s] 99%|█████████▉| 4466/4500 [00:06<00:00, 695.95it/s]100%|██████████| 4500/4500 [00:06<00:00, 659.71it/s]
test_p29 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p29
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p29.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.72it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.75it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.92it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.32it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p29_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p29_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p29_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p29_Holmes_probs.npy
{'Accuracy': 0.8547, 'Precision': 0.8675, 'Recall': 0.8547, 'F1-score': 0.8519}
starting gen taf script for test_p30
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 81/4500 [00:00<00:05, 806.56it/s]  4%|▎         | 162/4500 [00:00<00:06, 622.92it/s]  5%|▌         | 227/4500 [00:00<00:07, 575.62it/s]  6%|▋         | 291/4500 [00:00<00:07, 592.02it/s]  8%|▊         | 352/4500 [00:00<00:10, 394.83it/s]  9%|▉         | 399/4500 [00:00<00:12, 339.79it/s] 10%|▉         | 439/4500 [00:01<00:12, 321.49it/s] 11%|█         | 495/4500 [00:01<00:10, 368.86it/s] 12%|█▏        | 537/4500 [00:01<00:10, 366.55it/s] 13%|█▎        | 587/4500 [00:01<00:09, 397.94it/s] 15%|█▍        | 653/4500 [00:01<00:08, 465.59it/s] 16%|█▌        | 718/4500 [00:01<00:07, 511.50it/s] 18%|█▊        | 800/4500 [00:01<00:06, 596.71it/s] 20%|██        | 915/4500 [00:01<00:04, 744.30it/s] 23%|██▎       | 1013/4500 [00:01<00:04, 811.58it/s] 24%|██▍       | 1097/4500 [00:02<00:04, 806.86it/s] 27%|██▋       | 1215/4500 [00:02<00:03, 914.72it/s] 29%|██▉       | 1313/4500 [00:02<00:03, 933.18it/s] 31%|███▏      | 1411/4500 [00:02<00:03, 946.94it/s] 33%|███▎      | 1507/4500 [00:02<00:03, 759.76it/s] 36%|███▌      | 1605/4500 [00:02<00:03, 792.40it/s] 38%|███▊      | 1690/4500 [00:02<00:04, 642.42it/s] 39%|███▉      | 1762/4500 [00:02<00:04, 645.64it/s] 41%|████▏     | 1859/4500 [00:03<00:03, 719.98it/s] 44%|████▍     | 1972/4500 [00:03<00:03, 823.26it/s] 46%|████▌     | 2060/4500 [00:03<00:03, 783.59it/s] 48%|████▊     | 2149/4500 [00:03<00:02, 811.33it/s] 50%|████▉     | 2234/4500 [00:03<00:03, 707.60it/s] 51%|█████▏    | 2310/4500 [00:03<00:03, 639.54it/s] 53%|█████▎    | 2378/4500 [00:03<00:03, 603.66it/s] 54%|█████▍    | 2451/4500 [00:03<00:03, 634.29it/s] 56%|█████▌    | 2524/4500 [00:03<00:03, 656.14it/s] 58%|█████▊    | 2592/4500 [00:04<00:02, 657.22it/s] 59%|█████▉    | 2660/4500 [00:04<00:02, 630.07it/s] 61%|██████    | 2733/4500 [00:04<00:02, 643.74it/s] 62%|██████▏   | 2799/4500 [00:04<00:02, 640.80it/s] 64%|██████▍   | 2897/4500 [00:04<00:02, 735.36it/s] 66%|██████▌   | 2972/4500 [00:04<00:02, 735.82it/s] 68%|██████▊   | 3062/4500 [00:04<00:01, 757.42it/s] 70%|██████▉   | 3139/4500 [00:04<00:02, 655.44it/s] 71%|███████▏  | 3208/4500 [00:05<00:02, 574.87it/s] 73%|███████▎  | 3279/4500 [00:05<00:02, 600.69it/s] 74%|███████▍  | 3342/4500 [00:05<00:01, 598.96it/s] 76%|███████▌  | 3404/4500 [00:05<00:01, 588.11it/s] 77%|███████▋  | 3465/4500 [00:05<00:01, 550.97it/s] 78%|███████▊  | 3522/4500 [00:05<00:02, 453.04it/s] 79%|███████▉  | 3571/4500 [00:05<00:02, 337.92it/s] 80%|████████  | 3611/4500 [00:06<00:02, 309.88it/s] 82%|████████▏ | 3674/4500 [00:06<00:02, 373.41it/s] 83%|████████▎ | 3747/4500 [00:06<00:01, 450.71it/s] 85%|████████▍ | 3816/4500 [00:06<00:01, 504.38it/s] 87%|████████▋ | 3900/4500 [00:06<00:01, 585.24it/s] 89%|████████▉ | 3996/4500 [00:06<00:00, 670.84it/s] 91%|█████████ | 4080/4500 [00:06<00:00, 706.87it/s] 92%|█████████▏| 4155/4500 [00:06<00:00, 619.90it/s] 94%|█████████▍| 4244/4500 [00:06<00:00, 678.66it/s] 96%|█████████▌| 4316/4500 [00:07<00:00, 635.49it/s] 98%|█████████▊| 4414/4500 [00:07<00:00, 716.29it/s]100%|██████████| 4500/4500 [00:07<00:00, 615.03it/s]
test_p30 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p30
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p30.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.00s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.95it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.17it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.38it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.81it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p30_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p30_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p30_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p30_Holmes_probs.npy
{'Accuracy': 0.8711, 'Precision': 0.8815, 'Recall': 0.8711, 'F1-score': 0.8687}
starting gen taf script for test_p31
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 89/4500 [00:00<00:05, 877.44it/s]  4%|▍         | 177/4500 [00:00<00:08, 481.09it/s]  5%|▌         | 235/4500 [00:00<00:09, 468.11it/s]  7%|▋         | 301/4500 [00:00<00:08, 519.83it/s]  8%|▊         | 358/4500 [00:00<00:11, 368.09it/s]  9%|▉         | 403/4500 [00:01<00:12, 322.49it/s] 10%|█         | 464/4500 [00:01<00:10, 382.38it/s] 11%|█▏        | 510/4500 [00:01<00:10, 394.75it/s] 12%|█▏        | 555/4500 [00:01<00:09, 401.98it/s] 13%|█▎        | 605/4500 [00:01<00:09, 424.65it/s] 15%|█▍        | 658/4500 [00:01<00:08, 452.49it/s] 16%|█▌        | 706/4500 [00:01<00:08, 448.32it/s] 17%|█▋        | 753/4500 [00:01<00:08, 418.30it/s] 18%|█▊        | 797/4500 [00:01<00:09, 402.98it/s] 19%|█▉        | 857/4500 [00:01<00:08, 453.20it/s] 20%|██        | 904/4500 [00:02<00:07, 456.48it/s] 21%|██        | 951/4500 [00:02<00:07, 447.42it/s] 22%|██▏       | 1002/4500 [00:02<00:07, 461.78it/s] 23%|██▎       | 1049/4500 [00:02<00:07, 452.64it/s] 25%|██▍       | 1121/4500 [00:02<00:06, 526.84it/s] 27%|██▋       | 1219/4500 [00:02<00:05, 655.10it/s] 29%|██▊       | 1289/4500 [00:02<00:04, 667.72it/s] 31%|███       | 1374/4500 [00:02<00:04, 721.02it/s] 32%|███▏      | 1447/4500 [00:02<00:04, 619.59it/s] 34%|███▍      | 1525/4500 [00:03<00:04, 656.84it/s] 36%|███▌      | 1602/4500 [00:03<00:04, 654.73it/s] 37%|███▋      | 1670/4500 [00:03<00:05, 526.72it/s] 38%|███▊      | 1728/4500 [00:03<00:05, 500.90it/s] 40%|████      | 1801/4500 [00:03<00:04, 549.00it/s] 42%|████▏     | 1881/4500 [00:03<00:04, 605.53it/s] 44%|████▎     | 1968/4500 [00:03<00:03, 674.13it/s] 46%|████▌     | 2049/4500 [00:03<00:03, 704.41it/s] 47%|████▋     | 2127/4500 [00:04<00:03, 723.72it/s] 49%|████▉     | 2216/4500 [00:04<00:03, 753.37it/s] 51%|█████     | 2293/4500 [00:04<00:03, 628.96it/s] 52%|█████▏    | 2361/4500 [00:04<00:03, 573.87it/s] 54%|█████▍    | 2422/4500 [00:04<00:03, 562.96it/s] 56%|█████▌    | 2498/4500 [00:04<00:03, 603.11it/s] 57%|█████▋    | 2587/4500 [00:04<00:02, 657.53it/s] 59%|█████▉    | 2655/4500 [00:04<00:02, 629.76it/s] 60%|██████    | 2722/4500 [00:05<00:02, 635.52it/s] 62%|██████▏   | 2810/4500 [00:05<00:02, 693.38it/s] 64%|██████▍   | 2881/4500 [00:05<00:02, 652.42it/s] 66%|██████▋   | 2982/4500 [00:05<00:02, 736.33it/s] 68%|██████▊   | 3057/4500 [00:05<00:02, 690.65it/s] 70%|██████▉   | 3128/4500 [00:05<00:02, 520.90it/s] 71%|███████   | 3195/4500 [00:05<00:02, 543.32it/s] 73%|███████▎  | 3305/4500 [00:05<00:01, 675.33it/s] 75%|███████▌  | 3380/4500 [00:06<00:01, 587.46it/s] 77%|███████▋  | 3446/4500 [00:06<00:01, 584.54it/s] 78%|███████▊  | 3509/4500 [00:06<00:01, 542.28it/s] 79%|███████▉  | 3567/4500 [00:06<00:02, 363.64it/s] 80%|████████  | 3613/4500 [00:06<00:02, 341.84it/s] 82%|████████▏ | 3687/4500 [00:06<00:01, 416.66it/s] 83%|████████▎ | 3745/4500 [00:07<00:01, 447.31it/s] 85%|████████▌ | 3839/4500 [00:07<00:01, 554.42it/s] 87%|████████▋ | 3935/4500 [00:07<00:00, 647.90it/s] 89%|████████▉ | 4011/4500 [00:07<00:00, 660.12it/s] 91%|█████████ | 4082/4500 [00:07<00:00, 663.37it/s] 92%|█████████▏| 4152/4500 [00:07<00:00, 639.81it/s] 94%|█████████▍| 4219/4500 [00:07<00:00, 610.53it/s] 96%|█████████▌| 4327/4500 [00:07<00:00, 735.19it/s] 98%|█████████▊| 4404/4500 [00:07<00:00, 653.75it/s]100%|██████████| 4500/4500 [00:08<00:00, 560.80it/s]
test_p31 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p31
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p31.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.05s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.71it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.65it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.75it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.28it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p31_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p31_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p31_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p31_Holmes_probs.npy
{'Accuracy': 0.8816, 'Precision': 0.8904, 'Recall': 0.8816, 'F1-score': 0.8796}
starting gen taf script for test_p32
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 72/4500 [00:00<00:06, 700.78it/s]  3%|▎         | 143/4500 [00:00<00:08, 520.05it/s]  4%|▍         | 200/4500 [00:00<00:07, 538.05it/s]  6%|▌         | 262/4500 [00:00<00:07, 565.84it/s]  7%|▋         | 321/4500 [00:00<00:09, 456.88it/s]  8%|▊         | 371/4500 [00:00<00:11, 363.81it/s]  9%|▉         | 412/4500 [00:00<00:11, 356.58it/s] 11%|█         | 478/4500 [00:01<00:09, 429.73it/s] 12%|█▏        | 526/4500 [00:01<00:09, 438.45it/s] 13%|█▎        | 574/4500 [00:01<00:08, 449.41it/s] 14%|█▍        | 634/4500 [00:01<00:08, 482.87it/s] 15%|█▌        | 685/4500 [00:01<00:08, 467.68it/s] 17%|█▋        | 750/4500 [00:01<00:07, 508.81it/s] 18%|█▊        | 803/4500 [00:01<00:07, 481.37it/s] 19%|█▉        | 854/4500 [00:01<00:07, 488.99it/s] 21%|██        | 923/4500 [00:01<00:06, 533.60it/s] 22%|██▏       | 1001/4500 [00:02<00:05, 594.44it/s] 24%|██▍       | 1101/4500 [00:02<00:04, 706.49it/s] 28%|██▊       | 1246/4500 [00:02<00:03, 909.18it/s] 30%|███       | 1359/4500 [00:02<00:03, 963.69it/s] 32%|███▏      | 1457/4500 [00:02<00:03, 866.62it/s] 34%|███▍      | 1546/4500 [00:02<00:03, 769.25it/s] 36%|███▌      | 1627/4500 [00:02<00:03, 758.61it/s] 38%|███▊      | 1705/4500 [00:02<00:05, 550.83it/s] 40%|███▉      | 1782/4500 [00:03<00:04, 591.76it/s] 42%|████▏     | 1884/4500 [00:03<00:03, 687.66it/s] 44%|████▍     | 1981/4500 [00:03<00:03, 753.09it/s] 46%|████▌     | 2064/4500 [00:03<00:03, 737.02it/s] 48%|████▊     | 2143/4500 [00:03<00:03, 744.71it/s] 49%|████▉     | 2221/4500 [00:03<00:03, 687.85it/s] 51%|█████     | 2293/4500 [00:03<00:03, 693.34it/s] 53%|█████▎    | 2365/4500 [00:03<00:03, 551.44it/s] 54%|█████▍    | 2436/4500 [00:04<00:03, 576.91it/s] 56%|█████▋    | 2542/4500 [00:04<00:02, 694.18it/s] 58%|█████▊    | 2629/4500 [00:04<00:02, 710.42it/s] 60%|██████    | 2705/4500 [00:04<00:02, 715.67it/s] 62%|██████▏   | 2780/4500 [00:04<00:02, 691.00it/s] 64%|██████▎   | 2859/4500 [00:04<00:02, 713.35it/s] 66%|██████▌   | 2950/4500 [00:04<00:02, 767.28it/s] 67%|██████▋   | 3029/4500 [00:04<00:02, 722.52it/s] 69%|██████▉   | 3103/4500 [00:04<00:02, 680.60it/s] 71%|███████   | 3173/4500 [00:05<00:02, 625.04it/s] 72%|███████▏  | 3257/4500 [00:05<00:01, 680.41it/s] 74%|███████▍  | 3332/4500 [00:05<00:01, 691.79it/s] 76%|███████▌  | 3403/4500 [00:05<00:01, 635.99it/s] 77%|███████▋  | 3469/4500 [00:05<00:01, 561.15it/s] 78%|███████▊  | 3528/4500 [00:05<00:02, 450.48it/s] 80%|███████▉  | 3578/4500 [00:06<00:02, 348.43it/s] 80%|████████  | 3619/4500 [00:06<00:02, 357.88it/s] 82%|████████▏ | 3699/4500 [00:06<00:01, 452.19it/s] 84%|████████▎ | 3768/4500 [00:06<00:01, 501.15it/s] 86%|████████▌ | 3869/4500 [00:06<00:01, 622.27it/s] 88%|████████▊ | 3954/4500 [00:06<00:00, 680.33it/s] 90%|████████▉ | 4042/4500 [00:06<00:00, 711.19it/s] 91%|█████████▏| 4117/4500 [00:06<00:00, 677.81it/s] 93%|█████████▎| 4188/4500 [00:06<00:00, 633.73it/s] 96%|█████████▌| 4310/4500 [00:07<00:00, 757.59it/s] 98%|█████████▊| 4388/4500 [00:07<00:00, 690.77it/s]100%|██████████| 4500/4500 [00:07<00:00, 619.48it/s]
test_p32 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p32
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p32.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.10it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.51it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.00it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.39it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.71it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p32_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p32_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p32_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p32_Holmes_probs.npy
{'Accuracy': 0.8942, 'Precision': 0.9012, 'Recall': 0.8942, 'F1-score': 0.8924}
starting gen taf script for test_p33
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 79/4500 [00:00<00:05, 779.32it/s]  3%|▎         | 157/4500 [00:00<00:07, 589.04it/s]  5%|▍         | 219/4500 [00:00<00:07, 566.61it/s]  6%|▌         | 280/4500 [00:00<00:07, 575.60it/s]  8%|▊         | 339/4500 [00:00<00:09, 436.22it/s]  9%|▊         | 387/4500 [00:00<00:11, 352.37it/s] 10%|▉         | 444/4500 [00:00<00:10, 400.55it/s] 11%|█         | 504/4500 [00:01<00:08, 446.29it/s] 12%|█▏        | 554/4500 [00:01<00:08, 441.57it/s] 13%|█▎        | 602/4500 [00:01<00:09, 427.72it/s] 15%|█▍        | 670/4500 [00:01<00:07, 481.19it/s] 16%|█▌        | 721/4500 [00:01<00:08, 448.50it/s] 17%|█▋        | 768/4500 [00:01<00:09, 413.66it/s] 18%|█▊        | 811/4500 [00:01<00:08, 415.11it/s] 19%|█▉        | 860/4500 [00:01<00:08, 430.89it/s] 20%|██        | 922/4500 [00:02<00:07, 478.84it/s] 22%|██▏       | 981/4500 [00:02<00:06, 508.79it/s] 23%|██▎       | 1038/4500 [00:02<00:06, 513.56it/s] 25%|██▌       | 1127/4500 [00:02<00:05, 619.40it/s] 27%|██▋       | 1218/4500 [00:02<00:04, 695.78it/s] 29%|██▉       | 1299/4500 [00:02<00:04, 728.38it/s] 31%|███       | 1381/4500 [00:02<00:04, 743.77it/s] 32%|███▏      | 1456/4500 [00:02<00:04, 635.20it/s] 34%|███▍      | 1523/4500 [00:02<00:05, 559.07it/s] 36%|███▌      | 1598/4500 [00:03<00:04, 600.49it/s] 37%|███▋      | 1662/4500 [00:03<00:05, 513.01it/s] 38%|███▊      | 1718/4500 [00:03<00:05, 464.42it/s] 40%|███▉      | 1797/4500 [00:03<00:05, 533.23it/s] 42%|████▏     | 1891/4500 [00:03<00:04, 627.32it/s] 44%|████▍     | 2000/4500 [00:03<00:03, 730.45it/s] 46%|████▌     | 2078/4500 [00:03<00:03, 730.37it/s] 48%|████▊     | 2154/4500 [00:03<00:03, 704.55it/s] 49%|████▉     | 2227/4500 [00:04<00:03, 648.69it/s] 51%|█████     | 2294/4500 [00:04<00:03, 557.72it/s] 52%|█████▏    | 2353/4500 [00:04<00:04, 515.72it/s] 53%|█████▎    | 2407/4500 [00:04<00:04, 513.18it/s] 55%|█████▌    | 2487/4500 [00:04<00:03, 573.29it/s] 57%|█████▋    | 2562/4500 [00:04<00:03, 611.92it/s] 58%|█████▊    | 2625/4500 [00:04<00:03, 590.35it/s] 60%|█████▉    | 2693/4500 [00:04<00:02, 607.20it/s] 61%|██████▏   | 2765/4500 [00:05<00:02, 637.32it/s] 63%|██████▎   | 2830/4500 [00:05<00:02, 591.08it/s] 65%|██████▍   | 2903/4500 [00:05<00:02, 627.80it/s] 66%|██████▌   | 2972/4500 [00:05<00:02, 643.23it/s] 68%|██████▊   | 3043/4500 [00:05<00:02, 655.54it/s] 69%|██████▉   | 3110/4500 [00:05<00:02, 626.99it/s] 71%|███████   | 3174/4500 [00:05<00:02, 531.54it/s] 72%|███████▏  | 3259/4500 [00:05<00:02, 600.78it/s] 74%|███████▍  | 3347/4500 [00:05<00:01, 666.85it/s] 76%|███████▌  | 3417/4500 [00:06<00:01, 606.77it/s] 77%|███████▋  | 3481/4500 [00:06<00:01, 596.65it/s] 79%|███████▊  | 3543/4500 [00:06<00:02, 393.91it/s] 80%|███████▉  | 3593/4500 [00:06<00:02, 311.40it/s] 82%|████████▏ | 3685/4500 [00:06<00:01, 413.50it/s] 83%|████████▎ | 3746/4500 [00:06<00:01, 446.29it/s] 85%|████████▌ | 3831/4500 [00:07<00:01, 533.17it/s] 87%|████████▋ | 3930/4500 [00:07<00:00, 635.51it/s] 89%|████████▉ | 4004/4500 [00:07<00:00, 657.63it/s] 91%|█████████ | 4077/4500 [00:07<00:00, 643.33it/s] 92%|█████████▏| 4151/4500 [00:07<00:00, 666.26it/s] 94%|█████████▍| 4222/4500 [00:07<00:00, 591.75it/s] 96%|█████████▌| 4301/4500 [00:07<00:00, 637.62it/s] 97%|█████████▋| 4369/4500 [00:07<00:00, 596.49it/s] 99%|█████████▉| 4448/4500 [00:07<00:00, 640.66it/s]100%|██████████| 4500/4500 [00:08<00:00, 559.86it/s]
test_p33 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p33
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p33.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.07it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.36it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.82it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.20it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.39it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p33_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p33_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p33_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p33_Holmes_probs.npy
{'Accuracy': 0.9053, 'Precision': 0.9105, 'Recall': 0.9053, 'F1-score': 0.9039}
starting gen taf script for test_p34
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 79/4500 [00:00<00:05, 786.96it/s]  4%|▎         | 158/4500 [00:00<00:06, 627.90it/s]  5%|▍         | 223/4500 [00:00<00:07, 596.02it/s]  6%|▋         | 284/4500 [00:00<00:07, 597.23it/s]  8%|▊         | 345/4500 [00:00<00:10, 407.30it/s]  9%|▊         | 393/4500 [00:00<00:11, 343.06it/s] 10%|▉         | 443/4500 [00:01<00:10, 377.22it/s] 11%|█         | 486/4500 [00:01<00:10, 376.37it/s] 12%|█▏        | 528/4500 [00:01<00:10, 369.96it/s] 13%|█▎        | 568/4500 [00:01<00:10, 371.82it/s] 13%|█▎        | 607/4500 [00:01<00:10, 364.77it/s] 15%|█▍        | 667/4500 [00:01<00:09, 424.41it/s] 16%|█▌        | 718/4500 [00:01<00:08, 444.83it/s] 17%|█▋        | 764/4500 [00:01<00:08, 435.24it/s] 18%|█▊        | 812/4500 [00:01<00:08, 441.33it/s] 20%|██        | 902/4500 [00:01<00:06, 570.52it/s] 21%|██▏       | 961/4500 [00:02<00:06, 541.63it/s] 23%|██▎       | 1032/4500 [00:02<00:05, 587.44it/s] 25%|██▍       | 1111/4500 [00:02<00:05, 642.51it/s] 27%|██▋       | 1214/4500 [00:02<00:04, 750.22it/s] 29%|██▉       | 1306/4500 [00:02<00:03, 799.27it/s] 31%|███       | 1400/4500 [00:02<00:03, 835.99it/s] 33%|███▎      | 1485/4500 [00:02<00:04, 650.75it/s] 35%|███▍      | 1567/4500 [00:02<00:04, 690.10it/s] 36%|███▋      | 1642/4500 [00:03<00:04, 603.41it/s] 38%|███▊      | 1708/4500 [00:03<00:05, 514.76it/s] 40%|███▉      | 1795/4500 [00:03<00:04, 583.98it/s] 43%|████▎     | 1916/4500 [00:03<00:03, 723.17it/s] 44%|████▍     | 1999/4500 [00:03<00:03, 747.29it/s] 46%|████▌     | 2079/4500 [00:03<00:03, 732.13it/s] 49%|████▊     | 2184/4500 [00:03<00:02, 811.50it/s] 50%|█████     | 2269/4500 [00:03<00:03, 717.35it/s] 52%|█████▏    | 2345/4500 [00:04<00:03, 581.94it/s] 54%|█████▎    | 2410/4500 [00:04<00:03, 537.84it/s] 55%|█████▌    | 2485/4500 [00:04<00:03, 567.86it/s] 57%|█████▋    | 2575/4500 [00:04<00:03, 636.22it/s] 59%|█████▊    | 2643/4500 [00:04<00:02, 621.67it/s] 60%|██████    | 2710/4500 [00:04<00:02, 622.90it/s] 62%|██████▏   | 2775/4500 [00:04<00:02, 601.90it/s] 64%|██████▍   | 2876/4500 [00:04<00:02, 709.16it/s] 66%|██████▌   | 2950/4500 [00:05<00:02, 687.36it/s] 67%|██████▋   | 3021/4500 [00:05<00:02, 664.45it/s] 69%|██████▊   | 3089/4500 [00:05<00:02, 638.11it/s] 70%|███████   | 3154/4500 [00:05<00:02, 598.53it/s] 71%|███████▏  | 3215/4500 [00:05<00:02, 565.57it/s] 73%|███████▎  | 3300/4500 [00:05<00:01, 633.27it/s] 75%|███████▍  | 3365/4500 [00:05<00:01, 573.90it/s] 76%|███████▌  | 3424/4500 [00:05<00:02, 537.94it/s] 77%|███████▋  | 3480/4500 [00:06<00:02, 478.84it/s] 78%|███████▊  | 3530/4500 [00:06<00:02, 332.51it/s] 79%|███████▉  | 3570/4500 [00:06<00:02, 321.89it/s] 80%|████████  | 3607/4500 [00:06<00:02, 318.98it/s] 82%|████████▏ | 3687/4500 [00:06<00:01, 423.34it/s] 83%|████████▎ | 3736/4500 [00:06<00:01, 407.58it/s] 84%|████████▍ | 3797/4500 [00:06<00:01, 449.45it/s] 86%|████████▌ | 3877/4500 [00:07<00:01, 529.59it/s] 88%|████████▊ | 3956/4500 [00:07<00:00, 596.75it/s] 89%|████████▉ | 4020/4500 [00:07<00:00, 580.37it/s] 91%|█████████ | 4087/4500 [00:07<00:00, 593.83it/s] 92%|█████████▏| 4149/4500 [00:07<00:00, 585.96it/s] 94%|█████████▎| 4209/4500 [00:07<00:00, 487.32it/s] 95%|█████████▌| 4285/4500 [00:07<00:00, 551.00it/s] 97%|█████████▋| 4344/4500 [00:07<00:00, 549.68it/s] 99%|█████████▉| 4445/4500 [00:07<00:00, 666.90it/s]100%|██████████| 4500/4500 [00:08<00:00, 560.55it/s]
test_p34 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p34
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p34.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.06s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.67it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.65it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.82it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.26it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p34_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p34_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p34_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p34_Holmes_probs.npy
{'Accuracy': 0.9153, 'Precision': 0.92, 'Recall': 0.9153, 'F1-score': 0.9143}
starting gen taf script for test_p35
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 63/4500 [00:00<00:07, 595.81it/s]  3%|▎         | 123/4500 [00:00<00:07, 568.49it/s]  4%|▍         | 181/4500 [00:00<00:07, 565.17it/s]  5%|▌         | 238/4500 [00:00<00:08, 530.28it/s]  6%|▋         | 292/4500 [00:00<00:07, 526.27it/s]  8%|▊         | 345/4500 [00:00<00:11, 365.66it/s]  9%|▊         | 388/4500 [00:00<00:12, 322.54it/s]  9%|▉         | 427/4500 [00:01<00:12, 333.56it/s] 11%|█         | 490/4500 [00:01<00:09, 402.32it/s] 13%|█▎        | 564/4500 [00:01<00:08, 481.75it/s] 15%|█▌        | 681/4500 [00:01<00:05, 657.69it/s] 17%|█▋        | 754/4500 [00:01<00:05, 667.29it/s] 19%|█▊        | 833/4500 [00:01<00:05, 691.18it/s] 20%|██        | 905/4500 [00:01<00:05, 659.04it/s] 22%|██▏       | 986/4500 [00:01<00:05, 699.39it/s] 24%|██▎       | 1058/4500 [00:01<00:05, 666.88it/s] 25%|██▌       | 1133/4500 [00:02<00:04, 680.35it/s] 27%|██▋       | 1228/4500 [00:02<00:04, 755.51it/s] 30%|██▉       | 1342/4500 [00:02<00:03, 859.35it/s] 32%|███▏      | 1430/4500 [00:02<00:03, 854.43it/s] 34%|███▎      | 1517/4500 [00:02<00:04, 651.31it/s] 35%|███▌      | 1590/4500 [00:02<00:04, 623.54it/s] 37%|███▋      | 1658/4500 [00:02<00:05, 503.26it/s] 38%|███▊      | 1716/4500 [00:03<00:05, 498.39it/s] 40%|████      | 1801/4500 [00:03<00:04, 568.64it/s] 42%|████▏     | 1906/4500 [00:03<00:03, 679.31it/s] 44%|████▍     | 1981/4500 [00:03<00:03, 695.43it/s] 46%|████▌     | 2055/4500 [00:03<00:03, 664.80it/s] 48%|████▊     | 2153/4500 [00:03<00:03, 747.28it/s] 50%|████▉     | 2232/4500 [00:03<00:03, 635.49it/s] 51%|█████     | 2301/4500 [00:03<00:03, 578.09it/s] 53%|█████▎    | 2363/4500 [00:04<00:04, 520.23it/s] 54%|█████▍    | 2419/4500 [00:04<00:04, 518.00it/s] 55%|█████▌    | 2492/4500 [00:04<00:03, 567.37it/s] 57%|█████▋    | 2571/4500 [00:04<00:03, 619.81it/s] 59%|█████▊    | 2641/4500 [00:04<00:02, 639.52it/s] 60%|██████    | 2710/4500 [00:04<00:02, 652.28it/s] 62%|██████▏   | 2777/4500 [00:04<00:02, 600.89it/s] 63%|██████▎   | 2839/4500 [00:04<00:02, 605.04it/s] 64%|██████▍   | 2901/4500 [00:04<00:02, 567.30it/s] 66%|██████▋   | 2986/4500 [00:04<00:02, 637.87it/s] 68%|██████▊   | 3057/4500 [00:05<00:02, 654.50it/s] 69%|██████▉   | 3124/4500 [00:05<00:02, 600.50it/s] 71%|███████   | 3186/4500 [00:05<00:02, 507.22it/s] 72%|███████▏  | 3262/4500 [00:05<00:02, 566.70it/s] 74%|███████▍  | 3323/4500 [00:05<00:02, 512.48it/s] 75%|███████▌  | 3378/4500 [00:05<00:02, 496.93it/s] 76%|███████▋  | 3437/4500 [00:05<00:02, 504.28it/s] 78%|███████▊  | 3497/4500 [00:06<00:01, 502.69it/s] 79%|███████▉  | 3549/4500 [00:06<00:03, 311.30it/s] 80%|███████▉  | 3590/4500 [00:06<00:03, 280.45it/s] 82%|████████▏ | 3674/4500 [00:06<00:02, 380.25it/s] 83%|████████▎ | 3745/4500 [00:06<00:01, 442.38it/s] 85%|████████▍ | 3808/4500 [00:06<00:01, 482.45it/s] 86%|████████▌ | 3879/4500 [00:06<00:01, 532.79it/s] 88%|████████▊ | 3945/4500 [00:07<00:00, 556.93it/s] 89%|████████▉ | 4021/4500 [00:07<00:00, 610.25it/s] 91%|█████████ | 4087/4500 [00:07<00:00, 564.33it/s] 92%|█████████▏| 4150/4500 [00:07<00:00, 571.57it/s] 94%|█████████▎| 4210/4500 [00:07<00:00, 528.77it/s] 95%|█████████▌| 4286/4500 [00:07<00:00, 562.15it/s] 97%|█████████▋| 4360/4500 [00:07<00:00, 589.06it/s] 98%|█████████▊| 4432/4500 [00:07<00:00, 615.32it/s]100%|██████████| 4500/4500 [00:07<00:00, 566.33it/s]
test_p35 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p35
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p35.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.02s/it]evaluating model with Holmes:  22%|██▏       | 4/18 [00:01<00:03,  4.46it/s]evaluating model with Holmes:  50%|█████     | 9/18 [00:01<00:00, 10.91it/s]evaluating model with Holmes:  78%|███████▊  | 14/18 [00:01<00:00, 17.35it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.20it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p35_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p35_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p35_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p35_Holmes_probs.npy
{'Accuracy': 0.9229, 'Precision': 0.9265, 'Recall': 0.9229, 'F1-score': 0.922}
starting gen taf script for test_p36
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 65/4500 [00:00<00:07, 612.08it/s]  3%|▎         | 130/4500 [00:00<00:06, 629.87it/s]  4%|▍         | 194/4500 [00:00<00:08, 514.42it/s]  6%|▌         | 248/4500 [00:00<00:08, 501.59it/s]  7%|▋         | 301/4500 [00:00<00:08, 502.46it/s]  8%|▊         | 352/4500 [00:00<00:12, 345.29it/s]  9%|▊         | 393/4500 [00:01<00:13, 295.63it/s] 10%|▉         | 430/4500 [00:01<00:13, 309.60it/s] 10%|█         | 465/4500 [00:01<00:12, 313.92it/s] 12%|█▏        | 521/4500 [00:01<00:11, 359.53it/s] 13%|█▎        | 568/4500 [00:01<00:10, 385.10it/s] 14%|█▎        | 609/4500 [00:01<00:10, 378.38it/s] 14%|█▍        | 652/4500 [00:01<00:09, 389.71it/s] 16%|█▌        | 698/4500 [00:01<00:09, 403.18it/s] 16%|█▋        | 740/4500 [00:01<00:09, 401.40it/s] 17%|█▋        | 781/4500 [00:01<00:09, 379.57it/s] 18%|█▊        | 828/4500 [00:02<00:09, 403.88it/s] 19%|█▉        | 871/4500 [00:02<00:08, 403.38it/s] 21%|██        | 941/4500 [00:02<00:07, 486.18it/s] 22%|██▏       | 1000/4500 [00:02<00:06, 514.25it/s] 23%|██▎       | 1053/4500 [00:02<00:07, 463.96it/s] 25%|██▌       | 1130/4500 [00:02<00:06, 545.00it/s] 27%|██▋       | 1206/4500 [00:02<00:05, 602.47it/s] 28%|██▊       | 1271/4500 [00:02<00:05, 607.52it/s] 30%|██▉       | 1344/4500 [00:02<00:05, 631.08it/s] 31%|███▏      | 1413/4500 [00:03<00:04, 640.91it/s] 33%|███▎      | 1478/4500 [00:03<00:06, 456.69it/s] 34%|███▍      | 1532/4500 [00:03<00:06, 471.75it/s] 36%|███▌      | 1601/4500 [00:03<00:05, 512.32it/s] 37%|███▋      | 1657/4500 [00:03<00:05, 508.00it/s] 38%|███▊      | 1712/4500 [00:03<00:06, 461.38it/s] 40%|███▉      | 1781/4500 [00:03<00:05, 517.61it/s] 42%|████▏     | 1891/4500 [00:03<00:03, 659.57it/s] 44%|████▎     | 1961/4500 [00:04<00:03, 670.06it/s] 45%|████▌     | 2031/4500 [00:04<00:03, 636.69it/s] 47%|████▋     | 2108/4500 [00:04<00:03, 663.44it/s] 49%|████▉     | 2201/4500 [00:04<00:03, 722.37it/s] 51%|█████     | 2275/4500 [00:04<00:03, 630.64it/s] 52%|█████▏    | 2341/4500 [00:04<00:03, 552.58it/s] 53%|█████▎    | 2400/4500 [00:04<00:03, 525.33it/s] 55%|█████▌    | 2480/4500 [00:04<00:03, 590.44it/s] 57%|█████▋    | 2543/4500 [00:05<00:03, 589.40it/s] 58%|█████▊    | 2621/4500 [00:05<00:02, 631.85it/s] 60%|█████▉    | 2696/4500 [00:05<00:02, 661.53it/s] 61%|██████▏   | 2764/4500 [00:05<00:02, 603.19it/s] 63%|██████▎   | 2827/4500 [00:05<00:02, 608.41it/s] 64%|██████▍   | 2895/4500 [00:05<00:02, 612.32it/s] 66%|██████▌   | 2970/4500 [00:05<00:02, 645.72it/s] 68%|██████▊   | 3059/4500 [00:05<00:02, 706.62it/s] 70%|██████▉   | 3131/4500 [00:06<00:02, 564.03it/s] 71%|███████   | 3193/4500 [00:06<00:02, 480.57it/s] 73%|███████▎  | 3263/4500 [00:06<00:02, 524.81it/s] 74%|███████▍  | 3327/4500 [00:06<00:02, 551.36it/s] 75%|███████▌  | 3387/4500 [00:06<00:02, 528.16it/s] 77%|███████▋  | 3443/4500 [00:06<00:02, 476.01it/s] 78%|███████▊  | 3502/4500 [00:06<00:02, 497.81it/s] 79%|███████▉  | 3554/4500 [00:07<00:02, 337.33it/s] 80%|███████▉  | 3596/4500 [00:07<00:03, 283.67it/s] 81%|████████  | 3646/4500 [00:07<00:02, 323.17it/s] 83%|████████▎ | 3731/4500 [00:07<00:01, 424.68it/s] 84%|████████▍ | 3788/4500 [00:07<00:01, 456.66it/s] 86%|████████▌ | 3865/4500 [00:07<00:01, 532.76it/s] 88%|████████▊ | 3955/4500 [00:07<00:00, 618.33it/s] 90%|████████▉ | 4033/4500 [00:07<00:00, 660.66it/s] 91%|█████████ | 4104/4500 [00:08<00:00, 661.92it/s] 93%|█████████▎| 4174/4500 [00:08<00:00, 538.42it/s] 94%|█████████▍| 4250/4500 [00:08<00:00, 567.75it/s] 96%|█████████▌| 4312/4500 [00:08<00:00, 573.42it/s] 97%|█████████▋| 4379/4500 [00:08<00:00, 590.22it/s]100%|█████████▉| 4486/4500 [00:08<00:00, 715.45it/s]100%|██████████| 4500/4500 [00:08<00:00, 519.46it/s]
test_p36 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p36
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p36.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.01s/it]evaluating model with Holmes:  28%|██▊       | 5/18 [00:01<00:02,  5.83it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 12.30it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 18.68it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.69it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p36_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p36_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p36_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p36_Holmes_probs.npy
{'Accuracy': 0.93, 'Precision': 0.9332, 'Recall': 0.93, 'F1-score': 0.9292}
starting gen taf script for test_p37
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 76/4500 [00:00<00:05, 753.54it/s]  3%|▎         | 152/4500 [00:00<00:07, 591.34it/s]  5%|▍         | 214/4500 [00:00<00:07, 580.23it/s]  6%|▌         | 274/4500 [00:00<00:07, 562.56it/s]  7%|▋         | 331/4500 [00:00<00:09, 422.92it/s]  8%|▊         | 378/4500 [00:00<00:12, 331.50it/s]  9%|▉         | 416/4500 [00:01<00:12, 323.63it/s] 10%|█         | 470/4500 [00:01<00:10, 372.31it/s] 11%|█▏        | 513/4500 [00:01<00:10, 385.36it/s] 12%|█▏        | 555/4500 [00:01<00:10, 368.53it/s] 13%|█▎        | 595/4500 [00:01<00:10, 375.09it/s] 14%|█▍        | 647/4500 [00:01<00:09, 405.61it/s] 16%|█▌        | 702/4500 [00:01<00:08, 439.46it/s] 17%|█▋        | 748/4500 [00:01<00:10, 374.77it/s] 18%|█▊        | 788/4500 [00:01<00:10, 347.31it/s] 18%|█▊        | 829/4500 [00:02<00:10, 359.54it/s] 20%|█▉        | 878/4500 [00:02<00:09, 391.40it/s] 20%|██        | 919/4500 [00:02<00:09, 376.15it/s] 21%|██▏       | 958/4500 [00:02<00:09, 371.11it/s] 22%|██▏       | 999/4500 [00:02<00:09, 377.17it/s] 23%|██▎       | 1038/4500 [00:02<00:09, 371.61it/s] 24%|██▍       | 1088/4500 [00:02<00:08, 393.19it/s] 26%|██▌       | 1148/4500 [00:02<00:07, 446.24it/s] 27%|██▋       | 1237/4500 [00:02<00:05, 567.52it/s] 29%|██▉       | 1295/4500 [00:03<00:06, 517.02it/s] 30%|██▉       | 1349/4500 [00:03<00:06, 471.48it/s] 31%|███       | 1398/4500 [00:03<00:07, 433.72it/s] 32%|███▏      | 1449/4500 [00:03<00:06, 442.86it/s] 33%|███▎      | 1495/4500 [00:03<00:07, 382.18it/s] 35%|███▍      | 1560/4500 [00:03<00:06, 444.34it/s] 36%|███▌      | 1615/4500 [00:03<00:06, 466.89it/s] 37%|███▋      | 1664/4500 [00:03<00:06, 422.47it/s] 38%|███▊      | 1709/4500 [00:04<00:07, 349.88it/s] 40%|███▉      | 1787/4500 [00:04<00:06, 446.94it/s] 41%|████      | 1849/4500 [00:04<00:05, 485.17it/s] 43%|████▎     | 1936/4500 [00:04<00:04, 583.79it/s] 44%|████▍     | 2002/4500 [00:04<00:04, 603.64it/s] 46%|████▌     | 2076/4500 [00:04<00:03, 637.61it/s] 48%|████▊     | 2152/4500 [00:04<00:03, 668.41it/s] 49%|████▉     | 2221/4500 [00:04<00:03, 671.71it/s] 51%|█████     | 2290/4500 [00:05<00:03, 574.60it/s] 52%|█████▏    | 2351/4500 [00:05<00:04, 469.00it/s] 54%|█████▍    | 2426/4500 [00:05<00:03, 529.92it/s] 55%|█████▌    | 2496/4500 [00:05<00:03, 566.91it/s] 57%|█████▋    | 2558/4500 [00:05<00:03, 560.27it/s] 58%|█████▊    | 2630/4500 [00:05<00:03, 588.73it/s] 60%|█████▉    | 2699/4500 [00:05<00:02, 614.77it/s] 61%|██████▏   | 2766/4500 [00:05<00:02, 611.66it/s] 64%|██████▍   | 2869/4500 [00:05<00:02, 709.04it/s] 65%|██████▌   | 2947/4500 [00:06<00:02, 719.12it/s] 67%|██████▋   | 3023/4500 [00:06<00:02, 719.05it/s] 69%|██████▉   | 3096/4500 [00:06<00:01, 707.49it/s] 70%|███████   | 3168/4500 [00:06<00:02, 568.10it/s] 72%|███████▏  | 3230/4500 [00:06<00:02, 538.45it/s] 73%|███████▎  | 3289/4500 [00:06<00:02, 543.88it/s] 74%|███████▍  | 3346/4500 [00:06<00:02, 524.23it/s] 76%|███████▌  | 3400/4500 [00:07<00:02, 436.65it/s] 77%|███████▋  | 3457/4500 [00:07<00:02, 465.14it/s] 78%|███████▊  | 3507/4500 [00:07<00:02, 368.87it/s] 79%|███████▉  | 3549/4500 [00:07<00:02, 335.52it/s] 80%|███████▉  | 3586/4500 [00:07<00:03, 260.82it/s] 81%|████████  | 3647/4500 [00:07<00:02, 325.08it/s] 83%|████████▎ | 3738/4500 [00:07<00:01, 438.91it/s] 85%|████████▌ | 3836/4500 [00:08<00:01, 548.77it/s] 87%|████████▋ | 3901/4500 [00:08<00:01, 561.22it/s] 89%|████████▊ | 3990/4500 [00:08<00:00, 637.68it/s] 90%|█████████ | 4059/4500 [00:08<00:00, 631.10it/s] 92%|█████████▏| 4126/4500 [00:08<00:00, 514.12it/s] 93%|█████████▎| 4188/4500 [00:08<00:00, 531.02it/s] 95%|█████████▍| 4256/4500 [00:08<00:00, 567.82it/s] 96%|█████████▌| 4320/4500 [00:08<00:00, 553.44it/s] 97%|█████████▋| 4379/4500 [00:09<00:00, 519.82it/s] 99%|█████████▉| 4457/4500 [00:09<00:00, 585.02it/s]100%|██████████| 4500/4500 [00:09<00:00, 490.18it/s]
test_p37 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p37
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p37.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:14,  1.15it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:00<00:01,  7.81it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.50it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.85it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 14.10it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p37_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p37_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p37_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p37_Holmes_probs.npy
{'Accuracy': 0.936, 'Precision': 0.9388, 'Recall': 0.936, 'F1-score': 0.9354}
starting gen taf script for test_p38
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 79/4500 [00:00<00:05, 752.37it/s]  3%|▎         | 155/4500 [00:00<00:06, 633.15it/s]  5%|▍         | 220/4500 [00:00<00:07, 576.11it/s]  6%|▌         | 280/4500 [00:00<00:07, 583.14it/s]  8%|▊         | 339/4500 [00:00<00:10, 402.86it/s]  9%|▊         | 386/4500 [00:00<00:11, 348.55it/s]  9%|▉         | 426/4500 [00:01<00:11, 341.85it/s] 10%|█         | 468/4500 [00:01<00:11, 359.12it/s] 11%|█▏        | 507/4500 [00:01<00:11, 357.15it/s] 12%|█▏        | 546/4500 [00:01<00:11, 359.35it/s] 13%|█▎        | 594/4500 [00:01<00:10, 390.19it/s] 14%|█▍        | 643/4500 [00:01<00:09, 411.04it/s] 15%|█▌        | 694/4500 [00:01<00:08, 438.39it/s] 16%|█▋        | 739/4500 [00:01<00:09, 407.42it/s] 17%|█▋        | 781/4500 [00:01<00:09, 394.45it/s] 18%|█▊        | 822/4500 [00:01<00:09, 381.66it/s] 20%|█▉        | 883/4500 [00:02<00:08, 443.53it/s] 21%|██        | 929/4500 [00:02<00:08, 424.46it/s] 23%|██▎       | 1019/4500 [00:02<00:06, 549.14it/s] 24%|██▍       | 1086/4500 [00:02<00:05, 577.47it/s] 26%|██▋       | 1191/4500 [00:02<00:04, 701.27it/s] 28%|██▊       | 1264/4500 [00:02<00:04, 708.94it/s] 30%|██▉       | 1347/4500 [00:02<00:04, 718.33it/s] 32%|███▏      | 1420/4500 [00:02<00:04, 660.74it/s] 33%|███▎      | 1488/4500 [00:03<00:05, 547.80it/s] 35%|███▍      | 1561/4500 [00:03<00:05, 585.88it/s] 36%|███▌      | 1623/4500 [00:03<00:05, 538.58it/s] 37%|███▋      | 1680/4500 [00:03<00:05, 476.20it/s] 38%|███▊      | 1731/4500 [00:03<00:05, 480.70it/s] 40%|████      | 1816/4500 [00:03<00:04, 571.52it/s] 43%|████▎     | 1920/4500 [00:03<00:03, 694.61it/s] 45%|████▌     | 2028/4500 [00:03<00:03, 787.64it/s] 47%|████▋     | 2110/4500 [00:03<00:03, 747.54it/s] 49%|████▊     | 2188/4500 [00:04<00:03, 728.26it/s] 50%|█████     | 2263/4500 [00:04<00:03, 564.52it/s] 52%|█████▏    | 2329/4500 [00:04<00:03, 575.31it/s] 53%|█████▎    | 2392/4500 [00:04<00:04, 502.02it/s] 54%|█████▍    | 2447/4500 [00:04<00:04, 508.95it/s] 56%|█████▌    | 2526/4500 [00:04<00:03, 570.57it/s] 57%|█████▋    | 2587/4500 [00:04<00:03, 579.43it/s] 59%|█████▉    | 2648/4500 [00:05<00:03, 568.57it/s] 61%|██████    | 2728/4500 [00:05<00:02, 618.44it/s] 62%|██████▏   | 2797/4500 [00:05<00:02, 632.44it/s] 64%|██████▎   | 2862/4500 [00:05<00:02, 616.72it/s] 65%|██████▌   | 2932/4500 [00:05<00:02, 639.69it/s] 67%|██████▋   | 2997/4500 [00:05<00:02, 618.02it/s] 68%|██████▊   | 3060/4500 [00:05<00:02, 591.16it/s] 69%|██████▉   | 3120/4500 [00:05<00:02, 528.89it/s] 71%|███████   | 3176/4500 [00:05<00:02, 518.87it/s] 72%|███████▏  | 3238/4500 [00:06<00:02, 544.06it/s] 74%|███████▎  | 3310/4500 [00:06<00:02, 585.58it/s] 75%|███████▍  | 3370/4500 [00:06<00:01, 572.16it/s] 76%|███████▌  | 3428/4500 [00:06<00:02, 495.04it/s] 77%|███████▋  | 3483/4500 [00:06<00:02, 507.83it/s] 79%|███████▊  | 3536/4500 [00:06<00:02, 346.74it/s] 80%|███████▉  | 3579/4500 [00:07<00:03, 281.93it/s] 80%|████████  | 3617/4500 [00:07<00:02, 299.80it/s] 82%|████████▏ | 3680/4500 [00:07<00:02, 366.45it/s] 83%|████████▎ | 3753/4500 [00:07<00:01, 447.18it/s] 85%|████████▍ | 3824/4500 [00:07<00:01, 506.42it/s] 87%|████████▋ | 3916/4500 [00:07<00:00, 589.27it/s] 88%|████████▊ | 3980/4500 [00:07<00:00, 595.32it/s] 90%|████████▉ | 4043/4500 [00:07<00:00, 588.59it/s] 91%|█████████▏| 4112/4500 [00:07<00:00, 607.66it/s] 93%|█████████▎| 4175/4500 [00:08<00:00, 548.10it/s] 94%|█████████▍| 4232/4500 [00:08<00:00, 528.33it/s] 95%|█████████▌| 4290/4500 [00:08<00:00, 529.12it/s] 97%|█████████▋| 4361/4500 [00:08<00:00, 577.38it/s] 98%|█████████▊| 4428/4500 [00:08<00:00, 597.77it/s]100%|██████████| 4500/4500 [00:08<00:00, 528.66it/s]
test_p38 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p38
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p38.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.03it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.11it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.52it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.83it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.16it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p38_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p38_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p38_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p38_Holmes_probs.npy
{'Accuracy': 0.9389, 'Precision': 0.9409, 'Recall': 0.9389, 'F1-score': 0.9383}
starting gen taf script for test_p39
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 81/4500 [00:00<00:05, 793.20it/s]  4%|▎         | 161/4500 [00:00<00:12, 349.46it/s]  5%|▍         | 209/4500 [00:00<00:11, 372.32it/s]  6%|▌         | 265/4500 [00:00<00:10, 420.11it/s]  7%|▋         | 314/4500 [00:00<00:11, 376.27it/s]  8%|▊         | 357/4500 [00:00<00:12, 326.15it/s]  9%|▉         | 394/4500 [00:01<00:15, 268.96it/s] 10%|▉         | 434/4500 [00:01<00:13, 295.41it/s] 10%|█         | 468/4500 [00:01<00:13, 301.10it/s] 11%|█▏        | 514/4500 [00:01<00:11, 339.17it/s] 12%|█▏        | 551/4500 [00:01<00:11, 346.68it/s] 13%|█▎        | 588/4500 [00:01<00:11, 351.80it/s] 14%|█▍        | 642/4500 [00:01<00:09, 398.06it/s] 15%|█▌        | 692/4500 [00:01<00:09, 418.80it/s] 16%|█▋        | 735/4500 [00:02<00:09, 397.33it/s] 17%|█▋        | 776/4500 [00:02<00:09, 392.60it/s] 18%|█▊        | 822/4500 [00:02<00:09, 407.82it/s] 20%|█▉        | 880/4500 [00:02<00:07, 455.55it/s] 21%|██        | 942/4500 [00:02<00:07, 502.75it/s] 22%|██▏       | 1008/4500 [00:02<00:06, 544.13it/s] 24%|██▍       | 1071/4500 [00:02<00:06, 568.83it/s] 26%|██▋       | 1188/4500 [00:02<00:04, 745.48it/s] 28%|██▊       | 1275/4500 [00:02<00:04, 767.07it/s] 30%|███       | 1364/4500 [00:02<00:04, 776.37it/s] 32%|███▏      | 1442/4500 [00:03<00:05, 598.67it/s] 34%|███▎      | 1508/4500 [00:03<00:06, 495.14it/s] 35%|███▌      | 1580/4500 [00:03<00:05, 541.11it/s] 36%|███▋      | 1641/4500 [00:03<00:05, 506.93it/s] 38%|███▊      | 1697/4500 [00:03<00:06, 462.98it/s] 39%|███▉      | 1747/4500 [00:03<00:05, 468.76it/s] 41%|████      | 1833/4500 [00:03<00:04, 563.29it/s] 43%|████▎     | 1916/4500 [00:04<00:04, 630.15it/s] 45%|████▍     | 2006/4500 [00:04<00:03, 701.84it/s] 46%|████▌     | 2080/4500 [00:04<00:03, 710.77it/s] 48%|████▊     | 2154/4500 [00:04<00:03, 667.73it/s] 49%|████▉     | 2223/4500 [00:04<00:03, 624.89it/s] 51%|█████     | 2288/4500 [00:04<00:03, 569.57it/s] 52%|█████▏    | 2347/4500 [00:04<00:04, 497.82it/s] 53%|█████▎    | 2403/4500 [00:04<00:04, 512.03it/s] 55%|█████▍    | 2470/4500 [00:05<00:03, 542.12it/s] 57%|█████▋    | 2556/4500 [00:05<00:03, 617.88it/s] 59%|█████▉    | 2655/4500 [00:05<00:02, 701.01it/s] 61%|██████    | 2727/4500 [00:05<00:02, 654.89it/s] 62%|██████▏   | 2800/4500 [00:05<00:02, 663.86it/s] 64%|██████▍   | 2886/4500 [00:05<00:02, 699.64it/s] 66%|██████▌   | 2957/4500 [00:05<00:02, 698.09it/s] 67%|██████▋   | 3031/4500 [00:05<00:02, 689.99it/s] 69%|██████▉   | 3101/4500 [00:05<00:02, 656.88it/s] 70%|███████   | 3168/4500 [00:06<00:02, 583.73it/s] 72%|███████▏  | 3228/4500 [00:06<00:02, 502.75it/s] 73%|███████▎  | 3305/4500 [00:06<00:02, 560.39it/s] 75%|███████▍  | 3365/4500 [00:06<00:02, 522.57it/s] 76%|███████▌  | 3431/4500 [00:06<00:02, 530.61it/s] 78%|███████▊  | 3490/4500 [00:06<00:01, 545.53it/s] 79%|███████▉  | 3546/4500 [00:07<00:02, 332.50it/s] 80%|███████▉  | 3591/4500 [00:07<00:03, 284.23it/s] 81%|████████  | 3633/4500 [00:07<00:02, 307.54it/s] 82%|████████▏ | 3702/4500 [00:07<00:02, 382.22it/s] 84%|████████▎ | 3765/4500 [00:07<00:01, 432.44it/s] 86%|████████▌ | 3859/4500 [00:07<00:01, 552.69it/s] 87%|████████▋ | 3925/4500 [00:07<00:01, 573.21it/s] 89%|████████▉ | 3996/4500 [00:07<00:00, 606.62it/s] 90%|█████████ | 4062/4500 [00:08<00:00, 562.27it/s] 92%|█████████▏| 4133/4500 [00:08<00:00, 600.22it/s] 93%|█████████▎| 4197/4500 [00:08<00:00, 464.48it/s] 95%|█████████▌| 4276/4500 [00:08<00:00, 531.09it/s] 96%|█████████▋| 4336/4500 [00:08<00:00, 484.54it/s] 98%|█████████▊| 4409/4500 [00:08<00:00, 539.46it/s] 99%|█████████▉| 4469/4500 [00:08<00:00, 548.81it/s]100%|██████████| 4500/4500 [00:08<00:00, 510.12it/s]
test_p39 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p39
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p39.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.01s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.96it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.07it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.29it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.78it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p39_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p39_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p39_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p39_Holmes_probs.npy
{'Accuracy': 0.9436, 'Precision': 0.9456, 'Recall': 0.9436, 'F1-score': 0.9431}
starting gen taf script for test_p40
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 75/4500 [00:00<00:05, 739.29it/s]  3%|▎         | 149/4500 [00:00<00:06, 625.27it/s]  5%|▍         | 213/4500 [00:00<00:07, 587.28it/s]  6%|▌         | 273/4500 [00:00<00:07, 558.43it/s]  7%|▋         | 330/4500 [00:00<00:09, 454.47it/s]  8%|▊         | 378/4500 [00:00<00:10, 391.18it/s]  9%|▉         | 420/4500 [00:00<00:10, 384.34it/s] 10%|█         | 465/4500 [00:01<00:10, 399.78it/s] 11%|█▏        | 515/4500 [00:01<00:09, 417.25it/s] 12%|█▏        | 558/4500 [00:01<00:10, 371.61it/s] 13%|█▎        | 604/4500 [00:01<00:09, 391.75it/s] 14%|█▍        | 652/4500 [00:01<00:09, 414.80it/s] 15%|█▌        | 695/4500 [00:01<00:09, 400.84it/s] 16%|█▋        | 736/4500 [00:01<00:10, 372.68it/s] 17%|█▋        | 775/4500 [00:01<00:10, 360.22it/s] 18%|█▊        | 819/4500 [00:01<00:09, 378.50it/s] 19%|█▉        | 869/4500 [00:02<00:08, 410.93it/s] 21%|██        | 926/4500 [00:02<00:07, 455.07it/s] 22%|██▏       | 973/4500 [00:02<00:08, 430.32it/s] 23%|██▎       | 1030/4500 [00:02<00:07, 468.67it/s] 24%|██▍       | 1099/4500 [00:02<00:06, 525.52it/s] 26%|██▋       | 1184/4500 [00:02<00:05, 618.09it/s] 28%|██▊       | 1280/4500 [00:02<00:04, 713.61it/s] 30%|███       | 1353/4500 [00:02<00:04, 661.01it/s] 32%|███▏      | 1421/4500 [00:02<00:05, 590.12it/s] 33%|███▎      | 1483/4500 [00:03<00:05, 542.97it/s] 34%|███▍      | 1540/4500 [00:03<00:05, 526.17it/s] 35%|███▌      | 1594/4500 [00:03<00:05, 509.90it/s] 37%|███▋      | 1646/4500 [00:03<00:05, 507.65it/s] 38%|███▊      | 1698/4500 [00:03<00:07, 399.78it/s] 39%|███▉      | 1757/4500 [00:03<00:06, 435.96it/s] 41%|████      | 1844/4500 [00:03<00:04, 535.70it/s] 43%|████▎     | 1926/4500 [00:03<00:04, 602.39it/s] 45%|████▌     | 2026/4500 [00:04<00:03, 699.25it/s] 47%|████▋     | 2100/4500 [00:04<00:03, 640.11it/s] 48%|████▊     | 2168/4500 [00:04<00:03, 637.17it/s] 50%|████▉     | 2234/4500 [00:04<00:04, 516.10it/s] 51%|█████     | 2291/4500 [00:04<00:04, 489.33it/s] 52%|█████▏    | 2344/4500 [00:04<00:04, 498.48it/s] 53%|█████▎    | 2397/4500 [00:04<00:04, 452.39it/s] 55%|█████▍    | 2460/4500 [00:04<00:04, 491.84it/s] 56%|█████▌    | 2521/4500 [00:05<00:03, 510.19it/s] 57%|█████▋    | 2574/4500 [00:05<00:03, 507.46it/s] 58%|█████▊    | 2627/4500 [00:05<00:03, 494.82it/s] 60%|█████▉    | 2688/4500 [00:05<00:03, 524.65it/s] 61%|██████    | 2751/4500 [00:05<00:03, 553.87it/s] 63%|██████▎   | 2831/4500 [00:05<00:02, 622.69it/s] 64%|██████▍   | 2901/4500 [00:05<00:02, 630.04it/s] 66%|██████▌   | 2973/4500 [00:05<00:02, 655.84it/s] 68%|██████▊   | 3041/4500 [00:05<00:02, 662.51it/s] 69%|██████▉   | 3108/4500 [00:06<00:02, 624.53it/s] 70%|███████   | 3172/4500 [00:06<00:02, 496.00it/s] 72%|███████▏  | 3234/4500 [00:06<00:02, 525.54it/s] 74%|███████▎  | 3310/4500 [00:06<00:02, 579.21it/s] 75%|███████▍  | 3372/4500 [00:06<00:01, 564.83it/s] 76%|███████▌  | 3431/4500 [00:06<00:01, 546.95it/s] 78%|███████▊  | 3488/4500 [00:06<00:01, 522.64it/s] 79%|███████▊  | 3542/4500 [00:07<00:03, 296.40it/s] 80%|███████▉  | 3584/4500 [00:07<00:03, 268.62it/s] 81%|████████  | 3637/4500 [00:07<00:02, 305.39it/s] 82%|████████▏ | 3692/4500 [00:07<00:02, 348.07it/s] 83%|████████▎ | 3754/4500 [00:07<00:01, 399.02it/s] 86%|████████▌ | 3851/4500 [00:07<00:01, 523.91it/s] 87%|████████▋ | 3918/4500 [00:07<00:01, 558.48it/s] 89%|████████▉ | 4011/4500 [00:08<00:00, 651.16it/s] 91%|█████████ | 4082/4500 [00:08<00:00, 571.99it/s] 92%|█████████▏| 4145/4500 [00:08<00:00, 557.93it/s] 93%|█████████▎| 4205/4500 [00:08<00:00, 516.92it/s] 95%|█████████▌| 4293/4500 [00:08<00:00, 605.83it/s] 97%|█████████▋| 4358/4500 [00:08<00:00, 554.58it/s] 98%|█████████▊| 4426/4500 [00:08<00:00, 584.57it/s]100%|██████████| 4500/4500 [00:08<00:00, 506.81it/s]
test_p40 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p40
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p40.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.06it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.32it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.64it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.94it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.31it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p40_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p40_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p40_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p40_Holmes_probs.npy
{'Accuracy': 0.9471, 'Precision': 0.9489, 'Recall': 0.9471, 'F1-score': 0.9468}
starting gen taf script for test_p41
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 75/4500 [00:00<00:05, 749.36it/s]  3%|▎         | 150/4500 [00:00<00:07, 588.70it/s]  5%|▍         | 211/4500 [00:00<00:08, 535.84it/s]  6%|▌         | 272/4500 [00:00<00:07, 539.29it/s]  7%|▋         | 327/4500 [00:00<00:09, 445.78it/s]  8%|▊         | 374/4500 [00:00<00:12, 342.19it/s]  9%|▉         | 413/4500 [00:00<00:12, 339.65it/s] 10%|█         | 464/4500 [00:01<00:10, 378.26it/s] 11%|█▏        | 512/4500 [00:01<00:10, 398.69it/s] 13%|█▎        | 587/4500 [00:01<00:08, 488.27it/s] 15%|█▍        | 667/4500 [00:01<00:06, 569.04it/s] 17%|█▋        | 753/4500 [00:01<00:05, 648.62it/s] 19%|█▉        | 846/4500 [00:01<00:05, 722.94it/s] 21%|██        | 928/4500 [00:01<00:04, 732.80it/s] 23%|██▎       | 1019/4500 [00:01<00:04, 769.03it/s] 24%|██▍       | 1098/4500 [00:02<00:05, 620.30it/s] 27%|██▋       | 1211/4500 [00:02<00:04, 738.76it/s] 29%|██▉       | 1302/4500 [00:02<00:04, 782.47it/s] 31%|███       | 1386/4500 [00:02<00:04, 719.00it/s] 33%|███▎      | 1463/4500 [00:02<00:04, 638.47it/s] 34%|███▍      | 1531/4500 [00:02<00:05, 548.30it/s] 36%|███▌      | 1601/4500 [00:02<00:04, 582.70it/s] 37%|███▋      | 1664/4500 [00:02<00:05, 510.69it/s] 38%|███▊      | 1720/4500 [00:03<00:05, 472.00it/s] 40%|███▉      | 1795/4500 [00:03<00:05, 528.46it/s] 41%|████▏     | 1867/4500 [00:03<00:04, 569.02it/s] 43%|████▎     | 1952/4500 [00:03<00:04, 635.94it/s] 45%|████▍     | 2019/4500 [00:03<00:03, 640.04it/s] 46%|████▋     | 2086/4500 [00:03<00:03, 616.64it/s] 49%|████▊     | 2184/4500 [00:03<00:03, 714.86it/s] 50%|█████     | 2258/4500 [00:03<00:04, 534.51it/s] 52%|█████▏    | 2320/4500 [00:04<00:04, 512.58it/s] 53%|█████▎    | 2377/4500 [00:04<00:04, 471.76it/s] 54%|█████▍    | 2429/4500 [00:04<00:04, 477.26it/s] 55%|█████▌    | 2488/4500 [00:04<00:04, 496.64it/s] 57%|█████▋    | 2581/4500 [00:04<00:03, 595.51it/s] 59%|█████▉    | 2644/4500 [00:04<00:03, 604.39it/s] 60%|██████    | 2707/4500 [00:04<00:03, 563.46it/s] 61%|██████▏   | 2766/4500 [00:04<00:03, 543.97it/s] 63%|██████▎   | 2823/4500 [00:05<00:03, 550.54it/s] 64%|██████▍   | 2881/4500 [00:05<00:02, 548.40it/s] 66%|██████▌   | 2979/4500 [00:05<00:02, 655.39it/s] 68%|██████▊   | 3046/4500 [00:05<00:02, 628.43it/s] 69%|██████▉   | 3110/4500 [00:05<00:02, 606.05it/s] 70%|███████   | 3172/4500 [00:05<00:02, 489.58it/s] 72%|███████▏  | 3226/4500 [00:05<00:02, 492.05it/s] 73%|███████▎  | 3307/4500 [00:05<00:02, 561.23it/s] 75%|███████▍  | 3366/4500 [00:06<00:02, 505.74it/s] 76%|███████▌  | 3420/4500 [00:06<00:02, 464.95it/s] 78%|███████▊  | 3493/4500 [00:06<00:01, 524.57it/s] 79%|███████▉  | 3549/4500 [00:06<00:03, 294.05it/s] 80%|███████▉  | 3592/4500 [00:06<00:03, 249.15it/s] 81%|████████  | 3647/4500 [00:07<00:02, 292.23it/s] 83%|████████▎ | 3713/4500 [00:07<00:02, 357.21it/s] 84%|████████▎ | 3766/4500 [00:07<00:01, 384.13it/s] 86%|████████▌ | 3865/4500 [00:07<00:01, 518.99it/s] 87%|████████▋ | 3928/4500 [00:07<00:01, 518.60it/s] 89%|████████▊ | 3992/4500 [00:07<00:00, 536.02it/s] 90%|█████████ | 4052/4500 [00:07<00:00, 550.52it/s] 91%|█████████▏| 4112/4500 [00:07<00:00, 519.71it/s] 93%|█████████▎| 4171/4500 [00:07<00:00, 521.53it/s] 94%|█████████▍| 4226/4500 [00:08<00:00, 507.13it/s] 96%|█████████▌| 4309/4500 [00:08<00:00, 562.17it/s] 97%|█████████▋| 4367/4500 [00:08<00:00, 477.63it/s] 99%|█████████▊| 4442/4500 [00:08<00:00, 534.54it/s]100%|██████████| 4500/4500 [00:08<00:00, 529.14it/s]
test_p41 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p41
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p41.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.04it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.25it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.71it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.06it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.26it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p41_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p41_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p41_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p41_Holmes_probs.npy
{'Accuracy': 0.9516, 'Precision': 0.9535, 'Recall': 0.9516, 'F1-score': 0.9513}
starting gen taf script for test_p42
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 100/4500 [00:00<00:04, 912.97it/s]  4%|▍         | 192/4500 [00:00<00:08, 527.64it/s]  6%|▌         | 254/4500 [00:00<00:08, 523.42it/s]  7%|▋         | 311/4500 [00:00<00:08, 502.91it/s]  8%|▊         | 364/4500 [00:00<00:11, 360.99it/s]  9%|▉         | 406/4500 [00:01<00:13, 314.26it/s] 10%|█         | 453/4500 [00:01<00:11, 344.73it/s] 11%|█         | 505/4500 [00:01<00:10, 380.99it/s] 12%|█▏        | 548/4500 [00:01<00:10, 374.17it/s] 13%|█▎        | 595/4500 [00:01<00:09, 397.90it/s] 14%|█▍        | 638/4500 [00:01<00:09, 386.27it/s] 15%|█▌        | 679/4500 [00:01<00:09, 382.61it/s] 16%|█▌        | 720/4500 [00:01<00:09, 382.65it/s] 17%|█▋        | 767/4500 [00:01<00:09, 405.34it/s] 18%|█▊        | 822/4500 [00:01<00:08, 440.47it/s] 20%|██        | 905/4500 [00:02<00:06, 547.88it/s] 22%|██▏       | 973/4500 [00:02<00:06, 560.30it/s] 23%|██▎       | 1038/4500 [00:02<00:05, 581.09it/s] 24%|██▍       | 1100/4500 [00:02<00:05, 588.25it/s] 26%|██▌       | 1163/4500 [00:02<00:05, 600.28it/s] 28%|██▊       | 1253/4500 [00:02<00:04, 683.07it/s] 30%|██▉       | 1338/4500 [00:02<00:04, 723.14it/s] 31%|███▏      | 1411/4500 [00:02<00:05, 595.82it/s] 33%|███▎      | 1475/4500 [00:03<00:06, 502.31it/s] 35%|███▍      | 1572/4500 [00:03<00:04, 604.67it/s] 36%|███▋      | 1639/4500 [00:03<00:05, 516.07it/s] 38%|███▊      | 1697/4500 [00:03<00:05, 471.54it/s] 40%|███▉      | 1788/4500 [00:03<00:04, 567.98it/s] 41%|████      | 1851/4500 [00:03<00:04, 568.60it/s] 44%|████▎     | 1962/4500 [00:03<00:03, 704.13it/s] 46%|████▌     | 2057/4500 [00:03<00:03, 759.73it/s] 48%|████▊     | 2138/4500 [00:04<00:03, 686.64it/s] 49%|████▉     | 2211/4500 [00:04<00:03, 611.73it/s] 51%|█████     | 2277/4500 [00:04<00:04, 535.93it/s] 52%|█████▏    | 2335/4500 [00:04<00:04, 479.83it/s] 53%|█████▎    | 2387/4500 [00:04<00:04, 465.98it/s] 55%|█████▍    | 2453/4500 [00:04<00:04, 508.61it/s] 56%|█████▌    | 2519/4500 [00:04<00:03, 537.61it/s] 58%|█████▊    | 2592/4500 [00:04<00:03, 587.40it/s] 59%|█████▉    | 2654/4500 [00:05<00:03, 560.97it/s] 60%|██████    | 2712/4500 [00:05<00:03, 554.79it/s] 62%|██████▏   | 2769/4500 [00:05<00:03, 540.80it/s] 63%|██████▎   | 2855/4500 [00:05<00:02, 620.78it/s] 65%|██████▍   | 2919/4500 [00:05<00:02, 623.30it/s] 66%|██████▋   | 2983/4500 [00:05<00:02, 599.91it/s] 68%|██████▊   | 3044/4500 [00:05<00:02, 589.94it/s] 69%|██████▉   | 3109/4500 [00:05<00:02, 600.86it/s] 70%|███████   | 3170/4500 [00:06<00:02, 521.52it/s] 72%|███████▏  | 3225/4500 [00:06<00:02, 508.74it/s] 73%|███████▎  | 3283/4500 [00:06<00:02, 518.85it/s] 74%|███████▍  | 3346/4500 [00:06<00:02, 538.34it/s] 76%|███████▌  | 3401/4500 [00:06<00:02, 480.41it/s] 77%|███████▋  | 3456/4500 [00:06<00:02, 497.79it/s] 78%|███████▊  | 3508/4500 [00:06<00:02, 413.18it/s] 79%|███████▉  | 3553/4500 [00:07<00:03, 302.50it/s] 80%|███████▉  | 3590/4500 [00:07<00:04, 224.41it/s] 81%|████████▏ | 3664/4500 [00:07<00:02, 308.20it/s] 83%|████████▎ | 3716/4500 [00:07<00:02, 343.87it/s] 84%|████████▍ | 3791/4500 [00:07<00:01, 429.14it/s] 86%|████████▌ | 3857/4500 [00:07<00:01, 480.32it/s] 87%|████████▋ | 3919/4500 [00:07<00:01, 503.95it/s] 89%|████████▉ | 4011/4500 [00:07<00:00, 595.80it/s] 91%|█████████ | 4076/4500 [00:08<00:00, 514.87it/s] 92%|█████████▏| 4133/4500 [00:08<00:00, 478.58it/s] 93%|█████████▎| 4185/4500 [00:08<00:00, 445.83it/s] 95%|█████████▌| 4285/4500 [00:08<00:00, 576.50it/s] 97%|█████████▋| 4348/4500 [00:08<00:00, 550.92it/s] 98%|█████████▊| 4423/4500 [00:08<00:00, 599.55it/s]100%|██████████| 4500/4500 [00:08<00:00, 508.13it/s]
test_p42 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p42
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p42.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.03s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.81it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.95it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.06it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.56it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p42_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p42_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p42_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p42_Holmes_probs.npy
{'Accuracy': 0.9527, 'Precision': 0.9544, 'Recall': 0.9527, 'F1-score': 0.9524}
starting gen taf script for test_p43
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 77/4500 [00:00<00:06, 702.82it/s]  3%|▎         | 148/4500 [00:00<00:07, 596.23it/s]  5%|▍         | 209/4500 [00:00<00:09, 443.79it/s]  6%|▌         | 277/4500 [00:00<00:08, 510.96it/s]  7%|▋         | 333/4500 [00:00<00:09, 433.58it/s]  8%|▊         | 381/4500 [00:00<00:12, 329.08it/s]  9%|▉         | 422/4500 [00:01<00:11, 345.66it/s] 10%|█         | 461/4500 [00:01<00:13, 295.47it/s] 11%|█         | 495/4500 [00:01<00:15, 255.29it/s] 12%|█▏        | 526/4500 [00:01<00:15, 264.33it/s] 13%|█▎        | 569/4500 [00:01<00:13, 300.38it/s] 13%|█▎        | 606/4500 [00:01<00:12, 310.49it/s] 14%|█▍        | 640/4500 [00:01<00:12, 315.78it/s] 15%|█▌        | 676/4500 [00:01<00:11, 322.05it/s] 16%|█▌        | 713/4500 [00:02<00:11, 329.53it/s] 17%|█▋        | 748/4500 [00:02<00:11, 334.41it/s] 17%|█▋        | 783/4500 [00:02<00:12, 308.42it/s] 18%|█▊        | 832/4500 [00:02<00:10, 354.49it/s] 20%|█▉        | 891/4500 [00:02<00:08, 413.85it/s] 21%|██        | 934/4500 [00:02<00:08, 407.39it/s] 22%|██▏       | 976/4500 [00:02<00:08, 404.99it/s] 23%|██▎       | 1025/4500 [00:02<00:08, 424.87it/s] 24%|██▍       | 1096/4500 [00:02<00:06, 505.18it/s] 26%|██▋       | 1182/4500 [00:03<00:05, 598.17it/s] 28%|██▊       | 1279/4500 [00:03<00:04, 696.06it/s] 30%|██▉       | 1349/4500 [00:03<00:04, 645.14it/s] 31%|███▏      | 1415/4500 [00:03<00:04, 623.80it/s] 33%|███▎      | 1479/4500 [00:03<00:05, 539.75it/s] 34%|███▍      | 1536/4500 [00:03<00:05, 499.48it/s] 35%|███▌      | 1594/4500 [00:03<00:05, 515.40it/s] 37%|███▋      | 1648/4500 [00:03<00:06, 469.52it/s] 38%|███▊      | 1697/4500 [00:04<00:06, 417.32it/s] 39%|███▉      | 1777/4500 [00:04<00:05, 508.68it/s] 41%|████      | 1852/4500 [00:04<00:04, 567.00it/s] 43%|████▎     | 1940/4500 [00:04<00:03, 640.35it/s] 45%|████▍     | 2016/4500 [00:04<00:03, 658.91it/s] 46%|████▋     | 2090/4500 [00:04<00:03, 664.06it/s] 48%|████▊     | 2158/4500 [00:04<00:03, 643.75it/s] 49%|████▉     | 2224/4500 [00:04<00:04, 555.42it/s] 51%|█████     | 2283/4500 [00:04<00:04, 527.63it/s] 52%|█████▏    | 2338/4500 [00:05<00:04, 462.75it/s] 53%|█████▎    | 2387/4500 [00:05<00:05, 390.10it/s] 55%|█████▍    | 2473/4500 [00:05<00:04, 478.17it/s] 56%|█████▋    | 2535/4500 [00:05<00:03, 506.40it/s] 58%|█████▊    | 2605/4500 [00:05<00:03, 554.41it/s] 59%|█████▉    | 2666/4500 [00:05<00:03, 568.39it/s] 61%|██████    | 2733/4500 [00:05<00:02, 589.05it/s] 62%|██████▏   | 2794/4500 [00:05<00:02, 575.82it/s] 64%|██████▎   | 2862/4500 [00:06<00:02, 601.05it/s] 65%|██████▌   | 2929/4500 [00:06<00:02, 614.29it/s] 66%|██████▋   | 2992/4500 [00:06<00:02, 589.15it/s] 68%|██████▊   | 3061/4500 [00:06<00:02, 609.76it/s] 69%|██████▉   | 3123/4500 [00:06<00:02, 522.22it/s] 71%|███████   | 3178/4500 [00:06<00:02, 491.89it/s] 72%|███████▏  | 3229/4500 [00:06<00:02, 444.21it/s] 73%|███████▎  | 3295/4500 [00:06<00:02, 484.18it/s] 74%|███████▍  | 3349/4500 [00:07<00:02, 487.60it/s] 76%|███████▌  | 3400/4500 [00:07<00:02, 480.93it/s] 77%|███████▋  | 3449/4500 [00:07<00:02, 455.77it/s] 78%|███████▊  | 3501/4500 [00:07<00:02, 449.70it/s] 79%|███████▉  | 3547/4500 [00:07<00:03, 268.03it/s] 80%|███████▉  | 3583/4500 [00:07<00:03, 230.99it/s] 81%|████████  | 3625/4500 [00:08<00:03, 263.62it/s] 82%|████████▏ | 3676/4500 [00:08<00:02, 306.90it/s] 83%|████████▎ | 3747/4500 [00:08<00:01, 389.76it/s] 85%|████████▍ | 3807/4500 [00:08<00:01, 432.97it/s] 87%|████████▋ | 3894/4500 [00:08<00:01, 532.09it/s] 88%|████████▊ | 3969/4500 [00:08<00:00, 586.31it/s] 90%|████████▉ | 4036/4500 [00:08<00:00, 596.24it/s] 91%|█████████ | 4099/4500 [00:08<00:00, 553.97it/s] 92%|█████████▏| 4158/4500 [00:09<00:00, 483.29it/s] 94%|█████████▎| 4210/4500 [00:09<00:00, 477.66it/s] 96%|█████████▌| 4305/4500 [00:09<00:00, 564.26it/s] 97%|█████████▋| 4364/4500 [00:09<00:00, 521.22it/s] 98%|█████████▊| 4424/4500 [00:09<00:00, 540.69it/s]100%|██████████| 4500/4500 [00:09<00:00, 470.50it/s]
test_p43 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p43
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p43.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.77it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.89it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.13it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.53it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p43_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p43_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p43_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p43_Holmes_probs.npy
{'Accuracy': 0.956, 'Precision': 0.9574, 'Recall': 0.956, 'F1-score': 0.9557}
starting gen taf script for test_p44
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 81/4500 [00:00<00:05, 793.06it/s]  4%|▎         | 161/4500 [00:00<00:08, 518.92it/s]  5%|▍         | 219/4500 [00:00<00:08, 511.95it/s]  6%|▌         | 280/4500 [00:00<00:07, 542.98it/s]  7%|▋         | 337/4500 [00:00<00:10, 379.58it/s]  8%|▊         | 382/4500 [00:00<00:13, 316.22it/s]  9%|▉         | 419/4500 [00:01<00:12, 315.70it/s] 11%|█         | 474/4500 [00:01<00:11, 365.00it/s] 11%|█▏        | 516/4500 [00:01<00:10, 374.43it/s] 12%|█▏        | 557/4500 [00:01<00:10, 361.93it/s] 13%|█▎        | 596/4500 [00:01<00:10, 356.82it/s] 14%|█▍        | 636/4500 [00:01<00:10, 367.52it/s] 15%|█▌        | 675/4500 [00:01<00:10, 369.45it/s] 16%|█▌        | 718/4500 [00:01<00:09, 378.94it/s] 17%|█▋        | 757/4500 [00:01<00:10, 369.93it/s] 18%|█▊        | 795/4500 [00:02<00:10, 367.29it/s] 20%|█▉        | 878/4500 [00:02<00:07, 490.10it/s] 21%|██        | 939/4500 [00:02<00:06, 521.22it/s] 22%|██▏       | 1005/4500 [00:02<00:06, 542.15it/s] 24%|██▎       | 1061/4500 [00:02<00:06, 539.72it/s] 26%|██▌       | 1163/4500 [00:02<00:04, 675.61it/s] 28%|██▊       | 1246/4500 [00:02<00:04, 705.51it/s] 30%|██▉       | 1335/4500 [00:02<00:04, 742.30it/s] 31%|███▏      | 1410/4500 [00:02<00:04, 728.66it/s] 33%|███▎      | 1484/4500 [00:03<00:05, 535.52it/s] 34%|███▍      | 1545/4500 [00:03<00:05, 536.62it/s] 36%|███▌      | 1606/4500 [00:03<00:05, 548.85it/s] 37%|███▋      | 1665/4500 [00:03<00:06, 467.42it/s] 38%|███▊      | 1717/4500 [00:03<00:05, 473.96it/s] 39%|███▉      | 1770/4500 [00:03<00:05, 486.31it/s] 41%|████      | 1837/4500 [00:03<00:04, 533.57it/s] 43%|████▎     | 1925/4500 [00:03<00:04, 626.92it/s] 45%|████▌     | 2027/4500 [00:04<00:03, 720.04it/s] 47%|████▋     | 2102/4500 [00:04<00:03, 662.97it/s] 48%|████▊     | 2175/4500 [00:04<00:03, 664.52it/s] 50%|████▉     | 2243/4500 [00:04<00:03, 575.56it/s] 51%|█████     | 2304/4500 [00:04<00:03, 562.03it/s] 53%|█████▎    | 2363/4500 [00:04<00:04, 492.09it/s] 54%|█████▎    | 2415/4500 [00:04<00:04, 437.60it/s] 55%|█████▌    | 2497/4500 [00:04<00:03, 526.06it/s] 58%|█████▊    | 2591/4500 [00:05<00:03, 618.78it/s] 59%|█████▉    | 2658/4500 [00:05<00:03, 552.55it/s] 61%|██████    | 2726/4500 [00:05<00:03, 572.83it/s] 62%|██████▏   | 2787/4500 [00:05<00:03, 553.17it/s] 63%|██████▎   | 2855/4500 [00:05<00:02, 563.07it/s] 65%|██████▌   | 2929/4500 [00:05<00:02, 608.08it/s] 66%|██████▋   | 2992/4500 [00:05<00:02, 605.87it/s] 68%|██████▊   | 3054/4500 [00:05<00:02, 594.75it/s] 69%|██████▉   | 3115/4500 [00:06<00:02, 522.40it/s] 70%|███████   | 3170/4500 [00:06<00:02, 471.29it/s] 72%|███████▏  | 3250/4500 [00:06<00:02, 540.15it/s] 73%|███████▎  | 3307/4500 [00:06<00:02, 510.70it/s] 75%|███████▍  | 3360/4500 [00:06<00:02, 494.35it/s] 76%|███████▌  | 3411/4500 [00:06<00:02, 483.54it/s] 77%|███████▋  | 3476/4500 [00:06<00:01, 515.46it/s] 78%|███████▊  | 3529/4500 [00:07<00:02, 355.68it/s] 79%|███████▉  | 3572/4500 [00:07<00:03, 257.07it/s] 80%|████████  | 3606/4500 [00:07<00:03, 263.44it/s] 82%|████████▏ | 3678/4500 [00:07<00:02, 345.64it/s] 83%|████████▎ | 3723/4500 [00:07<00:02, 364.22it/s] 84%|████████▍ | 3783/4500 [00:07<00:01, 418.25it/s] 86%|████████▌ | 3857/4500 [00:07<00:01, 495.98it/s] 87%|████████▋ | 3933/4500 [00:07<00:01, 562.02it/s] 89%|████████▉ | 3995/4500 [00:08<00:00, 558.84it/s] 90%|█████████ | 4060/4500 [00:08<00:00, 580.47it/s] 92%|█████████▏| 4121/4500 [00:08<00:00, 558.10it/s] 93%|█████████▎| 4179/4500 [00:08<00:00, 461.94it/s] 94%|█████████▍| 4236/4500 [00:08<00:00, 481.91it/s] 96%|█████████▌| 4320/4500 [00:08<00:00, 572.79it/s] 97%|█████████▋| 4382/4500 [00:08<00:00, 496.00it/s] 99%|█████████▊| 4436/4500 [00:09<00:00, 467.20it/s]100%|██████████| 4500/4500 [00:09<00:00, 496.73it/s]
test_p44 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p44
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p44.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.03s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.82it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.01it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.30it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.54it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p44_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p44_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p44_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p44_Holmes_probs.npy
{'Accuracy': 0.9596, 'Precision': 0.9607, 'Recall': 0.9596, 'F1-score': 0.9593}
starting gen taf script for test_p45
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 70/4500 [00:00<00:06, 679.42it/s]  3%|▎         | 138/4500 [00:00<00:07, 551.51it/s]  4%|▍         | 195/4500 [00:00<00:08, 495.71it/s]  6%|▌         | 255/4500 [00:00<00:08, 523.26it/s]  7%|▋         | 309/4500 [00:00<00:08, 484.19it/s]  8%|▊         | 359/4500 [00:00<00:11, 366.50it/s]  9%|▉         | 400/4500 [00:01<00:13, 302.09it/s] 10%|▉         | 445/4500 [00:01<00:12, 333.12it/s] 11%|█         | 483/4500 [00:01<00:11, 336.40it/s] 12%|█▏        | 528/4500 [00:01<00:11, 354.55it/s] 13%|█▎        | 569/4500 [00:01<00:10, 368.63it/s] 14%|█▎        | 609/4500 [00:01<00:10, 373.75it/s] 15%|█▍        | 653/4500 [00:01<00:09, 391.94it/s] 16%|█▌        | 699/4500 [00:01<00:09, 408.35it/s] 16%|█▋        | 741/4500 [00:01<00:10, 354.39it/s] 18%|█▊        | 789/4500 [00:02<00:09, 386.55it/s] 19%|█▉        | 863/4500 [00:02<00:07, 473.37it/s] 21%|██        | 954/4500 [00:02<00:06, 582.05it/s] 23%|██▎       | 1017/4500 [00:02<00:05, 585.06it/s] 24%|██▍       | 1095/4500 [00:02<00:05, 634.65it/s] 27%|██▋       | 1201/4500 [00:02<00:04, 738.85it/s] 28%|██▊       | 1276/4500 [00:02<00:04, 707.87it/s] 30%|███       | 1360/4500 [00:02<00:04, 737.83it/s] 32%|███▏      | 1435/4500 [00:02<00:04, 667.08it/s] 33%|███▎      | 1504/4500 [00:03<00:05, 519.09it/s] 35%|███▌      | 1587/4500 [00:03<00:04, 589.75it/s] 37%|███▋      | 1653/4500 [00:03<00:06, 468.14it/s] 38%|███▊      | 1708/4500 [00:03<00:05, 467.07it/s] 39%|███▉      | 1765/4500 [00:03<00:05, 490.30it/s] 40%|████      | 1819/4500 [00:03<00:05, 502.41it/s] 42%|████▏     | 1907/4500 [00:03<00:04, 591.68it/s] 44%|████▍     | 1973/4500 [00:03<00:04, 603.42it/s] 45%|████▌     | 2036/4500 [00:04<00:04, 572.52it/s] 47%|████▋     | 2096/4500 [00:04<00:04, 558.75it/s] 48%|████▊     | 2154/4500 [00:04<00:04, 564.38it/s] 49%|████▉     | 2212/4500 [00:04<00:04, 552.80it/s] 50%|█████     | 2268/4500 [00:04<00:04, 500.42it/s] 52%|█████▏    | 2320/4500 [00:04<00:05, 415.38it/s] 53%|█████▎    | 2365/4500 [00:04<00:05, 382.19it/s] 53%|█████▎    | 2406/4500 [00:04<00:05, 385.53it/s] 55%|█████▍    | 2468/4500 [00:05<00:04, 438.98it/s] 57%|█████▋    | 2548/4500 [00:05<00:03, 523.60it/s] 58%|█████▊    | 2621/4500 [00:05<00:03, 539.45it/s] 59%|█████▉    | 2677/4500 [00:05<00:03, 478.18it/s] 61%|██████    | 2742/4500 [00:05<00:03, 516.85it/s] 62%|██████▏   | 2811/4500 [00:05<00:03, 558.19it/s] 64%|██████▍   | 2869/4500 [00:05<00:02, 559.05it/s] 65%|██████▌   | 2927/4500 [00:05<00:03, 516.44it/s] 67%|██████▋   | 3006/4500 [00:06<00:02, 588.41it/s] 68%|██████▊   | 3067/4500 [00:06<00:02, 537.83it/s] 69%|██████▉   | 3123/4500 [00:06<00:02, 535.94it/s] 71%|███████   | 3178/4500 [00:06<00:02, 472.95it/s] 72%|███████▏  | 3243/4500 [00:06<00:02, 513.08it/s] 73%|███████▎  | 3305/4500 [00:06<00:02, 538.40it/s] 75%|███████▍  | 3361/4500 [00:06<00:02, 470.65it/s] 76%|███████▌  | 3412/4500 [00:06<00:02, 450.28it/s] 77%|███████▋  | 3464/4500 [00:07<00:02, 466.45it/s] 78%|███████▊  | 3513/4500 [00:07<00:02, 339.69it/s] 79%|███████▉  | 3553/4500 [00:07<00:03, 272.83it/s] 80%|███████▉  | 3586/4500 [00:07<00:04, 215.32it/s] 80%|████████  | 3614/4500 [00:07<00:03, 223.67it/s] 81%|████████▏ | 3661/4500 [00:07<00:03, 271.51it/s] 83%|████████▎ | 3720/4500 [00:08<00:02, 340.20it/s] 84%|████████▍ | 3788/4500 [00:08<00:01, 413.80it/s] 86%|████████▌ | 3855/4500 [00:08<00:01, 476.12it/s] 87%|████████▋ | 3928/4500 [00:08<00:01, 535.55it/s] 89%|████████▉ | 4000/4500 [00:08<00:00, 576.91it/s] 90%|█████████ | 4062/4500 [00:08<00:00, 522.93it/s] 92%|█████████▏| 4118/4500 [00:08<00:00, 513.05it/s] 93%|█████████▎| 4172/4500 [00:08<00:00, 474.88it/s] 94%|█████████▍| 4222/4500 [00:08<00:00, 478.94it/s] 96%|█████████▌| 4298/4500 [00:09<00:00, 540.69it/s] 97%|█████████▋| 4355/4500 [00:09<00:00, 543.80it/s] 98%|█████████▊| 4411/4500 [00:09<00:00, 534.10it/s] 99%|█████████▉| 4466/4500 [00:09<00:00, 517.71it/s]100%|██████████| 4500/4500 [00:09<00:00, 477.42it/s]
test_p45 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p45
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p45.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:19,  1.12s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.28it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.15it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.19it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.86it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p45_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p45_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p45_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p45_Holmes_probs.npy
{'Accuracy': 0.96, 'Precision': 0.9611, 'Recall': 0.96, 'F1-score': 0.9598}
starting gen taf script for test_p46
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 64/4500 [00:00<00:07, 632.83it/s]  3%|▎         | 128/4500 [00:00<00:08, 498.57it/s]  4%|▍         | 180/4500 [00:00<00:09, 441.20it/s]  5%|▌         | 226/4500 [00:00<00:10, 418.13it/s]  6%|▋         | 288/4500 [00:00<00:08, 473.03it/s]  7%|▋         | 337/4500 [00:00<00:12, 334.41it/s]  8%|▊         | 376/4500 [00:01<00:15, 273.45it/s]  9%|▉         | 409/4500 [00:01<00:16, 245.77it/s] 10%|▉         | 448/4500 [00:01<00:14, 272.97it/s] 11%|█         | 488/4500 [00:01<00:13, 297.94it/s] 12%|█▏        | 529/4500 [00:01<00:12, 324.36it/s] 13%|█▎        | 565/4500 [00:01<00:12, 317.95it/s] 13%|█▎        | 606/4500 [00:01<00:11, 336.22it/s] 14%|█▍        | 642/4500 [00:01<00:11, 339.76it/s] 15%|█▌        | 678/4500 [00:02<00:12, 315.62it/s] 16%|█▌        | 720/4500 [00:02<00:11, 339.52it/s] 17%|█▋        | 755/4500 [00:02<00:11, 323.53it/s] 18%|█▊        | 789/4500 [00:02<00:11, 311.75it/s] 19%|█▊        | 838/4500 [00:02<00:10, 357.84it/s] 20%|██        | 910/4500 [00:02<00:08, 448.51it/s] 22%|██▏       | 969/4500 [00:02<00:07, 484.31it/s] 23%|██▎       | 1036/4500 [00:02<00:06, 536.83it/s] 24%|██▍       | 1096/4500 [00:02<00:06, 550.77it/s] 27%|██▋       | 1199/4500 [00:02<00:04, 686.55it/s] 29%|██▊       | 1290/4500 [00:03<00:04, 736.70it/s] 30%|███       | 1365/4500 [00:03<00:05, 588.20it/s] 32%|███▏      | 1429/4500 [00:03<00:06, 500.10it/s] 33%|███▎      | 1485/4500 [00:03<00:06, 438.45it/s] 34%|███▍      | 1534/4500 [00:03<00:06, 445.38it/s] 36%|███▌      | 1602/4500 [00:03<00:06, 478.41it/s] 37%|███▋      | 1653/4500 [00:03<00:06, 447.40it/s] 38%|███▊      | 1700/4500 [00:04<00:07, 387.84it/s] 39%|███▉      | 1759/4500 [00:04<00:06, 433.92it/s] 40%|████      | 1814/4500 [00:04<00:05, 461.09it/s] 42%|████▏     | 1885/4500 [00:04<00:04, 523.94it/s] 43%|████▎     | 1952/4500 [00:04<00:04, 557.12it/s] 45%|████▍     | 2010/4500 [00:04<00:04, 551.57it/s] 46%|████▌     | 2067/4500 [00:04<00:04, 553.84it/s] 47%|████▋     | 2126/4500 [00:04<00:04, 562.91it/s] 49%|████▉     | 2204/4500 [00:04<00:03, 625.24it/s] 50%|█████     | 2268/4500 [00:05<00:04, 481.01it/s] 52%|█████▏    | 2322/4500 [00:05<00:04, 437.87it/s] 53%|█████▎    | 2371/4500 [00:05<00:05, 418.23it/s] 54%|█████▍    | 2423/4500 [00:05<00:04, 435.10it/s] 55%|█████▌    | 2477/4500 [00:05<00:04, 451.49it/s] 56%|█████▋    | 2542/4500 [00:05<00:03, 498.85it/s] 58%|█████▊    | 2621/4500 [00:05<00:03, 571.37it/s] 60%|█████▉    | 2681/4500 [00:06<00:03, 547.98it/s] 61%|██████    | 2738/4500 [00:06<00:03, 533.99it/s] 62%|██████▏   | 2793/4500 [00:06<00:03, 497.49it/s] 64%|██████▍   | 2878/4500 [00:06<00:02, 581.87it/s] 65%|██████▌   | 2938/4500 [00:06<00:02, 561.46it/s] 67%|██████▋   | 3008/4500 [00:06<00:02, 598.88it/s] 68%|██████▊   | 3075/4500 [00:06<00:02, 606.05it/s] 70%|██████▉   | 3137/4500 [00:06<00:02, 537.16it/s] 71%|███████   | 3193/4500 [00:07<00:02, 459.52it/s] 72%|███████▏  | 3242/4500 [00:07<00:02, 466.48it/s] 73%|███████▎  | 3291/4500 [00:07<00:02, 471.83it/s] 74%|███████▍  | 3345/4500 [00:07<00:02, 489.53it/s] 75%|███████▌  | 3396/4500 [00:07<00:02, 458.86it/s] 77%|███████▋  | 3444/4500 [00:07<00:02, 442.14it/s] 78%|███████▊  | 3490/4500 [00:07<00:02, 417.21it/s] 79%|███████▊  | 3533/4500 [00:07<00:03, 286.03it/s] 79%|███████▉  | 3568/4500 [00:08<00:04, 232.09it/s] 80%|███████▉  | 3597/4500 [00:08<00:04, 211.33it/s] 81%|████████  | 3649/4500 [00:08<00:03, 267.49it/s] 82%|████████▏ | 3702/4500 [00:08<00:02, 320.16it/s] 84%|████████▍ | 3775/4500 [00:08<00:01, 410.66it/s] 85%|████████▌ | 3835/4500 [00:08<00:01, 455.20it/s] 87%|████████▋ | 3919/4500 [00:08<00:01, 549.05it/s] 88%|████████▊ | 3980/4500 [00:09<00:00, 533.40it/s] 90%|█████████ | 4060/4500 [00:09<00:00, 598.72it/s] 92%|█████████▏| 4124/4500 [00:09<00:00, 527.16it/s] 93%|█████████▎| 4181/4500 [00:09<00:00, 457.97it/s] 95%|█████████▌| 4275/4500 [00:09<00:00, 568.30it/s] 96%|█████████▋| 4338/4500 [00:09<00:00, 542.97it/s] 98%|█████████▊| 4397/4500 [00:09<00:00, 527.20it/s] 99%|█████████▉| 4462/4500 [00:09<00:00, 556.13it/s]100%|██████████| 4500/4500 [00:09<00:00, 453.43it/s]
test_p46 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p46
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p46.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.73it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.78it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.94it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.45it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p46_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p46_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p46_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p46_Holmes_probs.npy
{'Accuracy': 0.9609, 'Precision': 0.9618, 'Recall': 0.9609, 'F1-score': 0.9606}
starting gen taf script for test_p47
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 77/4500 [00:00<00:06, 726.17it/s]  3%|▎         | 150/4500 [00:00<00:08, 506.04it/s]  5%|▍         | 205/4500 [00:00<00:08, 495.02it/s]  6%|▌         | 260/4500 [00:00<00:08, 512.07it/s]  7%|▋         | 313/4500 [00:00<00:08, 491.29it/s]  8%|▊         | 363/4500 [00:00<00:12, 335.86it/s]  9%|▉         | 403/4500 [00:01<00:13, 310.95it/s] 10%|█         | 451/4500 [00:01<00:11, 348.67it/s] 11%|█         | 496/4500 [00:01<00:10, 373.02it/s] 12%|█▏        | 537/4500 [00:01<00:11, 348.53it/s] 13%|█▎        | 575/4500 [00:01<00:11, 345.48it/s] 14%|█▎        | 614/4500 [00:01<00:11, 353.10it/s] 15%|█▍        | 658/4500 [00:01<00:10, 371.05it/s] 15%|█▌        | 697/4500 [00:01<00:10, 346.67it/s] 16%|█▋        | 733/4500 [00:01<00:10, 343.49it/s] 17%|█▋        | 769/4500 [00:02<00:11, 320.11it/s] 18%|█▊        | 808/4500 [00:02<00:10, 336.09it/s] 19%|█▉        | 853/4500 [00:02<00:10, 360.67it/s] 20%|██        | 901/4500 [00:02<00:09, 392.18it/s] 21%|██        | 941/4500 [00:02<00:09, 383.61it/s] 22%|██▏       | 984/4500 [00:02<00:09, 390.38it/s] 23%|██▎       | 1024/4500 [00:02<00:08, 390.62it/s] 25%|██▍       | 1117/4500 [00:02<00:06, 539.92it/s] 27%|██▋       | 1218/4500 [00:02<00:04, 673.40it/s] 29%|██▉       | 1297/4500 [00:02<00:04, 699.27it/s] 31%|███       | 1387/4500 [00:03<00:04, 731.57it/s] 32%|███▏      | 1461/4500 [00:03<00:04, 610.09it/s] 34%|███▍      | 1526/4500 [00:03<00:05, 512.79it/s] 35%|███▌      | 1582/4500 [00:03<00:06, 481.07it/s] 36%|███▋      | 1634/4500 [00:03<00:06, 445.21it/s] 37%|███▋      | 1681/4500 [00:03<00:06, 429.72it/s] 38%|███▊      | 1726/4500 [00:03<00:06, 428.20it/s] 40%|███▉      | 1785/4500 [00:04<00:05, 467.22it/s] 41%|████      | 1838/4500 [00:04<00:05, 479.10it/s] 43%|████▎     | 1918/4500 [00:04<00:04, 565.78it/s] 44%|████▍     | 1989/4500 [00:04<00:04, 593.40it/s] 46%|████▌     | 2051/4500 [00:04<00:04, 584.53it/s] 48%|████▊     | 2140/4500 [00:04<00:03, 652.24it/s] 49%|████▉     | 2206/4500 [00:04<00:04, 569.86it/s] 50%|█████     | 2266/4500 [00:04<00:04, 551.45it/s] 52%|█████▏    | 2323/4500 [00:05<00:04, 492.27it/s] 53%|█████▎    | 2374/4500 [00:05<00:05, 402.61it/s] 54%|█████▎    | 2418/4500 [00:05<00:05, 407.41it/s] 56%|█████▌    | 2504/4500 [00:05<00:03, 509.82it/s] 57%|█████▋    | 2559/4500 [00:05<00:03, 492.00it/s] 58%|█████▊    | 2611/4500 [00:05<00:03, 498.54it/s] 59%|█████▉    | 2663/4500 [00:05<00:03, 491.66it/s] 61%|██████    | 2726/4500 [00:05<00:03, 514.93it/s] 62%|██████▏   | 2792/4500 [00:05<00:03, 553.09it/s] 63%|██████▎   | 2849/4500 [00:06<00:03, 531.41it/s] 65%|██████▍   | 2903/4500 [00:06<00:03, 515.71it/s] 66%|██████▌   | 2956/4500 [00:06<00:03, 508.49it/s] 67%|██████▋   | 3019/4500 [00:06<00:02, 517.08it/s] 68%|██████▊   | 3071/4500 [00:06<00:02, 514.76it/s] 69%|██████▉   | 3123/4500 [00:06<00:03, 439.49it/s] 70%|███████   | 3169/4500 [00:06<00:03, 420.86it/s] 72%|███████▏  | 3245/4500 [00:06<00:02, 486.56it/s] 73%|███████▎  | 3295/4500 [00:07<00:02, 435.16it/s] 74%|███████▍  | 3340/4500 [00:07<00:02, 426.19it/s] 75%|███████▌  | 3384/4500 [00:07<00:02, 408.93it/s] 77%|███████▋  | 3443/4500 [00:07<00:02, 445.35it/s] 78%|███████▊  | 3489/4500 [00:07<00:02, 419.85it/s] 78%|███████▊  | 3532/4500 [00:07<00:03, 289.65it/s] 79%|███████▉  | 3567/4500 [00:08<00:03, 242.07it/s] 80%|███████▉  | 3596/4500 [00:08<00:04, 208.17it/s] 81%|████████▏ | 3661/4500 [00:08<00:02, 284.49it/s] 83%|████████▎ | 3735/4500 [00:08<00:02, 371.60it/s] 84%|████████▍ | 3783/4500 [00:08<00:01, 390.23it/s] 85%|████████▌ | 3845/4500 [00:08<00:01, 442.27it/s] 87%|████████▋ | 3913/4500 [00:08<00:01, 501.30it/s] 88%|████████▊ | 3973/4500 [00:08<00:00, 527.41it/s] 90%|████████▉ | 4038/4500 [00:08<00:00, 551.02it/s] 91%|█████████ | 4096/4500 [00:09<00:00, 525.65it/s] 92%|█████████▏| 4151/4500 [00:09<00:00, 419.37it/s] 93%|█████████▎| 4198/4500 [00:09<00:00, 414.87it/s] 95%|█████████▍| 4267/4500 [00:09<00:00, 479.28it/s] 96%|█████████▋| 4338/4500 [00:09<00:00, 522.37it/s] 98%|█████████▊| 4394/4500 [00:09<00:00, 508.07it/s] 99%|█████████▉| 4459/4500 [00:09<00:00, 545.50it/s]100%|██████████| 4500/4500 [00:09<00:00, 455.84it/s]
test_p47 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p47
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p47.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.02it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.09it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.30it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.62it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.93it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p47_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p47_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p47_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p47_Holmes_probs.npy
{'Accuracy': 0.9631, 'Precision': 0.9639, 'Recall': 0.9631, 'F1-score': 0.9629}
starting gen taf script for test_p48
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 61/4500 [00:00<00:07, 582.53it/s]  3%|▎         | 120/4500 [00:00<00:07, 561.28it/s]  4%|▍         | 177/4500 [00:00<00:08, 513.27it/s]  5%|▌         | 231/4500 [00:00<00:08, 517.48it/s]  7%|▋         | 293/4500 [00:00<00:07, 550.51it/s]  8%|▊         | 349/4500 [00:00<00:11, 359.00it/s]  9%|▊         | 393/4500 [00:01<00:14, 280.40it/s] 10%|▉         | 431/4500 [00:01<00:13, 296.47it/s] 11%|█         | 480/4500 [00:01<00:11, 338.60it/s] 12%|█▏        | 520/4500 [00:01<00:11, 346.55it/s] 12%|█▏        | 559/4500 [00:01<00:11, 350.58it/s] 13%|█▎        | 598/4500 [00:01<00:10, 360.01it/s] 14%|█▍        | 637/4500 [00:01<00:10, 362.46it/s] 15%|█▌        | 675/4500 [00:01<00:10, 360.14it/s] 16%|█▌        | 713/4500 [00:01<00:10, 353.73it/s] 17%|█▋        | 750/4500 [00:02<00:10, 345.07it/s] 18%|█▊        | 790/4500 [00:02<00:10, 353.93it/s] 19%|█▊        | 833/4500 [00:02<00:09, 371.71it/s] 20%|██        | 909/4500 [00:02<00:07, 478.05it/s] 21%|██▏       | 958/4500 [00:02<00:09, 368.19it/s] 22%|██▏       | 1003/4500 [00:02<00:09, 375.25it/s] 23%|██▎       | 1057/4500 [00:02<00:08, 412.05it/s] 25%|██▌       | 1144/4500 [00:02<00:06, 530.07it/s] 28%|██▊       | 1243/4500 [00:02<00:04, 654.13it/s] 29%|██▉       | 1313/4500 [00:03<00:04, 650.95it/s] 31%|███       | 1385/4500 [00:03<00:04, 662.18it/s] 32%|███▏      | 1454/4500 [00:03<00:05, 554.37it/s] 34%|███▎      | 1514/4500 [00:03<00:06, 447.16it/s] 35%|███▌      | 1583/4500 [00:03<00:05, 496.92it/s] 36%|███▋      | 1639/4500 [00:03<00:06, 453.75it/s] 38%|███▊      | 1689/4500 [00:04<00:07, 379.68it/s] 38%|███▊      | 1732/4500 [00:04<00:07, 386.74it/s] 40%|████      | 1815/4500 [00:04<00:05, 480.23it/s] 42%|████▏     | 1872/4500 [00:04<00:05, 500.28it/s] 43%|████▎     | 1927/4500 [00:04<00:05, 513.07it/s] 44%|████▍     | 1995/4500 [00:04<00:04, 544.19it/s] 46%|████▌     | 2052/4500 [00:04<00:04, 544.17it/s] 47%|████▋     | 2108/4500 [00:04<00:04, 544.87it/s] 48%|████▊     | 2164/4500 [00:04<00:04, 522.61it/s] 49%|████▉     | 2219/4500 [00:04<00:04, 520.65it/s] 50%|█████     | 2272/4500 [00:05<00:04, 487.88it/s] 52%|█████▏    | 2322/4500 [00:05<00:05, 389.41it/s] 53%|█████▎    | 2367/4500 [00:05<00:05, 403.54it/s] 54%|█████▎    | 2411/4500 [00:05<00:05, 399.51it/s] 55%|█████▌    | 2485/4500 [00:05<00:04, 477.51it/s] 57%|█████▋    | 2544/4500 [00:05<00:03, 505.43it/s] 58%|█████▊    | 2597/4500 [00:05<00:03, 492.33it/s] 59%|█████▉    | 2653/4500 [00:05<00:03, 507.91it/s] 60%|██████    | 2705/4500 [00:06<00:03, 504.59it/s] 61%|██████▏   | 2757/4500 [00:06<00:03, 507.64it/s] 62%|██████▏   | 2812/4500 [00:06<00:03, 505.61it/s] 64%|██████▍   | 2883/4500 [00:06<00:02, 549.79it/s] 66%|██████▌   | 2961/4500 [00:06<00:02, 614.81it/s] 67%|██████▋   | 3023/4500 [00:06<00:02, 599.00it/s] 69%|██████▊   | 3084/4500 [00:06<00:02, 568.92it/s] 70%|██████▉   | 3142/4500 [00:06<00:03, 434.17it/s] 71%|███████   | 3191/4500 [00:07<00:03, 411.00it/s] 72%|███████▏  | 3236/4500 [00:07<00:03, 416.83it/s] 73%|███████▎  | 3292/4500 [00:07<00:02, 446.39it/s] 74%|███████▍  | 3347/4500 [00:07<00:02, 464.02it/s] 75%|███████▌  | 3396/4500 [00:07<00:02, 449.09it/s] 77%|███████▋  | 3443/4500 [00:07<00:02, 432.81it/s] 78%|███████▊  | 3488/4500 [00:07<00:02, 431.26it/s] 78%|███████▊  | 3532/4500 [00:08<00:03, 266.54it/s] 79%|███████▉  | 3567/4500 [00:08<00:03, 237.36it/s] 80%|███████▉  | 3597/4500 [00:08<00:04, 197.44it/s] 81%|████████  | 3652/4500 [00:08<00:03, 256.86it/s] 82%|████████▏ | 3711/4500 [00:08<00:02, 315.03it/s] 84%|████████▎ | 3761/4500 [00:08<00:02, 346.94it/s] 85%|████████▍ | 3822/4500 [00:08<00:01, 402.60it/s] 86%|████████▋ | 3890/4500 [00:08<00:01, 469.74it/s] 88%|████████▊ | 3964/4500 [00:09<00:01, 532.01it/s] 89%|████████▉ | 4022/4500 [00:09<00:00, 542.11it/s] 91%|█████████ | 4080/4500 [00:09<00:00, 473.23it/s] 92%|█████████▏| 4131/4500 [00:09<00:00, 457.61it/s] 93%|█████████▎| 4180/4500 [00:09<00:00, 458.79it/s] 94%|█████████▍| 4228/4500 [00:09<00:00, 463.83it/s] 96%|█████████▌| 4312/4500 [00:09<00:00, 545.00it/s] 97%|█████████▋| 4368/4500 [00:09<00:00, 497.53it/s] 98%|█████████▊| 4425/4500 [00:10<00:00, 512.02it/s]100%|██████████| 4500/4500 [00:10<00:00, 444.99it/s]
test_p48 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p48
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p48.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.09s/it]evaluating model with Holmes:  28%|██▊       | 5/18 [00:01<00:02,  5.42it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 11.65it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 17.97it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.05it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p48_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p48_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p48_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p48_Holmes_probs.npy
{'Accuracy': 0.9644, 'Precision': 0.9653, 'Recall': 0.9644, 'F1-score': 0.9642}
starting gen taf script for test_p49
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 66/4500 [00:00<00:06, 644.51it/s]  3%|▎         | 131/4500 [00:00<00:10, 432.86it/s]  4%|▍         | 179/4500 [00:00<00:09, 435.09it/s]  5%|▌         | 227/4500 [00:00<00:09, 447.08it/s]  6%|▋         | 287/4500 [00:00<00:08, 492.91it/s]  8%|▊         | 338/4500 [00:00<00:11, 367.33it/s]  8%|▊         | 380/4500 [00:01<00:13, 305.46it/s]  9%|▉         | 416/4500 [00:01<00:13, 310.85it/s] 10%|█         | 453/4500 [00:01<00:12, 320.83it/s] 11%|█▏        | 510/4500 [00:01<00:10, 380.13it/s] 12%|█▏        | 551/4500 [00:01<00:10, 366.66it/s] 13%|█▎        | 590/4500 [00:01<00:10, 363.08it/s] 14%|█▍        | 633/4500 [00:01<00:10, 374.59it/s] 15%|█▍        | 672/4500 [00:01<00:10, 368.10it/s] 16%|█▌        | 710/4500 [00:01<00:10, 371.24it/s] 17%|█▋        | 752/4500 [00:01<00:09, 382.84it/s] 18%|█▊        | 791/4500 [00:02<00:10, 359.47it/s] 19%|█▉        | 855/4500 [00:02<00:08, 435.49it/s] 21%|██        | 930/4500 [00:02<00:06, 515.69it/s] 22%|██▏       | 1010/4500 [00:02<00:05, 586.88it/s] 24%|██▍       | 1075/4500 [00:02<00:05, 597.92it/s] 25%|██▌       | 1136/4500 [00:02<00:05, 580.20it/s] 28%|██▊       | 1260/4500 [00:02<00:04, 765.50it/s] 30%|██▉       | 1346/4500 [00:02<00:03, 790.95it/s] 32%|███▏      | 1427/4500 [00:02<00:04, 700.10it/s] 33%|███▎      | 1500/4500 [00:03<00:06, 491.63it/s] 35%|███▍      | 1573/4500 [00:03<00:05, 538.76it/s] 36%|███▋      | 1636/4500 [00:03<00:06, 455.16it/s] 38%|███▊      | 1690/4500 [00:03<00:06, 412.89it/s] 39%|███▉      | 1756/4500 [00:03<00:05, 464.27it/s] 41%|████      | 1825/4500 [00:03<00:05, 513.31it/s] 42%|████▏     | 1895/4500 [00:04<00:04, 558.27it/s] 44%|████▎     | 1968/4500 [00:04<00:04, 602.58it/s] 45%|████▌     | 2033/4500 [00:04<00:04, 603.64it/s] 47%|████▋     | 2097/4500 [00:04<00:04, 583.13it/s] 48%|████▊     | 2158/4500 [00:04<00:04, 557.79it/s] 49%|████▉     | 2218/4500 [00:04<00:04, 554.13it/s] 51%|█████     | 2275/4500 [00:04<00:04, 498.57it/s] 52%|█████▏    | 2327/4500 [00:04<00:04, 441.57it/s] 53%|█████▎    | 2374/4500 [00:05<00:05, 398.39it/s] 54%|█████▍    | 2422/4500 [00:05<00:05, 406.06it/s] 55%|█████▌    | 2475/4500 [00:05<00:04, 430.61it/s] 57%|█████▋    | 2548/4500 [00:05<00:03, 498.38it/s] 58%|█████▊    | 2600/4500 [00:05<00:03, 491.62it/s] 59%|█████▉    | 2676/4500 [00:05<00:03, 556.31it/s] 61%|██████    | 2733/4500 [00:05<00:03, 453.34it/s] 62%|██████▏   | 2783/4500 [00:05<00:03, 447.58it/s] 63%|██████▎   | 2850/4500 [00:05<00:03, 494.31it/s] 65%|██████▍   | 2909/4500 [00:06<00:03, 506.20it/s] 66%|██████▌   | 2977/4500 [00:06<00:02, 548.57it/s] 68%|██████▊   | 3050/4500 [00:06<00:02, 591.39it/s] 69%|██████▉   | 3111/4500 [00:06<00:02, 527.15it/s] 70%|███████   | 3166/4500 [00:06<00:02, 488.24it/s] 71%|███████▏  | 3217/4500 [00:06<00:02, 456.29it/s] 73%|███████▎  | 3268/4500 [00:06<00:02, 463.92it/s] 74%|███████▎  | 3318/4500 [00:06<00:02, 464.63it/s] 75%|███████▍  | 3374/4500 [00:07<00:02, 483.16it/s] 76%|███████▌  | 3423/4500 [00:07<00:02, 476.62it/s] 77%|███████▋  | 3472/4500 [00:07<00:02, 389.57it/s] 78%|███████▊  | 3514/4500 [00:07<00:02, 365.84it/s] 79%|███████▉  | 3553/4500 [00:07<00:03, 241.79it/s] 80%|███████▉  | 3584/4500 [00:08<00:04, 202.60it/s] 80%|████████  | 3622/4500 [00:08<00:03, 227.42it/s] 82%|████████▏ | 3687/4500 [00:08<00:02, 309.18it/s] 83%|████████▎ | 3741/4500 [00:08<00:02, 351.90it/s] 85%|████████▍ | 3808/4500 [00:08<00:01, 424.87it/s] 86%|████████▋ | 3886/4500 [00:08<00:01, 490.77it/s] 88%|████████▊ | 3941/4500 [00:08<00:01, 505.34it/s] 89%|████████▉ | 4003/4500 [00:08<00:00, 505.77it/s] 90%|█████████ | 4062/4500 [00:08<00:00, 513.57it/s] 91%|█████████▏| 4116/4500 [00:09<00:00, 449.27it/s] 93%|█████████▎| 4164/4500 [00:09<00:00, 443.52it/s] 94%|█████████▎| 4211/4500 [00:09<00:00, 435.70it/s] 95%|█████████▍| 4274/4500 [00:09<00:00, 482.07it/s] 96%|█████████▋| 4337/4500 [00:09<00:00, 521.45it/s] 98%|█████████▊| 4391/4500 [00:09<00:00, 504.18it/s]100%|██████████| 4500/4500 [00:09<00:00, 464.27it/s]
test_p49 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p49
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p49.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.07s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.57it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.67it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.84it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.28it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p49_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p49_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p49_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p49_Holmes_probs.npy
{'Accuracy': 0.9664, 'Precision': 0.9672, 'Recall': 0.9664, 'F1-score': 0.9663}
starting gen taf script for test_p50
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 76/4500 [00:00<00:05, 738.06it/s]  3%|▎         | 150/4500 [00:00<00:08, 491.58it/s]  5%|▍         | 204/4500 [00:00<00:10, 423.70it/s]  6%|▌         | 249/4500 [00:00<00:11, 360.11it/s]  6%|▋         | 287/4500 [00:00<00:11, 357.35it/s]  7%|▋         | 324/4500 [00:00<00:14, 289.61it/s]  8%|▊         | 355/4500 [00:01<00:15, 261.64it/s]  9%|▊         | 383/4500 [00:01<00:17, 235.80it/s]  9%|▉         | 408/4500 [00:01<00:18, 226.84it/s] 10%|█         | 461/4500 [00:01<00:13, 296.16it/s] 11%|█         | 493/4500 [00:01<00:14, 285.70it/s] 12%|█▏        | 528/4500 [00:01<00:13, 296.70it/s] 13%|█▎        | 566/4500 [00:01<00:12, 311.36it/s] 13%|█▎        | 599/4500 [00:01<00:12, 303.76it/s] 14%|█▍        | 640/4500 [00:02<00:11, 324.93it/s] 15%|█▌        | 675/4500 [00:02<00:11, 324.34it/s] 16%|█▌        | 713/4500 [00:02<00:11, 334.23it/s] 17%|█▋        | 747/4500 [00:02<00:11, 321.85it/s] 17%|█▋        | 780/4500 [00:02<00:11, 316.09it/s] 18%|█▊        | 812/4500 [00:02<00:11, 316.54it/s] 19%|█▉        | 861/4500 [00:02<00:10, 359.57it/s] 20%|██        | 904/4500 [00:02<00:09, 375.35it/s] 21%|██        | 942/4500 [00:02<00:09, 367.43it/s] 22%|██▏       | 980/4500 [00:02<00:09, 366.89it/s] 23%|██▎       | 1027/4500 [00:03<00:08, 390.85it/s] 24%|██▍       | 1087/4500 [00:03<00:07, 446.92it/s] 26%|██▌       | 1154/4500 [00:03<00:06, 504.33it/s] 27%|██▋       | 1216/4500 [00:03<00:06, 529.66it/s] 29%|██▊       | 1293/4500 [00:03<00:05, 586.30it/s] 30%|███       | 1360/4500 [00:03<00:05, 610.35it/s] 32%|███▏      | 1422/4500 [00:03<00:05, 555.11it/s] 33%|███▎      | 1479/4500 [00:03<00:06, 450.18it/s] 34%|███▍      | 1528/4500 [00:04<00:06, 438.41it/s] 35%|███▌      | 1591/4500 [00:04<00:06, 482.28it/s] 36%|███▋      | 1642/4500 [00:04<00:06, 457.49it/s] 38%|███▊      | 1690/4500 [00:04<00:06, 418.78it/s] 39%|███▉      | 1745/4500 [00:04<00:06, 428.39it/s] 40%|████      | 1800/4500 [00:04<00:05, 456.38it/s] 41%|████▏     | 1858/4500 [00:04<00:05, 483.93it/s] 43%|████▎     | 1926/4500 [00:04<00:04, 526.26it/s] 45%|████▍     | 2004/4500 [00:04<00:04, 592.84it/s] 46%|████▌     | 2065/4500 [00:05<00:04, 553.58it/s] 47%|████▋     | 2123/4500 [00:05<00:04, 554.95it/s] 48%|████▊     | 2180/4500 [00:05<00:04, 557.21it/s] 50%|████▉     | 2237/4500 [00:05<00:04, 504.26it/s] 51%|█████     | 2289/4500 [00:05<00:04, 458.56it/s] 52%|█████▏    | 2337/4500 [00:05<00:05, 370.53it/s] 53%|█████▎    | 2388/4500 [00:05<00:05, 393.66it/s] 55%|█████▍    | 2454/4500 [00:05<00:04, 457.42it/s] 56%|█████▌    | 2511/4500 [00:06<00:04, 482.73it/s] 57%|█████▋    | 2563/4500 [00:06<00:04, 477.99it/s] 58%|█████▊    | 2631/4500 [00:06<00:03, 520.42it/s] 60%|█████▉    | 2685/4500 [00:06<00:03, 524.60it/s] 61%|██████    | 2739/4500 [00:06<00:03, 498.54it/s] 62%|██████▏   | 2790/4500 [00:06<00:03, 458.84it/s] 63%|██████▎   | 2838/4500 [00:06<00:03, 458.65it/s] 64%|██████▍   | 2901/4500 [00:06<00:03, 504.87it/s] 66%|██████▌   | 2954/4500 [00:06<00:03, 503.59it/s] 67%|██████▋   | 3006/4500 [00:07<00:03, 477.99it/s] 68%|██████▊   | 3076/4500 [00:07<00:02, 538.58it/s] 70%|██████▉   | 3131/4500 [00:07<00:02, 471.05it/s] 71%|███████   | 3181/4500 [00:07<00:03, 423.39it/s] 72%|███████▏  | 3252/4500 [00:07<00:02, 487.08it/s] 73%|███████▎  | 3307/4500 [00:07<00:02, 495.02it/s] 75%|███████▍  | 3359/4500 [00:07<00:02, 464.97it/s] 76%|███████▌  | 3407/4500 [00:07<00:02, 463.58it/s] 77%|███████▋  | 3455/4500 [00:08<00:02, 412.01it/s] 78%|███████▊  | 3501/4500 [00:08<00:02, 400.21it/s] 79%|███████▊  | 3543/4500 [00:08<00:03, 298.37it/s] 79%|███████▉  | 3577/4500 [00:08<00:04, 225.15it/s] 80%|████████  | 3605/4500 [00:08<00:04, 210.09it/s] 82%|████████▏ | 3687/4500 [00:08<00:02, 323.04it/s] 83%|████████▎ | 3752/4500 [00:09<00:01, 385.57it/s] 85%|████████▍ | 3813/4500 [00:09<00:01, 422.88it/s] 86%|████████▋ | 3892/4500 [00:09<00:01, 499.55it/s] 88%|████████▊ | 3951/4500 [00:09<00:01, 519.19it/s] 89%|████████▉ | 4008/4500 [00:09<00:00, 518.81it/s] 90%|█████████ | 4067/4500 [00:09<00:00, 530.00it/s] 92%|█████████▏| 4123/4500 [00:09<00:00, 525.95it/s] 93%|█████████▎| 4178/4500 [00:09<00:00, 456.02it/s] 94%|█████████▍| 4238/4500 [00:10<00:00, 491.25it/s] 96%|█████████▌| 4315/4500 [00:10<00:00, 557.42it/s] 97%|█████████▋| 4374/4500 [00:10<00:00, 482.69it/s] 98%|█████████▊| 4426/4500 [00:10<00:00, 473.96it/s]100%|██████████| 4500/4500 [00:10<00:00, 429.96it/s]
test_p50 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p50
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p50.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.06it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.32it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.83it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.24it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.43it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p50_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p50_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p50_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p50_Holmes_probs.npy
{'Accuracy': 0.9682, 'Precision': 0.9688, 'Recall': 0.9682, 'F1-score': 0.9681}
starting gen taf script for test_p51
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 85/4500 [00:00<00:05, 833.65it/s]  4%|▍         | 169/4500 [00:00<00:09, 471.88it/s]  5%|▌         | 226/4500 [00:00<00:08, 493.24it/s]  6%|▋         | 291/4500 [00:00<00:07, 538.96it/s]  8%|▊         | 350/4500 [00:00<00:10, 405.69it/s]  9%|▉         | 397/4500 [00:00<00:12, 319.16it/s] 10%|▉         | 442/4500 [00:01<00:11, 345.05it/s] 11%|█         | 489/4500 [00:01<00:10, 369.91it/s] 12%|█▏        | 531/4500 [00:01<00:10, 360.84it/s] 13%|█▎        | 573/4500 [00:01<00:10, 369.07it/s] 14%|█▎        | 613/4500 [00:01<00:10, 364.31it/s] 14%|█▍        | 651/4500 [00:01<00:11, 325.02it/s] 15%|█▌        | 691/4500 [00:01<00:11, 338.28it/s] 16%|█▌        | 727/4500 [00:01<00:11, 329.05it/s] 17%|█▋        | 764/4500 [00:02<00:11, 339.20it/s] 18%|█▊        | 799/4500 [00:02<00:10, 339.14it/s] 19%|█▉        | 859/4500 [00:02<00:08, 410.23it/s] 21%|██        | 923/4500 [00:02<00:07, 470.62it/s] 22%|██▏       | 976/4500 [00:02<00:07, 484.84it/s] 23%|██▎       | 1026/4500 [00:02<00:07, 484.75it/s] 24%|██▍       | 1084/4500 [00:02<00:06, 505.42it/s] 25%|██▌       | 1135/4500 [00:02<00:07, 478.55it/s] 27%|██▋       | 1226/4500 [00:02<00:05, 595.80it/s] 29%|██▉       | 1300/4500 [00:02<00:05, 633.79it/s] 30%|███       | 1372/4500 [00:03<00:04, 653.00it/s] 32%|███▏      | 1438/4500 [00:03<00:05, 561.02it/s] 33%|███▎      | 1497/4500 [00:03<00:06, 434.93it/s] 35%|███▍      | 1565/4500 [00:03<00:06, 489.02it/s] 36%|███▌      | 1620/4500 [00:03<00:06, 428.99it/s] 37%|███▋      | 1668/4500 [00:03<00:06, 408.29it/s] 38%|███▊      | 1713/4500 [00:03<00:07, 386.51it/s] 39%|███▉      | 1771/4500 [00:04<00:06, 429.49it/s] 41%|████      | 1840/4500 [00:04<00:05, 490.04it/s] 43%|████▎     | 1928/4500 [00:04<00:04, 585.23it/s] 44%|████▍     | 1990/4500 [00:04<00:04, 570.97it/s] 46%|████▌     | 2061/4500 [00:04<00:04, 608.16it/s] 47%|████▋     | 2124/4500 [00:04<00:04, 574.01it/s] 49%|████▉     | 2198/4500 [00:04<00:03, 618.22it/s] 50%|█████     | 2262/4500 [00:04<00:04, 495.61it/s] 51%|█████▏    | 2317/4500 [00:05<00:05, 433.75it/s] 53%|█████▎    | 2365/4500 [00:05<00:04, 432.28it/s] 54%|█████▎    | 2412/4500 [00:05<00:05, 410.39it/s] 55%|█████▌    | 2483/4500 [00:05<00:04, 479.94it/s] 57%|█████▋    | 2554/4500 [00:05<00:03, 536.61it/s] 58%|█████▊    | 2611/4500 [00:05<00:03, 521.98it/s] 59%|█████▉    | 2666/4500 [00:05<00:03, 521.13it/s] 61%|██████    | 2738/4500 [00:05<00:03, 561.38it/s] 62%|██████▏   | 2796/4500 [00:05<00:03, 539.53it/s] 64%|██████▎   | 2860/4500 [00:06<00:02, 566.77it/s] 65%|██████▍   | 2919/4500 [00:06<00:02, 558.10it/s] 66%|██████▋   | 2991/4500 [00:06<00:02, 600.89it/s] 68%|██████▊   | 3052/4500 [00:06<00:02, 560.13it/s] 69%|██████▉   | 3109/4500 [00:06<00:02, 503.19it/s] 70%|███████   | 3161/4500 [00:06<00:03, 409.26it/s] 72%|███████▏  | 3229/4500 [00:06<00:02, 465.53it/s] 73%|███████▎  | 3280/4500 [00:07<00:02, 449.81it/s] 74%|███████▍  | 3338/4500 [00:07<00:02, 471.60it/s] 75%|███████▌  | 3388/4500 [00:07<00:02, 454.72it/s] 76%|███████▋  | 3435/4500 [00:07<00:02, 456.80it/s] 77%|███████▋  | 3482/4500 [00:07<00:02, 432.02it/s] 78%|███████▊  | 3527/4500 [00:07<00:03, 282.24it/s] 79%|███████▉  | 3563/4500 [00:07<00:03, 238.62it/s] 80%|███████▉  | 3593/4500 [00:08<00:04, 201.92it/s] 81%|████████  | 3645/4500 [00:08<00:03, 257.20it/s] 82%|████████▏ | 3692/4500 [00:08<00:02, 296.38it/s] 83%|████████▎ | 3751/4500 [00:08<00:02, 355.52it/s] 85%|████████▍ | 3808/4500 [00:08<00:01, 402.52it/s] 86%|████████▌ | 3870/4500 [00:08<00:01, 451.12it/s] 87%|████████▋ | 3927/4500 [00:08<00:01, 482.16it/s] 89%|████████▉ | 4003/4500 [00:08<00:00, 538.73it/s] 90%|█████████ | 4060/4500 [00:09<00:00, 524.78it/s] 91%|█████████▏| 4115/4500 [00:09<00:00, 474.38it/s] 93%|█████████▎| 4167/4500 [00:09<00:00, 455.55it/s] 94%|█████████▍| 4242/4500 [00:09<00:00, 525.24it/s] 96%|█████████▌| 4306/4500 [00:09<00:00, 542.08it/s] 97%|█████████▋| 4362/4500 [00:09<00:00, 487.86it/s] 98%|█████████▊| 4426/4500 [00:09<00:00, 525.76it/s]100%|█████████▉| 4481/4500 [00:09<00:00, 524.83it/s]100%|██████████| 4500/4500 [00:09<00:00, 454.13it/s]
test_p51 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p51
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p51.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.05it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.23it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.71it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.63it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.20it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p51_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p51_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p51_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p51_Holmes_probs.npy
{'Accuracy': 0.97, 'Precision': 0.9704, 'Recall': 0.97, 'F1-score': 0.9699}
starting gen taf script for test_p52
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 75/4500 [00:00<00:06, 726.10it/s]  3%|▎         | 148/4500 [00:00<00:08, 515.99it/s]  5%|▍         | 204/4500 [00:00<00:11, 367.79it/s]  5%|▌         | 246/4500 [00:00<00:11, 372.70it/s]  6%|▋         | 287/4500 [00:00<00:12, 340.49it/s]  7%|▋         | 323/4500 [00:00<00:16, 250.09it/s]  8%|▊         | 352/4500 [00:01<00:19, 211.41it/s]  8%|▊         | 376/4500 [00:01<00:20, 196.40it/s]  9%|▉         | 398/4500 [00:01<00:23, 175.15it/s]  9%|▉         | 426/4500 [00:01<00:20, 196.13it/s] 10%|█         | 470/4500 [00:01<00:16, 247.51it/s] 11%|█         | 503/4500 [00:01<00:15, 263.40it/s] 12%|█▏        | 532/4500 [00:01<00:15, 254.67it/s] 12%|█▏        | 560/4500 [00:02<00:15, 252.36it/s] 13%|█▎        | 587/4500 [00:02<00:15, 251.43it/s] 14%|█▎        | 613/4500 [00:02<00:15, 250.24it/s] 14%|█▍        | 651/4500 [00:02<00:13, 282.51it/s] 15%|█▌        | 680/4500 [00:02<00:14, 270.99it/s] 16%|█▌        | 708/4500 [00:02<00:14, 267.75it/s] 16%|█▋        | 736/4500 [00:02<00:16, 234.79it/s] 17%|█▋        | 764/4500 [00:02<00:15, 244.03it/s] 18%|█▊        | 793/4500 [00:02<00:14, 254.23it/s] 18%|█▊        | 828/4500 [00:03<00:13, 279.25it/s] 20%|█▉        | 884/4500 [00:03<00:10, 353.86it/s] 21%|██        | 948/4500 [00:03<00:08, 428.00it/s] 22%|██▏       | 1005/4500 [00:03<00:07, 459.99it/s] 24%|██▎       | 1068/4500 [00:03<00:06, 492.27it/s] 26%|██▌       | 1158/4500 [00:03<00:05, 604.32it/s] 27%|██▋       | 1221/4500 [00:03<00:05, 610.88it/s] 29%|██▊       | 1290/4500 [00:03<00:05, 626.50it/s] 30%|███       | 1366/4500 [00:03<00:04, 644.97it/s] 32%|███▏      | 1431/4500 [00:04<00:05, 568.58it/s] 33%|███▎      | 1490/4500 [00:04<00:07, 412.97it/s] 35%|███▍      | 1563/4500 [00:04<00:06, 474.92it/s] 36%|███▌      | 1618/4500 [00:04<00:06, 448.25it/s] 37%|███▋      | 1668/4500 [00:04<00:07, 393.91it/s] 39%|███▊      | 1735/4500 [00:04<00:06, 445.23it/s] 40%|████      | 1808/4500 [00:04<00:05, 497.47it/s] 42%|████▏     | 1890/4500 [00:05<00:04, 576.85it/s] 44%|████▍     | 1976/4500 [00:05<00:03, 646.20it/s] 45%|████▌     | 2045/4500 [00:05<00:04, 586.69it/s] 47%|████▋     | 2108/4500 [00:05<00:04, 583.10it/s] 48%|████▊     | 2177/4500 [00:05<00:03, 597.61it/s] 50%|████▉     | 2239/4500 [00:05<00:04, 559.32it/s] 51%|█████     | 2297/4500 [00:05<00:04, 453.81it/s] 52%|█████▏    | 2347/4500 [00:06<00:05, 405.71it/s] 53%|█████▎    | 2391/4500 [00:06<00:05, 384.31it/s] 54%|█████▍    | 2439/4500 [00:06<00:05, 406.18it/s] 55%|█████▌    | 2482/4500 [00:06<00:05, 401.70it/s] 56%|█████▌    | 2524/4500 [00:06<00:04, 400.09it/s] 57%|█████▋    | 2574/4500 [00:06<00:04, 419.66it/s] 59%|█████▊    | 2642/4500 [00:06<00:03, 477.08it/s] 60%|██████    | 2715/4500 [00:06<00:03, 534.47it/s] 62%|██████▏   | 2770/4500 [00:06<00:03, 502.16it/s] 63%|██████▎   | 2840/4500 [00:07<00:03, 543.52it/s] 64%|██████▍   | 2900/4500 [00:07<00:02, 557.45it/s] 66%|██████▌   | 2973/4500 [00:07<00:02, 591.48it/s] 67%|██████▋   | 3033/4500 [00:07<00:02, 544.34it/s] 69%|██████▊   | 3089/4500 [00:07<00:02, 526.68it/s] 70%|██████▉   | 3143/4500 [00:07<00:02, 476.49it/s] 71%|███████   | 3192/4500 [00:07<00:03, 380.17it/s] 72%|███████▏  | 3236/4500 [00:07<00:03, 392.03it/s] 73%|███████▎  | 3298/4500 [00:08<00:02, 443.90it/s] 74%|███████▍  | 3346/4500 [00:08<00:02, 444.07it/s] 75%|███████▌  | 3393/4500 [00:08<00:02, 434.79it/s] 76%|███████▋  | 3440/4500 [00:08<00:02, 432.02it/s] 77%|███████▋  | 3485/4500 [00:08<00:03, 322.40it/s] 78%|███████▊  | 3522/4500 [00:08<00:03, 281.54it/s] 79%|███████▉  | 3554/4500 [00:09<00:04, 224.54it/s] 80%|███████▉  | 3581/4500 [00:09<00:04, 204.28it/s] 80%|████████  | 3611/4500 [00:09<00:04, 221.00it/s] 82%|████████▏ | 3678/4500 [00:09<00:02, 316.37it/s] 83%|████████▎ | 3731/4500 [00:09<00:02, 366.23it/s] 84%|████████▍ | 3787/4500 [00:09<00:01, 407.73it/s] 86%|████████▌ | 3862/4500 [00:09<00:01, 494.32it/s] 88%|████████▊ | 3941/4500 [00:09<00:00, 571.99it/s] 89%|████████▉ | 4014/4500 [00:09<00:00, 579.24it/s] 91%|█████████ | 4075/4500 [00:10<00:00, 541.89it/s] 92%|█████████▏| 4132/4500 [00:10<00:00, 507.84it/s] 93%|█████████▎| 4185/4500 [00:10<00:00, 433.62it/s] 94%|█████████▍| 4250/4500 [00:10<00:00, 479.44it/s] 96%|█████████▌| 4325/4500 [00:10<00:00, 500.25it/s] 97%|█████████▋| 4377/4500 [00:10<00:00, 478.51it/s] 99%|█████████▉| 4450/4500 [00:10<00:00, 536.33it/s]100%|██████████| 4500/4500 [00:10<00:00, 414.45it/s]
test_p52 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p52
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p52.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.01it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.01it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.26it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.49it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.93it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p52_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p52_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p52_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p52_Holmes_probs.npy
{'Accuracy': 0.9711, 'Precision': 0.9715, 'Recall': 0.9711, 'F1-score': 0.971}
starting gen taf script for test_p53
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 62/4500 [00:00<00:07, 600.29it/s]  3%|▎         | 123/4500 [00:00<00:08, 512.11it/s]  4%|▍         | 175/4500 [00:00<00:09, 434.97it/s]  5%|▍         | 224/4500 [00:00<00:09, 450.15it/s]  6%|▋         | 286/4500 [00:00<00:08, 499.45it/s]  8%|▊         | 338/4500 [00:00<00:11, 362.61it/s]  8%|▊         | 380/4500 [00:01<00:13, 306.92it/s]  9%|▉         | 419/4500 [00:01<00:12, 323.18it/s] 10%|█         | 455/4500 [00:01<00:12, 328.03it/s] 11%|█         | 504/4500 [00:01<00:10, 368.58it/s] 12%|█▏        | 544/4500 [00:01<00:10, 367.42it/s] 13%|█▎        | 583/4500 [00:01<00:10, 366.93it/s] 14%|█▍        | 624/4500 [00:01<00:10, 376.10it/s] 15%|█▍        | 663/4500 [00:01<00:10, 366.42it/s] 16%|█▌        | 701/4500 [00:01<00:12, 311.19it/s] 16%|█▋        | 734/4500 [00:02<00:13, 284.25it/s] 17%|█▋        | 785/4500 [00:02<00:11, 337.35it/s] 18%|█▊        | 826/4500 [00:02<00:10, 355.63it/s] 19%|█▉        | 874/4500 [00:02<00:09, 383.22it/s] 20%|██        | 914/4500 [00:02<00:09, 377.06it/s] 21%|██▏       | 959/4500 [00:02<00:09, 390.67it/s] 23%|██▎       | 1014/4500 [00:02<00:08, 435.07it/s] 24%|██▎       | 1067/4500 [00:02<00:07, 452.29it/s] 25%|██▌       | 1130/4500 [00:02<00:06, 497.22it/s] 27%|██▋       | 1207/4500 [00:02<00:05, 575.28it/s] 29%|██▊       | 1283/4500 [00:03<00:05, 617.92it/s] 30%|██▉       | 1346/4500 [00:03<00:05, 615.48it/s] 31%|███▏      | 1408/4500 [00:03<00:05, 571.47it/s] 33%|███▎      | 1466/4500 [00:03<00:06, 492.54it/s] 34%|███▎      | 1518/4500 [00:03<00:06, 452.51it/s] 36%|███▌      | 1600/4500 [00:03<00:05, 543.25it/s] 37%|███▋      | 1658/4500 [00:03<00:06, 422.29it/s] 38%|███▊      | 1707/4500 [00:04<00:07, 371.76it/s] 39%|███▉      | 1759/4500 [00:04<00:06, 400.15it/s] 41%|████      | 1835/4500 [00:04<00:05, 482.32it/s] 42%|████▏     | 1892/4500 [00:04<00:05, 504.03it/s] 44%|████▎     | 1961/4500 [00:04<00:04, 549.79it/s] 45%|████▌     | 2047/4500 [00:04<00:03, 629.05it/s] 47%|████▋     | 2114/4500 [00:04<00:04, 561.10it/s] 48%|████▊     | 2174/4500 [00:04<00:04, 543.52it/s] 50%|████▉     | 2231/4500 [00:05<00:04, 502.91it/s] 51%|█████     | 2284/4500 [00:05<00:05, 418.25it/s] 52%|█████▏    | 2330/4500 [00:05<00:05, 409.73it/s] 53%|█████▎    | 2374/4500 [00:05<00:05, 392.68it/s] 54%|█████▍    | 2423/4500 [00:05<00:05, 409.00it/s] 55%|█████▍    | 2472/4500 [00:05<00:04, 420.86it/s] 57%|█████▋    | 2553/4500 [00:05<00:03, 522.55it/s] 58%|█████▊    | 2608/4500 [00:05<00:03, 508.44it/s] 59%|█████▉    | 2662/4500 [00:06<00:03, 511.31it/s] 60%|██████    | 2715/4500 [00:06<00:03, 504.33it/s] 61%|██████▏   | 2767/4500 [00:06<00:03, 436.21it/s] 63%|██████▎   | 2825/4500 [00:06<00:03, 466.47it/s] 64%|██████▍   | 2883/4500 [00:06<00:03, 487.91it/s] 65%|██████▌   | 2942/4500 [00:06<00:03, 507.87it/s] 67%|██████▋   | 3009/4500 [00:06<00:02, 538.66it/s] 68%|██████▊   | 3064/4500 [00:06<00:02, 523.34it/s] 69%|██████▉   | 3117/4500 [00:06<00:03, 458.75it/s] 70%|███████   | 3165/4500 [00:07<00:02, 448.53it/s] 72%|███████▏  | 3237/4500 [00:07<00:02, 515.50it/s] 73%|███████▎  | 3291/4500 [00:07<00:02, 470.06it/s] 74%|███████▍  | 3341/4500 [00:07<00:02, 466.94it/s] 75%|███████▌  | 3389/4500 [00:07<00:02, 462.87it/s] 76%|███████▋  | 3437/4500 [00:07<00:02, 407.68it/s] 78%|███████▊  | 3491/4500 [00:07<00:02, 434.78it/s] 79%|███████▊  | 3536/4500 [00:08<00:03, 255.60it/s] 79%|███████▉  | 3572/4500 [00:08<00:04, 219.02it/s] 80%|████████  | 3602/4500 [00:08<00:04, 211.15it/s] 81%|████████  | 3655/4500 [00:08<00:03, 266.14it/s] 83%|████████▎ | 3717/4500 [00:08<00:02, 333.50it/s] 84%|████████▎ | 3767/4500 [00:08<00:01, 369.97it/s] 85%|████████▍ | 3824/4500 [00:08<00:01, 416.17it/s] 86%|████████▌ | 3874/4500 [00:09<00:01, 437.21it/s] 87%|████████▋ | 3922/4500 [00:09<00:01, 441.86it/s] 88%|████████▊ | 3978/4500 [00:09<00:01, 467.84it/s] 90%|████████▉ | 4030/4500 [00:09<00:00, 477.90it/s] 91%|█████████ | 4093/4500 [00:09<00:00, 509.61it/s] 92%|█████████▏| 4146/4500 [00:09<00:00, 452.36it/s] 93%|█████████▎| 4194/4500 [00:09<00:00, 428.33it/s] 95%|█████████▍| 4261/4500 [00:09<00:00, 490.67it/s] 96%|█████████▌| 4328/4500 [00:10<00:00, 531.25it/s] 97%|█████████▋| 4383/4500 [00:10<00:00, 436.90it/s] 99%|█████████▊| 4437/4500 [00:10<00:00, 461.87it/s]100%|██████████| 4500/4500 [00:10<00:00, 435.00it/s]
test_p53 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p53
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p53.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.00s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.97it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.06it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.32it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.73it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p53_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p53_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p53_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p53_Holmes_probs.npy
{'Accuracy': 0.9713, 'Precision': 0.9718, 'Recall': 0.9713, 'F1-score': 0.9712}
starting gen taf script for test_p54
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 55/4500 [00:00<00:08, 540.45it/s]  2%|▏         | 110/4500 [00:00<00:08, 487.88it/s]  4%|▎         | 160/4500 [00:00<00:10, 425.51it/s]  5%|▍         | 206/4500 [00:00<00:09, 436.04it/s]  6%|▌         | 260/4500 [00:00<00:09, 463.65it/s]  7%|▋         | 309/4500 [00:00<00:08, 468.60it/s]  8%|▊         | 357/4500 [00:00<00:12, 342.28it/s]  9%|▉         | 396/4500 [00:01<00:14, 287.19it/s] 10%|▉         | 430/4500 [00:01<00:13, 297.82it/s] 10%|█         | 464/4500 [00:01<00:16, 247.49it/s] 11%|█         | 493/4500 [00:01<00:18, 222.01it/s] 12%|█▏        | 518/4500 [00:01<00:18, 214.82it/s] 12%|█▏        | 542/4500 [00:01<00:18, 219.62it/s] 13%|█▎        | 575/4500 [00:01<00:16, 242.32it/s] 14%|█▎        | 610/4500 [00:02<00:14, 267.31it/s] 15%|█▍        | 659/4500 [00:02<00:11, 321.84it/s] 16%|█▌        | 701/4500 [00:02<00:11, 341.35it/s] 16%|█▋        | 737/4500 [00:02<00:12, 298.93it/s] 17%|█▋        | 770/4500 [00:02<00:12, 303.64it/s] 18%|█▊        | 807/4500 [00:02<00:11, 317.23it/s] 19%|█▉        | 858/4500 [00:02<00:09, 368.12it/s] 21%|██        | 923/4500 [00:02<00:08, 443.82it/s] 22%|██▏       | 983/4500 [00:02<00:07, 476.96it/s] 23%|██▎       | 1032/4500 [00:03<00:07, 455.72it/s] 24%|██▍       | 1079/4500 [00:03<00:07, 453.23it/s] 26%|██▋       | 1192/4500 [00:03<00:05, 637.72it/s] 28%|██▊       | 1260/4500 [00:03<00:05, 640.54it/s] 29%|██▉       | 1327/4500 [00:03<00:04, 639.14it/s] 31%|███       | 1392/4500 [00:03<00:05, 617.82it/s] 32%|███▏      | 1455/4500 [00:03<00:05, 516.99it/s] 34%|███▎      | 1510/4500 [00:03<00:06, 478.12it/s] 35%|███▍      | 1565/4500 [00:03<00:06, 474.74it/s] 36%|███▌      | 1615/4500 [00:04<00:06, 454.07it/s] 37%|███▋      | 1662/4500 [00:04<00:06, 438.65it/s] 38%|███▊      | 1707/4500 [00:04<00:07, 365.63it/s] 39%|███▉      | 1761/4500 [00:04<00:06, 402.70it/s] 40%|████      | 1820/4500 [00:04<00:05, 447.20it/s] 42%|████▏     | 1878/4500 [00:04<00:05, 473.71it/s] 43%|████▎     | 1946/4500 [00:04<00:04, 521.32it/s] 45%|████▍     | 2019/4500 [00:04<00:04, 578.41it/s] 46%|████▋     | 2083/4500 [00:05<00:04, 569.33it/s] 48%|████▊     | 2151/4500 [00:05<00:03, 593.82it/s] 49%|████▉     | 2212/4500 [00:05<00:04, 520.04it/s] 50%|█████     | 2267/4500 [00:05<00:04, 452.62it/s] 51%|█████▏    | 2316/4500 [00:05<00:04, 447.63it/s] 53%|█████▎    | 2363/4500 [00:05<00:04, 430.75it/s] 54%|█████▎    | 2408/4500 [00:05<00:05, 401.15it/s] 55%|█████▍    | 2454/4500 [00:05<00:04, 413.33it/s] 56%|█████▋    | 2538/4500 [00:06<00:03, 513.33it/s] 58%|█████▊    | 2591/4500 [00:06<00:04, 470.67it/s] 59%|█████▉    | 2656/4500 [00:06<00:03, 500.23it/s] 60%|██████    | 2708/4500 [00:06<00:03, 499.74it/s] 61%|██████▏   | 2759/4500 [00:06<00:03, 492.70it/s] 63%|██████▎   | 2817/4500 [00:06<00:03, 514.03it/s] 64%|██████▍   | 2869/4500 [00:06<00:03, 498.65it/s] 65%|██████▌   | 2927/4500 [00:06<00:03, 507.48it/s] 66%|██████▌   | 2979/4500 [00:06<00:03, 445.12it/s] 68%|██████▊   | 3039/4500 [00:07<00:03, 475.02it/s] 69%|██████▊   | 3090/4500 [00:07<00:02, 478.95it/s] 70%|██████▉   | 3139/4500 [00:07<00:03, 403.95it/s] 71%|███████   | 3182/4500 [00:07<00:03, 397.10it/s] 72%|███████▏  | 3245/4500 [00:07<00:02, 447.54it/s] 73%|███████▎  | 3299/4500 [00:07<00:02, 469.39it/s] 74%|███████▍  | 3350/4500 [00:07<00:02, 480.42it/s] 76%|███████▌  | 3400/4500 [00:07<00:02, 438.37it/s] 77%|███████▋  | 3446/4500 [00:08<00:02, 410.17it/s] 78%|███████▊  | 3489/4500 [00:08<00:03, 329.99it/s] 78%|███████▊  | 3525/4500 [00:08<00:03, 248.62it/s] 79%|███████▉  | 3555/4500 [00:08<00:04, 219.00it/s] 80%|███████▉  | 3581/4500 [00:08<00:04, 191.95it/s] 80%|████████  | 3603/4500 [00:08<00:04, 195.70it/s] 81%|████████▏ | 3658/4500 [00:09<00:03, 268.49it/s] 83%|████████▎ | 3729/4500 [00:09<00:02, 366.74it/s] 84%|████████▍ | 3778/4500 [00:09<00:01, 395.92it/s] 85%|████████▍ | 3824/4500 [00:09<00:01, 408.18it/s] 86%|████████▌ | 3869/4500 [00:09<00:01, 412.38it/s] 87%|████████▋ | 3920/4500 [00:09<00:01, 431.32it/s] 88%|████████▊ | 3978/4500 [00:09<00:01, 471.96it/s] 89%|████████▉ | 4027/4500 [00:09<00:01, 470.49it/s] 91%|█████████ | 4076/4500 [00:09<00:00, 462.35it/s] 92%|█████████▏| 4124/4500 [00:10<00:00, 462.46it/s] 93%|█████████▎| 4171/4500 [00:10<00:00, 380.99it/s] 94%|█████████▍| 4248/4500 [00:10<00:00, 474.48it/s] 96%|█████████▌| 4326/4500 [00:10<00:00, 535.83it/s] 97%|█████████▋| 4383/4500 [00:10<00:00, 499.54it/s] 99%|█████████▊| 4436/4500 [00:10<00:00, 486.70it/s]100%|██████████| 4500/4500 [00:10<00:00, 418.73it/s]
test_p54 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p54
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p54.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.06s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.61it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.61it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.80it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.30it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p54_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p54_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p54_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p54_Holmes_probs.npy
{'Accuracy': 0.9724, 'Precision': 0.9728, 'Recall': 0.9724, 'F1-score': 0.9724}
starting gen taf script for test_p55
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 50/4500 [00:00<00:08, 495.58it/s]  2%|▏         | 100/4500 [00:00<00:09, 451.13it/s]  3%|▎         | 146/4500 [00:00<00:10, 417.20it/s]  4%|▍         | 189/4500 [00:00<00:11, 390.29it/s]  5%|▌         | 246/4500 [00:00<00:09, 442.11it/s]  7%|▋         | 296/4500 [00:00<00:09, 457.53it/s]  8%|▊         | 343/4500 [00:00<00:12, 334.06it/s]  8%|▊         | 382/4500 [00:01<00:15, 263.91it/s]  9%|▉         | 414/4500 [00:01<00:15, 258.87it/s] 10%|▉         | 447/4500 [00:01<00:14, 274.06it/s] 11%|█         | 489/4500 [00:01<00:13, 308.31it/s] 12%|█▏        | 537/4500 [00:01<00:11, 351.28it/s] 13%|█▎        | 576/4500 [00:01<00:11, 333.66it/s] 14%|█▎        | 612/4500 [00:01<00:11, 339.14it/s] 14%|█▍        | 648/4500 [00:01<00:11, 336.21it/s] 15%|█▌        | 685/4500 [00:02<00:11, 340.57it/s] 16%|█▋        | 732/4500 [00:02<00:10, 362.62it/s] 17%|█▋        | 769/4500 [00:02<00:10, 350.87it/s] 19%|█▉        | 855/4500 [00:02<00:07, 485.88it/s] 20%|██        | 905/4500 [00:02<00:07, 484.33it/s] 21%|██        | 956/4500 [00:02<00:07, 483.13it/s] 22%|██▏       | 1005/4500 [00:02<00:07, 484.43it/s] 24%|██▎       | 1062/4500 [00:02<00:06, 497.64it/s] 25%|██▌       | 1141/4500 [00:02<00:05, 577.37it/s] 27%|██▋       | 1231/4500 [00:02<00:04, 670.58it/s] 29%|██▉       | 1299/4500 [00:03<00:05, 638.68it/s] 30%|███       | 1364/4500 [00:03<00:05, 611.63it/s] 32%|███▏      | 1426/4500 [00:03<00:06, 506.74it/s] 33%|███▎      | 1480/4500 [00:03<00:06, 440.90it/s] 34%|███▍      | 1537/4500 [00:03<00:06, 463.93it/s] 35%|███▌      | 1591/4500 [00:03<00:06, 467.38it/s] 36%|███▋      | 1640/4500 [00:03<00:06, 461.38it/s] 38%|███▊      | 1688/4500 [00:04<00:07, 395.11it/s] 38%|███▊      | 1730/4500 [00:04<00:07, 378.60it/s] 40%|███▉      | 1778/4500 [00:04<00:06, 401.09it/s] 41%|████      | 1846/4500 [00:04<00:05, 470.71it/s] 42%|████▏     | 1907/4500 [00:04<00:05, 505.03it/s] 44%|████▎     | 1966/4500 [00:04<00:04, 525.74it/s] 45%|████▍     | 2020/4500 [00:04<00:04, 505.75it/s] 46%|████▌     | 2072/4500 [00:04<00:04, 504.21it/s] 48%|████▊     | 2149/4500 [00:04<00:04, 575.60it/s] 49%|████▉     | 2208/4500 [00:05<00:04, 558.60it/s] 50%|█████     | 2265/4500 [00:05<00:04, 495.15it/s] 51%|█████▏    | 2317/4500 [00:05<00:05, 421.75it/s] 52%|█████▏    | 2362/4500 [00:05<00:05, 384.33it/s] 53%|█████▎    | 2403/4500 [00:05<00:05, 361.13it/s] 55%|█████▍    | 2460/4500 [00:05<00:04, 409.37it/s] 56%|█████▌    | 2525/4500 [00:05<00:04, 463.95it/s] 58%|█████▊    | 2590/4500 [00:05<00:03, 511.20it/s] 59%|█████▉    | 2644/4500 [00:06<00:03, 483.28it/s] 60%|█████▉    | 2695/4500 [00:06<00:03, 481.23it/s] 61%|██████    | 2745/4500 [00:06<00:03, 450.47it/s] 62%|██████▏   | 2792/4500 [00:06<00:03, 454.79it/s] 64%|██████▎   | 2864/4500 [00:06<00:03, 514.38it/s] 65%|██████▌   | 2929/4500 [00:06<00:02, 545.04it/s] 66%|██████▋   | 2986/4500 [00:06<00:02, 545.02it/s] 68%|██████▊   | 3048/4500 [00:06<00:02, 558.28it/s] 69%|██████▉   | 3105/4500 [00:06<00:02, 520.79it/s] 70%|███████   | 3158/4500 [00:07<00:03, 441.36it/s] 71%|███████   | 3205/4500 [00:07<00:03, 422.72it/s] 72%|███████▏  | 3253/4500 [00:07<00:02, 432.15it/s] 74%|███████▎  | 3312/4500 [00:07<00:02, 472.09it/s] 75%|███████▍  | 3361/4500 [00:07<00:02, 425.43it/s] 76%|███████▌  | 3410/4500 [00:07<00:02, 431.98it/s] 77%|███████▋  | 3455/4500 [00:07<00:02, 413.41it/s] 78%|███████▊  | 3498/4500 [00:07<00:02, 374.82it/s] 79%|███████▊  | 3537/4500 [00:08<00:04, 226.29it/s] 79%|███████▉  | 3568/4500 [00:08<00:04, 186.83it/s] 80%|███████▉  | 3594/4500 [00:08<00:04, 197.62it/s] 81%|████████  | 3638/4500 [00:08<00:03, 235.77it/s] 82%|████████▏ | 3701/4500 [00:08<00:02, 314.12it/s] 84%|████████▎ | 3759/4500 [00:09<00:01, 372.66it/s] 85%|████████▍ | 3803/4500 [00:09<00:01, 380.96it/s] 86%|████████▌ | 3862/4500 [00:09<00:01, 429.04it/s] 87%|████████▋ | 3909/4500 [00:09<00:01, 432.92it/s] 88%|████████▊ | 3978/4500 [00:09<00:01, 483.21it/s] 90%|████████▉ | 4029/4500 [00:09<00:00, 483.09it/s] 91%|█████████ | 4085/4500 [00:09<00:00, 504.30it/s] 92%|█████████▏| 4137/4500 [00:09<00:00, 378.11it/s] 93%|█████████▎| 4181/4500 [00:09<00:00, 390.56it/s] 94%|█████████▍| 4243/4500 [00:10<00:00, 446.95it/s] 96%|█████████▌| 4314/4500 [00:10<00:00, 500.39it/s] 97%|█████████▋| 4368/4500 [00:10<00:00, 461.33it/s] 98%|█████████▊| 4417/4500 [00:10<00:00, 452.89it/s]100%|██████████| 4500/4500 [00:10<00:00, 427.54it/s]
test_p55 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p55
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p55.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.12it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.64it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.33it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.83it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.97it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p55_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p55_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p55_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p55_Holmes_probs.npy
{'Accuracy': 0.9736, 'Precision': 0.9739, 'Recall': 0.9736, 'F1-score': 0.9735}
starting gen taf script for test_p56
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 67/4500 [00:00<00:07, 625.36it/s]  3%|▎         | 130/4500 [00:00<00:08, 490.08it/s]  4%|▍         | 181/4500 [00:00<00:09, 475.95it/s]  5%|▌         | 230/4500 [00:00<00:09, 471.18it/s]  6%|▌         | 278/4500 [00:00<00:11, 367.90it/s]  7%|▋         | 318/4500 [00:00<00:15, 277.32it/s]  8%|▊         | 350/4500 [00:01<00:16, 256.33it/s]  8%|▊         | 379/4500 [00:01<00:17, 236.54it/s]  9%|▉         | 405/4500 [00:01<00:17, 231.53it/s] 10%|█         | 454/4500 [00:01<00:13, 289.56it/s] 11%|█         | 489/4500 [00:01<00:13, 304.25it/s] 12%|█▏        | 522/4500 [00:01<00:15, 254.91it/s] 12%|█▏        | 551/4500 [00:01<00:15, 254.27it/s] 13%|█▎        | 579/4500 [00:01<00:15, 258.84it/s] 14%|█▍        | 622/4500 [00:02<00:12, 301.59it/s] 15%|█▍        | 654/4500 [00:02<00:12, 303.52it/s] 15%|█▌        | 697/4500 [00:02<00:11, 330.93it/s] 16%|█▌        | 731/4500 [00:02<00:12, 290.70it/s] 17%|█▋        | 762/4500 [00:02<00:12, 292.17it/s] 18%|█▊        | 793/4500 [00:02<00:12, 291.57it/s] 19%|█▊        | 835/4500 [00:02<00:11, 326.46it/s] 19%|█▉        | 871/4500 [00:02<00:11, 329.43it/s] 20%|██        | 918/4500 [00:02<00:09, 364.63it/s] 21%|██        | 956/4500 [00:03<00:10, 325.78it/s] 22%|██▏       | 990/4500 [00:03<00:11, 307.97it/s] 23%|██▎       | 1032/4500 [00:03<00:10, 331.58it/s] 24%|██▍       | 1072/4500 [00:03<00:10, 340.79it/s] 25%|██▌       | 1125/4500 [00:03<00:08, 389.16it/s] 27%|██▋       | 1194/4500 [00:03<00:07, 467.06it/s] 28%|██▊       | 1271/4500 [00:03<00:05, 551.73it/s] 30%|██▉       | 1338/4500 [00:03<00:05, 580.66it/s] 31%|███▏      | 1407/4500 [00:03<00:05, 594.94it/s] 33%|███▎      | 1468/4500 [00:04<00:07, 426.89it/s] 34%|███▎      | 1518/4500 [00:04<00:07, 408.82it/s] 35%|███▌      | 1586/4500 [00:04<00:06, 469.18it/s] 36%|███▋      | 1639/4500 [00:04<00:07, 395.95it/s] 37%|███▋      | 1684/4500 [00:04<00:08, 349.31it/s] 39%|███▊      | 1734/4500 [00:04<00:07, 379.97it/s] 40%|███▉      | 1779/4500 [00:04<00:06, 396.05it/s] 41%|████      | 1839/4500 [00:05<00:06, 441.09it/s] 43%|████▎     | 1920/4500 [00:05<00:04, 528.53it/s] 44%|████▍     | 1986/4500 [00:05<00:04, 559.27it/s] 46%|████▌     | 2060/4500 [00:05<00:04, 596.44it/s] 47%|████▋     | 2122/4500 [00:05<00:04, 565.69it/s] 49%|████▊     | 2189/4500 [00:05<00:03, 591.75it/s] 50%|█████     | 2250/4500 [00:05<00:04, 497.54it/s] 51%|█████     | 2303/4500 [00:05<00:05, 418.66it/s] 52%|█████▏    | 2349/4500 [00:06<00:05, 393.79it/s] 53%|█████▎    | 2392/4500 [00:06<00:05, 362.06it/s] 54%|█████▍    | 2451/4500 [00:06<00:05, 400.31it/s] 55%|█████▌    | 2495/4500 [00:06<00:04, 404.41it/s] 57%|█████▋    | 2552/4500 [00:06<00:04, 442.30it/s] 58%|█████▊    | 2608/4500 [00:06<00:04, 452.27it/s] 59%|█████▉    | 2655/4500 [00:06<00:04, 445.99it/s] 60%|██████    | 2705/4500 [00:06<00:04, 443.27it/s] 61%|██████▏   | 2765/4500 [00:07<00:03, 477.81it/s] 63%|██████▎   | 2820/4500 [00:07<00:03, 483.96it/s] 65%|██████▍   | 2909/4500 [00:07<00:02, 583.72it/s] 66%|██████▌   | 2974/4500 [00:07<00:02, 571.84it/s] 67%|██████▋   | 3032/4500 [00:07<00:02, 559.34it/s] 69%|██████▊   | 3089/4500 [00:07<00:02, 513.64it/s] 70%|██████▉   | 3142/4500 [00:07<00:03, 419.80it/s] 71%|███████   | 3187/4500 [00:07<00:03, 382.37it/s] 72%|███████▏  | 3232/4500 [00:08<00:03, 393.80it/s] 73%|███████▎  | 3284/4500 [00:08<00:02, 421.05it/s] 74%|███████▍  | 3328/4500 [00:08<00:02, 421.32it/s] 75%|███████▍  | 3372/4500 [00:08<00:02, 381.75it/s] 76%|███████▌  | 3412/4500 [00:08<00:02, 369.19it/s] 77%|███████▋  | 3467/4500 [00:08<00:02, 403.72it/s] 78%|███████▊  | 3509/4500 [00:08<00:03, 320.17it/s] 79%|███████▉  | 3545/4500 [00:09<00:04, 231.87it/s] 79%|███████▉  | 3574/4500 [00:09<00:04, 195.42it/s] 80%|███████▉  | 3598/4500 [00:09<00:04, 186.73it/s] 81%|████████  | 3647/4500 [00:09<00:03, 242.36it/s] 82%|████████▏ | 3710/4500 [00:09<00:02, 323.63it/s] 83%|████████▎ | 3751/4500 [00:09<00:02, 336.72it/s] 85%|████████▍ | 3812/4500 [00:09<00:01, 401.31it/s] 86%|████████▌ | 3858/4500 [00:10<00:01, 414.59it/s] 87%|████████▋ | 3913/4500 [00:10<00:01, 448.53it/s] 89%|████████▊ | 3983/4500 [00:10<00:01, 510.62it/s] 90%|████████▉ | 4047/4500 [00:10<00:00, 541.65it/s] 91%|█████████ | 4103/4500 [00:10<00:00, 434.62it/s] 92%|█████████▏| 4151/4500 [00:10<00:00, 437.38it/s] 93%|█████████▎| 4198/4500 [00:10<00:00, 428.50it/s] 95%|█████████▌| 4283/4500 [00:10<00:00, 532.46it/s] 96%|█████████▋| 4340/4500 [00:10<00:00, 508.40it/s] 98%|█████████▊| 4393/4500 [00:11<00:00, 468.41it/s] 99%|█████████▉| 4467/4500 [00:11<00:00, 537.83it/s]100%|██████████| 4500/4500 [00:11<00:00, 399.77it/s]
test_p56 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p56
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p56.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.09s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.52it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.44it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.48it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.15it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p56_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p56_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p56_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p56_Holmes_probs.npy
{'Accuracy': 0.9731, 'Precision': 0.9736, 'Recall': 0.9731, 'F1-score': 0.973}
starting gen taf script for test_p57
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 60/4500 [00:00<00:07, 564.74it/s]  3%|▎         | 117/4500 [00:00<00:08, 500.71it/s]  4%|▎         | 168/4500 [00:00<00:09, 459.71it/s]  5%|▍         | 215/4500 [00:00<00:09, 460.38it/s]  6%|▌         | 266/4500 [00:00<00:08, 472.78it/s]  7%|▋         | 314/4500 [00:00<00:10, 403.33it/s]  8%|▊         | 356/4500 [00:00<00:14, 283.55it/s]  9%|▊         | 390/4500 [00:01<00:15, 264.05it/s]  9%|▉         | 422/4500 [00:01<00:15, 269.58it/s] 10%|█         | 459/4500 [00:01<00:13, 292.68it/s] 11%|█         | 506/4500 [00:01<00:12, 329.10it/s] 12%|█▏        | 542/4500 [00:01<00:12, 323.85it/s] 13%|█▎        | 582/4500 [00:01<00:11, 343.66it/s] 14%|█▍        | 639/4500 [00:01<00:09, 400.03it/s] 15%|█▌        | 681/4500 [00:01<00:09, 399.57it/s] 16%|█▌        | 722/4500 [00:02<00:10, 358.44it/s] 17%|█▋        | 765/4500 [00:02<00:09, 375.20it/s] 18%|█▊        | 811/4500 [00:02<00:09, 395.65it/s] 19%|█▉        | 876/4500 [00:02<00:07, 460.14it/s] 21%|██        | 927/4500 [00:02<00:07, 463.07it/s] 22%|██▏       | 974/4500 [00:02<00:08, 435.49it/s] 23%|██▎       | 1033/4500 [00:02<00:07, 477.36it/s] 24%|██▍       | 1084/4500 [00:02<00:07, 479.79it/s] 26%|██▌       | 1169/4500 [00:02<00:05, 581.57it/s] 28%|██▊       | 1268/4500 [00:02<00:04, 682.83it/s] 30%|███       | 1362/4500 [00:03<00:04, 755.69it/s] 32%|███▏      | 1439/4500 [00:03<00:05, 603.89it/s] 33%|███▎      | 1505/4500 [00:03<00:06, 475.14it/s] 35%|███▌      | 1575/4500 [00:03<00:05, 521.01it/s] 36%|███▋      | 1634/4500 [00:03<00:06, 422.35it/s] 37%|███▋      | 1684/4500 [00:04<00:07, 361.24it/s] 39%|███▊      | 1737/4500 [00:04<00:07, 393.65it/s] 40%|███▉      | 1783/4500 [00:04<00:06, 397.26it/s] 41%|████      | 1845/4500 [00:04<00:06, 439.85it/s] 42%|████▏     | 1903/4500 [00:04<00:05, 474.17it/s] 44%|████▎     | 1968/4500 [00:04<00:04, 515.70it/s] 45%|████▍     | 2023/4500 [00:04<00:04, 496.76it/s] 46%|████▌     | 2075/4500 [00:04<00:04, 497.18it/s] 48%|████▊     | 2140/4500 [00:04<00:04, 527.36it/s] 49%|████▉     | 2203/4500 [00:04<00:04, 548.35it/s] 50%|█████     | 2259/4500 [00:05<00:04, 465.27it/s] 51%|█████▏    | 2309/4500 [00:05<00:05, 392.84it/s] 52%|█████▏    | 2352/4500 [00:05<00:05, 363.50it/s] 53%|█████▎    | 2397/4500 [00:05<00:05, 377.46it/s] 54%|█████▍    | 2442/4500 [00:05<00:05, 388.57it/s] 56%|█████▌    | 2499/4500 [00:05<00:04, 433.06it/s] 57%|█████▋    | 2548/4500 [00:05<00:04, 445.89it/s] 58%|█████▊    | 2595/4500 [00:06<00:04, 423.99it/s] 59%|█████▊    | 2639/4500 [00:06<00:04, 410.91it/s] 60%|█████▉    | 2693/4500 [00:06<00:04, 441.73it/s] 61%|██████    | 2753/4500 [00:06<00:03, 482.48it/s] 62%|██████▏   | 2803/4500 [00:06<00:04, 408.02it/s] 64%|██████▎   | 2859/4500 [00:06<00:03, 444.33it/s] 65%|██████▌   | 2926/4500 [00:06<00:03, 493.46it/s] 66%|██████▌   | 2978/4500 [00:06<00:03, 480.92it/s] 67%|██████▋   | 3036/4500 [00:06<00:02, 493.56it/s] 69%|██████▊   | 3087/4500 [00:07<00:02, 474.95it/s] 70%|██████▉   | 3136/4500 [00:07<00:03, 375.20it/s] 71%|███████   | 3178/4500 [00:07<00:03, 383.25it/s] 72%|███████▏  | 3239/4500 [00:07<00:02, 438.96it/s] 73%|███████▎  | 3286/4500 [00:07<00:02, 425.00it/s] 74%|███████▍  | 3339/4500 [00:07<00:02, 450.57it/s] 75%|███████▌  | 3386/4500 [00:07<00:02, 427.11it/s] 76%|███████▌  | 3431/4500 [00:07<00:02, 407.25it/s] 77%|███████▋  | 3473/4500 [00:08<00:02, 377.12it/s] 78%|███████▊  | 3512/4500 [00:08<00:03, 302.07it/s] 79%|███████▉  | 3545/4500 [00:08<00:04, 225.72it/s] 79%|███████▉  | 3572/4500 [00:08<00:05, 185.29it/s] 80%|███████▉  | 3595/4500 [00:08<00:05, 164.30it/s] 81%|████████  | 3649/4500 [00:09<00:03, 230.48it/s] 82%|████████▏ | 3702/4500 [00:09<00:02, 290.46it/s] 83%|████████▎ | 3739/4500 [00:09<00:02, 304.56it/s] 84%|████████▍ | 3785/4500 [00:09<00:02, 336.04it/s] 85%|████████▌ | 3838/4500 [00:09<00:01, 382.85it/s] 87%|████████▋ | 3898/4500 [00:09<00:01, 433.59it/s] 88%|████████▊ | 3950/4500 [00:09<00:01, 453.59it/s] 89%|████████▉ | 4012/4500 [00:09<00:01, 469.48it/s] 90%|█████████ | 4061/4500 [00:09<00:00, 439.04it/s] 92%|█████████▏| 4120/4500 [00:10<00:00, 472.50it/s] 93%|█████████▎| 4169/4500 [00:10<00:00, 378.99it/s] 94%|█████████▎| 4215/4500 [00:10<00:00, 396.57it/s] 95%|█████████▌| 4276/4500 [00:10<00:00, 443.66it/s] 96%|█████████▌| 4327/4500 [00:10<00:00, 441.62it/s] 97%|█████████▋| 4374/4500 [00:10<00:00, 416.18it/s] 98%|█████████▊| 4418/4500 [00:10<00:00, 399.82it/s]100%|██████████| 4500/4500 [00:10<00:00, 412.48it/s]
test_p57 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p57
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p57.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.82it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.94it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.16it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.55it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p57_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p57_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p57_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p57_Holmes_probs.npy
{'Accuracy': 0.9751, 'Precision': 0.9756, 'Recall': 0.9751, 'F1-score': 0.975}
starting gen taf script for test_p58
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 63/4500 [00:00<00:07, 628.60it/s]  3%|▎         | 126/4500 [00:00<00:08, 503.77it/s]  4%|▍         | 178/4500 [00:00<00:09, 472.58it/s]  5%|▌         | 227/4500 [00:00<00:09, 464.46it/s]  6%|▋         | 292/4500 [00:00<00:08, 521.96it/s]  8%|▊         | 346/4500 [00:00<00:11, 374.02it/s]  9%|▊         | 389/4500 [00:00<00:12, 326.29it/s] 10%|▉         | 435/4500 [00:01<00:11, 352.72it/s] 11%|█         | 483/4500 [00:01<00:10, 379.28it/s] 12%|█▏        | 525/4500 [00:01<00:10, 375.36it/s] 13%|█▎        | 565/4500 [00:01<00:10, 358.88it/s] 13%|█▎        | 603/4500 [00:01<00:11, 343.71it/s] 14%|█▍        | 639/4500 [00:01<00:11, 329.08it/s] 15%|█▍        | 674/4500 [00:01<00:11, 327.83it/s] 16%|█▌        | 708/4500 [00:01<00:11, 327.85it/s] 16%|█▋        | 742/4500 [00:01<00:11, 329.09it/s] 17%|█▋        | 776/4500 [00:02<00:11, 328.01it/s] 18%|█▊        | 814/4500 [00:02<00:10, 339.31it/s] 19%|█▉        | 853/4500 [00:02<00:10, 353.19it/s] 20%|█▉        | 896/4500 [00:02<00:10, 358.48it/s] 21%|██        | 953/4500 [00:02<00:08, 415.38it/s] 22%|██▏       | 1004/4500 [00:02<00:08, 431.37it/s] 24%|██▍       | 1071/4500 [00:02<00:06, 491.68it/s] 25%|██▌       | 1145/4500 [00:02<00:06, 554.02it/s] 27%|██▋       | 1211/4500 [00:02<00:05, 584.30it/s] 28%|██▊       | 1270/4500 [00:03<00:05, 558.72it/s] 29%|██▉       | 1327/4500 [00:03<00:05, 561.22it/s] 31%|███       | 1384/4500 [00:03<00:05, 526.11it/s] 32%|███▏      | 1438/4500 [00:03<00:06, 444.04it/s] 33%|███▎      | 1488/4500 [00:03<00:06, 441.92it/s] 34%|███▍      | 1534/4500 [00:03<00:06, 435.60it/s] 36%|███▌      | 1603/4500 [00:03<00:05, 492.29it/s] 37%|███▋      | 1654/4500 [00:04<00:07, 374.69it/s] 38%|███▊      | 1697/4500 [00:04<00:08, 333.62it/s] 39%|███▊      | 1739/4500 [00:04<00:07, 348.24it/s] 40%|████      | 1810/4500 [00:04<00:06, 432.36it/s] 42%|████▏     | 1872/4500 [00:04<00:05, 478.00it/s] 43%|████▎     | 1927/4500 [00:04<00:05, 496.24it/s] 44%|████▍     | 2001/4500 [00:04<00:04, 550.56it/s] 46%|████▌     | 2064/4500 [00:04<00:04, 569.34it/s] 47%|████▋     | 2123/4500 [00:04<00:04, 531.00it/s] 49%|████▊     | 2187/4500 [00:05<00:04, 552.29it/s] 50%|████▉     | 2244/4500 [00:05<00:04, 484.29it/s] 51%|█████     | 2295/4500 [00:05<00:05, 392.89it/s] 52%|█████▏    | 2339/4500 [00:05<00:06, 330.44it/s] 53%|█████▎    | 2376/4500 [00:05<00:07, 302.57it/s] 55%|█████▍    | 2456/4500 [00:05<00:05, 405.08it/s] 56%|█████▌    | 2503/4500 [00:05<00:04, 416.91it/s] 57%|█████▋    | 2570/4500 [00:06<00:04, 479.16it/s] 58%|█████▊    | 2623/4500 [00:06<00:04, 449.67it/s] 59%|█████▉    | 2674/4500 [00:06<00:03, 464.13it/s] 61%|██████    | 2724/4500 [00:06<00:04, 439.79it/s] 62%|██████▏   | 2770/4500 [00:06<00:04, 428.58it/s] 63%|██████▎   | 2822/4500 [00:06<00:03, 445.53it/s] 64%|██████▍   | 2887/4500 [00:06<00:03, 495.66it/s] 65%|██████▌   | 2947/4500 [00:06<00:03, 514.98it/s] 67%|██████▋   | 3000/4500 [00:06<00:03, 474.85it/s] 68%|██████▊   | 3053/4500 [00:07<00:03, 476.78it/s] 69%|██████▉   | 3102/4500 [00:07<00:02, 472.82it/s] 70%|███████   | 3150/4500 [00:07<00:03, 417.07it/s] 71%|███████   | 3194/4500 [00:07<00:03, 354.78it/s] 72%|███████▏  | 3257/4500 [00:07<00:03, 413.80it/s] 73%|███████▎  | 3302/4500 [00:07<00:02, 411.23it/s] 74%|███████▍  | 3346/4500 [00:07<00:03, 350.40it/s] 76%|███████▌  | 3408/4500 [00:08<00:02, 394.20it/s] 77%|███████▋  | 3453/4500 [00:08<00:02, 402.57it/s] 78%|███████▊  | 3496/4500 [00:08<00:02, 398.35it/s] 79%|███████▊  | 3538/4500 [00:08<00:04, 227.24it/s] 79%|███████▉  | 3570/4500 [00:08<00:05, 174.98it/s] 80%|███████▉  | 3598/4500 [00:09<00:04, 189.16it/s] 81%|████████  | 3652/4500 [00:09<00:03, 248.05it/s] 82%|████████▏ | 3706/4500 [00:09<00:02, 304.11it/s] 83%|████████▎ | 3749/4500 [00:09<00:02, 329.11it/s] 84%|████████▍ | 3802/4500 [00:09<00:01, 370.74it/s] 86%|████████▌ | 3876/4500 [00:09<00:01, 463.08it/s] 87%|████████▋ | 3928/4500 [00:09<00:01, 457.91it/s] 88%|████████▊ | 3980/4500 [00:09<00:01, 453.84it/s] 90%|████████▉ | 4029/4500 [00:09<00:01, 407.32it/s] 91%|█████████ | 4079/4500 [00:10<00:00, 428.44it/s] 92%|█████████▏| 4127/4500 [00:10<00:00, 438.18it/s] 93%|█████████▎| 4173/4500 [00:10<00:00, 408.70it/s] 94%|█████████▎| 4216/4500 [00:10<00:00, 395.20it/s] 96%|█████████▌| 4300/4500 [00:10<00:00, 504.95it/s] 97%|█████████▋| 4353/4500 [00:10<00:00, 430.35it/s] 98%|█████████▊| 4399/4500 [00:10<00:00, 394.99it/s] 99%|█████████▉| 4474/4500 [00:10<00:00, 475.70it/s]100%|██████████| 4500/4500 [00:10<00:00, 410.38it/s]
test_p58 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p58
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p58.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.04it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.21it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.63it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.02it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.23it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p58_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p58_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p58_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p58_Holmes_probs.npy
{'Accuracy': 0.976, 'Precision': 0.9764, 'Recall': 0.976, 'F1-score': 0.9759}
starting gen taf script for test_p59
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 65/4500 [00:00<00:06, 636.38it/s]  3%|▎         | 129/4500 [00:00<00:09, 469.06it/s]  4%|▍         | 179/4500 [00:00<00:10, 426.85it/s]  5%|▍         | 223/4500 [00:00<00:10, 407.29it/s]  6%|▌         | 280/4500 [00:00<00:09, 453.79it/s]  7%|▋         | 327/4500 [00:00<00:11, 362.58it/s]  8%|▊         | 367/4500 [00:01<00:14, 288.13it/s]  9%|▉         | 400/4500 [00:01<00:15, 257.11it/s] 10%|▉         | 440/4500 [00:01<00:14, 285.28it/s] 11%|█         | 499/4500 [00:01<00:11, 353.94it/s] 12%|█▏        | 539/4500 [00:01<00:11, 348.11it/s] 13%|█▎        | 577/4500 [00:01<00:11, 347.27it/s] 14%|█▎        | 614/4500 [00:01<00:11, 334.33it/s] 14%|█▍        | 649/4500 [00:01<00:13, 292.23it/s] 15%|█▌        | 684/4500 [00:02<00:12, 305.30it/s] 16%|█▌        | 716/4500 [00:02<00:13, 281.40it/s] 17%|█▋        | 746/4500 [00:02<00:14, 266.47it/s] 17%|█▋        | 774/4500 [00:02<00:14, 263.68it/s] 18%|█▊        | 808/4500 [00:02<00:13, 283.21it/s] 19%|█▉        | 848/4500 [00:02<00:11, 313.64it/s] 20%|██        | 902/4500 [00:02<00:09, 367.06it/s] 21%|██        | 940/4500 [00:02<00:10, 335.20it/s] 22%|██▏       | 975/4500 [00:02<00:11, 311.77it/s] 22%|██▏       | 1007/4500 [00:03<00:12, 273.30it/s] 23%|██▎       | 1053/4500 [00:03<00:11, 312.66it/s] 25%|██▍       | 1123/4500 [00:03<00:08, 405.76it/s] 27%|██▋       | 1211/4500 [00:03<00:06, 527.06it/s] 29%|██▊       | 1287/4500 [00:03<00:05, 587.34it/s] 30%|██▉       | 1349/4500 [00:03<00:05, 588.31it/s] 31%|███▏      | 1410/4500 [00:03<00:05, 589.16it/s] 33%|███▎      | 1471/4500 [00:03<00:06, 437.88it/s] 34%|███▍      | 1522/4500 [00:04<00:07, 398.24it/s] 35%|███▌      | 1580/4500 [00:04<00:06, 431.91it/s] 36%|███▌      | 1628/4500 [00:04<00:06, 420.38it/s] 37%|███▋      | 1673/4500 [00:04<00:08, 335.72it/s] 38%|███▊      | 1728/4500 [00:04<00:07, 380.29it/s] 40%|███▉      | 1785/4500 [00:04<00:06, 416.69it/s] 41%|████▏     | 1861/4500 [00:04<00:05, 501.36it/s] 43%|████▎     | 1916/4500 [00:04<00:05, 511.56it/s] 44%|████▍     | 1978/4500 [00:05<00:04, 533.92it/s] 45%|████▌     | 2034/4500 [00:05<00:04, 508.78it/s] 47%|████▋     | 2105/4500 [00:05<00:04, 557.09it/s] 48%|████▊     | 2163/4500 [00:05<00:04, 517.53it/s] 49%|████▉     | 2217/4500 [00:05<00:04, 508.34it/s] 50%|█████     | 2269/4500 [00:05<00:05, 419.41it/s] 51%|█████▏    | 2314/4500 [00:05<00:05, 378.56it/s] 52%|█████▏    | 2355/4500 [00:06<00:05, 377.43it/s] 53%|█████▎    | 2395/4500 [00:06<00:06, 343.69it/s] 54%|█████▍    | 2452/4500 [00:06<00:05, 391.77it/s] 56%|█████▌    | 2506/4500 [00:06<00:04, 416.99it/s] 57%|█████▋    | 2560/4500 [00:06<00:04, 448.80it/s] 58%|█████▊    | 2628/4500 [00:06<00:03, 507.99it/s] 60%|█████▉    | 2681/4500 [00:06<00:04, 412.34it/s] 61%|██████    | 2731/4500 [00:06<00:04, 430.12it/s] 62%|██████▏   | 2778/4500 [00:06<00:04, 418.00it/s] 63%|██████▎   | 2836/4500 [00:07<00:03, 450.18it/s] 65%|██████▍   | 2905/4500 [00:07<00:03, 501.25it/s] 66%|██████▌   | 2979/4500 [00:07<00:02, 539.77it/s] 68%|██████▊   | 3061/4500 [00:07<00:02, 614.06it/s] 69%|██████▉   | 3125/4500 [00:07<00:02, 508.01it/s] 71%|███████   | 3180/4500 [00:07<00:03, 409.49it/s] 72%|███████▏  | 3232/4500 [00:07<00:02, 432.77it/s] 73%|███████▎  | 3283/4500 [00:08<00:02, 444.55it/s] 74%|███████▍  | 3331/4500 [00:08<00:02, 441.97it/s] 75%|███████▌  | 3378/4500 [00:08<00:02, 422.24it/s] 76%|███████▌  | 3426/4500 [00:08<00:02, 432.60it/s] 77%|███████▋  | 3471/4500 [00:08<00:02, 387.00it/s] 78%|███████▊  | 3512/4500 [00:08<00:03, 316.36it/s] 79%|███████▉  | 3547/4500 [00:08<00:04, 237.85it/s] 79%|███████▉  | 3576/4500 [00:09<00:04, 194.79it/s] 80%|████████  | 3600/4500 [00:09<00:04, 189.75it/s] 81%|████████  | 3634/4500 [00:09<00:03, 217.84it/s] 82%|████████▏ | 3681/4500 [00:09<00:03, 265.51it/s] 83%|████████▎ | 3724/4500 [00:09<00:02, 298.26it/s] 84%|████████▍ | 3789/4500 [00:09<00:01, 375.07it/s] 85%|████████▌ | 3838/4500 [00:09<00:01, 395.43it/s] 87%|████████▋ | 3916/4500 [00:09<00:01, 491.51it/s] 88%|████████▊ | 3969/4500 [00:10<00:01, 501.75it/s] 90%|████████▉ | 4029/4500 [00:10<00:00, 524.17it/s] 91%|█████████ | 4084/4500 [00:10<00:00, 487.77it/s] 92%|█████████▏| 4135/4500 [00:10<00:00, 462.70it/s] 93%|█████████▎| 4183/4500 [00:10<00:00, 415.11it/s] 94%|█████████▍| 4239/4500 [00:10<00:00, 447.51it/s] 96%|█████████▌| 4298/4500 [00:10<00:00, 478.00it/s] 97%|█████████▋| 4357/4500 [00:10<00:00, 495.45it/s] 98%|█████████▊| 4409/4500 [00:11<00:00, 499.45it/s] 99%|█████████▉| 4474/4500 [00:11<00:00, 537.88it/s]100%|██████████| 4500/4500 [00:11<00:00, 404.26it/s]
test_p59 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p59
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p59.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.08s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.55it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.48it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.61it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.14it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p59_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p59_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p59_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p59_Holmes_probs.npy
{'Accuracy': 0.9767, 'Precision': 0.9771, 'Recall': 0.9767, 'F1-score': 0.9765}
starting gen taf script for test_p60
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 71/4500 [00:00<00:06, 693.87it/s]  3%|▎         | 141/4500 [00:00<00:09, 456.79it/s]  4%|▍         | 192/4500 [00:00<00:11, 384.19it/s]  5%|▌         | 234/4500 [00:00<00:11, 366.38it/s]  6%|▌         | 279/4500 [00:00<00:10, 388.68it/s]  7%|▋         | 320/4500 [00:00<00:13, 311.78it/s]  8%|▊         | 354/4500 [00:01<00:16, 256.71it/s]  9%|▊         | 383/4500 [00:01<00:17, 236.36it/s]  9%|▉         | 425/4500 [00:01<00:14, 273.40it/s] 10%|█         | 455/4500 [00:01<00:14, 277.66it/s] 11%|█         | 499/4500 [00:01<00:12, 315.74it/s] 12%|█▏        | 533/4500 [00:01<00:12, 306.24it/s] 13%|█▎        | 566/4500 [00:01<00:12, 307.78it/s] 13%|█▎        | 602/4500 [00:01<00:12, 310.73it/s] 14%|█▍        | 642/4500 [00:01<00:11, 329.88it/s] 15%|█▌        | 690/4500 [00:02<00:10, 367.88it/s] 16%|█▌        | 728/4500 [00:02<00:10, 355.51it/s] 17%|█▋        | 765/4500 [00:02<00:11, 335.19it/s] 18%|█▊        | 800/4500 [00:02<00:11, 314.47it/s] 20%|█▉        | 896/4500 [00:02<00:07, 483.83it/s] 21%|██        | 954/4500 [00:02<00:07, 501.50it/s] 23%|██▎       | 1021/4500 [00:02<00:06, 537.24it/s] 24%|██▍       | 1078/4500 [00:02<00:06, 544.89it/s] 25%|██▌       | 1134/4500 [00:03<00:06, 517.15it/s] 27%|██▋       | 1207/4500 [00:03<00:05, 570.74it/s] 28%|██▊       | 1272/4500 [00:03<00:05, 586.85it/s] 30%|██▉       | 1332/4500 [00:03<00:05, 586.12it/s] 31%|███       | 1392/4500 [00:03<00:05, 542.49it/s] 32%|███▏      | 1448/4500 [00:03<00:06, 505.82it/s] 33%|███▎      | 1500/4500 [00:03<00:07, 426.05it/s] 35%|███▍      | 1574/4500 [00:03<00:05, 499.85it/s] 36%|███▌      | 1628/4500 [00:04<00:06, 415.06it/s] 37%|███▋      | 1674/4500 [00:04<00:08, 347.79it/s] 38%|███▊      | 1720/4500 [00:04<00:07, 366.05it/s] 40%|████      | 1804/4500 [00:04<00:05, 465.49it/s] 41%|████▏     | 1858/4500 [00:04<00:05, 478.25it/s] 43%|████▎     | 1934/4500 [00:04<00:04, 542.58it/s] 45%|████▍     | 2003/4500 [00:04<00:04, 581.45it/s] 46%|████▌     | 2068/4500 [00:04<00:04, 588.39it/s] 47%|████▋     | 2129/4500 [00:04<00:04, 578.16it/s] 49%|████▊     | 2189/4500 [00:05<00:04, 541.76it/s] 50%|████▉     | 2245/4500 [00:05<00:04, 454.43it/s] 51%|█████     | 2294/4500 [00:05<00:05, 385.50it/s] 52%|█████▏    | 2336/4500 [00:05<00:06, 327.79it/s] 53%|█████▎    | 2381/4500 [00:05<00:06, 346.49it/s] 54%|█████▍    | 2420/4500 [00:05<00:05, 352.61it/s] 55%|█████▌    | 2485/4500 [00:05<00:04, 422.39it/s] 56%|█████▋    | 2542/4500 [00:06<00:04, 456.26it/s] 58%|█████▊    | 2591/4500 [00:06<00:04, 443.56it/s] 59%|█████▉    | 2650/4500 [00:06<00:04, 448.01it/s] 60%|█████▉    | 2699/4500 [00:06<00:03, 454.23it/s] 61%|██████    | 2754/4500 [00:06<00:03, 468.12it/s] 62%|██████▏   | 2805/4500 [00:06<00:03, 469.87it/s] 63%|██████▎   | 2853/4500 [00:06<00:03, 444.25it/s] 65%|██████▍   | 2910/4500 [00:06<00:03, 453.91it/s] 66%|██████▌   | 2969/4500 [00:06<00:03, 489.02it/s] 67%|██████▋   | 3019/4500 [00:07<00:03, 478.62it/s] 68%|██████▊   | 3068/4500 [00:07<00:03, 445.18it/s] 69%|██████▉   | 3114/4500 [00:07<00:03, 418.46it/s] 70%|███████   | 3157/4500 [00:07<00:03, 401.91it/s] 71%|███████   | 3198/4500 [00:07<00:03, 369.94it/s] 72%|███████▏  | 3252/4500 [00:07<00:03, 403.60it/s] 74%|███████▍  | 3319/4500 [00:07<00:02, 473.67it/s] 75%|███████▍  | 3368/4500 [00:07<00:02, 473.83it/s] 76%|███████▌  | 3417/4500 [00:08<00:02, 450.45it/s] 77%|███████▋  | 3463/4500 [00:08<00:02, 418.83it/s] 78%|███████▊  | 3506/4500 [00:08<00:02, 336.39it/s] 79%|███████▊  | 3543/4500 [00:08<00:04, 196.86it/s] 79%|███████▉  | 3572/4500 [00:08<00:04, 195.33it/s] 80%|███████▉  | 3598/4500 [00:09<00:04, 182.48it/s] 81%|████████  | 3644/4500 [00:09<00:03, 226.47it/s] 82%|████████▏ | 3700/4500 [00:09<00:02, 289.85it/s] 84%|████████▍ | 3770/4500 [00:09<00:01, 374.82it/s] 85%|████████▍ | 3815/4500 [00:09<00:01, 384.21it/s] 86%|████████▌ | 3876/4500 [00:09<00:01, 429.58it/s] 88%|████████▊ | 3940/4500 [00:09<00:01, 483.40it/s] 89%|████████▊ | 3993/4500 [00:09<00:01, 487.87it/s] 90%|████████▉ | 4045/4500 [00:09<00:00, 481.52it/s] 91%|█████████ | 4095/4500 [00:10<00:00, 451.26it/s] 92%|█████████▏| 4142/4500 [00:10<00:00, 416.75it/s] 93%|█████████▎| 4186/4500 [00:10<00:00, 404.04it/s] 94%|█████████▍| 4245/4500 [00:10<00:00, 448.51it/s] 96%|█████████▌| 4319/4500 [00:10<00:00, 508.56it/s] 97%|█████████▋| 4371/4500 [00:10<00:00, 469.29it/s] 98%|█████████▊| 4419/4500 [00:10<00:00, 464.36it/s] 99%|█████████▉| 4471/4500 [00:10<00:00, 478.94it/s]100%|██████████| 4500/4500 [00:10<00:00, 411.55it/s]
test_p60 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p60
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p60.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.08it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.44it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.02it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.49it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.57it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p60_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p60_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p60_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p60_Holmes_probs.npy
{'Accuracy': 0.9769, 'Precision': 0.9772, 'Recall': 0.9769, 'F1-score': 0.9768}
starting gen taf script for test_p61
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 56/4500 [00:00<00:08, 528.61it/s]  2%|▏         | 109/4500 [00:00<00:15, 275.81it/s]  3%|▎         | 143/4500 [00:00<00:19, 220.52it/s]  4%|▍         | 178/4500 [00:00<00:17, 250.81it/s]  5%|▍         | 222/4500 [00:00<00:14, 297.91it/s]  6%|▌         | 258/4500 [00:00<00:13, 314.27it/s]  7%|▋         | 298/4500 [00:00<00:12, 325.77it/s]  7%|▋         | 333/4500 [00:01<00:17, 232.24it/s]  8%|▊         | 362/4500 [00:01<00:20, 206.46it/s]  9%|▊         | 387/4500 [00:01<00:20, 203.89it/s] 10%|▉         | 428/4500 [00:01<00:16, 244.40it/s] 11%|█         | 481/4500 [00:01<00:13, 308.00it/s] 11%|█▏        | 516/4500 [00:01<00:13, 300.27it/s] 12%|█▏        | 549/4500 [00:02<00:13, 286.73it/s] 13%|█▎        | 580/4500 [00:02<00:14, 273.71it/s] 14%|█▎        | 610/4500 [00:02<00:14, 270.16it/s] 14%|█▍        | 647/4500 [00:02<00:13, 285.65it/s] 15%|█▌        | 681/4500 [00:02<00:12, 299.09it/s] 16%|█▌        | 713/4500 [00:02<00:12, 303.69it/s] 17%|█▋        | 744/4500 [00:02<00:13, 284.09it/s] 17%|█▋        | 777/4500 [00:02<00:12, 289.45it/s] 18%|█▊        | 819/4500 [00:02<00:11, 324.86it/s] 19%|█▉        | 862/4500 [00:03<00:10, 353.16it/s] 20%|██        | 917/4500 [00:03<00:08, 400.30it/s] 22%|██▏       | 989/4500 [00:03<00:07, 486.03it/s] 23%|██▎       | 1039/4500 [00:03<00:07, 454.52it/s] 24%|██▍       | 1086/4500 [00:03<00:07, 458.27it/s] 26%|██▌       | 1173/4500 [00:03<00:05, 572.78it/s] 28%|██▊       | 1270/4500 [00:03<00:04, 686.61it/s] 30%|██▉       | 1340/4500 [00:03<00:04, 660.09it/s] 31%|███▏      | 1408/4500 [00:03<00:05, 616.19it/s] 33%|███▎      | 1471/4500 [00:04<00:06, 480.37it/s] 34%|███▍      | 1525/4500 [00:04<00:06, 443.97it/s] 35%|███▌      | 1588/4500 [00:04<00:05, 486.03it/s] 36%|███▋      | 1641/4500 [00:04<00:06, 415.08it/s] 37%|███▋      | 1687/4500 [00:04<00:08, 350.42it/s] 39%|███▊      | 1734/4500 [00:04<00:07, 372.19it/s] 40%|███▉      | 1798/4500 [00:04<00:06, 426.69it/s] 41%|████      | 1853/4500 [00:05<00:05, 450.59it/s] 42%|████▏     | 1905/4500 [00:05<00:05, 464.95it/s] 44%|████▎     | 1966/4500 [00:05<00:05, 490.79it/s] 45%|████▌     | 2028/4500 [00:05<00:04, 518.98it/s] 46%|████▋     | 2082/4500 [00:05<00:04, 498.15it/s] 48%|████▊     | 2149/4500 [00:05<00:04, 534.60it/s] 49%|████▉     | 2214/4500 [00:05<00:04, 544.77it/s] 50%|█████     | 2270/4500 [00:05<00:05, 408.78it/s] 51%|█████▏    | 2317/4500 [00:06<00:05, 382.84it/s] 52%|█████▏    | 2359/4500 [00:06<00:06, 329.65it/s] 53%|█████▎    | 2396/4500 [00:06<00:06, 326.21it/s] 55%|█████▍    | 2465/4500 [00:06<00:04, 408.12it/s] 56%|█████▌    | 2514/4500 [00:06<00:04, 428.15it/s] 57%|█████▋    | 2561/4500 [00:06<00:05, 387.59it/s] 58%|█████▊    | 2608/4500 [00:06<00:04, 404.70it/s] 59%|█████▉    | 2670/4500 [00:06<00:03, 458.75it/s] 60%|██████    | 2719/4500 [00:07<00:04, 429.48it/s] 61%|██████▏   | 2764/4500 [00:07<00:04, 422.48it/s] 63%|██████▎   | 2818/4500 [00:07<00:03, 441.70it/s] 64%|██████▎   | 2867/4500 [00:07<00:03, 438.08it/s] 65%|██████▌   | 2928/4500 [00:07<00:03, 473.24it/s] 66%|██████▌   | 2977/4500 [00:07<00:03, 471.03it/s] 67%|██████▋   | 3036/4500 [00:07<00:03, 473.25it/s] 69%|██████▊   | 3092/4500 [00:07<00:02, 495.50it/s] 70%|██████▉   | 3142/4500 [00:08<00:03, 406.64it/s] 71%|███████   | 3186/4500 [00:08<00:03, 382.67it/s] 72%|███████▏  | 3240/4500 [00:08<00:03, 419.60it/s] 73%|███████▎  | 3289/4500 [00:08<00:02, 435.32it/s] 74%|███████▍  | 3347/4500 [00:08<00:02, 460.17it/s] 75%|███████▌  | 3395/4500 [00:08<00:02, 413.87it/s] 77%|███████▋  | 3443/4500 [00:08<00:02, 429.85it/s] 78%|███████▊  | 3488/4500 [00:08<00:03, 310.74it/s] 78%|███████▊  | 3525/4500 [00:09<00:04, 223.70it/s] 79%|███████▉  | 3555/4500 [00:09<00:04, 232.96it/s] 80%|███████▉  | 3584/4500 [00:09<00:04, 185.43it/s] 80%|████████  | 3608/4500 [00:09<00:05, 177.42it/s] 82%|████████▏ | 3703/4500 [00:09<00:02, 320.61it/s] 83%|████████▎ | 3746/4500 [00:10<00:02, 309.34it/s] 84%|████████▍ | 3785/4500 [00:10<00:02, 318.35it/s] 85%|████████▌ | 3830/4500 [00:10<00:01, 346.12it/s] 86%|████████▌ | 3878/4500 [00:10<00:01, 376.69it/s] 88%|████████▊ | 3945/4500 [00:10<00:01, 441.00it/s] 89%|████████▉ | 3997/4500 [00:10<00:01, 445.69it/s] 90%|█████████ | 4055/4500 [00:10<00:00, 471.29it/s] 91%|█████████ | 4104/4500 [00:10<00:00, 445.09it/s] 92%|█████████▏| 4150/4500 [00:11<00:00, 389.11it/s] 93%|█████████▎| 4191/4500 [00:11<00:00, 380.80it/s] 94%|█████████▍| 4251/4500 [00:11<00:00, 434.29it/s] 96%|█████████▌| 4312/4500 [00:11<00:00, 479.02it/s] 97%|█████████▋| 4362/4500 [00:11<00:00, 419.35it/s] 98%|█████████▊| 4410/4500 [00:11<00:00, 429.35it/s]100%|██████████| 4500/4500 [00:11<00:00, 385.34it/s]
test_p61 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p61
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p61.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.07s/it]evaluating model with Holmes:  28%|██▊       | 5/18 [00:01<00:02,  5.51it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 11.80it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 18.14it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.20it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p61_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p61_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p61_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p61_Holmes_probs.npy
{'Accuracy': 0.9776, 'Precision': 0.978, 'Recall': 0.9776, 'F1-score': 0.9775}
starting gen taf script for test_p62
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 74/4500 [00:00<00:05, 738.45it/s]  3%|▎         | 148/4500 [00:00<00:10, 414.67it/s]  4%|▍         | 198/4500 [00:00<00:11, 385.47it/s]  6%|▌         | 251/4500 [00:00<00:10, 422.80it/s]  7%|▋         | 304/4500 [00:00<00:09, 448.91it/s]  8%|▊         | 352/4500 [00:00<00:12, 336.53it/s]  9%|▊         | 391/4500 [00:01<00:14, 278.35it/s] 10%|▉         | 439/4500 [00:01<00:12, 319.17it/s] 11%|█         | 479/4500 [00:01<00:12, 332.78it/s] 12%|█▏        | 523/4500 [00:01<00:11, 354.43it/s] 12%|█▏        | 562/4500 [00:01<00:11, 357.78it/s] 13%|█▎        | 600/4500 [00:01<00:12, 307.01it/s] 14%|█▍        | 634/4500 [00:01<00:12, 303.92it/s] 15%|█▍        | 667/4500 [00:01<00:12, 303.68it/s] 16%|█▌        | 703/4500 [00:02<00:12, 311.57it/s] 16%|█▋        | 736/4500 [00:02<00:12, 313.01it/s] 17%|█▋        | 768/4500 [00:02<00:13, 285.59it/s] 18%|█▊        | 805/4500 [00:02<00:12, 303.07it/s] 19%|█▉        | 849/4500 [00:02<00:10, 334.71it/s] 20%|█▉        | 897/4500 [00:02<00:10, 354.55it/s] 21%|██        | 934/4500 [00:02<00:09, 357.84it/s] 22%|██▏       | 981/4500 [00:02<00:09, 389.01it/s] 23%|██▎       | 1022/4500 [00:02<00:08, 394.68it/s] 24%|██▍       | 1069/4500 [00:03<00:08, 411.74it/s] 26%|██▌       | 1168/4500 [00:03<00:05, 578.55it/s] 28%|██▊       | 1247/4500 [00:03<00:05, 640.05it/s] 29%|██▉       | 1314/4500 [00:03<00:04, 648.00it/s] 31%|███       | 1380/4500 [00:03<00:04, 633.11it/s] 32%|███▏      | 1444/4500 [00:03<00:05, 517.31it/s] 33%|███▎      | 1500/4500 [00:03<00:07, 402.17it/s] 34%|███▍      | 1547/4500 [00:03<00:07, 413.62it/s] 36%|███▌      | 1614/4500 [00:04<00:06, 472.32it/s] 37%|███▋      | 1667/4500 [00:04<00:07, 357.15it/s] 38%|███▊      | 1714/4500 [00:04<00:07, 380.51it/s] 39%|███▉      | 1759/4500 [00:04<00:07, 388.41it/s] 40%|████      | 1811/4500 [00:04<00:06, 415.36it/s] 42%|████▏     | 1882/4500 [00:04<00:05, 488.10it/s] 43%|████▎     | 1940/4500 [00:04<00:05, 509.28it/s] 45%|████▍     | 2016/4500 [00:04<00:04, 560.09it/s] 46%|████▌     | 2075/4500 [00:05<00:04, 534.40it/s] 47%|████▋     | 2131/4500 [00:05<00:04, 494.73it/s] 49%|████▊     | 2193/4500 [00:05<00:04, 501.08it/s] 50%|████▉     | 2245/4500 [00:05<00:05, 402.97it/s] 51%|█████     | 2289/4500 [00:05<00:05, 387.73it/s] 52%|█████▏    | 2331/4500 [00:05<00:05, 361.86it/s] 53%|█████▎    | 2369/4500 [00:05<00:06, 312.31it/s] 54%|█████▍    | 2431/4500 [00:06<00:05, 377.69it/s] 55%|█████▌    | 2485/4500 [00:06<00:04, 408.48it/s] 56%|█████▋    | 2540/4500 [00:06<00:04, 430.85it/s] 58%|█████▊    | 2608/4500 [00:06<00:03, 488.40it/s] 59%|█████▉    | 2660/4500 [00:06<00:04, 402.55it/s] 60%|██████    | 2711/4500 [00:06<00:04, 427.03it/s] 62%|██████▏   | 2768/4500 [00:06<00:03, 455.63it/s] 63%|██████▎   | 2817/4500 [00:06<00:03, 457.27it/s] 64%|██████▍   | 2879/4500 [00:06<00:03, 486.84it/s] 65%|██████▌   | 2930/4500 [00:07<00:03, 472.96it/s] 66%|██████▌   | 2979/4500 [00:07<00:03, 471.82it/s] 67%|██████▋   | 3028/4500 [00:07<00:03, 475.41it/s] 68%|██████▊   | 3077/4500 [00:07<00:03, 390.46it/s] 69%|██████▉   | 3119/4500 [00:07<00:03, 390.43it/s] 70%|███████   | 3160/4500 [00:07<00:03, 364.74it/s] 71%|███████   | 3198/4500 [00:07<00:03, 351.89it/s] 72%|███████▏  | 3249/4500 [00:07<00:03, 389.64it/s] 74%|███████▎  | 3309/4500 [00:08<00:02, 439.32it/s] 75%|███████▍  | 3355/4500 [00:08<00:02, 422.49it/s] 76%|███████▌  | 3399/4500 [00:08<00:02, 369.96it/s] 76%|███████▋  | 3438/4500 [00:08<00:03, 351.37it/s] 77%|███████▋  | 3482/4500 [00:08<00:02, 363.19it/s] 78%|███████▊  | 3520/4500 [00:08<00:03, 251.42it/s] 79%|███████▉  | 3551/4500 [00:09<00:05, 182.54it/s] 79%|███████▉  | 3576/4500 [00:09<00:05, 173.73it/s] 80%|███████▉  | 3598/4500 [00:09<00:05, 168.55it/s] 81%|████████▏ | 3662/4500 [00:09<00:03, 253.43it/s] 82%|████████▏ | 3703/4500 [00:09<00:02, 284.83it/s] 84%|████████▎ | 3766/4500 [00:09<00:02, 364.02it/s] 85%|████████▍ | 3809/4500 [00:09<00:01, 375.78it/s] 86%|████████▌ | 3860/4500 [00:09<00:01, 398.95it/s] 87%|████████▋ | 3918/4500 [00:10<00:01, 441.61it/s] 88%|████████▊ | 3965/4500 [00:10<00:01, 415.00it/s] 89%|████████▉ | 4009/4500 [00:10<00:01, 419.89it/s] 90%|█████████ | 4053/4500 [00:10<00:01, 416.84it/s] 91%|█████████ | 4099/4500 [00:10<00:00, 423.83it/s] 92%|█████████▏| 4143/4500 [00:10<00:00, 392.18it/s] 93%|█████████▎| 4184/4500 [00:10<00:00, 353.78it/s] 94%|█████████▍| 4243/4500 [00:10<00:00, 407.41it/s] 96%|█████████▌| 4313/4500 [00:11<00:00, 482.51it/s] 97%|█████████▋| 4364/4500 [00:11<00:00, 456.13it/s] 98%|█████████▊| 4412/4500 [00:11<00:00, 412.34it/s]100%|██████████| 4500/4500 [00:11<00:00, 394.72it/s]
test_p62 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p62
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p62.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.01it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.03it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.26it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.52it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.92it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p62_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p62_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p62_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p62_Holmes_probs.npy
{'Accuracy': 0.9782, 'Precision': 0.9786, 'Recall': 0.9782, 'F1-score': 0.9781}
starting gen taf script for test_p63
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 67/4500 [00:00<00:06, 652.32it/s]  3%|▎         | 133/4500 [00:00<00:10, 407.11it/s]  4%|▍         | 180/4500 [00:00<00:10, 424.98it/s]  5%|▌         | 226/4500 [00:00<00:09, 433.29it/s]  6%|▌         | 272/4500 [00:00<00:14, 298.12it/s]  7%|▋         | 308/4500 [00:00<00:14, 291.99it/s]  8%|▊         | 341/4500 [00:01<00:15, 275.43it/s]  8%|▊         | 371/4500 [00:01<00:17, 235.48it/s]  9%|▉         | 397/4500 [00:01<00:18, 222.24it/s] 10%|▉         | 445/4500 [00:01<00:14, 277.64it/s] 11%|█         | 488/4500 [00:01<00:12, 313.71it/s] 12%|█▏        | 525/4500 [00:01<00:12, 325.32it/s] 12%|█▏        | 560/4500 [00:01<00:14, 271.99it/s] 13%|█▎        | 590/4500 [00:01<00:15, 255.32it/s] 14%|█▎        | 618/4500 [00:02<00:14, 260.72it/s] 15%|█▍        | 661/4500 [00:02<00:12, 298.39it/s] 16%|█▌        | 701/4500 [00:02<00:11, 320.75it/s] 16%|█▋        | 735/4500 [00:02<00:12, 299.73it/s] 17%|█▋        | 780/4500 [00:02<00:11, 336.70it/s] 19%|█▉        | 858/4500 [00:02<00:08, 449.99it/s] 20%|██        | 912/4500 [00:02<00:08, 446.76it/s] 22%|██▏       | 982/4500 [00:02<00:07, 488.91it/s] 23%|██▎       | 1032/4500 [00:03<00:07, 456.32it/s] 24%|██▍       | 1079/4500 [00:03<00:07, 454.46it/s] 26%|██▌       | 1152/4500 [00:03<00:06, 527.78it/s] 27%|██▋       | 1232/4500 [00:03<00:05, 583.02it/s] 29%|██▊       | 1292/4500 [00:03<00:05, 575.83it/s] 31%|███       | 1373/4500 [00:03<00:05, 622.92it/s] 32%|███▏      | 1436/4500 [00:03<00:06, 485.26it/s] 33%|███▎      | 1490/4500 [00:03<00:07, 412.76it/s] 35%|███▍      | 1556/4500 [00:04<00:06, 466.77it/s] 36%|███▌      | 1608/4500 [00:04<00:06, 449.82it/s] 37%|███▋      | 1657/4500 [00:04<00:07, 379.45it/s] 38%|███▊      | 1699/4500 [00:04<00:08, 328.82it/s] 39%|███▉      | 1760/4500 [00:04<00:07, 387.63it/s] 40%|████      | 1822/4500 [00:04<00:06, 434.17it/s] 42%|████▏     | 1906/4500 [00:04<00:04, 531.29it/s] 44%|████▎     | 1965/4500 [00:04<00:04, 512.21it/s] 45%|████▍     | 2020/4500 [00:05<00:04, 501.89it/s] 46%|████▌     | 2079/4500 [00:05<00:04, 511.90it/s] 47%|████▋     | 2132/4500 [00:05<00:04, 489.54it/s] 49%|████▉     | 2197/4500 [00:05<00:04, 506.60it/s] 50%|████▉     | 2249/4500 [00:05<00:05, 417.81it/s] 51%|█████     | 2294/4500 [00:05<00:06, 362.60it/s] 52%|█████▏    | 2334/4500 [00:05<00:06, 315.66it/s] 53%|█████▎    | 2375/4500 [00:06<00:06, 335.46it/s] 54%|█████▎    | 2412/4500 [00:06<00:06, 311.00it/s] 55%|█████▍    | 2454/4500 [00:06<00:06, 334.41it/s] 56%|█████▌    | 2498/4500 [00:06<00:05, 355.93it/s] 57%|█████▋    | 2548/4500 [00:06<00:05, 375.56it/s] 58%|█████▊    | 2615/4500 [00:06<00:04, 437.06it/s] 59%|█████▉    | 2666/4500 [00:06<00:04, 448.42it/s] 60%|██████    | 2712/4500 [00:06<00:04, 440.76it/s] 61%|██████▏   | 2757/4500 [00:06<00:04, 415.29it/s] 63%|██████▎   | 2813/4500 [00:07<00:03, 445.80it/s] 64%|██████▍   | 2873/4500 [00:07<00:03, 465.68it/s] 65%|██████▍   | 2923/4500 [00:07<00:03, 466.50it/s] 66%|██████▌   | 2970/4500 [00:07<00:03, 467.38it/s] 67%|██████▋   | 3026/4500 [00:07<00:03, 490.43it/s] 68%|██████▊   | 3076/4500 [00:07<00:03, 461.54it/s] 69%|██████▉   | 3123/4500 [00:07<00:03, 410.24it/s] 70%|███████   | 3166/4500 [00:07<00:03, 345.09it/s] 71%|███████▏  | 3211/4500 [00:08<00:03, 362.82it/s] 72%|███████▏  | 3250/4500 [00:08<00:03, 364.73it/s] 74%|███████▎  | 3311/4500 [00:08<00:02, 404.95it/s] 75%|███████▍  | 3366/4500 [00:08<00:02, 415.46it/s] 76%|███████▌  | 3415/4500 [00:08<00:02, 423.66it/s] 77%|███████▋  | 3458/4500 [00:08<00:02, 390.01it/s] 78%|███████▊  | 3498/4500 [00:08<00:03, 309.43it/s] 78%|███████▊  | 3532/4500 [00:09<00:04, 209.51it/s] 79%|███████▉  | 3559/4500 [00:09<00:04, 191.78it/s] 80%|███████▉  | 3583/4500 [00:09<00:05, 171.36it/s] 81%|████████  | 3627/4500 [00:09<00:04, 217.62it/s] 82%|████████▏ | 3688/4500 [00:09<00:02, 284.61it/s] 83%|████████▎ | 3742/4500 [00:09<00:02, 336.17it/s] 84%|████████▍ | 3783/4500 [00:10<00:02, 339.17it/s] 85%|████████▌ | 3828/4500 [00:10<00:01, 365.82it/s] 86%|████████▌ | 3880/4500 [00:10<00:01, 405.56it/s] 87%|████████▋ | 3924/4500 [00:10<00:01, 397.45it/s] 88%|████████▊ | 3981/4500 [00:10<00:01, 441.05it/s] 90%|████████▉ | 4037/4500 [00:10<00:01, 462.46it/s] 91%|█████████ | 4085/4500 [00:10<00:00, 449.81it/s] 92%|█████████▏| 4131/4500 [00:10<00:01, 352.57it/s] 93%|█████████▎| 4170/4500 [00:11<00:00, 349.97it/s] 94%|█████████▍| 4242/4500 [00:11<00:00, 436.68it/s] 95%|█████████▌| 4294/4500 [00:11<00:00, 447.93it/s] 96%|█████████▋| 4342/4500 [00:11<00:00, 446.16it/s] 98%|█████████▊| 4389/4500 [00:11<00:00, 408.18it/s] 99%|█████████▊| 4436/4500 [00:11<00:00, 423.55it/s]100%|██████████| 4500/4500 [00:11<00:00, 386.44it/s]
test_p63 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p63
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p63.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.08it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.45it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.10it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.63it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.65it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p63_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p63_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p63_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p63_Holmes_probs.npy
{'Accuracy': 0.9784, 'Precision': 0.9788, 'Recall': 0.9784, 'F1-score': 0.9784}
starting gen taf script for test_p64
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 67/4500 [00:00<00:06, 642.32it/s]  3%|▎         | 132/4500 [00:00<00:10, 423.02it/s]  4%|▍         | 179/4500 [00:00<00:10, 408.12it/s]  5%|▍         | 222/4500 [00:00<00:10, 405.90it/s]  6%|▋         | 284/4500 [00:00<00:09, 464.63it/s]  7%|▋         | 333/4500 [00:00<00:13, 303.30it/s]  8%|▊         | 371/4500 [00:01<00:17, 241.64it/s]  9%|▉         | 402/4500 [00:01<00:17, 230.56it/s] 10%|▉         | 440/4500 [00:01<00:15, 258.03it/s] 11%|█         | 480/4500 [00:01<00:14, 285.63it/s] 12%|█▏        | 522/4500 [00:01<00:12, 316.74it/s] 13%|█▎        | 563/4500 [00:01<00:11, 338.46it/s] 13%|█▎        | 600/4500 [00:01<00:12, 305.39it/s] 14%|█▍        | 634/4500 [00:02<00:13, 294.50it/s] 15%|█▍        | 666/4500 [00:02<00:13, 285.87it/s] 16%|█▌        | 701/4500 [00:02<00:12, 301.92it/s] 16%|█▋        | 733/4500 [00:02<00:13, 276.50it/s] 17%|█▋        | 766/4500 [00:02<00:13, 284.54it/s] 18%|█▊        | 804/4500 [00:02<00:12, 301.94it/s] 20%|█▉        | 892/4500 [00:02<00:07, 456.47it/s] 21%|██        | 940/4500 [00:02<00:07, 459.84it/s] 22%|██▏       | 994/4500 [00:02<00:07, 477.91it/s] 23%|██▎       | 1043/4500 [00:03<00:07, 462.40it/s] 24%|██▍       | 1091/4500 [00:03<00:08, 402.52it/s] 27%|██▋       | 1199/4500 [00:03<00:05, 569.08it/s] 28%|██▊       | 1260/4500 [00:03<00:05, 563.31it/s] 30%|██▉       | 1337/4500 [00:03<00:05, 616.06it/s] 31%|███       | 1401/4500 [00:03<00:05, 546.26it/s] 32%|███▏      | 1459/4500 [00:03<00:06, 490.90it/s] 34%|███▎      | 1511/4500 [00:03<00:06, 443.90it/s] 35%|███▍      | 1558/4500 [00:04<00:06, 450.09it/s] 36%|███▌      | 1607/4500 [00:04<00:06, 432.48it/s] 37%|███▋      | 1652/4500 [00:04<00:07, 368.61it/s] 38%|███▊      | 1691/4500 [00:04<00:08, 349.63it/s] 38%|███▊      | 1728/4500 [00:04<00:08, 333.15it/s] 40%|███▉      | 1796/4500 [00:04<00:06, 409.61it/s] 41%|████      | 1848/4500 [00:04<00:06, 429.81it/s] 43%|████▎     | 1925/4500 [00:04<00:05, 507.83it/s] 44%|████▍     | 1982/4500 [00:05<00:04, 519.59it/s] 45%|████▌     | 2036/4500 [00:05<00:04, 508.80it/s] 46%|████▋     | 2088/4500 [00:05<00:05, 443.94it/s] 48%|████▊     | 2148/4500 [00:05<00:04, 480.66it/s] 49%|████▉     | 2209/4500 [00:05<00:04, 513.22it/s] 50%|█████     | 2263/4500 [00:05<00:05, 414.65it/s] 51%|█████▏    | 2309/4500 [00:05<00:06, 362.19it/s] 52%|█████▏    | 2349/4500 [00:06<00:06, 330.29it/s] 53%|█████▎    | 2385/4500 [00:06<00:06, 309.19it/s] 54%|█████▍    | 2433/4500 [00:06<00:05, 344.90it/s] 56%|█████▌    | 2514/4500 [00:06<00:04, 447.85it/s] 57%|█████▋    | 2563/4500 [00:06<00:04, 441.10it/s] 58%|█████▊    | 2624/4500 [00:06<00:03, 481.55it/s] 59%|█████▉    | 2675/4500 [00:06<00:04, 447.27it/s] 60%|██████    | 2722/4500 [00:06<00:04, 443.13it/s] 62%|██████▏   | 2775/4500 [00:06<00:03, 453.14it/s] 63%|██████▎   | 2834/4500 [00:07<00:03, 481.71it/s] 64%|██████▍   | 2897/4500 [00:07<00:03, 503.00it/s] 66%|██████▌   | 2948/4500 [00:07<00:03, 491.18it/s] 67%|██████▋   | 2998/4500 [00:07<00:03, 466.40it/s] 68%|██████▊   | 3046/4500 [00:07<00:03, 450.75it/s] 69%|██████▊   | 3092/4500 [00:07<00:03, 395.64it/s] 70%|██████▉   | 3133/4500 [00:07<00:03, 355.74it/s] 71%|███████   | 3178/4500 [00:07<00:03, 369.16it/s] 72%|███████▏  | 3231/4500 [00:08<00:03, 393.99it/s] 73%|███████▎  | 3272/4500 [00:08<00:03, 389.58it/s] 74%|███████▎  | 3316/4500 [00:08<00:02, 399.13it/s] 75%|███████▍  | 3357/4500 [00:08<00:02, 400.63it/s] 76%|███████▌  | 3399/4500 [00:08<00:02, 399.83it/s] 76%|███████▋  | 3440/4500 [00:08<00:03, 351.36it/s] 77%|███████▋  | 3486/4500 [00:08<00:02, 365.31it/s] 78%|███████▊  | 3524/4500 [00:09<00:03, 247.29it/s] 79%|███████▉  | 3555/4500 [00:09<00:04, 200.91it/s] 80%|███████▉  | 3580/4500 [00:09<00:05, 155.07it/s] 81%|████████  | 3626/4500 [00:09<00:04, 203.93it/s] 82%|████████▏ | 3695/4500 [00:09<00:02, 294.74it/s] 83%|████████▎ | 3748/4500 [00:09<00:02, 334.90it/s] 84%|████████▍ | 3799/4500 [00:09<00:01, 373.87it/s] 85%|████████▌ | 3844/4500 [00:10<00:01, 372.93it/s] 86%|████████▋ | 3890/4500 [00:10<00:01, 387.35it/s] 88%|████████▊ | 3974/4500 [00:10<00:01, 494.31it/s] 90%|████████▉ | 4028/4500 [00:10<00:00, 494.35it/s] 91%|█████████ | 4080/4500 [00:10<00:00, 427.69it/s] 92%|█████████▏| 4126/4500 [00:10<00:01, 368.75it/s] 93%|█████████▎| 4167/4500 [00:10<00:00, 367.96it/s] 94%|█████████▍| 4222/4500 [00:10<00:00, 409.24it/s] 95%|█████████▌| 4290/4500 [00:11<00:00, 474.74it/s] 96%|█████████▋| 4341/4500 [00:11<00:00, 438.96it/s] 98%|█████████▊| 4388/4500 [00:11<00:00, 418.55it/s] 99%|█████████▊| 4439/4500 [00:11<00:00, 436.01it/s]100%|██████████| 4500/4500 [00:11<00:00, 391.79it/s]
test_p64 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p64
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p64.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.05it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.23it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.69it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.10it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.33it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p64_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p64_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p64_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p64_Holmes_probs.npy
{'Accuracy': 0.9798, 'Precision': 0.9801, 'Recall': 0.9798, 'F1-score': 0.9797}
starting gen taf script for test_p65
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 63/4500 [00:00<00:07, 627.26it/s]  3%|▎         | 126/4500 [00:00<00:10, 419.75it/s]  4%|▍         | 172/4500 [00:00<00:10, 394.77it/s]  5%|▍         | 215/4500 [00:00<00:10, 403.04it/s]  6%|▌         | 281/4500 [00:00<00:08, 482.76it/s]  7%|▋         | 332/4500 [00:00<00:10, 382.65it/s]  8%|▊         | 375/4500 [00:01<00:14, 286.93it/s]  9%|▉         | 410/4500 [00:01<00:14, 273.72it/s] 10%|▉         | 449/4500 [00:01<00:13, 298.55it/s] 11%|█         | 496/4500 [00:01<00:11, 338.59it/s] 12%|█▏        | 534/4500 [00:01<00:11, 333.06it/s] 13%|█▎        | 575/4500 [00:01<00:11, 352.16it/s] 14%|█▎        | 615/4500 [00:01<00:10, 361.13it/s] 15%|█▍        | 653/4500 [00:01<00:13, 278.33it/s] 15%|█▌        | 688/4500 [00:02<00:12, 293.31it/s] 16%|█▌        | 721/4500 [00:02<00:12, 291.33it/s] 17%|█▋        | 753/4500 [00:02<00:14, 255.40it/s] 17%|█▋        | 782/4500 [00:02<00:14, 255.49it/s] 18%|█▊        | 813/4500 [00:02<00:14, 261.87it/s] 19%|█▉        | 862/4500 [00:02<00:11, 314.99it/s] 20%|██        | 909/4500 [00:02<00:10, 351.64it/s] 21%|██        | 946/4500 [00:02<00:10, 347.71it/s] 22%|██▏       | 982/4500 [00:02<00:10, 330.14it/s] 23%|██▎       | 1016/4500 [00:03<00:11, 310.00it/s] 24%|██▎       | 1064/4500 [00:03<00:10, 338.02it/s] 25%|██▍       | 1122/4500 [00:03<00:08, 396.03it/s] 27%|██▋       | 1209/4500 [00:03<00:06, 512.40it/s] 28%|██▊       | 1274/4500 [00:03<00:05, 543.97it/s] 30%|██▉       | 1338/4500 [00:03<00:05, 568.05it/s] 31%|███       | 1396/4500 [00:03<00:06, 483.71it/s] 32%|███▏      | 1447/4500 [00:03<00:07, 434.02it/s] 33%|███▎      | 1493/4500 [00:04<00:07, 404.65it/s] 34%|███▍      | 1536/4500 [00:04<00:07, 406.16it/s] 35%|███▌      | 1583/4500 [00:04<00:07, 409.67it/s] 36%|███▌      | 1625/4500 [00:04<00:08, 358.38it/s] 37%|███▋      | 1671/4500 [00:04<00:07, 369.88it/s] 38%|███▊      | 1710/4500 [00:04<00:08, 326.34it/s] 40%|███▉      | 1781/4500 [00:04<00:06, 408.01it/s] 41%|████      | 1836/4500 [00:04<00:06, 426.97it/s] 42%|████▏     | 1892/4500 [00:05<00:05, 460.61it/s] 43%|████▎     | 1955/4500 [00:05<00:05, 495.56it/s] 45%|████▍     | 2021/4500 [00:05<00:04, 537.98it/s] 46%|████▌     | 2077/4500 [00:05<00:04, 543.33it/s] 47%|████▋     | 2133/4500 [00:05<00:04, 545.65it/s] 49%|████▊     | 2190/4500 [00:05<00:04, 531.92it/s] 50%|████▉     | 2244/4500 [00:05<00:05, 420.43it/s] 51%|█████     | 2290/4500 [00:05<00:06, 364.37it/s] 52%|█████▏    | 2331/4500 [00:06<00:06, 317.29it/s] 53%|█████▎    | 2366/4500 [00:06<00:06, 316.60it/s] 53%|█████▎    | 2403/4500 [00:06<00:06, 328.28it/s] 55%|█████▍    | 2463/4500 [00:06<00:05, 395.53it/s] 56%|█████▌    | 2506/4500 [00:06<00:05, 372.40it/s] 57%|█████▋    | 2556/4500 [00:06<00:04, 404.45it/s] 58%|█████▊    | 2617/4500 [00:06<00:04, 444.43it/s] 59%|█████▉    | 2663/4500 [00:06<00:04, 417.10it/s] 60%|██████    | 2706/4500 [00:07<00:04, 397.57it/s] 61%|██████    | 2747/4500 [00:07<00:04, 387.13it/s] 63%|██████▎   | 2813/4500 [00:07<00:03, 452.82it/s] 64%|██████▍   | 2869/4500 [00:07<00:03, 479.83it/s] 65%|██████▍   | 2924/4500 [00:07<00:03, 493.49it/s] 66%|██████▌   | 2975/4500 [00:07<00:03, 489.55it/s] 67%|██████▋   | 3025/4500 [00:07<00:03, 469.57it/s] 68%|██████▊   | 3073/4500 [00:07<00:03, 453.44it/s] 69%|██████▉   | 3119/4500 [00:07<00:03, 395.78it/s] 70%|███████   | 3160/4500 [00:08<00:04, 306.35it/s] 72%|███████▏  | 3219/4500 [00:08<00:03, 368.38it/s] 73%|███████▎  | 3265/4500 [00:08<00:03, 387.39it/s] 74%|███████▎  | 3315/4500 [00:08<00:02, 411.62it/s] 75%|███████▍  | 3363/4500 [00:08<00:02, 420.76it/s] 76%|███████▌  | 3408/4500 [00:08<00:02, 413.75it/s] 77%|███████▋  | 3451/4500 [00:08<00:02, 356.21it/s] 78%|███████▊  | 3500/4500 [00:09<00:02, 357.18it/s] 79%|███████▊  | 3538/4500 [00:09<00:04, 209.21it/s] 79%|███████▉  | 3567/4500 [00:09<00:05, 176.58it/s] 80%|███████▉  | 3591/4500 [00:09<00:05, 168.42it/s] 81%|████████▏ | 3663/4500 [00:09<00:03, 261.65it/s] 83%|████████▎ | 3718/4500 [00:10<00:02, 317.97it/s] 84%|████████▎ | 3760/4500 [00:10<00:02, 336.51it/s] 84%|████████▍ | 3802/4500 [00:10<00:02, 332.28it/s] 86%|████████▌ | 3851/4500 [00:10<00:01, 368.60it/s] 87%|████████▋ | 3909/4500 [00:10<00:01, 417.63it/s] 88%|████████▊ | 3979/4500 [00:10<00:01, 485.77it/s] 90%|████████▉ | 4031/4500 [00:10<00:01, 463.30it/s] 91%|█████████ | 4080/4500 [00:10<00:00, 460.74it/s] 92%|█████████▏| 4128/4500 [00:10<00:00, 399.90it/s] 93%|█████████▎| 4171/4500 [00:11<00:00, 330.36it/s] 94%|█████████▍| 4237/4500 [00:11<00:00, 399.55it/s] 95%|█████████▌| 4286/4500 [00:11<00:00, 413.00it/s] 96%|█████████▋| 4336/4500 [00:11<00:00, 421.27it/s] 97%|█████████▋| 4381/4500 [00:11<00:00, 394.12it/s] 99%|█████████▉| 4447/4500 [00:11<00:00, 459.03it/s]100%|██████████| 4500/4500 [00:11<00:00, 380.97it/s]
test_p65 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p65
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p65.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.09s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.46it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.35it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.46it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.01it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p65_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p65_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p65_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p65_Holmes_probs.npy
{'Accuracy': 0.9793, 'Precision': 0.9796, 'Recall': 0.9793, 'F1-score': 0.9793}
starting gen taf script for test_p66
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 73/4500 [00:00<00:06, 689.61it/s]  3%|▎         | 142/4500 [00:00<00:09, 475.20it/s]  4%|▍         | 194/4500 [00:00<00:09, 438.48it/s]  6%|▌         | 252/4500 [00:00<00:08, 480.99it/s]  7%|▋         | 303/4500 [00:00<00:08, 478.21it/s]  8%|▊         | 353/4500 [00:00<00:12, 319.12it/s]  9%|▊         | 392/4500 [00:01<00:13, 302.18it/s] 10%|▉         | 436/4500 [00:01<00:12, 329.16it/s] 11%|█         | 495/4500 [00:01<00:10, 385.15it/s] 12%|█▏        | 538/4500 [00:01<00:11, 350.59it/s] 13%|█▎        | 577/4500 [00:01<00:11, 353.20it/s] 14%|█▎        | 615/4500 [00:01<00:11, 332.82it/s] 15%|█▍        | 657/4500 [00:01<00:10, 349.76it/s] 16%|█▌        | 706/4500 [00:01<00:10, 370.64it/s] 17%|█▋        | 745/4500 [00:01<00:10, 375.16it/s] 17%|█▋        | 784/4500 [00:02<00:10, 360.02it/s] 19%|█▉        | 861/4500 [00:02<00:07, 466.19it/s] 20%|██        | 909/4500 [00:02<00:07, 469.70it/s] 22%|██▏       | 984/4500 [00:02<00:06, 538.89it/s] 23%|██▎       | 1039/4500 [00:02<00:06, 507.23it/s] 24%|██▍       | 1091/4500 [00:02<00:07, 440.85it/s] 26%|██▌       | 1179/4500 [00:02<00:06, 551.88it/s] 28%|██▊       | 1238/4500 [00:02<00:05, 546.85it/s] 29%|██▉       | 1317/4500 [00:02<00:05, 608.94it/s] 31%|███       | 1381/4500 [00:03<00:05, 576.29it/s] 32%|███▏      | 1441/4500 [00:03<00:06, 462.40it/s] 33%|███▎      | 1492/4500 [00:03<00:07, 386.12it/s] 34%|███▍      | 1552/4500 [00:03<00:06, 424.84it/s] 36%|███▌      | 1600/4500 [00:03<00:06, 427.66it/s] 37%|███▋      | 1646/4500 [00:03<00:07, 360.86it/s] 37%|███▋      | 1686/4500 [00:04<00:08, 327.67it/s] 38%|███▊      | 1728/4500 [00:04<00:07, 346.52it/s] 39%|███▉      | 1774/4500 [00:04<00:07, 372.86it/s] 40%|████      | 1822/4500 [00:04<00:06, 397.53it/s] 42%|████▏     | 1882/4500 [00:04<00:05, 443.56it/s] 44%|████▎     | 1966/4500 [00:04<00:04, 537.46it/s] 45%|████▌     | 2027/4500 [00:04<00:04, 545.05it/s] 46%|████▋     | 2083/4500 [00:04<00:04, 510.93it/s] 48%|████▊     | 2143/4500 [00:04<00:04, 525.25it/s] 49%|████▉     | 2197/4500 [00:05<00:04, 519.21it/s] 50%|█████     | 2250/4500 [00:05<00:05, 417.73it/s] 51%|█████     | 2296/4500 [00:05<00:06, 319.78it/s] 52%|█████▏    | 2334/4500 [00:05<00:06, 317.28it/s] 53%|█████▎    | 2374/4500 [00:05<00:06, 329.00it/s] 54%|█████▍    | 2433/4500 [00:05<00:05, 383.74it/s] 55%|█████▌    | 2487/4500 [00:05<00:04, 417.16it/s] 56%|█████▋    | 2541/4500 [00:06<00:04, 446.87it/s] 58%|█████▊    | 2593/4500 [00:06<00:04, 460.73it/s] 59%|█████▊    | 2641/4500 [00:06<00:04, 463.90it/s] 60%|█████▉    | 2695/4500 [00:06<00:03, 475.89it/s] 61%|██████    | 2744/4500 [00:06<00:04, 438.33it/s] 62%|██████▏   | 2789/4500 [00:06<00:03, 437.77it/s] 63%|██████▎   | 2835/4500 [00:06<00:03, 432.04it/s] 64%|██████▍   | 2888/4500 [00:06<00:03, 446.66it/s] 65%|██████▌   | 2934/4500 [00:06<00:03, 450.28it/s] 66%|██████▋   | 2988/4500 [00:06<00:03, 472.09it/s] 67%|██████▋   | 3036/4500 [00:07<00:03, 458.64it/s] 69%|██████▊   | 3083/4500 [00:07<00:03, 439.06it/s] 70%|██████▉   | 3128/4500 [00:07<00:03, 347.49it/s] 70%|███████   | 3168/4500 [00:07<00:03, 357.19it/s] 71%|███████▏  | 3208/4500 [00:07<00:03, 355.34it/s] 72%|███████▏  | 3256/4500 [00:07<00:03, 385.98it/s] 74%|███████▎  | 3318/4500 [00:07<00:02, 429.46it/s] 75%|███████▍  | 3363/4500 [00:08<00:02, 394.01it/s] 76%|███████▌  | 3404/4500 [00:08<00:03, 360.42it/s] 76%|███████▋  | 3442/4500 [00:08<00:02, 361.03it/s] 77%|███████▋  | 3479/4500 [00:08<00:02, 344.47it/s] 78%|███████▊  | 3514/4500 [00:08<00:04, 221.90it/s] 79%|███████▊  | 3542/4500 [00:08<00:04, 201.54it/s] 79%|███████▉  | 3567/4500 [00:09<00:05, 165.96it/s] 80%|███████▉  | 3588/4500 [00:09<00:05, 155.85it/s] 80%|████████  | 3606/4500 [00:09<00:05, 157.57it/s] 82%|████████▏ | 3669/4500 [00:09<00:03, 252.17it/s] 83%|████████▎ | 3717/4500 [00:09<00:02, 301.54it/s] 84%|████████▎ | 3764/4500 [00:09<00:02, 340.84it/s] 85%|████████▍ | 3803/4500 [00:09<00:01, 352.15it/s] 85%|████████▌ | 3847/4500 [00:09<00:01, 372.53it/s] 87%|████████▋ | 3911/4500 [00:09<00:01, 439.04it/s] 88%|████████▊ | 3966/4500 [00:10<00:01, 464.36it/s] 89%|████████▉ | 4014/4500 [00:10<00:01, 420.75it/s] 90%|█████████ | 4058/4500 [00:10<00:01, 409.95it/s] 91%|█████████ | 4101/4500 [00:10<00:01, 392.26it/s] 92%|█████████▏| 4142/4500 [00:10<00:00, 376.23it/s] 93%|█████████▎| 4181/4500 [00:10<00:00, 341.28it/s] 94%|█████████▍| 4242/4500 [00:10<00:00, 405.25it/s] 95%|█████████▌| 4293/4500 [00:10<00:00, 425.21it/s] 97%|█████████▋| 4345/4500 [00:11<00:00, 415.94it/s] 98%|█████████▊| 4388/4500 [00:11<00:00, 391.50it/s] 99%|█████████▉| 4448/4500 [00:11<00:00, 436.13it/s]100%|██████████| 4500/4500 [00:11<00:00, 395.73it/s]
test_p66 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p66
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p66.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:14,  1.17it/s]evaluating model with Holmes:  17%|█▋        | 3/18 [00:00<00:03,  3.84it/s]evaluating model with Holmes:  44%|████▍     | 8/18 [00:01<00:00, 11.33it/s]evaluating model with Holmes:  72%|███████▏  | 13/18 [00:01<00:00, 18.60it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 25.05it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.72it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p66_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p66_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p66_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p66_Holmes_probs.npy
{'Accuracy': 0.9793, 'Precision': 0.9796, 'Recall': 0.9793, 'F1-score': 0.9792}
starting gen taf script for test_p67
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 49/4500 [00:00<00:09, 475.15it/s]  2%|▏         | 97/4500 [00:00<00:12, 340.14it/s]  3%|▎         | 134/4500 [00:00<00:13, 329.30it/s]  4%|▍         | 178/4500 [00:00<00:11, 366.05it/s]  5%|▍         | 222/4500 [00:00<00:11, 383.64it/s]  6%|▋         | 283/4500 [00:00<00:09, 452.33it/s]  7%|▋         | 330/4500 [00:00<00:12, 346.53it/s]  8%|▊         | 369/4500 [00:01<00:14, 286.80it/s]  9%|▉         | 402/4500 [00:01<00:16, 242.44it/s] 10%|▉         | 442/4500 [00:01<00:15, 268.09it/s] 11%|█         | 473/4500 [00:01<00:15, 266.49it/s] 11%|█▏        | 508/4500 [00:01<00:14, 285.02it/s] 12%|█▏        | 539/4500 [00:01<00:13, 287.26it/s] 13%|█▎        | 570/4500 [00:01<00:14, 267.54it/s] 13%|█▎        | 599/4500 [00:01<00:14, 270.35it/s] 14%|█▍        | 627/4500 [00:02<00:14, 258.94it/s] 15%|█▍        | 658/4500 [00:02<00:14, 269.21it/s] 15%|█▌        | 694/4500 [00:02<00:12, 293.80it/s] 16%|█▌        | 725/4500 [00:02<00:14, 257.95it/s] 17%|█▋        | 752/4500 [00:02<00:14, 258.26it/s] 17%|█▋        | 779/4500 [00:02<00:15, 243.88it/s] 18%|█▊        | 817/4500 [00:02<00:13, 279.51it/s] 20%|█▉        | 890/4500 [00:02<00:09, 398.81it/s] 21%|██        | 944/4500 [00:03<00:08, 425.35it/s] 22%|██▏       | 988/4500 [00:03<00:10, 343.78it/s] 23%|██▎       | 1026/4500 [00:03<00:10, 330.22it/s] 24%|██▍       | 1077/4500 [00:03<00:09, 371.86it/s] 25%|██▌       | 1142/4500 [00:03<00:07, 439.24it/s] 27%|██▋       | 1214/4500 [00:03<00:06, 511.60it/s] 28%|██▊       | 1277/4500 [00:03<00:05, 541.15it/s] 30%|██▉       | 1348/4500 [00:03<00:05, 588.46it/s] 31%|███▏      | 1410/4500 [00:03<00:05, 595.92it/s] 33%|███▎      | 1471/4500 [00:04<00:07, 425.07it/s] 34%|███▍      | 1522/4500 [00:04<00:07, 400.07it/s] 35%|███▌      | 1577/4500 [00:04<00:07, 412.02it/s] 36%|███▌      | 1623/4500 [00:04<00:06, 420.48it/s] 37%|███▋      | 1669/4500 [00:04<00:08, 329.14it/s] 38%|███▊      | 1707/4500 [00:04<00:09, 307.48it/s] 39%|███▉      | 1765/4500 [00:05<00:07, 365.01it/s] 40%|████      | 1806/4500 [00:05<00:07, 374.45it/s] 41%|████▏     | 1866/4500 [00:05<00:06, 423.97it/s] 43%|████▎     | 1931/4500 [00:05<00:05, 481.75it/s] 44%|████▍     | 1995/4500 [00:05<00:04, 512.18it/s] 46%|████▌     | 2062/4500 [00:05<00:04, 525.72it/s] 47%|████▋     | 2117/4500 [00:05<00:05, 474.43it/s] 48%|████▊     | 2167/4500 [00:05<00:04, 468.86it/s] 49%|████▉     | 2224/4500 [00:05<00:04, 488.93it/s] 51%|█████     | 2274/4500 [00:06<00:05, 394.31it/s] 51%|█████▏    | 2317/4500 [00:06<00:05, 372.42it/s] 52%|█████▏    | 2357/4500 [00:06<00:06, 328.91it/s] 53%|█████▎    | 2393/4500 [00:06<00:06, 325.65it/s] 54%|█████▍    | 2439/4500 [00:06<00:05, 356.44it/s] 55%|█████▌    | 2492/4500 [00:06<00:05, 383.69it/s] 57%|█████▋    | 2552/4500 [00:06<00:04, 428.98it/s] 58%|█████▊    | 2597/4500 [00:06<00:04, 429.46it/s] 59%|█████▉    | 2650/4500 [00:07<00:04, 456.62it/s] 60%|█████▉    | 2697/4500 [00:07<00:04, 404.42it/s] 61%|██████    | 2740/4500 [00:07<00:04, 393.71it/s] 62%|██████▏   | 2789/4500 [00:07<00:04, 407.82it/s] 63%|██████▎   | 2834/4500 [00:07<00:03, 418.16it/s] 64%|██████▍   | 2890/4500 [00:07<00:03, 444.82it/s] 66%|██████▌   | 2952/4500 [00:07<00:03, 482.14it/s] 67%|██████▋   | 3001/4500 [00:07<00:03, 440.63it/s] 68%|██████▊   | 3046/4500 [00:08<00:03, 418.50it/s] 69%|██████▉   | 3096/4500 [00:08<00:03, 438.72it/s] 70%|██████▉   | 3141/4500 [00:08<00:03, 369.32it/s] 71%|███████   | 3181/4500 [00:08<00:03, 349.34it/s] 72%|███████▏  | 3218/4500 [00:08<00:03, 354.15it/s] 72%|███████▏  | 3255/4500 [00:08<00:03, 334.43it/s] 73%|███████▎  | 3304/4500 [00:08<00:03, 365.82it/s] 74%|███████▍  | 3342/4500 [00:08<00:03, 332.06it/s] 75%|███████▌  | 3384/4500 [00:09<00:03, 349.63it/s] 76%|███████▋  | 3435/4500 [00:09<00:02, 389.03it/s] 77%|███████▋  | 3476/4500 [00:09<00:03, 317.25it/s] 78%|███████▊  | 3511/4500 [00:09<00:04, 242.35it/s] 79%|███████▊  | 3540/4500 [00:09<00:04, 203.18it/s] 79%|███████▉  | 3564/4500 [00:10<00:05, 165.89it/s] 80%|███████▉  | 3584/4500 [00:10<00:06, 140.07it/s] 80%|████████  | 3610/4500 [00:10<00:05, 159.83it/s] 82%|████████▏ | 3671/4500 [00:10<00:03, 245.35it/s] 83%|████████▎ | 3733/4500 [00:10<00:02, 323.97it/s] 84%|████████▍ | 3777/4500 [00:10<00:02, 348.55it/s] 85%|████████▌ | 3837/4500 [00:10<00:01, 402.74it/s] 86%|████████▋ | 3882/4500 [00:10<00:01, 394.70it/s] 87%|████████▋ | 3935/4500 [00:10<00:01, 425.13it/s] 88%|████████▊ | 3981/4500 [00:11<00:01, 427.64it/s] 90%|████████▉ | 4042/4500 [00:11<00:00, 468.50it/s] 91%|█████████ | 4091/4500 [00:11<00:01, 391.89it/s] 92%|█████████▏| 4134/4500 [00:11<00:00, 384.01it/s] 93%|█████████▎| 4175/4500 [00:11<00:00, 373.38it/s] 94%|█████████▎| 4214/4500 [00:11<00:00, 355.27it/s] 95%|█████████▍| 4271/4500 [00:11<00:00, 408.07it/s] 96%|█████████▌| 4314/4500 [00:11<00:00, 391.55it/s] 97%|█████████▋| 4356/4500 [00:12<00:00, 392.69it/s] 98%|█████████▊| 4407/4500 [00:12<00:00, 415.50it/s] 99%|█████████▉| 4474/4500 [00:12<00:00, 483.08it/s]100%|██████████| 4500/4500 [00:12<00:00, 366.15it/s]
test_p67 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p67
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p67.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.06s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.63it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.67it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.86it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.33it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p67_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p67_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p67_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p67_Holmes_probs.npy
{'Accuracy': 0.9807, 'Precision': 0.981, 'Recall': 0.9807, 'F1-score': 0.9806}
starting gen taf script for test_p68
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 47/4500 [00:00<00:09, 453.89it/s]  2%|▏         | 93/4500 [00:00<00:12, 351.80it/s]  3%|▎         | 130/4500 [00:00<00:13, 328.02it/s]  4%|▍         | 175/4500 [00:00<00:11, 360.72it/s]  5%|▍         | 218/4500 [00:00<00:11, 374.68it/s]  6%|▌         | 277/4500 [00:00<00:09, 441.05it/s]  7%|▋         | 323/4500 [00:00<00:11, 376.52it/s]  8%|▊         | 363/4500 [00:01<00:14, 288.27it/s]  9%|▉         | 396/4500 [00:01<00:16, 251.25it/s] 10%|▉         | 435/4500 [00:01<00:14, 280.45it/s] 11%|█         | 478/4500 [00:01<00:12, 314.98it/s] 11%|█▏        | 513/4500 [00:01<00:12, 319.94it/s] 12%|█▏        | 549/4500 [00:01<00:12, 327.64it/s] 13%|█▎        | 584/4500 [00:01<00:12, 306.70it/s] 14%|█▎        | 618/4500 [00:01<00:12, 312.41it/s] 14%|█▍        | 651/4500 [00:02<00:14, 273.38it/s] 15%|█▌        | 682/4500 [00:02<00:13, 282.44it/s] 16%|█▌        | 712/4500 [00:02<00:13, 275.41it/s] 16%|█▋        | 741/4500 [00:02<00:14, 258.19it/s] 17%|█▋        | 769/4500 [00:02<00:14, 252.54it/s] 18%|█▊        | 805/4500 [00:02<00:13, 273.75it/s] 19%|█▉        | 850/4500 [00:02<00:11, 315.97it/s] 20%|█▉        | 896/4500 [00:02<00:10, 339.92it/s] 21%|██        | 931/4500 [00:02<00:10, 325.64it/s] 22%|██▏       | 972/4500 [00:03<00:10, 342.25it/s] 23%|██▎       | 1022/4500 [00:03<00:09, 384.95it/s] 24%|██▍       | 1074/4500 [00:03<00:08, 419.87it/s] 25%|██▌       | 1137/4500 [00:03<00:07, 473.93it/s] 27%|██▋       | 1206/4500 [00:03<00:06, 528.44it/s] 28%|██▊       | 1279/4500 [00:03<00:05, 582.72it/s] 30%|██▉       | 1338/4500 [00:03<00:05, 539.59it/s] 31%|███       | 1393/4500 [00:03<00:06, 506.68it/s] 32%|███▏      | 1445/4500 [00:04<00:07, 384.75it/s] 33%|███▎      | 1489/4500 [00:04<00:08, 367.61it/s] 34%|███▍      | 1552/4500 [00:04<00:06, 426.30it/s] 36%|███▌      | 1599/4500 [00:04<00:07, 406.72it/s] 37%|███▋      | 1643/4500 [00:04<00:08, 357.08it/s] 37%|███▋      | 1682/4500 [00:04<00:08, 334.26it/s] 38%|███▊      | 1719/4500 [00:04<00:08, 340.31it/s] 40%|███▉      | 1784/4500 [00:04<00:06, 417.19it/s] 41%|████      | 1840/4500 [00:05<00:05, 447.18it/s] 42%|████▏     | 1905/4500 [00:05<00:05, 499.74it/s] 44%|████▎     | 1964/4500 [00:05<00:04, 516.95it/s] 45%|████▌     | 2025/4500 [00:05<00:04, 525.25it/s] 46%|████▌     | 2079/4500 [00:05<00:04, 508.34it/s] 47%|████▋     | 2131/4500 [00:05<00:04, 485.76it/s] 48%|████▊     | 2181/4500 [00:05<00:04, 486.39it/s] 50%|████▉     | 2231/4500 [00:05<00:05, 384.64it/s] 51%|█████     | 2273/4500 [00:06<00:05, 380.46it/s] 51%|█████▏    | 2314/4500 [00:06<00:06, 332.80it/s] 52%|█████▏    | 2357/4500 [00:06<00:06, 350.82it/s] 53%|█████▎    | 2395/4500 [00:06<00:06, 323.62it/s] 55%|█████▍    | 2468/4500 [00:06<00:04, 418.43it/s] 56%|█████▌    | 2513/4500 [00:06<00:04, 408.23it/s] 57%|█████▋    | 2587/4500 [00:06<00:03, 489.47it/s] 59%|█████▊    | 2639/4500 [00:06<00:03, 478.17it/s] 60%|█████▉    | 2689/4500 [00:07<00:03, 455.18it/s] 61%|██████    | 2736/4500 [00:07<00:04, 391.02it/s] 62%|██████▏   | 2788/4500 [00:07<00:04, 413.94it/s] 63%|██████▎   | 2837/4500 [00:07<00:03, 433.02it/s] 64%|██████▍   | 2884/4500 [00:07<00:03, 437.97it/s] 65%|██████▌   | 2930/4500 [00:07<00:03, 414.21it/s] 67%|██████▋   | 2997/4500 [00:07<00:03, 477.16it/s] 68%|██████▊   | 3046/4500 [00:07<00:03, 446.73it/s] 69%|██████▊   | 3092/4500 [00:07<00:03, 427.20it/s] 70%|██████▉   | 3138/4500 [00:08<00:03, 403.25it/s] 71%|███████   | 3180/4500 [00:08<00:03, 360.58it/s] 72%|███████▏  | 3226/4500 [00:08<00:03, 384.20it/s] 73%|███████▎  | 3277/4500 [00:08<00:03, 405.57it/s] 74%|███████▍  | 3319/4500 [00:08<00:03, 381.99it/s] 75%|███████▍  | 3363/4500 [00:08<00:02, 381.21it/s] 76%|███████▌  | 3404/4500 [00:08<00:02, 385.51it/s] 77%|███████▋  | 3443/4500 [00:08<00:02, 355.96it/s] 77%|███████▋  | 3480/4500 [00:09<00:03, 327.82it/s] 78%|███████▊  | 3514/4500 [00:09<00:04, 239.79it/s] 79%|███████▊  | 3542/4500 [00:09<00:04, 195.97it/s] 79%|███████▉  | 3565/4500 [00:09<00:05, 160.07it/s] 80%|███████▉  | 3584/4500 [00:09<00:06, 138.45it/s] 81%|████████  | 3626/4500 [00:10<00:04, 186.64it/s] 82%|████████▏ | 3684/4500 [00:10<00:03, 256.15it/s] 83%|████████▎ | 3730/4500 [00:10<00:02, 295.05it/s] 84%|████████▎ | 3767/4500 [00:10<00:02, 306.89it/s] 85%|████████▍ | 3817/4500 [00:10<00:01, 350.59it/s] 86%|████████▌ | 3877/4500 [00:10<00:01, 413.85it/s] 87%|████████▋ | 3932/4500 [00:10<00:01, 447.92it/s] 89%|████████▉ | 4001/4500 [00:10<00:00, 504.70it/s] 90%|█████████ | 4054/4500 [00:10<00:00, 473.62it/s] 91%|█████████ | 4104/4500 [00:11<00:00, 407.21it/s] 92%|█████████▏| 4148/4500 [00:11<00:00, 390.90it/s] 93%|█████████▎| 4189/4500 [00:11<00:00, 366.15it/s] 94%|█████████▍| 4227/4500 [00:11<00:00, 358.26it/s] 95%|█████████▍| 4271/4500 [00:11<00:00, 378.92it/s] 96%|█████████▌| 4310/4500 [00:11<00:00, 353.44it/s] 97%|█████████▋| 4365/4500 [00:11<00:00, 400.61it/s] 98%|█████████▊| 4407/4500 [00:11<00:00, 368.63it/s] 99%|█████████▉| 4473/4500 [00:12<00:00, 443.05it/s]100%|██████████| 4500/4500 [00:12<00:00, 372.36it/s]
test_p68 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p68
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p68.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.28it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.07it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.05it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.77it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p68_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p68_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p68_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p68_Holmes_probs.npy
{'Accuracy': 0.9807, 'Precision': 0.981, 'Recall': 0.9807, 'F1-score': 0.9806}
starting gen taf script for test_p69
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 51/4500 [00:00<00:09, 489.93it/s]  2%|▏         | 100/4500 [00:00<00:10, 422.26it/s]  3%|▎         | 143/4500 [00:00<00:10, 403.14it/s]  4%|▍         | 184/4500 [00:00<00:10, 395.26it/s]  5%|▍         | 224/4500 [00:00<00:10, 393.70it/s]  7%|▋         | 298/4500 [00:00<00:08, 504.85it/s]  8%|▊         | 350/4500 [00:00<00:12, 327.60it/s]  9%|▊         | 391/4500 [00:01<00:14, 286.03it/s]  9%|▉         | 426/4500 [00:01<00:14, 286.50it/s] 10%|█         | 468/4500 [00:01<00:12, 315.71it/s] 11%|█         | 504/4500 [00:01<00:12, 325.59it/s] 12%|█▏        | 542/4500 [00:01<00:11, 339.47it/s] 13%|█▎        | 579/4500 [00:01<00:11, 330.28it/s] 14%|█▍        | 623/4500 [00:01<00:10, 353.03it/s] 15%|█▍        | 660/4500 [00:01<00:10, 353.76it/s] 16%|█▌        | 701/4500 [00:01<00:10, 365.65it/s] 16%|█▋        | 739/4500 [00:02<00:10, 345.39it/s] 17%|█▋        | 775/4500 [00:02<00:10, 345.38it/s] 18%|█▊        | 816/4500 [00:02<00:10, 363.16it/s] 20%|█▉        | 893/4500 [00:02<00:07, 462.93it/s] 22%|██▏       | 971/4500 [00:02<00:06, 550.71it/s] 23%|██▎       | 1027/4500 [00:02<00:06, 523.72it/s] 24%|██▍       | 1080/4500 [00:02<00:06, 489.49it/s] 26%|██▌       | 1155/4500 [00:02<00:06, 555.37it/s] 27%|██▋       | 1232/4500 [00:02<00:05, 601.52it/s] 29%|██▊       | 1293/4500 [00:03<00:05, 594.00it/s] 30%|███       | 1353/4500 [00:03<00:05, 557.64it/s] 31%|███▏      | 1410/4500 [00:03<00:06, 506.65it/s] 32%|███▏      | 1462/4500 [00:03<00:07, 393.06it/s] 33%|███▎      | 1506/4500 [00:03<00:08, 359.83it/s] 35%|███▍      | 1556/4500 [00:03<00:07, 389.54it/s] 36%|███▌      | 1599/4500 [00:03<00:07, 392.88it/s] 36%|███▋      | 1641/4500 [00:04<00:07, 386.37it/s] 37%|███▋      | 1682/4500 [00:04<00:08, 323.04it/s] 38%|███▊      | 1719/4500 [00:04<00:08, 328.47it/s] 40%|███▉      | 1778/4500 [00:04<00:06, 392.80it/s] 41%|████      | 1831/4500 [00:04<00:06, 422.05it/s] 42%|████▏     | 1876/4500 [00:04<00:06, 417.88it/s] 43%|████▎     | 1946/4500 [00:04<00:05, 494.20it/s] 45%|████▍     | 2015/4500 [00:04<00:04, 530.90it/s] 46%|████▌     | 2070/4500 [00:04<00:04, 519.26it/s] 47%|████▋     | 2129/4500 [00:05<00:04, 528.17it/s] 49%|████▊     | 2183/4500 [00:05<00:04, 505.28it/s] 50%|████▉     | 2235/4500 [00:05<00:04, 487.24it/s] 51%|█████     | 2285/4500 [00:05<00:05, 390.28it/s] 52%|█████▏    | 2328/4500 [00:05<00:06, 326.91it/s] 53%|█████▎    | 2366/4500 [00:05<00:06, 337.52it/s] 53%|█████▎    | 2403/4500 [00:05<00:06, 342.42it/s] 54%|█████▍    | 2440/4500 [00:06<00:06, 338.57it/s] 55%|█████▌    | 2497/4500 [00:06<00:05, 383.34it/s] 57%|█████▋    | 2546/4500 [00:06<00:04, 410.56it/s] 58%|█████▊    | 2613/4500 [00:06<00:04, 463.43it/s] 59%|█████▉    | 2661/4500 [00:06<00:04, 448.46it/s] 60%|██████    | 2707/4500 [00:06<00:04, 418.76it/s] 61%|██████    | 2750/4500 [00:06<00:04, 391.04it/s] 62%|██████▏   | 2807/4500 [00:06<00:03, 426.64it/s] 63%|██████▎   | 2854/4500 [00:06<00:03, 437.03it/s] 65%|██████▍   | 2911/4500 [00:07<00:03, 464.66it/s] 66%|██████▌   | 2959/4500 [00:07<00:03, 449.17it/s] 67%|██████▋   | 3025/4500 [00:07<00:02, 492.10it/s] 68%|██████▊   | 3075/4500 [00:07<00:02, 487.85it/s] 69%|██████▉   | 3125/4500 [00:07<00:03, 441.64it/s] 70%|███████   | 3171/4500 [00:07<00:03, 385.68it/s] 71%|███████▏  | 3212/4500 [00:07<00:03, 371.76it/s] 72%|███████▏  | 3251/4500 [00:07<00:03, 365.25it/s] 73%|███████▎  | 3300/4500 [00:08<00:03, 391.57it/s] 74%|███████▍  | 3342/4500 [00:08<00:02, 398.17it/s] 75%|███████▌  | 3383/4500 [00:08<00:03, 354.29it/s] 76%|███████▌  | 3430/4500 [00:08<00:02, 384.08it/s] 77%|███████▋  | 3470/4500 [00:08<00:03, 326.52it/s] 78%|███████▊  | 3505/4500 [00:08<00:03, 280.31it/s] 79%|███████▊  | 3536/4500 [00:09<00:05, 177.10it/s] 79%|███████▉  | 3560/4500 [00:09<00:05, 163.20it/s] 80%|███████▉  | 3581/4500 [00:09<00:05, 165.17it/s] 80%|████████  | 3601/4500 [00:09<00:05, 169.94it/s] 81%|████████▏ | 3657/4500 [00:09<00:03, 250.56it/s] 82%|████████▏ | 3708/4500 [00:09<00:02, 307.30it/s] 83%|████████▎ | 3744/4500 [00:09<00:02, 316.93it/s] 84%|████████▍ | 3780/4500 [00:09<00:02, 309.65it/s] 85%|████████▌ | 3835/4500 [00:10<00:01, 370.07it/s] 87%|████████▋ | 3897/4500 [00:10<00:01, 432.38it/s] 88%|████████▊ | 3965/4500 [00:10<00:01, 500.40it/s] 89%|████████▉ | 4018/4500 [00:10<00:01, 443.69it/s] 90%|█████████ | 4066/4500 [00:10<00:01, 429.99it/s] 91%|█████████▏| 4111/4500 [00:10<00:00, 390.42it/s] 92%|█████████▏| 4152/4500 [00:10<00:01, 327.47it/s] 93%|█████████▎| 4201/4500 [00:10<00:00, 359.68it/s] 95%|█████████▍| 4265/4500 [00:11<00:00, 421.52it/s] 96%|█████████▌| 4311/4500 [00:11<00:00, 423.69it/s] 97%|█████████▋| 4359/4500 [00:11<00:00, 432.88it/s] 98%|█████████▊| 4404/4500 [00:11<00:00, 420.51it/s] 99%|█████████▉| 4460/4500 [00:11<00:00, 447.80it/s]100%|██████████| 4500/4500 [00:11<00:00, 390.52it/s]
test_p69 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p69
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p69.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.03s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.84it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.98it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.21it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.64it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p69_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p69_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p69_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p69_Holmes_probs.npy
{'Accuracy': 0.9811, 'Precision': 0.9815, 'Recall': 0.9811, 'F1-score': 0.9811}
starting gen taf script for test_p70
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 71/4500 [00:00<00:06, 705.02it/s]  3%|▎         | 142/4500 [00:00<00:08, 486.64it/s]  4%|▍         | 195/4500 [00:00<00:10, 393.74it/s]  5%|▌         | 247/4500 [00:00<00:10, 423.78it/s]  7%|▋         | 301/4500 [00:00<00:09, 453.54it/s]  8%|▊         | 349/4500 [00:00<00:12, 328.23it/s]  9%|▊         | 388/4500 [00:01<00:13, 309.39it/s]  9%|▉         | 423/4500 [00:01<00:12, 318.31it/s] 11%|█         | 484/4500 [00:01<00:10, 389.72it/s] 12%|█▏        | 527/4500 [00:01<00:10, 375.69it/s] 13%|█▎        | 568/4500 [00:01<00:11, 356.53it/s] 14%|█▎        | 611/4500 [00:01<00:10, 372.83it/s] 14%|█▍        | 650/4500 [00:01<00:10, 351.00it/s] 15%|█▌        | 687/4500 [00:01<00:10, 351.08it/s] 16%|█▌        | 726/4500 [00:01<00:10, 359.47it/s] 17%|█▋        | 763/4500 [00:02<00:11, 322.96it/s] 18%|█▊        | 797/4500 [00:02<00:12, 303.64it/s] 19%|█▉        | 851/4500 [00:02<00:10, 362.26it/s] 20%|██        | 901/4500 [00:02<00:09, 396.28it/s] 21%|██        | 947/4500 [00:02<00:08, 410.03it/s] 22%|██▏       | 996/4500 [00:02<00:08, 421.61it/s] 23%|██▎       | 1052/4500 [00:02<00:07, 459.67it/s] 25%|██▍       | 1119/4500 [00:02<00:06, 514.51it/s] 27%|██▋       | 1199/4500 [00:02<00:05, 574.73it/s] 28%|██▊       | 1257/4500 [00:03<00:06, 529.47it/s] 29%|██▉       | 1311/4500 [00:03<00:06, 495.29it/s] 31%|███       | 1386/4500 [00:03<00:05, 561.59it/s] 32%|███▏      | 1444/4500 [00:03<00:07, 388.97it/s] 33%|███▎      | 1491/4500 [00:03<00:08, 364.68it/s] 34%|███▍      | 1550/4500 [00:03<00:07, 410.07it/s] 36%|███▌      | 1601/4500 [00:03<00:07, 409.23it/s] 37%|███▋      | 1646/4500 [00:04<00:08, 339.47it/s] 37%|███▋      | 1685/4500 [00:04<00:09, 297.93it/s] 38%|███▊      | 1725/4500 [00:04<00:08, 318.96it/s] 39%|███▉      | 1763/4500 [00:04<00:08, 328.92it/s] 41%|████      | 1824/4500 [00:04<00:06, 395.69it/s] 42%|████▏     | 1898/4500 [00:04<00:05, 472.81it/s] 44%|████▍     | 1982/4500 [00:04<00:04, 563.05it/s] 45%|████▌     | 2042/4500 [00:04<00:04, 524.43it/s] 47%|████▋     | 2097/4500 [00:05<00:04, 503.35it/s] 48%|████▊     | 2150/4500 [00:05<00:04, 507.39it/s] 49%|████▉     | 2205/4500 [00:05<00:04, 496.38it/s] 50%|█████     | 2256/4500 [00:05<00:05, 392.38it/s] 51%|█████     | 2299/4500 [00:05<00:06, 365.34it/s] 52%|█████▏    | 2339/4500 [00:05<00:06, 309.43it/s] 53%|█████▎    | 2373/4500 [00:05<00:06, 307.64it/s] 54%|█████▍    | 2438/4500 [00:06<00:05, 374.03it/s] 55%|█████▌    | 2478/4500 [00:06<00:05, 378.79it/s] 56%|█████▌    | 2523/4500 [00:06<00:05, 387.72it/s] 57%|█████▋    | 2581/4500 [00:06<00:04, 437.47it/s] 58%|█████▊    | 2627/4500 [00:06<00:04, 408.00it/s] 60%|█████▉    | 2686/4500 [00:06<00:04, 436.76it/s] 61%|██████    | 2734/4500 [00:06<00:03, 445.59it/s] 62%|██████▏   | 2780/4500 [00:06<00:04, 397.23it/s] 63%|██████▎   | 2853/4500 [00:07<00:03, 482.25it/s] 65%|██████▍   | 2904/4500 [00:07<00:03, 441.55it/s] 66%|██████▌   | 2964/4500 [00:07<00:03, 480.91it/s] 67%|██████▋   | 3021/4500 [00:07<00:02, 502.83it/s] 68%|██████▊   | 3074/4500 [00:07<00:03, 400.26it/s] 69%|██████▉   | 3121/4500 [00:07<00:03, 407.33it/s] 70%|███████   | 3165/4500 [00:07<00:03, 391.70it/s] 71%|███████▏  | 3207/4500 [00:07<00:03, 346.53it/s] 72%|███████▏  | 3252/4500 [00:08<00:03, 367.09it/s] 74%|███████▎  | 3318/4500 [00:08<00:02, 430.48it/s] 75%|███████▍  | 3364/4500 [00:08<00:03, 370.71it/s] 76%|███████▌  | 3404/4500 [00:08<00:03, 325.06it/s] 76%|███████▋  | 3439/4500 [00:08<00:03, 314.20it/s] 77%|███████▋  | 3472/4500 [00:08<00:03, 300.71it/s] 78%|███████▊  | 3504/4500 [00:08<00:03, 288.67it/s] 79%|███████▊  | 3534/4500 [00:09<00:04, 197.27it/s] 79%|███████▉  | 3558/4500 [00:09<00:06, 152.39it/s] 80%|███████▉  | 3578/4500 [00:09<00:06, 143.70it/s] 80%|████████  | 3613/4500 [00:09<00:04, 178.25it/s] 81%|████████▏ | 3657/4500 [00:09<00:03, 229.30it/s] 83%|████████▎ | 3713/4500 [00:09<00:02, 288.04it/s] 84%|████████▎ | 3758/4500 [00:10<00:02, 323.52it/s] 84%|████████▍ | 3795/4500 [00:10<00:02, 329.31it/s] 86%|████████▌ | 3876/4500 [00:10<00:01, 441.90it/s] 87%|████████▋ | 3924/4500 [00:10<00:01, 413.18it/s] 88%|████████▊ | 3976/4500 [00:10<00:01, 437.36it/s] 90%|████████▉ | 4034/4500 [00:10<00:01, 461.25it/s] 91%|█████████ | 4082/4500 [00:10<00:01, 359.30it/s] 92%|█████████▏| 4138/4500 [00:10<00:00, 400.95it/s] 93%|█████████▎| 4183/4500 [00:11<00:00, 333.97it/s] 94%|█████████▍| 4247/4500 [00:11<00:00, 395.76it/s] 96%|█████████▌| 4307/4500 [00:11<00:00, 437.00it/s] 97%|█████████▋| 4358/4500 [00:11<00:00, 438.47it/s] 98%|█████████▊| 4405/4500 [00:11<00:00, 412.18it/s] 99%|█████████▉| 4454/4500 [00:11<00:00, 431.62it/s]100%|██████████| 4500/4500 [00:11<00:00, 384.14it/s]
test_p70 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p70
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p70.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:20,  1.21s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:02,  5.94it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 11.58it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 17.46it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.26it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p70_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p70_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p70_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p70_Holmes_probs.npy
{'Accuracy': 0.9818, 'Precision': 0.9821, 'Recall': 0.9818, 'F1-score': 0.9817}
starting gen taf script for test_p71
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 68/4500 [00:00<00:06, 649.64it/s]  3%|▎         | 133/4500 [00:00<00:09, 483.70it/s]  4%|▍         | 184/4500 [00:00<00:10, 429.83it/s]  5%|▌         | 229/4500 [00:00<00:09, 432.63it/s]  6%|▌         | 280/4500 [00:00<00:09, 452.42it/s]  7%|▋         | 327/4500 [00:00<00:11, 357.17it/s]  8%|▊         | 366/4500 [00:00<00:13, 299.17it/s]  9%|▉         | 399/4500 [00:01<00:15, 264.87it/s] 10%|▉         | 449/4500 [00:01<00:13, 309.13it/s] 11%|█         | 496/4500 [00:01<00:11, 344.62it/s] 12%|█▏        | 534/4500 [00:01<00:12, 316.61it/s] 13%|█▎        | 568/4500 [00:01<00:13, 283.15it/s] 13%|█▎        | 600/4500 [00:01<00:13, 287.51it/s] 14%|█▍        | 633/4500 [00:01<00:12, 297.89it/s] 15%|█▍        | 670/4500 [00:01<00:12, 314.75it/s] 16%|█▌        | 703/4500 [00:02<00:12, 308.59it/s] 16%|█▋        | 735/4500 [00:02<00:12, 294.86it/s] 17%|█▋        | 770/4500 [00:02<00:12, 303.75it/s] 18%|█▊        | 807/4500 [00:02<00:11, 321.24it/s] 19%|█▉        | 861/4500 [00:02<00:09, 373.84it/s] 21%|██        | 934/4500 [00:02<00:07, 454.92it/s] 22%|██▏       | 980/4500 [00:02<00:08, 425.71it/s] 23%|██▎       | 1023/4500 [00:02<00:08, 391.01it/s] 24%|██▍       | 1072/4500 [00:03<00:08, 404.35it/s] 26%|██▋       | 1185/4500 [00:03<00:05, 597.18it/s] 28%|██▊       | 1248/4500 [00:03<00:05, 577.77it/s] 29%|██▉       | 1308/4500 [00:03<00:05, 572.86it/s] 30%|███       | 1367/4500 [00:03<00:06, 489.62it/s] 32%|███▏      | 1419/4500 [00:03<00:06, 486.63it/s] 33%|███▎      | 1470/4500 [00:03<00:07, 412.36it/s] 34%|███▎      | 1515/4500 [00:03<00:07, 411.89it/s] 35%|███▍      | 1559/4500 [00:04<00:07, 415.10it/s] 36%|███▌      | 1602/4500 [00:04<00:07, 408.01it/s] 37%|███▋      | 1644/4500 [00:04<00:07, 362.48it/s] 37%|███▋      | 1682/4500 [00:04<00:08, 327.66it/s] 38%|███▊      | 1717/4500 [00:04<00:08, 319.50it/s] 40%|███▉      | 1796/4500 [00:04<00:06, 425.03it/s] 41%|████      | 1856/4500 [00:04<00:05, 460.68it/s] 42%|████▏     | 1911/4500 [00:04<00:05, 483.94it/s] 44%|████▍     | 1976/4500 [00:04<00:04, 516.11it/s] 45%|████▌     | 2036/4500 [00:05<00:04, 522.40it/s] 46%|████▋     | 2089/4500 [00:05<00:04, 504.42it/s] 48%|████▊     | 2140/4500 [00:05<00:04, 503.95it/s] 49%|████▊     | 2191/4500 [00:05<00:04, 472.05it/s] 50%|████▉     | 2239/4500 [00:05<00:05, 416.37it/s] 51%|█████     | 2282/4500 [00:05<00:06, 339.21it/s] 52%|█████▏    | 2319/4500 [00:05<00:06, 322.84it/s] 52%|█████▏    | 2354/4500 [00:06<00:07, 299.97it/s] 53%|█████▎    | 2396/4500 [00:06<00:06, 325.34it/s] 54%|█████▍    | 2431/4500 [00:06<00:06, 331.40it/s] 55%|█████▍    | 2472/4500 [00:06<00:05, 350.29it/s] 56%|█████▌    | 2518/4500 [00:06<00:05, 378.09it/s] 57%|█████▋    | 2557/4500 [00:06<00:05, 373.81it/s] 58%|█████▊    | 2606/4500 [00:06<00:04, 400.65it/s] 59%|█████▉    | 2647/4500 [00:06<00:04, 401.33it/s] 60%|██████    | 2704/4500 [00:06<00:04, 439.62it/s] 61%|██████    | 2749/4500 [00:06<00:04, 407.01it/s] 62%|██████▏   | 2791/4500 [00:07<00:04, 373.94it/s] 63%|██████▎   | 2849/4500 [00:07<00:03, 427.84it/s] 64%|██████▍   | 2894/4500 [00:07<00:03, 433.64it/s] 65%|██████▌   | 2944/4500 [00:07<00:03, 448.12it/s] 66%|██████▋   | 2990/4500 [00:07<00:03, 445.17it/s] 67%|██████▋   | 3036/4500 [00:07<00:03, 448.22it/s] 68%|██████▊   | 3082/4500 [00:07<00:03, 444.80it/s] 69%|██████▉   | 3127/4500 [00:07<00:03, 416.12it/s] 70%|███████   | 3170/4500 [00:08<00:04, 326.45it/s] 71%|███████   | 3206/4500 [00:08<00:03, 328.85it/s] 72%|███████▏  | 3251/4500 [00:08<00:03, 358.93it/s] 73%|███████▎  | 3299/4500 [00:08<00:03, 386.31it/s] 74%|███████▍  | 3340/4500 [00:08<00:03, 375.08it/s] 75%|███████▌  | 3379/4500 [00:08<00:03, 360.97it/s] 76%|███████▌  | 3417/4500 [00:08<00:03, 348.99it/s] 77%|███████▋  | 3462/4500 [00:08<00:02, 357.31it/s] 78%|███████▊  | 3499/4500 [00:08<00:02, 344.72it/s] 79%|███████▊  | 3534/4500 [00:09<00:05, 177.36it/s] 79%|███████▉  | 3561/4500 [00:09<00:05, 168.53it/s] 80%|███████▉  | 3584/4500 [00:09<00:06, 147.44it/s] 80%|████████  | 3622/4500 [00:09<00:04, 185.72it/s] 82%|████████▏ | 3683/4500 [00:10<00:03, 265.60it/s] 83%|████████▎ | 3730/4500 [00:10<00:02, 306.78it/s] 84%|████████▍ | 3782/4500 [00:10<00:02, 334.76it/s] 85%|████████▍ | 3821/4500 [00:10<00:01, 339.88it/s] 86%|████████▋ | 3883/4500 [00:10<00:01, 406.40it/s] 87%|████████▋ | 3930/4500 [00:10<00:01, 422.90it/s] 88%|████████▊ | 3977/4500 [00:10<00:01, 426.15it/s] 90%|████████▉ | 4031/4500 [00:10<00:01, 443.46it/s] 91%|█████████ | 4078/4500 [00:10<00:00, 428.13it/s] 92%|█████████▏| 4122/4500 [00:11<00:01, 352.32it/s] 92%|█████████▏| 4160/4500 [00:11<00:01, 324.23it/s] 93%|█████████▎| 4201/4500 [00:11<00:00, 344.52it/s] 95%|█████████▍| 4266/4500 [00:11<00:00, 420.08it/s] 96%|█████████▌| 4311/4500 [00:11<00:00, 412.41it/s] 97%|█████████▋| 4355/4500 [00:11<00:00, 347.14it/s] 98%|█████████▊| 4393/4500 [00:11<00:00, 351.24it/s] 99%|█████████▉| 4447/4500 [00:11<00:00, 398.01it/s]100%|██████████| 4500/4500 [00:11<00:00, 375.08it/s]
test_p71 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p71
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p71.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:20,  1.18s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.04it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 11.57it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 17.39it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.31it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p71_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p71_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p71_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p71_Holmes_probs.npy
{'Accuracy': 0.9824, 'Precision': 0.9827, 'Recall': 0.9824, 'F1-score': 0.9824}
starting gen taf script for test_p72
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 51/4500 [00:00<00:09, 476.20it/s]  2%|▏         | 99/4500 [00:00<00:11, 375.40it/s]  3%|▎         | 138/4500 [00:00<00:12, 345.67it/s]  4%|▍         | 177/4500 [00:00<00:12, 359.92it/s]  5%|▍         | 214/4500 [00:00<00:12, 333.39it/s]  6%|▌         | 260/4500 [00:00<00:11, 367.35it/s]  7%|▋         | 301/4500 [00:00<00:11, 378.08it/s]  8%|▊         | 340/4500 [00:01<00:17, 243.26it/s]  8%|▊         | 371/4500 [00:01<00:17, 231.50it/s]  9%|▉         | 399/4500 [00:01<00:18, 226.81it/s] 10%|▉         | 436/4500 [00:01<00:15, 255.09it/s] 10%|█         | 465/4500 [00:01<00:16, 251.45it/s] 11%|█▏        | 509/4500 [00:01<00:13, 297.23it/s] 12%|█▏        | 542/4500 [00:01<00:14, 278.50it/s] 13%|█▎        | 573/4500 [00:01<00:14, 276.82it/s] 13%|█▎        | 604/4500 [00:02<00:14, 278.05it/s] 14%|█▍        | 641/4500 [00:02<00:12, 302.19it/s] 15%|█▍        | 673/4500 [00:02<00:13, 273.49it/s] 16%|█▌        | 702/4500 [00:02<00:14, 265.92it/s] 16%|█▋        | 733/4500 [00:02<00:13, 276.81it/s] 17%|█▋        | 762/4500 [00:02<00:13, 272.44it/s] 18%|█▊        | 790/4500 [00:02<00:15, 240.79it/s] 18%|█▊        | 816/4500 [00:02<00:15, 244.50it/s] 20%|█▉        | 886/4500 [00:03<00:10, 357.62it/s] 21%|██        | 952/4500 [00:03<00:08, 430.02it/s] 22%|██▏       | 1008/4500 [00:03<00:07, 460.19it/s] 23%|██▎       | 1055/4500 [00:03<00:08, 418.85it/s] 25%|██▌       | 1134/4500 [00:03<00:06, 512.70it/s] 27%|██▋       | 1221/4500 [00:03<00:05, 596.12it/s] 29%|██▉       | 1300/4500 [00:03<00:04, 648.84it/s] 30%|███       | 1367/4500 [00:03<00:05, 532.13it/s] 32%|███▏      | 1425/4500 [00:04<00:06, 476.09it/s] 33%|███▎      | 1477/4500 [00:04<00:07, 393.37it/s] 34%|███▍      | 1521/4500 [00:04<00:07, 374.05it/s] 35%|███▌      | 1590/4500 [00:04<00:06, 440.11it/s] 36%|███▋      | 1639/4500 [00:04<00:07, 372.36it/s] 37%|███▋      | 1681/4500 [00:04<00:09, 300.28it/s] 38%|███▊      | 1721/4500 [00:05<00:09, 299.37it/s] 40%|███▉      | 1798/4500 [00:05<00:06, 397.48it/s] 41%|████      | 1854/4500 [00:05<00:06, 431.18it/s] 42%|████▏     | 1903/4500 [00:05<00:05, 436.99it/s] 44%|████▍     | 1972/4500 [00:05<00:05, 496.38it/s] 45%|████▌     | 2026/4500 [00:05<00:05, 441.64it/s] 47%|████▋     | 2098/4500 [00:05<00:04, 493.08it/s] 48%|████▊     | 2151/4500 [00:05<00:04, 471.56it/s] 49%|████▉     | 2201/4500 [00:05<00:05, 458.31it/s] 50%|████▉     | 2249/4500 [00:06<00:05, 385.46it/s] 51%|█████     | 2291/4500 [00:06<00:06, 356.62it/s] 52%|█████▏    | 2329/4500 [00:06<00:07, 297.05it/s] 52%|█████▏    | 2362/4500 [00:06<00:07, 285.78it/s] 53%|█████▎    | 2396/4500 [00:06<00:07, 290.45it/s] 55%|█████▍    | 2457/4500 [00:06<00:05, 365.78it/s] 56%|█████▌    | 2506/4500 [00:06<00:05, 390.64it/s] 57%|█████▋    | 2555/4500 [00:07<00:04, 416.69it/s] 58%|█████▊    | 2618/4500 [00:07<00:04, 466.93it/s] 59%|█████▉    | 2667/4500 [00:07<00:04, 426.65it/s] 60%|██████    | 2713/4500 [00:07<00:04, 435.35it/s] 61%|██████▏   | 2758/4500 [00:07<00:04, 405.27it/s] 62%|██████▏   | 2800/4500 [00:07<00:04, 390.93it/s] 63%|██████▎   | 2850/4500 [00:07<00:03, 413.11it/s] 65%|██████▍   | 2913/4500 [00:07<00:03, 469.82it/s] 66%|██████▌   | 2962/4500 [00:07<00:03, 438.31it/s] 67%|██████▋   | 3007/4500 [00:08<00:03, 428.24it/s] 68%|██████▊   | 3056/4500 [00:08<00:03, 442.34it/s] 69%|██████▉   | 3101/4500 [00:08<00:03, 431.02it/s] 70%|██████▉   | 3145/4500 [00:08<00:04, 308.87it/s] 71%|███████   | 3193/4500 [00:08<00:03, 344.77it/s] 72%|███████▏  | 3241/4500 [00:08<00:03, 367.85it/s] 73%|███████▎  | 3292/4500 [00:08<00:03, 400.25it/s] 74%|███████▍  | 3336/4500 [00:08<00:03, 349.71it/s] 75%|███████▌  | 3375/4500 [00:09<00:03, 357.65it/s] 76%|███████▌  | 3414/4500 [00:09<00:02, 364.40it/s] 77%|███████▋  | 3455/4500 [00:09<00:02, 359.24it/s] 78%|███████▊  | 3493/4500 [00:09<00:03, 287.40it/s] 78%|███████▊  | 3525/4500 [00:09<00:04, 200.82it/s] 79%|███████▉  | 3551/4500 [00:09<00:04, 210.66it/s] 79%|███████▉  | 3577/4500 [00:10<00:06, 145.74it/s] 80%|████████  | 3609/4500 [00:10<00:05, 174.10it/s] 81%|████████▏ | 3666/4500 [00:10<00:03, 247.30it/s] 82%|████████▏ | 3700/4500 [00:10<00:03, 261.55it/s] 83%|████████▎ | 3757/4500 [00:10<00:02, 326.62it/s] 84%|████████▍ | 3796/4500 [00:10<00:02, 331.45it/s] 85%|████████▌ | 3844/4500 [00:10<00:01, 351.97it/s] 87%|████████▋ | 3908/4500 [00:11<00:01, 423.39it/s] 88%|████████▊ | 3964/4500 [00:11<00:01, 449.30it/s] 89%|████████▉ | 4012/4500 [00:11<00:01, 413.81it/s] 90%|█████████ | 4056/4500 [00:11<00:01, 409.42it/s] 91%|█████████ | 4099/4500 [00:11<00:01, 395.08it/s] 92%|█████████▏| 4143/4500 [00:11<00:00, 405.59it/s] 93%|█████████▎| 4185/4500 [00:11<00:00, 377.43it/s] 94%|█████████▍| 4224/4500 [00:11<00:00, 378.69it/s] 95%|█████████▌| 4282/4500 [00:11<00:00, 429.34it/s] 96%|█████████▌| 4326/4500 [00:12<00:00, 426.44it/s] 97%|█████████▋| 4370/4500 [00:12<00:00, 399.73it/s] 98%|█████████▊| 4419/4500 [00:12<00:00, 418.91it/s]100%|█████████▉| 4488/4500 [00:12<00:00, 484.26it/s]100%|██████████| 4500/4500 [00:12<00:00, 363.35it/s]
test_p72 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p72
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p72.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.01s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.91it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.06it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.25it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.73it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p72_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p72_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p72_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p72_Holmes_probs.npy
{'Accuracy': 0.9824, 'Precision': 0.9827, 'Recall': 0.9824, 'F1-score': 0.9824}
starting gen taf script for test_p73
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 77/4500 [00:00<00:06, 722.63it/s]  3%|▎         | 150/4500 [00:00<00:10, 411.19it/s]  4%|▍         | 199/4500 [00:00<00:10, 411.25it/s]  6%|▌         | 261/4500 [00:00<00:09, 469.67it/s]  7%|▋         | 312/4500 [00:00<00:09, 450.45it/s]  8%|▊         | 360/4500 [00:00<00:13, 309.02it/s]  9%|▉         | 398/4500 [00:01<00:14, 282.84it/s] 10%|▉         | 432/4500 [00:01<00:13, 292.19it/s] 11%|█         | 493/4500 [00:01<00:11, 360.96it/s] 12%|█▏        | 534/4500 [00:01<00:11, 338.34it/s] 13%|█▎        | 571/4500 [00:01<00:11, 339.88it/s] 14%|█▎        | 608/4500 [00:01<00:12, 316.80it/s] 14%|█▍        | 651/4500 [00:01<00:11, 331.92it/s] 15%|█▌        | 686/4500 [00:01<00:12, 316.83it/s] 16%|█▌        | 719/4500 [00:02<00:12, 314.34it/s] 17%|█▋        | 752/4500 [00:02<00:13, 286.70it/s] 18%|█▊        | 793/4500 [00:02<00:11, 312.47it/s] 19%|█▊        | 840/4500 [00:02<00:10, 349.21it/s] 20%|█▉        | 878/4500 [00:02<00:10, 352.48it/s] 21%|██        | 931/4500 [00:02<00:09, 388.83it/s] 22%|██▏       | 971/4500 [00:02<00:09, 388.65it/s] 23%|██▎       | 1044/4500 [00:02<00:07, 483.04it/s] 24%|██▍       | 1094/4500 [00:02<00:07, 434.09it/s] 26%|██▋       | 1191/4500 [00:03<00:05, 574.79it/s] 28%|██▊       | 1276/4500 [00:03<00:04, 650.29it/s] 30%|██▉       | 1344/4500 [00:03<00:04, 634.29it/s] 31%|███▏      | 1410/4500 [00:03<00:06, 509.28it/s] 33%|███▎      | 1466/4500 [00:03<00:07, 404.10it/s] 34%|███▎      | 1513/4500 [00:03<00:07, 392.85it/s] 35%|███▍      | 1564/4500 [00:03<00:07, 416.47it/s] 36%|███▌      | 1618/4500 [00:04<00:06, 444.36it/s] 37%|███▋      | 1666/4500 [00:04<00:08, 350.54it/s] 38%|███▊      | 1707/4500 [00:04<00:08, 331.61it/s] 39%|███▉      | 1749/4500 [00:04<00:07, 348.48it/s] 40%|███▉      | 1798/4500 [00:04<00:07, 375.80it/s] 41%|████      | 1856/4500 [00:04<00:06, 423.39it/s] 42%|████▏     | 1904/4500 [00:04<00:06, 430.13it/s] 44%|████▎     | 1967/4500 [00:04<00:05, 473.09it/s] 45%|████▌     | 2035/4500 [00:05<00:04, 529.27it/s] 46%|████▋     | 2090/4500 [00:05<00:05, 477.62it/s] 48%|████▊     | 2155/4500 [00:05<00:04, 522.38it/s] 49%|████▉     | 2210/4500 [00:05<00:04, 509.87it/s] 50%|█████     | 2263/4500 [00:05<00:05, 388.69it/s] 51%|█████▏    | 2307/4500 [00:05<00:06, 349.64it/s] 52%|█████▏    | 2346/4500 [00:05<00:07, 307.19it/s] 53%|█████▎    | 2389/4500 [00:06<00:06, 330.08it/s] 54%|█████▍    | 2439/4500 [00:06<00:05, 365.18it/s] 55%|█████▌    | 2488/4500 [00:06<00:05, 388.84it/s] 57%|█████▋    | 2547/4500 [00:06<00:04, 433.05it/s] 58%|█████▊    | 2607/4500 [00:06<00:04, 464.81it/s] 59%|█████▉    | 2656/4500 [00:06<00:04, 431.63it/s] 60%|██████    | 2701/4500 [00:06<00:04, 417.27it/s] 61%|██████▏   | 2762/4500 [00:06<00:03, 457.06it/s] 62%|██████▏   | 2809/4500 [00:06<00:03, 435.13it/s] 64%|██████▍   | 2883/4500 [00:07<00:03, 505.29it/s] 65%|██████▌   | 2935/4500 [00:07<00:03, 453.08it/s] 67%|██████▋   | 2994/4500 [00:07<00:03, 486.76it/s] 68%|██████▊   | 3045/4500 [00:07<00:03, 482.78it/s] 69%|██████▉   | 3095/4500 [00:07<00:02, 484.25it/s] 70%|██████▉   | 3145/4500 [00:07<00:03, 384.37it/s] 71%|███████   | 3188/4500 [00:07<00:04, 327.49it/s] 72%|███████▏  | 3235/4500 [00:08<00:03, 358.08it/s] 73%|███████▎  | 3284/4500 [00:08<00:03, 388.87it/s] 74%|███████▍  | 3334/4500 [00:08<00:02, 413.83it/s] 75%|███████▌  | 3379/4500 [00:08<00:02, 386.69it/s] 76%|███████▌  | 3422/4500 [00:08<00:02, 396.70it/s] 77%|███████▋  | 3464/4500 [00:08<00:03, 334.91it/s] 78%|███████▊  | 3501/4500 [00:08<00:03, 283.88it/s] 79%|███████▊  | 3533/4500 [00:09<00:05, 187.56it/s] 79%|███████▉  | 3558/4500 [00:09<00:05, 164.87it/s] 80%|███████▉  | 3579/4500 [00:09<00:05, 159.51it/s] 80%|███████▉  | 3598/4500 [00:09<00:05, 158.51it/s] 81%|████████  | 3641/4500 [00:09<00:04, 210.53it/s] 82%|████████▏ | 3702/4500 [00:09<00:02, 295.41it/s] 83%|████████▎ | 3737/4500 [00:10<00:02, 292.62it/s] 84%|████████▍ | 3779/4500 [00:10<00:02, 321.39it/s] 85%|████████▍ | 3817/4500 [00:10<00:02, 336.21it/s] 86%|████████▌ | 3862/4500 [00:10<00:01, 365.80it/s] 87%|████████▋ | 3910/4500 [00:10<00:01, 380.39it/s] 88%|████████▊ | 3961/4500 [00:10<00:01, 398.84it/s] 89%|████████▉ | 4012/4500 [00:10<00:01, 423.84it/s] 90%|█████████ | 4056/4500 [00:10<00:01, 377.19it/s] 91%|█████████ | 4096/4500 [00:10<00:01, 372.73it/s] 92%|█████████▏| 4135/4500 [00:11<00:01, 347.03it/s] 93%|█████████▎| 4171/4500 [00:11<00:00, 333.90it/s] 94%|█████████▎| 4215/4500 [00:11<00:00, 357.47it/s] 94%|█████████▍| 4252/4500 [00:11<00:00, 359.38it/s] 96%|█████████▌| 4298/4500 [00:11<00:00, 382.97it/s] 96%|█████████▋| 4337/4500 [00:11<00:00, 368.31it/s] 97%|█████████▋| 4385/4500 [00:11<00:00, 381.14it/s] 99%|█████████▉| 4453/4500 [00:11<00:00, 462.24it/s]100%|██████████| 4500/4500 [00:11<00:00, 378.75it/s]
test_p73 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p73
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p73.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.09s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.46it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.47it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.59it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.10it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p73_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p73_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p73_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p73_Holmes_probs.npy
{'Accuracy': 0.9827, 'Precision': 0.9829, 'Recall': 0.9827, 'F1-score': 0.9827}
starting gen taf script for test_p74
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 62/4500 [00:00<00:07, 584.91it/s]  3%|▎         | 121/4500 [00:00<00:10, 435.06it/s]  4%|▎         | 167/4500 [00:00<00:12, 342.54it/s]  5%|▍         | 212/4500 [00:00<00:11, 371.84it/s]  6%|▋         | 283/4500 [00:00<00:08, 471.09it/s]  7%|▋         | 334/4500 [00:00<00:11, 361.62it/s]  8%|▊         | 376/4500 [00:01<00:13, 315.18it/s]  9%|▉         | 412/4500 [00:01<00:13, 293.98it/s] 10%|█         | 457/4500 [00:01<00:12, 325.37it/s] 11%|█         | 493/4500 [00:01<00:13, 299.78it/s] 12%|█▏        | 526/4500 [00:01<00:14, 274.83it/s] 12%|█▏        | 556/4500 [00:01<00:15, 255.56it/s] 13%|█▎        | 585/4500 [00:01<00:15, 260.01it/s] 14%|█▍        | 624/4500 [00:01<00:13, 291.19it/s] 15%|█▍        | 655/4500 [00:02<00:13, 287.29it/s] 15%|█▌        | 695/4500 [00:02<00:12, 308.33it/s] 16%|█▌        | 727/4500 [00:02<00:13, 288.44it/s] 17%|█▋        | 764/4500 [00:02<00:12, 296.26it/s] 18%|█▊        | 797/4500 [00:02<00:12, 301.71it/s] 19%|█▉        | 855/4500 [00:02<00:09, 376.94it/s] 20%|█▉        | 897/4500 [00:02<00:09, 382.67it/s] 21%|██▏       | 961/4500 [00:02<00:07, 448.28it/s] 22%|██▏       | 1007/4500 [00:02<00:07, 450.67it/s] 23%|██▎       | 1053/4500 [00:03<00:08, 404.35it/s] 24%|██▍       | 1095/4500 [00:03<00:08, 407.70it/s] 27%|██▋       | 1196/4500 [00:03<00:06, 546.55it/s] 28%|██▊       | 1260/4500 [00:03<00:05, 571.82it/s] 29%|██▉       | 1324/4500 [00:03<00:05, 582.67it/s] 31%|███       | 1383/4500 [00:03<00:05, 551.34it/s] 32%|███▏      | 1439/4500 [00:03<00:07, 407.12it/s] 33%|███▎      | 1486/4500 [00:04<00:08, 368.51it/s] 34%|███▍      | 1528/4500 [00:04<00:08, 370.36it/s] 35%|███▌      | 1582/4500 [00:04<00:07, 400.28it/s] 36%|███▌      | 1625/4500 [00:04<00:08, 338.98it/s] 37%|███▋      | 1662/4500 [00:04<00:08, 324.05it/s] 38%|███▊      | 1697/4500 [00:04<00:08, 313.34it/s] 39%|███▉      | 1749/4500 [00:04<00:07, 358.82it/s] 40%|████      | 1809/4500 [00:04<00:06, 419.11it/s] 41%|████▏     | 1865/4500 [00:04<00:05, 449.48it/s] 43%|████▎     | 1939/4500 [00:05<00:04, 521.76it/s] 44%|████▍     | 2002/4500 [00:05<00:04, 541.96it/s] 46%|████▌     | 2058/4500 [00:05<00:04, 521.36it/s] 47%|████▋     | 2115/4500 [00:05<00:04, 509.36it/s] 48%|████▊     | 2167/4500 [00:05<00:04, 507.22it/s] 49%|████▉     | 2219/4500 [00:05<00:05, 418.68it/s] 50%|█████     | 2264/4500 [00:05<00:05, 372.81it/s] 51%|█████     | 2304/4500 [00:05<00:06, 355.89it/s] 52%|█████▏    | 2342/4500 [00:06<00:07, 300.01it/s] 53%|█████▎    | 2378/4500 [00:06<00:06, 310.98it/s] 54%|█████▎    | 2411/4500 [00:06<00:06, 304.79it/s] 54%|█████▍    | 2452/4500 [00:06<00:06, 327.55it/s] 56%|█████▌    | 2508/4500 [00:06<00:05, 380.95it/s] 57%|█████▋    | 2574/4500 [00:06<00:04, 434.24it/s] 58%|█████▊    | 2619/4500 [00:06<00:04, 419.37it/s] 59%|█████▉    | 2662/4500 [00:06<00:04, 420.65it/s] 60%|██████    | 2705/4500 [00:07<00:04, 377.35it/s] 61%|██████    | 2747/4500 [00:07<00:04, 387.80it/s] 62%|██████▏   | 2798/4500 [00:07<00:04, 418.41it/s] 64%|██████▍   | 2873/4500 [00:07<00:03, 504.44it/s] 65%|██████▌   | 2925/4500 [00:07<00:03, 427.95it/s] 66%|██████▋   | 2989/4500 [00:07<00:03, 477.30it/s] 68%|██████▊   | 3040/4500 [00:07<00:03, 475.26it/s] 69%|██████▊   | 3090/4500 [00:07<00:03, 443.70it/s] 70%|██████▉   | 3136/4500 [00:08<00:04, 335.16it/s] 71%|███████   | 3175/4500 [00:08<00:04, 309.06it/s] 72%|███████▏  | 3228/4500 [00:08<00:03, 353.04it/s] 73%|███████▎  | 3274/4500 [00:08<00:03, 367.54it/s] 74%|███████▍  | 3321/4500 [00:08<00:03, 389.78it/s] 75%|███████▍  | 3363/4500 [00:08<00:03, 377.86it/s] 76%|███████▌  | 3403/4500 [00:08<00:03, 342.67it/s] 76%|███████▋  | 3439/4500 [00:09<00:03, 324.00it/s] 77%|███████▋  | 3473/4500 [00:09<00:03, 319.75it/s] 78%|███████▊  | 3506/4500 [00:09<00:03, 278.21it/s] 79%|███████▊  | 3536/4500 [00:09<00:05, 182.36it/s] 79%|███████▉  | 3560/4500 [00:09<00:06, 153.63it/s] 80%|███████▉  | 3580/4500 [00:10<00:06, 147.09it/s] 80%|███████▉  | 3598/4500 [00:10<00:06, 141.48it/s] 81%|████████  | 3640/4500 [00:10<00:04, 189.33it/s] 82%|████████▏ | 3705/4500 [00:10<00:02, 284.60it/s] 83%|████████▎ | 3740/4500 [00:10<00:02, 281.47it/s] 84%|████████▍ | 3798/4500 [00:10<00:01, 351.88it/s] 85%|████████▌ | 3841/4500 [00:10<00:01, 370.80it/s] 87%|████████▋ | 3895/4500 [00:10<00:01, 402.29it/s] 88%|████████▊ | 3938/4500 [00:10<00:01, 394.21it/s] 88%|████████▊ | 3980/4500 [00:11<00:01, 370.22it/s] 89%|████████▉ | 4023/4500 [00:11<00:01, 385.00it/s] 90%|█████████ | 4063/4500 [00:11<00:01, 366.46it/s] 91%|█████████▏| 4108/4500 [00:11<00:01, 370.82it/s] 92%|█████████▏| 4146/4500 [00:11<00:00, 367.88it/s] 93%|█████████▎| 4184/4500 [00:11<00:00, 316.19it/s] 94%|█████████▍| 4248/4500 [00:11<00:00, 377.78it/s] 95%|█████████▌| 4288/4500 [00:11<00:00, 382.90it/s] 96%|█████████▋| 4339/4500 [00:12<00:00, 399.53it/s] 97%|█████████▋| 4380/4500 [00:12<00:00, 355.20it/s] 98%|█████████▊| 4417/4500 [00:12<00:00, 354.30it/s] 99%|█████████▉| 4458/4500 [00:12<00:00, 363.91it/s]100%|██████████| 4500/4500 [00:12<00:00, 363.16it/s]
test_p74 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p74
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p74.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:14,  1.14it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:00<00:01,  7.77it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.38it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.72it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.94it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p74_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p74_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p74_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p74_Holmes_probs.npy
{'Accuracy': 0.9829, 'Precision': 0.9832, 'Recall': 0.9829, 'F1-score': 0.9829}
starting gen taf script for test_p75
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 66/4500 [00:00<00:06, 657.88it/s]  3%|▎         | 132/4500 [00:00<00:09, 464.69it/s]  4%|▍         | 182/4500 [00:00<00:09, 434.60it/s]  5%|▌         | 228/4500 [00:00<00:11, 382.47it/s]  6%|▌         | 275/4500 [00:00<00:10, 401.77it/s]  7%|▋         | 317/4500 [00:00<00:12, 345.30it/s]  8%|▊         | 354/4500 [00:01<00:16, 258.27it/s]  9%|▊         | 384/4500 [00:01<00:17, 239.91it/s]  9%|▉         | 419/4500 [00:01<00:15, 260.88it/s] 10%|█         | 455/4500 [00:01<00:14, 279.84it/s] 11%|█         | 494/4500 [00:01<00:13, 306.97it/s] 12%|█▏        | 527/4500 [00:01<00:13, 284.98it/s] 13%|█▎        | 569/4500 [00:01<00:12, 316.17it/s] 13%|█▎        | 603/4500 [00:01<00:12, 306.23it/s] 14%|█▍        | 640/4500 [00:01<00:12, 321.34it/s] 15%|█▍        | 674/4500 [00:02<00:11, 322.36it/s] 16%|█▌        | 707/4500 [00:02<00:12, 301.96it/s] 17%|█▋        | 743/4500 [00:02<00:12, 312.58it/s] 17%|█▋        | 775/4500 [00:02<00:12, 298.83it/s] 19%|█▊        | 842/4500 [00:02<00:09, 398.78it/s] 20%|█▉        | 893/4500 [00:02<00:08, 422.77it/s] 21%|██        | 951/4500 [00:02<00:07, 456.04it/s] 22%|██▏       | 998/4500 [00:02<00:07, 443.55it/s] 23%|██▎       | 1043/4500 [00:03<00:09, 381.03it/s] 24%|██▍       | 1083/4500 [00:03<00:09, 377.56it/s] 26%|██▌       | 1150/4500 [00:03<00:07, 451.23it/s] 27%|██▋       | 1223/4500 [00:03<00:06, 519.20it/s] 29%|██▊       | 1283/4500 [00:03<00:05, 536.70it/s] 30%|██▉       | 1338/4500 [00:03<00:05, 538.58it/s] 31%|███       | 1393/4500 [00:03<00:06, 477.70it/s] 32%|███▏      | 1443/4500 [00:03<00:06, 442.12it/s] 33%|███▎      | 1489/4500 [00:04<00:08, 357.59it/s] 34%|███▍      | 1540/4500 [00:04<00:07, 390.79it/s] 35%|███▌      | 1597/4500 [00:04<00:06, 434.49it/s] 37%|███▋      | 1644/4500 [00:04<00:08, 347.49it/s] 37%|███▋      | 1684/4500 [00:04<00:08, 341.57it/s] 38%|███▊      | 1722/4500 [00:04<00:08, 339.37it/s] 39%|███▉      | 1774/4500 [00:04<00:07, 374.88it/s] 41%|████      | 1823/4500 [00:04<00:06, 397.71it/s] 42%|████▏     | 1905/4500 [00:04<00:05, 497.49it/s] 44%|████▎     | 1966/4500 [00:05<00:04, 523.22it/s] 45%|████▍     | 2020/4500 [00:05<00:05, 464.46it/s] 46%|████▋     | 2082/4500 [00:05<00:04, 501.25it/s] 47%|████▋     | 2135/4500 [00:05<00:04, 488.47it/s] 49%|████▊     | 2186/4500 [00:05<00:05, 456.89it/s] 50%|████▉     | 2233/4500 [00:05<00:05, 408.85it/s] 51%|█████     | 2276/4500 [00:05<00:06, 345.78it/s] 51%|█████▏    | 2313/4500 [00:06<00:06, 328.58it/s] 52%|█████▏    | 2348/4500 [00:06<00:07, 305.21it/s] 53%|█████▎    | 2385/4500 [00:06<00:06, 320.30it/s] 54%|█████▍    | 2419/4500 [00:06<00:06, 308.13it/s] 55%|█████▍    | 2461/4500 [00:06<00:06, 335.85it/s] 56%|█████▌    | 2527/4500 [00:06<00:04, 411.39it/s] 58%|█████▊    | 2592/4500 [00:06<00:04, 466.75it/s] 59%|█████▊    | 2640/4500 [00:06<00:04, 435.90it/s] 60%|█████▉    | 2685/4500 [00:07<00:04, 399.90it/s] 61%|██████    | 2727/4500 [00:07<00:04, 362.98it/s] 62%|██████▏   | 2791/4500 [00:07<00:04, 425.17it/s] 63%|██████▎   | 2840/4500 [00:07<00:03, 435.45it/s] 64%|██████▍   | 2885/4500 [00:07<00:03, 418.31it/s] 65%|██████▌   | 2941/4500 [00:07<00:03, 444.02it/s] 66%|██████▋   | 2991/4500 [00:07<00:03, 446.58it/s] 67%|██████▋   | 3037/4500 [00:07<00:03, 420.49it/s] 68%|██████▊   | 3080/4500 [00:07<00:03, 408.43it/s] 69%|██████▉   | 3122/4500 [00:08<00:03, 405.17it/s] 70%|███████   | 3163/4500 [00:08<00:04, 332.92it/s] 71%|███████   | 3199/4500 [00:08<00:04, 309.33it/s] 72%|███████▏  | 3257/4500 [00:08<00:03, 365.40it/s] 74%|███████▎  | 3308/4500 [00:08<00:02, 401.12it/s] 74%|███████▍  | 3351/4500 [00:08<00:02, 392.62it/s] 75%|███████▌  | 3392/4500 [00:08<00:03, 353.22it/s] 76%|███████▌  | 3429/4500 [00:08<00:03, 354.66it/s] 77%|███████▋  | 3466/4500 [00:09<00:03, 323.83it/s] 78%|███████▊  | 3500/4500 [00:09<00:03, 289.21it/s] 78%|███████▊  | 3531/4500 [00:09<00:05, 188.40it/s] 79%|███████▉  | 3555/4500 [00:09<00:05, 175.56it/s] 79%|███████▉  | 3576/4500 [00:09<00:05, 168.68it/s] 80%|███████▉  | 3596/4500 [00:10<00:06, 140.57it/s] 81%|████████  | 3636/4500 [00:10<00:04, 188.66it/s] 82%|████████▏ | 3685/4500 [00:10<00:03, 250.52it/s] 83%|████████▎ | 3727/4500 [00:10<00:02, 283.91it/s] 84%|████████▍ | 3772/4500 [00:10<00:02, 307.35it/s] 85%|████████▌ | 3830/4500 [00:10<00:01, 373.97it/s] 86%|████████▋ | 3889/4500 [00:10<00:01, 417.99it/s] 87%|████████▋ | 3934/4500 [00:10<00:01, 419.01it/s] 89%|████████▊ | 3983/4500 [00:10<00:01, 423.18it/s] 89%|████████▉ | 4027/4500 [00:11<00:01, 420.31it/s] 91%|█████████ | 4083/4500 [00:11<00:00, 456.10it/s] 92%|█████████▏| 4130/4500 [00:11<00:00, 400.32it/s] 93%|█████████▎| 4172/4500 [00:11<00:00, 374.18it/s] 94%|█████████▎| 4216/4500 [00:11<00:00, 385.67it/s] 95%|█████████▌| 4275/4500 [00:11<00:00, 435.19it/s] 96%|█████████▌| 4320/4500 [00:11<00:00, 422.86it/s] 97%|█████████▋| 4364/4500 [00:11<00:00, 353.71it/s] 98%|█████████▊| 4416/4500 [00:12<00:00, 386.42it/s]100%|█████████▉| 4492/4500 [00:12<00:00, 481.35it/s]100%|██████████| 4500/4500 [00:12<00:00, 369.44it/s]
test_p75 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p75
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p75.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:13,  1.27it/s]evaluating model with Holmes:  11%|█         | 2/18 [00:01<00:07,  2.22it/s]evaluating model with Holmes:  39%|███▉      | 7/18 [00:01<00:01,  9.57it/s]evaluating model with Holmes:  67%|██████▋   | 12/18 [00:01<00:00, 16.76it/s]evaluating model with Holmes:  94%|█████████▍| 17/18 [00:01<00:00, 23.46it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.16it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p75_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p75_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p75_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p75_Holmes_probs.npy
{'Accuracy': 0.9838, 'Precision': 0.984, 'Recall': 0.9838, 'F1-score': 0.9838}
starting gen taf script for test_p76
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 38/4500 [00:00<00:12, 354.64it/s]  2%|▏         | 79/4500 [00:00<00:11, 383.05it/s]  3%|▎         | 118/4500 [00:00<00:11, 371.80it/s]  3%|▎         | 156/4500 [00:00<00:14, 306.79it/s]  4%|▍         | 189/4500 [00:00<00:14, 305.62it/s]  6%|▌         | 252/4500 [00:00<00:10, 399.83it/s]  7%|▋         | 301/4500 [00:00<00:10, 400.19it/s]  8%|▊         | 343/4500 [00:01<00:14, 288.55it/s]  8%|▊         | 377/4500 [00:01<00:16, 245.17it/s]  9%|▉         | 406/4500 [00:01<00:16, 241.38it/s] 10%|▉         | 447/4500 [00:01<00:14, 275.40it/s] 11%|█         | 489/4500 [00:01<00:12, 309.54it/s] 12%|█▏        | 523/4500 [00:01<00:13, 288.72it/s] 12%|█▏        | 555/4500 [00:01<00:13, 293.02it/s] 13%|█▎        | 586/4500 [00:01<00:13, 289.58it/s] 14%|█▎        | 617/4500 [00:02<00:13, 287.52it/s] 14%|█▍        | 647/4500 [00:02<00:13, 276.67it/s] 15%|█▌        | 680/4500 [00:02<00:13, 285.35it/s] 16%|█▌        | 709/4500 [00:02<00:13, 278.45it/s] 16%|█▋        | 739/4500 [00:02<00:13, 281.91it/s] 17%|█▋        | 768/4500 [00:02<00:13, 270.14it/s] 18%|█▊        | 796/4500 [00:02<00:14, 249.47it/s] 19%|█▊        | 838/4500 [00:02<00:12, 293.02it/s] 20%|█▉        | 894/4500 [00:02<00:10, 357.77it/s] 21%|██        | 954/4500 [00:03<00:08, 424.16it/s] 22%|██▏       | 998/4500 [00:03<00:09, 365.13it/s] 23%|██▎       | 1037/4500 [00:03<00:09, 355.77it/s] 24%|██▍       | 1075/4500 [00:03<00:09, 360.04it/s] 26%|██▌       | 1159/4500 [00:03<00:06, 486.17it/s] 27%|██▋       | 1214/4500 [00:03<00:06, 503.59it/s] 28%|██▊       | 1267/4500 [00:03<00:06, 495.72it/s] 29%|██▉       | 1324/4500 [00:03<00:06, 516.51it/s] 31%|███       | 1380/4500 [00:03<00:06, 516.94it/s] 32%|███▏      | 1433/4500 [00:04<00:07, 390.95it/s] 33%|███▎      | 1477/4500 [00:04<00:08, 376.29it/s] 34%|███▎      | 1518/4500 [00:04<00:08, 355.19it/s] 35%|███▌      | 1579/4500 [00:04<00:07, 405.80it/s] 36%|███▌      | 1623/4500 [00:04<00:07, 384.48it/s] 37%|███▋      | 1664/4500 [00:04<00:08, 323.89it/s] 38%|███▊      | 1699/4500 [00:05<00:09, 288.73it/s] 39%|███▉      | 1745/4500 [00:05<00:08, 325.82it/s] 40%|███▉      | 1787/4500 [00:05<00:07, 348.26it/s] 41%|████      | 1847/4500 [00:05<00:06, 411.08it/s] 42%|████▏     | 1906/4500 [00:05<00:05, 452.09it/s] 44%|████▍     | 1969/4500 [00:05<00:05, 499.13it/s] 45%|████▍     | 2023/4500 [00:05<00:04, 499.03it/s] 46%|████▌     | 2075/4500 [00:05<00:04, 501.13it/s] 47%|████▋     | 2127/4500 [00:05<00:05, 451.17it/s] 48%|████▊     | 2174/4500 [00:05<00:05, 437.62it/s] 49%|████▉     | 2219/4500 [00:06<00:05, 427.01it/s] 50%|█████     | 2263/4500 [00:06<00:06, 358.31it/s] 51%|█████     | 2301/4500 [00:06<00:06, 314.24it/s] 52%|█████▏    | 2335/4500 [00:06<00:07, 307.58it/s] 53%|█████▎    | 2368/4500 [00:06<00:07, 303.33it/s] 53%|█████▎    | 2400/4500 [00:06<00:06, 307.43it/s] 54%|█████▍    | 2432/4500 [00:06<00:07, 290.54it/s] 55%|█████▌    | 2490/4500 [00:07<00:05, 365.37it/s] 56%|█████▋    | 2542/4500 [00:07<00:04, 399.09it/s] 57%|█████▋    | 2584/4500 [00:07<00:04, 395.64it/s] 58%|█████▊    | 2626/4500 [00:07<00:04, 398.39it/s] 59%|█████▉    | 2669/4500 [00:07<00:04, 370.21it/s] 60%|██████    | 2707/4500 [00:07<00:05, 347.16it/s] 61%|██████    | 2747/4500 [00:07<00:04, 353.80it/s] 62%|██████▏   | 2806/4500 [00:07<00:04, 400.36it/s] 63%|██████▎   | 2848/4500 [00:07<00:04, 376.08it/s] 64%|██████▍   | 2899/4500 [00:08<00:04, 399.83it/s] 66%|██████▌   | 2966/4500 [00:08<00:03, 470.75it/s] 67%|██████▋   | 3015/4500 [00:08<00:03, 411.53it/s] 68%|██████▊   | 3059/4500 [00:08<00:03, 393.66it/s] 69%|██████▉   | 3100/4500 [00:08<00:03, 378.92it/s] 70%|██████▉   | 3139/4500 [00:08<00:03, 355.46it/s] 71%|███████   | 3177/4500 [00:08<00:03, 358.18it/s] 71%|███████▏  | 3214/4500 [00:08<00:03, 338.99it/s] 72%|███████▏  | 3258/4500 [00:09<00:03, 364.70it/s] 73%|███████▎  | 3299/4500 [00:09<00:03, 373.94it/s] 74%|███████▍  | 3337/4500 [00:09<00:03, 350.99it/s] 75%|███████▍  | 3373/4500 [00:09<00:03, 339.05it/s] 76%|███████▌  | 3408/4500 [00:09<00:03, 336.11it/s] 76%|███████▋  | 3442/4500 [00:09<00:03, 326.98it/s] 77%|███████▋  | 3475/4500 [00:09<00:03, 300.47it/s] 78%|███████▊  | 3506/4500 [00:09<00:04, 230.66it/s] 78%|███████▊  | 3532/4500 [00:10<00:04, 195.60it/s] 79%|███████▉  | 3554/4500 [00:10<00:05, 168.21it/s] 79%|███████▉  | 3573/4500 [00:10<00:06, 147.29it/s] 80%|███████▉  | 3590/4500 [00:10<00:06, 132.44it/s] 80%|████████  | 3621/4500 [00:10<00:05, 166.60it/s] 82%|████████▏ | 3692/4500 [00:10<00:02, 281.31it/s] 83%|████████▎ | 3726/4500 [00:10<00:02, 290.77it/s] 84%|████████▎ | 3759/4500 [00:11<00:02, 285.46it/s] 85%|████████▍ | 3812/4500 [00:11<00:02, 339.10it/s] 86%|████████▌ | 3854/4500 [00:11<00:01, 358.31it/s] 87%|████████▋ | 3907/4500 [00:11<00:01, 399.65it/s] 88%|████████▊ | 3949/4500 [00:11<00:01, 401.48it/s] 89%|████████▉ | 4005/4500 [00:11<00:01, 433.50it/s] 90%|█████████ | 4050/4500 [00:11<00:01, 359.30it/s] 91%|█████████ | 4101/4500 [00:11<00:01, 383.55it/s] 92%|█████████▏| 4142/4500 [00:12<00:01, 348.79it/s] 93%|█████████▎| 4179/4500 [00:12<00:00, 335.52it/s] 95%|█████████▍| 4253/4500 [00:12<00:00, 430.71it/s] 96%|█████████▌| 4299/4500 [00:12<00:00, 403.72it/s] 96%|█████████▋| 4342/4500 [00:12<00:00, 404.07it/s] 97%|█████████▋| 4384/4500 [00:12<00:00, 392.17it/s] 99%|█████████▊| 4437/4500 [00:12<00:00, 419.00it/s]100%|█████████▉| 4480/4500 [00:12<00:00, 415.69it/s]100%|██████████| 4500/4500 [00:12<00:00, 349.32it/s]
test_p76 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p76
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p76.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.74it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.75it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.95it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.53it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p76_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p76_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p76_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p76_Holmes_probs.npy
{'Accuracy': 0.9856, 'Precision': 0.9858, 'Recall': 0.9856, 'F1-score': 0.9856}
starting gen taf script for test_p77
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 50/4500 [00:00<00:09, 480.19it/s]  2%|▏         | 99/4500 [00:00<00:10, 432.14it/s]  3%|▎         | 143/4500 [00:00<00:11, 371.43it/s]  4%|▍         | 181/4500 [00:00<00:12, 332.78it/s]  5%|▍         | 221/4500 [00:00<00:12, 349.38it/s]  6%|▌         | 281/4500 [00:00<00:10, 421.33it/s]  7%|▋         | 325/4500 [00:00<00:11, 376.57it/s]  8%|▊         | 365/4500 [00:01<00:14, 289.24it/s]  9%|▉         | 398/4500 [00:01<00:15, 262.83it/s] 10%|▉         | 435/4500 [00:01<00:14, 280.26it/s] 10%|█         | 470/4500 [00:01<00:13, 293.16it/s] 11%|█▏        | 515/4500 [00:01<00:12, 328.27it/s] 12%|█▏        | 550/4500 [00:01<00:12, 320.25it/s] 13%|█▎        | 584/4500 [00:01<00:12, 318.65it/s] 14%|█▍        | 629/4500 [00:01<00:11, 347.72it/s] 15%|█▍        | 665/4500 [00:01<00:11, 347.97it/s] 16%|█▌        | 702/4500 [00:02<00:10, 354.12it/s] 16%|█▋        | 738/4500 [00:02<00:11, 314.64it/s] 17%|█▋        | 771/4500 [00:02<00:12, 300.84it/s] 18%|█▊        | 802/4500 [00:02<00:12, 297.06it/s] 20%|█▉        | 878/4500 [00:02<00:08, 418.41it/s] 20%|██        | 922/4500 [00:02<00:08, 408.13it/s] 22%|██▏       | 969/4500 [00:02<00:08, 410.60it/s] 23%|██▎       | 1017/4500 [00:02<00:08, 412.32it/s] 24%|██▎       | 1059/4500 [00:03<00:08, 399.42it/s] 25%|██▍       | 1123/4500 [00:03<00:07, 461.88it/s] 27%|██▋       | 1211/4500 [00:03<00:05, 574.46it/s] 28%|██▊       | 1274/4500 [00:03<00:05, 570.35it/s] 30%|██▉       | 1332/4500 [00:03<00:05, 556.93it/s] 31%|███       | 1396/4500 [00:03<00:05, 575.53it/s] 32%|███▏      | 1455/4500 [00:03<00:07, 399.45it/s] 33%|███▎      | 1503/4500 [00:03<00:07, 375.13it/s] 35%|███▍      | 1555/4500 [00:04<00:07, 403.52it/s] 36%|███▌      | 1600/4500 [00:04<00:07, 404.11it/s] 37%|███▋      | 1644/4500 [00:04<00:07, 389.47it/s] 37%|███▋      | 1686/4500 [00:04<00:08, 341.28it/s] 38%|███▊      | 1725/4500 [00:04<00:08, 344.36it/s] 40%|███▉      | 1787/4500 [00:04<00:06, 409.42it/s] 41%|████      | 1836/4500 [00:04<00:06, 425.39it/s] 42%|████▏     | 1901/4500 [00:04<00:05, 474.87it/s] 44%|████▍     | 1978/4500 [00:05<00:04, 534.17it/s] 45%|████▌     | 2033/4500 [00:05<00:04, 512.65it/s] 46%|████▋     | 2088/4500 [00:05<00:04, 501.02it/s] 48%|████▊     | 2139/4500 [00:05<00:04, 500.54it/s] 49%|████▊     | 2190/4500 [00:05<00:05, 456.84it/s] 50%|████▉     | 2237/4500 [00:05<00:05, 380.44it/s] 51%|█████     | 2278/4500 [00:05<00:05, 370.95it/s] 51%|█████▏    | 2317/4500 [00:05<00:07, 311.31it/s] 52%|█████▏    | 2351/4500 [00:06<00:06, 308.04it/s] 53%|█████▎    | 2384/4500 [00:06<00:07, 279.87it/s] 54%|█████▍    | 2432/4500 [00:06<00:06, 325.58it/s] 55%|█████▌    | 2477/4500 [00:06<00:05, 345.89it/s] 56%|█████▌    | 2519/4500 [00:06<00:05, 362.85it/s] 57%|█████▋    | 2576/4500 [00:06<00:04, 415.75it/s] 58%|█████▊    | 2620/4500 [00:06<00:04, 404.04it/s] 60%|█████▉    | 2682/4500 [00:06<00:04, 451.59it/s] 61%|██████    | 2729/4500 [00:06<00:04, 434.83it/s] 62%|██████▏   | 2774/4500 [00:07<00:04, 403.34it/s] 63%|██████▎   | 2824/4500 [00:07<00:03, 419.49it/s] 64%|██████▍   | 2870/4500 [00:07<00:04, 406.37it/s] 65%|██████▍   | 2916/4500 [00:07<00:03, 409.46it/s] 66%|██████▌   | 2958/4500 [00:07<00:03, 403.17it/s] 67%|██████▋   | 3015/4500 [00:07<00:03, 448.86it/s] 68%|██████▊   | 3061/4500 [00:07<00:03, 438.94it/s] 69%|██████▉   | 3106/4500 [00:07<00:03, 397.47it/s] 70%|██████▉   | 3147/4500 [00:08<00:03, 375.84it/s] 71%|███████   | 3186/4500 [00:08<00:04, 318.89it/s] 72%|███████▏  | 3220/4500 [00:08<00:04, 316.46it/s] 73%|███████▎  | 3268/4500 [00:08<00:03, 349.06it/s] 73%|███████▎  | 3305/4500 [00:08<00:03, 354.00it/s] 74%|███████▍  | 3343/4500 [00:08<00:03, 356.95it/s] 75%|███████▌  | 3380/4500 [00:08<00:03, 343.34it/s] 76%|███████▌  | 3415/4500 [00:08<00:03, 306.27it/s] 77%|███████▋  | 3461/4500 [00:09<00:03, 345.70it/s] 78%|███████▊  | 3497/4500 [00:09<00:03, 312.06it/s] 78%|███████▊  | 3530/4500 [00:09<00:04, 196.20it/s] 79%|███████▉  | 3556/4500 [00:09<00:05, 175.60it/s] 80%|███████▉  | 3578/4500 [00:09<00:05, 158.69it/s] 80%|███████▉  | 3597/4500 [00:10<00:06, 140.70it/s] 81%|████████  | 3652/4500 [00:10<00:03, 213.39it/s] 82%|████████▏ | 3687/4500 [00:10<00:03, 241.24it/s] 83%|████████▎ | 3747/4500 [00:10<00:02, 316.86it/s] 84%|████████▍ | 3785/4500 [00:10<00:02, 312.23it/s] 85%|████████▌ | 3839/4500 [00:10<00:01, 361.49it/s] 86%|████████▋ | 3888/4500 [00:10<00:01, 386.19it/s] 87%|████████▋ | 3930/4500 [00:10<00:01, 373.33it/s] 88%|████████▊ | 3970/4500 [00:10<00:01, 377.36it/s] 89%|████████▉ | 4011/4500 [00:11<00:01, 376.03it/s] 90%|█████████ | 4060/4500 [00:11<00:01, 403.20it/s] 91%|█████████ | 4102/4500 [00:11<00:01, 376.65it/s] 92%|█████████▏| 4141/4500 [00:11<00:01, 352.32it/s] 93%|█████████▎| 4178/4500 [00:11<00:00, 334.46it/s] 94%|█████████▎| 4213/4500 [00:11<00:00, 328.60it/s] 95%|█████████▍| 4273/4500 [00:11<00:00, 381.47it/s] 96%|█████████▌| 4313/4500 [00:11<00:00, 384.74it/s] 97%|█████████▋| 4360/4500 [00:11<00:00, 407.36it/s] 98%|█████████▊| 4402/4500 [00:12<00:00, 349.69it/s] 99%|█████████▉| 4458/4500 [00:12<00:00, 402.53it/s]100%|██████████| 4500/4500 [00:12<00:00, 366.47it/s]
test_p77 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p77
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p77.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.10s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.36it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.26it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.28it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.95it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p77_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p77_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p77_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p77_Holmes_probs.npy
{'Accuracy': 0.9858, 'Precision': 0.9859, 'Recall': 0.9858, 'F1-score': 0.9858}
starting gen taf script for test_p78
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 63/4500 [00:00<00:07, 628.84it/s]  3%|▎         | 126/4500 [00:00<00:10, 407.45it/s]  4%|▍         | 172/4500 [00:00<00:11, 361.63it/s]  5%|▍         | 211/4500 [00:00<00:12, 355.33it/s]  6%|▌         | 273/4500 [00:00<00:09, 429.34it/s]  7%|▋         | 319/4500 [00:00<00:11, 375.11it/s]  8%|▊         | 359/4500 [00:00<00:13, 315.53it/s]  9%|▉         | 394/4500 [00:01<00:15, 267.76it/s]  9%|▉         | 424/4500 [00:01<00:15, 265.26it/s] 10%|█         | 470/4500 [00:01<00:13, 305.91it/s] 11%|█▏        | 507/4500 [00:01<00:12, 314.27it/s] 12%|█▏        | 541/4500 [00:01<00:12, 317.00it/s] 13%|█▎        | 574/4500 [00:01<00:13, 298.48it/s] 14%|█▍        | 619/4500 [00:01<00:11, 331.43it/s] 15%|█▍        | 654/4500 [00:02<00:12, 296.22it/s] 15%|█▌        | 685/4500 [00:02<00:12, 297.92it/s] 16%|█▌        | 721/4500 [00:02<00:12, 314.10it/s] 17%|█▋        | 754/4500 [00:02<00:13, 269.98it/s] 18%|█▊        | 790/4500 [00:02<00:12, 291.29it/s] 19%|█▉        | 864/4500 [00:02<00:08, 406.17it/s] 20%|██        | 914/4500 [00:02<00:08, 411.50it/s] 22%|██▏       | 974/4500 [00:02<00:07, 451.06it/s] 23%|██▎       | 1021/4500 [00:02<00:07, 444.77it/s] 24%|██▎       | 1067/4500 [00:03<00:08, 419.91it/s] 25%|██▍       | 1122/4500 [00:03<00:07, 451.33it/s] 27%|██▋       | 1221/4500 [00:03<00:05, 572.26it/s] 29%|██▊       | 1290/4500 [00:03<00:05, 602.80it/s] 30%|███       | 1351/4500 [00:03<00:06, 505.46it/s] 31%|███       | 1405/4500 [00:03<00:06, 461.01it/s] 32%|███▏      | 1454/4500 [00:03<00:07, 384.43it/s] 33%|███▎      | 1496/4500 [00:04<00:09, 314.92it/s] 34%|███▍      | 1552/4500 [00:04<00:08, 363.71it/s] 35%|███▌      | 1594/4500 [00:04<00:07, 366.60it/s] 36%|███▋      | 1635/4500 [00:04<00:08, 354.28it/s] 37%|███▋      | 1673/4500 [00:04<00:09, 308.59it/s] 38%|███▊      | 1710/4500 [00:04<00:08, 316.34it/s] 39%|███▉      | 1746/4500 [00:04<00:08, 324.91it/s] 40%|████      | 1814/4500 [00:04<00:06, 414.00it/s] 41%|████▏     | 1858/4500 [00:05<00:06, 398.18it/s] 42%|████▏     | 1904/4500 [00:05<00:06, 411.16it/s] 44%|████▍     | 1971/4500 [00:05<00:05, 477.72it/s] 45%|████▌     | 2031/4500 [00:05<00:04, 511.75it/s] 46%|████▋     | 2084/4500 [00:05<00:05, 472.90it/s] 47%|████▋     | 2133/4500 [00:05<00:05, 466.32it/s] 48%|████▊     | 2181/4500 [00:05<00:05, 405.77it/s] 49%|████▉     | 2224/4500 [00:05<00:05, 401.20it/s] 50%|█████     | 2266/4500 [00:06<00:07, 318.19it/s] 51%|█████▏    | 2313/4500 [00:06<00:06, 333.49it/s] 52%|█████▏    | 2349/4500 [00:06<00:07, 304.90it/s] 53%|█████▎    | 2384/4500 [00:06<00:06, 308.49it/s] 54%|█████▍    | 2426/4500 [00:06<00:06, 334.91it/s] 55%|█████▍    | 2462/4500 [00:06<00:06, 324.03it/s] 56%|█████▌    | 2519/4500 [00:06<00:05, 382.62it/s] 57%|█████▋    | 2559/4500 [00:06<00:05, 367.91it/s] 58%|█████▊    | 2619/4500 [00:06<00:04, 413.49it/s] 59%|█████▉    | 2662/4500 [00:07<00:04, 393.65it/s] 60%|██████    | 2702/4500 [00:07<00:04, 373.76it/s] 61%|██████    | 2756/4500 [00:07<00:04, 404.40it/s] 62%|██████▏   | 2797/4500 [00:07<00:04, 400.65it/s] 63%|██████▎   | 2850/4500 [00:07<00:03, 424.55it/s] 64%|██████▍   | 2901/4500 [00:07<00:03, 435.88it/s] 65%|██████▌   | 2945/4500 [00:07<00:03, 393.90it/s] 66%|██████▋   | 2986/4500 [00:07<00:04, 373.89it/s] 68%|██████▊   | 3049/4500 [00:08<00:03, 439.13it/s] 69%|██████▉   | 3095/4500 [00:08<00:03, 427.79it/s] 70%|██████▉   | 3139/4500 [00:08<00:03, 381.12it/s] 71%|███████   | 3179/4500 [00:08<00:04, 303.68it/s] 72%|███████▏  | 3235/4500 [00:08<00:03, 343.16it/s] 73%|███████▎  | 3289/4500 [00:08<00:03, 374.71it/s] 74%|███████▍  | 3329/4500 [00:08<00:03, 378.68it/s] 75%|███████▍  | 3369/4500 [00:08<00:03, 352.77it/s] 76%|███████▌  | 3409/4500 [00:09<00:03, 354.06it/s] 77%|███████▋  | 3446/4500 [00:09<00:03, 297.59it/s] 77%|███████▋  | 3478/4500 [00:09<00:03, 295.85it/s] 78%|███████▊  | 3509/4500 [00:09<00:04, 230.53it/s] 79%|███████▊  | 3535/4500 [00:09<00:04, 201.82it/s] 79%|███████▉  | 3558/4500 [00:10<00:05, 161.08it/s] 79%|███████▉  | 3577/4500 [00:10<00:06, 134.70it/s] 80%|████████  | 3603/4500 [00:10<00:05, 155.80it/s] 81%|████████  | 3639/4500 [00:10<00:04, 193.27it/s] 82%|████████▏ | 3698/4500 [00:10<00:02, 272.65it/s] 83%|████████▎ | 3742/4500 [00:10<00:02, 311.02it/s] 84%|████████▍ | 3785/4500 [00:10<00:02, 334.97it/s] 85%|████████▌ | 3832/4500 [00:10<00:01, 369.74it/s] 86%|████████▌ | 3874/4500 [00:10<00:01, 383.30it/s] 87%|████████▋ | 3917/4500 [00:11<00:01, 396.14it/s] 88%|████████▊ | 3969/4500 [00:11<00:01, 431.26it/s] 89%|████████▉ | 4014/4500 [00:11<00:01, 375.97it/s] 90%|█████████ | 4056/4500 [00:11<00:01, 362.11it/s] 91%|█████████ | 4097/4500 [00:11<00:01, 368.81it/s] 92%|█████████▏| 4136/4500 [00:11<00:01, 318.13it/s] 93%|█████████▎| 4170/4500 [00:11<00:01, 284.24it/s] 94%|█████████▎| 4213/4500 [00:12<00:00, 317.23it/s] 95%|█████████▌| 4276/4500 [00:12<00:00, 394.85it/s] 96%|█████████▌| 4319/4500 [00:12<00:00, 374.45it/s] 97%|█████████▋| 4359/4500 [00:12<00:00, 316.74it/s] 98%|█████████▊| 4394/4500 [00:12<00:00, 316.35it/s] 99%|█████████▉| 4445/4500 [00:12<00:00, 353.92it/s]100%|██████████| 4500/4500 [00:12<00:00, 354.23it/s]
test_p78 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p78
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p78.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.05s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.66it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.70it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.88it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.36it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p78_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p78_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p78_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p78_Holmes_probs.npy
{'Accuracy': 0.9864, 'Precision': 0.9866, 'Recall': 0.9864, 'F1-score': 0.9865}
starting gen taf script for test_p79
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 50/4500 [00:00<00:10, 430.69it/s]  2%|▏         | 94/4500 [00:00<00:11, 377.07it/s]  3%|▎         | 132/4500 [00:00<00:11, 372.31it/s]  4%|▍         | 170/4500 [00:00<00:12, 336.69it/s]  5%|▍         | 214/4500 [00:00<00:11, 363.28it/s]  6%|▌         | 266/4500 [00:00<00:10, 410.04it/s]  7%|▋         | 308/4500 [00:00<00:10, 390.70it/s]  8%|▊         | 348/4500 [00:00<00:12, 320.39it/s]  9%|▊         | 383/4500 [00:01<00:15, 266.57it/s]  9%|▉         | 426/4500 [00:01<00:13, 303.70it/s] 10%|█         | 460/4500 [00:01<00:13, 292.46it/s] 11%|█         | 492/4500 [00:01<00:13, 296.45it/s] 12%|█▏        | 525/4500 [00:01<00:13, 298.67it/s] 12%|█▏        | 556/4500 [00:01<00:13, 299.64it/s] 13%|█▎        | 587/4500 [00:01<00:13, 292.50it/s] 14%|█▍        | 621/4500 [00:01<00:12, 302.43it/s] 14%|█▍        | 652/4500 [00:02<00:13, 288.17it/s] 15%|█▌        | 682/4500 [00:02<00:13, 284.36it/s] 16%|█▌        | 714/4500 [00:02<00:13, 283.30it/s] 17%|█▋        | 743/4500 [00:02<00:13, 282.89it/s] 17%|█▋        | 772/4500 [00:02<00:13, 275.67it/s] 18%|█▊        | 807/4500 [00:02<00:12, 289.62it/s] 19%|█▉        | 863/4500 [00:02<00:10, 363.23it/s] 20%|██        | 911/4500 [00:02<00:09, 385.28it/s] 21%|██        | 950/4500 [00:02<00:09, 385.15it/s] 22%|██▏       | 1005/4500 [00:03<00:08, 431.67it/s] 23%|██▎       | 1053/4500 [00:03<00:08, 423.80it/s] 25%|██▍       | 1111/4500 [00:03<00:07, 463.65it/s] 26%|██▋       | 1191/4500 [00:03<00:05, 554.28it/s] 28%|██▊       | 1253/4500 [00:03<00:05, 561.57it/s] 29%|██▉       | 1320/4500 [00:03<00:05, 587.73it/s] 31%|███       | 1380/4500 [00:03<00:05, 535.12it/s] 32%|███▏      | 1435/4500 [00:03<00:06, 447.02it/s] 33%|███▎      | 1483/4500 [00:04<00:08, 349.24it/s] 34%|███▍      | 1527/4500 [00:04<00:08, 356.35it/s] 35%|███▌      | 1597/4500 [00:04<00:06, 426.26it/s] 37%|███▋      | 1644/4500 [00:04<00:08, 350.88it/s] 37%|███▋      | 1684/4500 [00:04<00:08, 320.16it/s] 38%|███▊      | 1720/4500 [00:04<00:08, 322.60it/s] 39%|███▉      | 1758/4500 [00:04<00:08, 335.80it/s] 41%|████      | 1829/4500 [00:04<00:06, 422.19it/s] 42%|████▏     | 1877/4500 [00:05<00:06, 437.01it/s] 43%|████▎     | 1934/4500 [00:05<00:05, 467.17it/s] 44%|████▍     | 1984/4500 [00:05<00:05, 471.45it/s] 45%|████▌     | 2041/4500 [00:05<00:05, 489.58it/s] 46%|████▋     | 2091/4500 [00:05<00:05, 480.06it/s] 48%|████▊     | 2140/4500 [00:05<00:05, 428.70it/s] 49%|████▊     | 2185/4500 [00:05<00:05, 432.09it/s] 50%|████▉     | 2230/4500 [00:05<00:05, 415.43it/s] 51%|█████     | 2273/4500 [00:06<00:06, 320.81it/s] 51%|█████▏    | 2309/4500 [00:06<00:06, 317.35it/s] 52%|█████▏    | 2344/4500 [00:06<00:07, 285.92it/s] 53%|█████▎    | 2383/4500 [00:06<00:06, 307.32it/s] 54%|█████▎    | 2416/4500 [00:06<00:07, 278.06it/s] 55%|█████▍    | 2453/4500 [00:06<00:06, 295.47it/s] 56%|█████▌    | 2513/4500 [00:06<00:05, 371.39it/s] 57%|█████▋    | 2553/4500 [00:06<00:05, 373.74it/s] 58%|█████▊    | 2606/4500 [00:07<00:04, 408.74it/s] 59%|█████▉    | 2652/4500 [00:07<00:04, 403.70it/s] 60%|█████▉    | 2694/4500 [00:07<00:05, 352.60it/s] 61%|██████    | 2732/4500 [00:07<00:05, 351.46it/s] 62%|██████▏   | 2784/4500 [00:07<00:04, 382.82it/s] 63%|██████▎   | 2828/4500 [00:07<00:04, 397.27it/s] 64%|██████▍   | 2879/4500 [00:07<00:03, 426.08it/s] 65%|██████▍   | 2923/4500 [00:07<00:04, 371.08it/s] 66%|██████▌   | 2980/4500 [00:07<00:03, 419.42it/s] 67%|██████▋   | 3024/4500 [00:08<00:03, 396.69it/s] 68%|██████▊   | 3066/4500 [00:08<00:03, 390.81it/s] 69%|██████▉   | 3107/4500 [00:08<00:03, 370.43it/s] 70%|██████▉   | 3145/4500 [00:08<00:04, 325.22it/s] 71%|███████   | 3179/4500 [00:08<00:04, 310.53it/s] 71%|███████▏  | 3216/4500 [00:08<00:04, 316.48it/s] 72%|███████▏  | 3249/4500 [00:08<00:04, 309.12it/s] 74%|███████▎  | 3313/4500 [00:08<00:03, 385.74it/s] 75%|███████▍  | 3353/4500 [00:09<00:03, 330.89it/s] 75%|███████▌  | 3395/4500 [00:09<00:03, 345.34it/s] 76%|███████▌  | 3431/4500 [00:09<00:03, 340.06it/s] 77%|███████▋  | 3466/4500 [00:09<00:03, 332.15it/s] 78%|███████▊  | 3500/4500 [00:09<00:03, 286.79it/s] 78%|███████▊  | 3530/4500 [00:09<00:04, 199.71it/s] 79%|███████▉  | 3555/4500 [00:10<00:06, 145.45it/s] 79%|███████▉  | 3575/4500 [00:10<00:07, 126.98it/s] 80%|███████▉  | 3592/4500 [00:10<00:06, 131.43it/s] 81%|████████  | 3645/4500 [00:10<00:04, 204.33it/s] 83%|████████▎ | 3713/4500 [00:10<00:02, 300.22it/s] 83%|████████▎ | 3752/4500 [00:10<00:02, 305.08it/s] 84%|████████▍ | 3795/4500 [00:11<00:02, 332.84it/s] 85%|████████▌ | 3834/4500 [00:11<00:02, 315.46it/s] 87%|████████▋ | 3907/4500 [00:11<00:01, 390.97it/s] 88%|████████▊ | 3953/4500 [00:11<00:01, 407.63it/s] 89%|████████▉ | 3996/4500 [00:11<00:01, 411.47it/s] 90%|████████▉ | 4039/4500 [00:11<00:01, 373.60it/s] 91%|█████████ | 4078/4500 [00:11<00:01, 363.87it/s] 91%|█████████▏| 4117/4500 [00:11<00:01, 369.00it/s] 92%|█████████▏| 4155/4500 [00:11<00:01, 336.10it/s] 93%|█████████▎| 4190/4500 [00:12<00:01, 309.24it/s] 94%|█████████▍| 4236/4500 [00:12<00:00, 345.07it/s] 95%|█████████▌| 4281/4500 [00:12<00:00, 364.87it/s] 96%|█████████▌| 4319/4500 [00:12<00:00, 350.26it/s] 97%|█████████▋| 4355/4500 [00:12<00:00, 343.25it/s] 98%|█████████▊| 4390/4500 [00:12<00:00, 343.26it/s] 99%|█████████▊| 4433/4500 [00:12<00:00, 365.62it/s] 99%|█████████▉| 4472/4500 [00:12<00:00, 363.77it/s]100%|██████████| 4500/4500 [00:12<00:00, 349.01it/s]
test_p79 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p79
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p79.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.08it/s]evaluating model with Holmes:  28%|██▊       | 5/18 [00:01<00:02,  6.21it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 12.95it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 19.57it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.38it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p79_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p79_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p79_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p79_Holmes_probs.npy
{'Accuracy': 0.9864, 'Precision': 0.9866, 'Recall': 0.9864, 'F1-score': 0.9865}
starting gen taf script for test_p80
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 39/4500 [00:00<00:11, 389.00it/s]  2%|▏         | 78/4500 [00:00<00:13, 334.33it/s]  2%|▏         | 112/4500 [00:00<00:13, 316.46it/s]  3%|▎         | 144/4500 [00:00<00:14, 301.80it/s]  4%|▍         | 183/4500 [00:00<00:13, 329.51it/s]  5%|▍         | 219/4500 [00:00<00:12, 329.38it/s]  6%|▌         | 274/4500 [00:00<00:10, 386.97it/s]  7%|▋         | 313/4500 [00:00<00:11, 375.13it/s]  8%|▊         | 351/4500 [00:01<00:13, 301.43it/s]  9%|▊         | 384/4500 [00:01<00:15, 260.40it/s]  9%|▉         | 413/4500 [00:01<00:16, 255.38it/s] 10%|█         | 454/4500 [00:01<00:13, 291.77it/s] 11%|█         | 497/4500 [00:01<00:12, 325.59it/s] 12%|█▏        | 532/4500 [00:01<00:12, 313.30it/s] 13%|█▎        | 567/4500 [00:01<00:12, 318.59it/s] 13%|█▎        | 602/4500 [00:01<00:12, 319.12it/s] 14%|█▍        | 641/4500 [00:02<00:11, 338.34it/s] 15%|█▌        | 676/4500 [00:02<00:11, 321.23it/s] 16%|█▌        | 712/4500 [00:02<00:11, 318.51it/s] 17%|█▋        | 745/4500 [00:02<00:12, 300.64it/s] 18%|█▊        | 794/4500 [00:02<00:11, 336.61it/s] 19%|█▉        | 855/4500 [00:02<00:08, 407.56it/s] 20%|██        | 918/4500 [00:02<00:07, 468.11it/s] 21%|██▏       | 966/4500 [00:02<00:07, 465.07it/s] 23%|██▎       | 1014/4500 [00:02<00:07, 467.94it/s] 24%|██▎       | 1062/4500 [00:03<00:07, 434.56it/s] 25%|██▍       | 1107/4500 [00:03<00:08, 407.60it/s] 26%|██▌       | 1177/4500 [00:03<00:06, 480.01it/s] 28%|██▊       | 1238/4500 [00:03<00:06, 505.87it/s] 29%|██▊       | 1290/4500 [00:03<00:06, 505.02it/s] 30%|███       | 1360/4500 [00:03<00:05, 553.65it/s] 31%|███▏      | 1416/4500 [00:03<00:06, 468.57it/s] 33%|███▎      | 1466/4500 [00:03<00:08, 372.18it/s] 34%|███▎      | 1508/4500 [00:04<00:08, 350.57it/s] 35%|███▍      | 1564/4500 [00:04<00:07, 393.76it/s] 36%|███▌      | 1607/4500 [00:04<00:07, 396.48it/s] 37%|███▋      | 1650/4500 [00:04<00:08, 337.30it/s] 37%|███▋      | 1687/4500 [00:04<00:09, 295.22it/s] 39%|███▊      | 1739/4500 [00:04<00:08, 344.34it/s] 40%|███▉      | 1785/4500 [00:04<00:07, 367.69it/s] 41%|████      | 1834/4500 [00:04<00:06, 393.83it/s] 42%|████▏     | 1876/4500 [00:05<00:06, 392.74it/s] 43%|████▎     | 1937/4500 [00:05<00:05, 443.89it/s] 44%|████▍     | 1984/4500 [00:05<00:05, 450.03it/s] 45%|████▌     | 2031/4500 [00:05<00:05, 449.50it/s] 46%|████▋     | 2091/4500 [00:05<00:05, 480.85it/s] 48%|████▊     | 2142/4500 [00:05<00:04, 487.38it/s] 49%|████▊     | 2193/4500 [00:05<00:04, 480.35it/s] 50%|████▉     | 2242/4500 [00:05<00:05, 384.41it/s] 51%|█████     | 2284/4500 [00:06<00:07, 316.47it/s] 52%|█████▏    | 2320/4500 [00:06<00:07, 302.73it/s] 53%|█████▎    | 2369/4500 [00:06<00:06, 343.89it/s] 53%|█████▎    | 2407/4500 [00:06<00:06, 311.21it/s] 55%|█████▍    | 2465/4500 [00:06<00:05, 361.81it/s] 56%|█████▋    | 2534/4500 [00:06<00:04, 437.85it/s] 57%|█████▋    | 2581/4500 [00:06<00:04, 432.33it/s] 58%|█████▊    | 2627/4500 [00:06<00:05, 365.18it/s] 60%|█████▉    | 2680/4500 [00:07<00:04, 397.57it/s] 61%|██████    | 2723/4500 [00:07<00:04, 389.23it/s] 61%|██████▏   | 2764/4500 [00:07<00:04, 390.91it/s] 62%|██████▏   | 2805/4500 [00:07<00:04, 392.39it/s] 64%|██████▎   | 2862/4500 [00:07<00:03, 430.58it/s] 65%|██████▍   | 2912/4500 [00:07<00:03, 439.94it/s] 66%|██████▌   | 2967/4500 [00:07<00:03, 462.94it/s] 67%|██████▋   | 3014/4500 [00:07<00:03, 426.31it/s] 68%|██████▊   | 3058/4500 [00:08<00:03, 401.56it/s] 69%|██████▉   | 3109/4500 [00:08<00:03, 423.99it/s] 70%|███████   | 3153/4500 [00:08<00:03, 412.75it/s] 71%|███████   | 3195/4500 [00:08<00:03, 337.34it/s] 72%|███████▏  | 3251/4500 [00:08<00:03, 371.27it/s] 73%|███████▎  | 3291/4500 [00:08<00:03, 378.17it/s] 74%|███████▍  | 3331/4500 [00:08<00:03, 359.40it/s] 75%|███████▍  | 3369/4500 [00:08<00:03, 318.17it/s] 76%|███████▌  | 3406/4500 [00:09<00:03, 322.38it/s] 77%|███████▋  | 3447/4500 [00:09<00:03, 335.23it/s] 78%|███████▊  | 3492/4500 [00:09<00:02, 347.03it/s] 78%|███████▊  | 3528/4500 [00:09<00:04, 240.63it/s] 79%|███████▉  | 3557/4500 [00:09<00:05, 162.89it/s] 80%|███████▉  | 3580/4500 [00:10<00:05, 159.87it/s] 80%|████████  | 3601/4500 [00:10<00:05, 154.60it/s] 81%|████████  | 3646/4500 [00:10<00:04, 209.20it/s] 82%|████████▏ | 3694/4500 [00:10<00:03, 263.60it/s] 83%|████████▎ | 3734/4500 [00:10<00:02, 294.62it/s] 84%|████████▍ | 3769/4500 [00:10<00:02, 287.75it/s] 85%|████████▍ | 3809/4500 [00:10<00:02, 313.41it/s] 86%|████████▌ | 3880/4500 [00:10<00:01, 405.38it/s] 87%|████████▋ | 3924/4500 [00:10<00:01, 404.89it/s] 88%|████████▊ | 3970/4500 [00:11<00:01, 410.28it/s] 89%|████████▉ | 4015/4500 [00:11<00:01, 412.85it/s] 90%|█████████ | 4058/4500 [00:11<00:01, 388.13it/s] 91%|█████████ | 4104/4500 [00:11<00:00, 404.74it/s] 92%|█████████▏| 4146/4500 [00:11<00:01, 346.74it/s] 93%|█████████▎| 4183/4500 [00:11<00:00, 328.06it/s] 94%|█████████▍| 4228/4500 [00:11<00:00, 356.70it/s] 95%|█████████▌| 4295/4500 [00:11<00:00, 438.60it/s] 96%|█████████▋| 4342/4500 [00:12<00:00, 397.44it/s] 97%|█████████▋| 4384/4500 [00:12<00:00, 355.04it/s] 98%|█████████▊| 4423/4500 [00:12<00:00, 361.17it/s]100%|██████████| 4500/4500 [00:12<00:00, 363.64it/s]
test_p80 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p80
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p80.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.00s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.94it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.06it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.29it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.78it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p80_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p80_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p80_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p80_Holmes_probs.npy
{'Accuracy': 0.9867, 'Precision': 0.9868, 'Recall': 0.9867, 'F1-score': 0.9867}
starting gen taf script for test_p81
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 54/4500 [00:00<00:08, 525.51it/s]  2%|▏         | 107/4500 [00:00<00:11, 391.77it/s]  3%|▎         | 149/4500 [00:00<00:12, 355.50it/s]  4%|▍         | 186/4500 [00:00<00:15, 272.55it/s]  5%|▍         | 216/4500 [00:00<00:15, 279.37it/s]  6%|▌         | 272/4500 [00:00<00:11, 353.41it/s]  7%|▋         | 311/4500 [00:00<00:12, 322.48it/s]  8%|▊         | 346/4500 [00:01<00:18, 221.50it/s]  8%|▊         | 374/4500 [00:01<00:20, 198.99it/s]  9%|▉         | 398/4500 [00:01<00:22, 182.17it/s] 10%|▉         | 448/4500 [00:01<00:16, 242.41it/s] 11%|█         | 477/4500 [00:01<00:17, 225.65it/s] 11%|█         | 503/4500 [00:01<00:17, 222.82it/s] 12%|█▏        | 530/4500 [00:02<00:17, 229.78it/s] 12%|█▏        | 555/4500 [00:02<00:17, 220.57it/s] 13%|█▎        | 583/4500 [00:02<00:17, 229.61it/s] 14%|█▎        | 610/4500 [00:02<00:16, 236.49it/s] 14%|█▍        | 635/4500 [00:02<00:16, 229.73it/s] 15%|█▍        | 659/4500 [00:02<00:17, 218.64it/s] 16%|█▌        | 716/4500 [00:02<00:12, 293.28it/s] 17%|█▋        | 747/4500 [00:02<00:12, 289.66it/s] 18%|█▊        | 790/4500 [00:03<00:11, 320.81it/s] 18%|█▊        | 826/4500 [00:03<00:11, 331.02it/s] 20%|█▉        | 894/4500 [00:03<00:08, 414.34it/s] 21%|██        | 941/4500 [00:03<00:08, 427.67it/s] 22%|██▏       | 985/4500 [00:03<00:08, 429.74it/s] 23%|██▎       | 1029/4500 [00:03<00:09, 363.08it/s] 24%|██▎       | 1068/4500 [00:03<00:09, 360.21it/s] 25%|██▌       | 1146/4500 [00:03<00:07, 466.33it/s] 27%|██▋       | 1207/4500 [00:03<00:06, 493.83it/s] 29%|██▊       | 1287/4500 [00:04<00:05, 577.79it/s] 30%|██▉       | 1347/4500 [00:04<00:05, 550.74it/s] 31%|███       | 1404/4500 [00:04<00:05, 536.09it/s] 32%|███▏      | 1459/4500 [00:04<00:07, 409.83it/s] 33%|███▎      | 1505/4500 [00:04<00:08, 372.89it/s] 34%|███▍      | 1549/4500 [00:04<00:07, 383.48it/s] 35%|███▌      | 1591/4500 [00:04<00:08, 359.23it/s] 36%|███▌      | 1629/4500 [00:04<00:07, 363.49it/s] 37%|███▋      | 1667/4500 [00:05<00:08, 325.12it/s] 38%|███▊      | 1702/4500 [00:05<00:10, 274.82it/s] 39%|███▉      | 1765/4500 [00:05<00:07, 346.19it/s] 40%|████      | 1807/4500 [00:05<00:07, 363.61it/s] 41%|████▏     | 1862/4500 [00:05<00:06, 403.41it/s] 43%|████▎     | 1919/4500 [00:05<00:05, 447.04it/s] 44%|████▍     | 1980/4500 [00:05<00:05, 489.80it/s] 45%|████▌     | 2043/4500 [00:05<00:04, 519.93it/s] 47%|████▋     | 2097/4500 [00:06<00:04, 517.68it/s] 48%|████▊     | 2150/4500 [00:06<00:05, 439.80it/s] 49%|████▉     | 2197/4500 [00:06<00:05, 385.54it/s] 50%|████▉     | 2239/4500 [00:06<00:06, 369.56it/s] 51%|█████     | 2278/4500 [00:06<00:07, 314.89it/s] 51%|█████▏    | 2312/4500 [00:06<00:07, 287.15it/s] 52%|█████▏    | 2352/4500 [00:06<00:06, 308.12it/s] 53%|█████▎    | 2385/4500 [00:07<00:07, 301.86it/s] 54%|█████▍    | 2431/4500 [00:07<00:06, 336.98it/s] 55%|█████▍    | 2469/4500 [00:07<00:05, 342.65it/s] 56%|█████▌    | 2526/4500 [00:07<00:04, 403.22it/s] 57%|█████▋    | 2586/4500 [00:07<00:04, 452.52it/s] 59%|█████▊    | 2633/4500 [00:07<00:04, 429.01it/s] 59%|█████▉    | 2677/4500 [00:07<00:04, 388.92it/s] 60%|██████    | 2718/4500 [00:07<00:05, 350.63it/s] 61%|██████▏   | 2763/4500 [00:07<00:04, 360.54it/s] 62%|██████▏   | 2802/4500 [00:08<00:04, 366.08it/s] 63%|██████▎   | 2856/4500 [00:08<00:03, 411.05it/s] 65%|██████▍   | 2905/4500 [00:08<00:03, 415.64it/s] 66%|██████▌   | 2952/4500 [00:08<00:03, 414.84it/s] 67%|██████▋   | 3005/4500 [00:08<00:03, 446.03it/s] 68%|██████▊   | 3051/4500 [00:08<00:03, 404.21it/s] 69%|██████▉   | 3098/4500 [00:08<00:03, 405.92it/s] 70%|██████▉   | 3140/4500 [00:08<00:04, 336.92it/s] 71%|███████   | 3176/4500 [00:09<00:04, 324.77it/s] 71%|███████▏  | 3210/4500 [00:09<00:04, 310.42it/s] 72%|███████▏  | 3256/4500 [00:09<00:03, 347.43it/s] 73%|███████▎  | 3299/4500 [00:09<00:03, 368.02it/s] 74%|███████▍  | 3338/4500 [00:09<00:03, 350.92it/s] 75%|███████▌  | 3375/4500 [00:09<00:03, 340.41it/s] 76%|███████▌  | 3418/4500 [00:09<00:03, 357.52it/s] 77%|███████▋  | 3455/4500 [00:09<00:03, 325.69it/s] 78%|███████▊  | 3496/4500 [00:09<00:02, 339.69it/s] 78%|███████▊  | 3531/4500 [00:10<00:04, 212.57it/s] 79%|███████▉  | 3559/4500 [00:10<00:05, 163.59it/s] 80%|███████▉  | 3582/4500 [00:10<00:06, 145.12it/s] 80%|████████  | 3601/4500 [00:10<00:05, 150.93it/s] 81%|████████  | 3639/4500 [00:11<00:04, 193.83it/s] 82%|████████▏ | 3677/4500 [00:11<00:03, 229.42it/s] 83%|████████▎ | 3723/4500 [00:11<00:02, 274.75it/s] 84%|████████▍ | 3771/4500 [00:11<00:02, 309.50it/s] 85%|████████▌ | 3828/4500 [00:11<00:01, 372.56it/s] 86%|████████▌ | 3869/4500 [00:11<00:01, 374.94it/s] 87%|████████▋ | 3918/4500 [00:11<00:01, 400.01it/s] 88%|████████▊ | 3976/4500 [00:11<00:01, 447.32it/s] 89%|████████▉ | 4023/4500 [00:11<00:01, 436.50it/s] 90%|█████████ | 4068/4500 [00:12<00:01, 404.23it/s] 91%|█████████▏| 4110/4500 [00:12<00:01, 376.73it/s] 92%|█████████▏| 4156/4500 [00:12<00:00, 395.71it/s] 93%|█████████▎| 4197/4500 [00:12<00:00, 372.83it/s] 94%|█████████▍| 4242/4500 [00:12<00:00, 383.91it/s] 95%|█████████▌| 4283/4500 [00:12<00:00, 389.72it/s] 96%|█████████▌| 4323/4500 [00:12<00:00, 353.38it/s] 97%|█████████▋| 4360/4500 [00:12<00:00, 348.72it/s] 98%|█████████▊| 4397/4500 [00:12<00:00, 351.80it/s] 99%|█████████▉| 4447/4500 [00:13<00:00, 391.27it/s]100%|██████████| 4500/4500 [00:13<00:00, 342.96it/s]
test_p81 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p81
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p81.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.00it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.97it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.28it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.55it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.87it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p81_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p81_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p81_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p81_Holmes_probs.npy
{'Accuracy': 0.9871, 'Precision': 0.9873, 'Recall': 0.9871, 'F1-score': 0.9872}
starting gen taf script for test_p82
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 59/4500 [00:00<00:07, 584.85it/s]  3%|▎         | 118/4500 [00:00<00:09, 472.64it/s]  4%|▎         | 167/4500 [00:00<00:11, 381.81it/s]  5%|▍         | 208/4500 [00:00<00:11, 385.35it/s]  6%|▌         | 257/4500 [00:00<00:10, 412.31it/s]  7%|▋         | 301/4500 [00:00<00:10, 417.66it/s]  8%|▊         | 344/4500 [00:00<00:14, 288.77it/s]  8%|▊         | 379/4500 [00:01<00:16, 256.05it/s]  9%|▉         | 422/4500 [00:01<00:14, 290.08it/s] 10%|█         | 472/4500 [00:01<00:12, 329.58it/s] 12%|█▏        | 529/4500 [00:01<00:10, 371.06it/s] 13%|█▎        | 577/4500 [00:01<00:09, 396.09it/s] 14%|█▍        | 628/4500 [00:01<00:09, 422.16it/s] 15%|█▌        | 692/4500 [00:01<00:08, 471.77it/s] 16%|█▋        | 741/4500 [00:01<00:08, 435.26it/s] 17%|█▋        | 787/4500 [00:02<00:09, 383.92it/s] 19%|█▊        | 834/4500 [00:02<00:09, 401.94it/s] 20%|██        | 912/4500 [00:02<00:07, 494.82it/s] 21%|██▏       | 964/4500 [00:02<00:07, 495.55it/s] 23%|██▎       | 1016/4500 [00:02<00:07, 449.73it/s] 24%|██▎       | 1063/4500 [00:02<00:07, 445.63it/s] 25%|██▍       | 1121/4500 [00:02<00:07, 475.96it/s] 27%|██▋       | 1198/4500 [00:02<00:05, 551.25it/s] 29%|██▊       | 1284/4500 [00:02<00:05, 630.17it/s] 30%|██▉       | 1349/4500 [00:03<00:05, 584.40it/s] 31%|███▏      | 1409/4500 [00:03<00:05, 532.57it/s] 33%|███▎      | 1464/4500 [00:03<00:08, 377.12it/s] 34%|███▎      | 1509/4500 [00:03<00:08, 364.22it/s] 35%|███▌      | 1587/4500 [00:03<00:06, 432.04it/s] 36%|███▋      | 1635/4500 [00:03<00:07, 373.98it/s] 37%|███▋      | 1677/4500 [00:04<00:08, 331.49it/s] 38%|███▊      | 1714/4500 [00:04<00:08, 328.64it/s] 39%|███▉      | 1761/4500 [00:04<00:07, 353.21it/s] 40%|████      | 1820/4500 [00:04<00:06, 403.20it/s] 41%|████▏     | 1863/4500 [00:04<00:06, 409.91it/s] 42%|████▏     | 1906/4500 [00:04<00:06, 414.03it/s] 44%|████▍     | 1969/4500 [00:04<00:05, 468.26it/s] 45%|████▌     | 2032/4500 [00:04<00:04, 501.23it/s] 46%|████▋     | 2084/4500 [00:04<00:05, 475.00it/s] 47%|████▋     | 2133/4500 [00:05<00:05, 468.29it/s] 48%|████▊     | 2181/4500 [00:05<00:05, 424.92it/s] 49%|████▉     | 2225/4500 [00:05<00:06, 365.28it/s] 50%|█████     | 2264/4500 [00:05<00:07, 292.03it/s] 51%|█████     | 2297/4500 [00:05<00:07, 294.46it/s] 52%|█████▏    | 2329/4500 [00:05<00:07, 288.94it/s] 53%|█████▎    | 2369/4500 [00:05<00:06, 315.49it/s] 53%|█████▎    | 2403/4500 [00:06<00:06, 319.28it/s] 54%|█████▍    | 2440/4500 [00:06<00:06, 331.61it/s] 55%|█████▌    | 2486/4500 [00:06<00:05, 366.66it/s] 56%|█████▋    | 2533/4500 [00:06<00:04, 395.52it/s] 58%|█████▊    | 2601/4500 [00:06<00:03, 474.95it/s] 59%|█████▉    | 2650/4500 [00:06<00:04, 398.68it/s] 60%|█████▉    | 2693/4500 [00:06<00:04, 389.87it/s] 61%|██████    | 2734/4500 [00:06<00:04, 358.88it/s] 62%|██████▏   | 2772/4500 [00:06<00:04, 355.96it/s] 63%|██████▎   | 2830/4500 [00:07<00:04, 414.11it/s] 64%|██████▍   | 2884/4500 [00:07<00:03, 446.89it/s] 65%|██████▌   | 2931/4500 [00:07<00:03, 430.98it/s] 66%|██████▌   | 2976/4500 [00:07<00:03, 431.04it/s] 67%|██████▋   | 3020/4500 [00:07<00:03, 406.13it/s] 68%|██████▊   | 3063/4500 [00:07<00:03, 411.46it/s] 69%|██████▉   | 3105/4500 [00:07<00:03, 350.08it/s] 70%|██████▉   | 3142/4500 [00:07<00:04, 323.36it/s] 71%|███████   | 3176/4500 [00:08<00:04, 306.15it/s] 72%|███████▏  | 3222/4500 [00:08<00:03, 333.98it/s] 73%|███████▎  | 3294/4500 [00:08<00:02, 432.73it/s] 74%|███████▍  | 3340/4500 [00:08<00:02, 394.33it/s] 75%|███████▌  | 3382/4500 [00:08<00:02, 388.66it/s] 76%|███████▌  | 3423/4500 [00:08<00:03, 358.50it/s] 77%|███████▋  | 3461/4500 [00:08<00:03, 303.54it/s] 78%|███████▊  | 3494/4500 [00:08<00:03, 286.23it/s] 78%|███████▊  | 3524/4500 [00:09<00:05, 189.81it/s] 79%|███████▉  | 3548/4500 [00:09<00:06, 153.24it/s] 79%|███████▉  | 3568/4500 [00:09<00:06, 143.59it/s] 80%|███████▉  | 3586/4500 [00:09<00:07, 126.54it/s] 81%|████████  | 3629/4500 [00:10<00:04, 178.06it/s] 82%|████████▏ | 3676/4500 [00:10<00:03, 233.74it/s] 83%|████████▎ | 3720/4500 [00:10<00:02, 277.11it/s] 84%|████████▍ | 3773/4500 [00:10<00:02, 334.65it/s] 85%|████████▍ | 3812/4500 [00:10<00:02, 336.40it/s] 86%|████████▌ | 3857/4500 [00:10<00:01, 353.53it/s] 87%|████████▋ | 3904/4500 [00:10<00:01, 381.70it/s] 88%|████████▊ | 3945/4500 [00:10<00:01, 382.12it/s] 89%|████████▊ | 3985/4500 [00:10<00:01, 353.66it/s] 90%|████████▉ | 4039/4500 [00:11<00:01, 393.14it/s] 91%|█████████ | 4080/4500 [00:11<00:01, 369.61it/s] 92%|█████████▏| 4118/4500 [00:11<00:01, 371.12it/s] 92%|█████████▏| 4156/4500 [00:11<00:01, 328.70it/s] 93%|█████████▎| 4191/4500 [00:11<00:00, 328.23it/s] 94%|█████████▍| 4230/4500 [00:11<00:00, 329.34it/s] 95%|█████████▍| 4270/4500 [00:11<00:00, 347.65it/s] 96%|█████████▌| 4316/4500 [00:11<00:00, 361.27it/s] 97%|█████████▋| 4353/4500 [00:11<00:00, 333.91it/s] 97%|█████████▋| 4387/4500 [00:12<00:00, 309.40it/s] 99%|█████████▉| 4451/4500 [00:12<00:00, 390.10it/s]100%|██████████| 4500/4500 [00:12<00:00, 365.81it/s]
test_p82 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p82
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p82.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.03it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.12it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.48it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.87it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.10it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p82_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p82_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p82_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p82_Holmes_probs.npy
{'Accuracy': 0.9876, 'Precision': 0.9877, 'Recall': 0.9876, 'F1-score': 0.9876}
starting gen taf script for test_p83
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 66/4500 [00:00<00:06, 640.10it/s]  3%|▎         | 131/4500 [00:00<00:09, 466.03it/s]  4%|▍         | 181/4500 [00:00<00:10, 416.19it/s]  5%|▌         | 225/4500 [00:00<00:10, 407.93it/s]  6%|▋         | 287/4500 [00:00<00:08, 471.95it/s]  7%|▋         | 336/4500 [00:00<00:12, 337.55it/s]  8%|▊         | 376/4500 [00:01<00:14, 277.94it/s]  9%|▉         | 409/4500 [00:01<00:15, 265.00it/s] 10%|▉         | 441/4500 [00:01<00:14, 274.70it/s] 11%|█         | 488/4500 [00:01<00:12, 314.19it/s] 12%|█▏        | 523/4500 [00:01<00:14, 283.14it/s] 12%|█▏        | 554/4500 [00:01<00:14, 275.27it/s] 13%|█▎        | 583/4500 [00:01<00:14, 261.89it/s] 14%|█▎        | 614/4500 [00:01<00:14, 267.99it/s] 15%|█▍        | 653/4500 [00:02<00:13, 288.10it/s] 15%|█▌        | 689/4500 [00:02<00:12, 298.73it/s] 16%|█▌        | 720/4500 [00:02<00:12, 301.40it/s] 17%|█▋        | 751/4500 [00:02<00:13, 271.20it/s] 17%|█▋        | 779/4500 [00:02<00:14, 253.95it/s] 18%|█▊        | 806/4500 [00:02<00:14, 249.39it/s] 19%|█▊        | 838/4500 [00:02<00:13, 267.72it/s] 19%|█▉        | 876/4500 [00:02<00:12, 291.06it/s] 20%|██        | 922/4500 [00:02<00:10, 332.42it/s] 21%|██▏       | 966/4500 [00:03<00:09, 360.76it/s] 22%|██▏       | 1007/4500 [00:03<00:09, 374.66it/s] 23%|██▎       | 1045/4500 [00:03<00:09, 373.94it/s] 24%|██▍       | 1084/4500 [00:03<00:09, 378.29it/s] 26%|██▌       | 1164/4500 [00:03<00:06, 501.69it/s] 28%|██▊       | 1239/4500 [00:03<00:05, 574.67it/s] 29%|██▉       | 1297/4500 [00:03<00:05, 556.64it/s] 30%|███       | 1354/4500 [00:03<00:06, 492.24it/s] 31%|███       | 1405/4500 [00:03<00:06, 445.91it/s] 32%|███▏      | 1452/4500 [00:04<00:09, 337.11it/s] 33%|███▎      | 1491/4500 [00:04<00:10, 290.01it/s] 34%|███▍      | 1536/4500 [00:04<00:09, 317.97it/s] 36%|███▌      | 1601/4500 [00:04<00:07, 386.93it/s] 37%|███▋      | 1645/4500 [00:04<00:09, 302.83it/s] 37%|███▋      | 1682/4500 [00:04<00:09, 295.73it/s] 38%|███▊      | 1716/4500 [00:05<00:09, 284.49it/s] 39%|███▉      | 1770/4500 [00:05<00:08, 338.43it/s] 40%|████      | 1815/4500 [00:05<00:07, 360.01it/s] 41%|████▏     | 1863/4500 [00:05<00:06, 388.16it/s] 43%|████▎     | 1917/4500 [00:05<00:06, 418.06it/s] 44%|████▎     | 1961/4500 [00:05<00:06, 420.80it/s] 45%|████▍     | 2017/4500 [00:05<00:05, 447.40it/s] 46%|████▌     | 2063/4500 [00:05<00:05, 448.42it/s] 47%|████▋     | 2119/4500 [00:05<00:05, 454.30it/s] 48%|████▊     | 2172/4500 [00:06<00:04, 474.37it/s] 49%|████▉     | 2220/4500 [00:06<00:05, 436.79it/s] 50%|█████     | 2265/4500 [00:06<00:06, 352.88it/s] 51%|█████     | 2304/4500 [00:06<00:06, 331.59it/s] 52%|█████▏    | 2340/4500 [00:06<00:07, 276.26it/s] 53%|█████▎    | 2374/4500 [00:06<00:07, 288.15it/s] 54%|█████▎    | 2413/4500 [00:06<00:06, 301.86it/s] 55%|█████▍    | 2458/4500 [00:07<00:06, 332.28it/s] 56%|█████▌    | 2502/4500 [00:07<00:05, 357.84it/s] 57%|█████▋    | 2551/4500 [00:07<00:04, 392.22it/s] 58%|█████▊    | 2592/4500 [00:07<00:04, 387.68it/s] 59%|█████▉    | 2645/4500 [00:07<00:04, 421.27it/s] 60%|█████▉    | 2689/4500 [00:07<00:04, 411.62it/s] 61%|██████    | 2731/4500 [00:07<00:04, 390.78it/s] 62%|██████▏   | 2775/4500 [00:07<00:04, 398.05it/s] 63%|██████▎   | 2816/4500 [00:07<00:04, 371.48it/s] 63%|██████▎   | 2856/4500 [00:08<00:04, 375.78it/s] 65%|██████▍   | 2915/4500 [00:08<00:03, 434.81it/s] 66%|██████▌   | 2960/4500 [00:08<00:03, 387.40it/s] 67%|██████▋   | 3003/4500 [00:08<00:03, 379.89it/s] 68%|██████▊   | 3042/4500 [00:08<00:03, 376.48it/s] 68%|██████▊   | 3082/4500 [00:08<00:03, 366.14it/s] 69%|██████▉   | 3120/4500 [00:08<00:04, 329.00it/s] 70%|███████   | 3154/4500 [00:08<00:04, 301.48it/s] 71%|███████   | 3188/4500 [00:09<00:04, 306.82it/s] 72%|███████▏  | 3225/4500 [00:09<00:04, 313.50it/s] 73%|███████▎  | 3286/4500 [00:09<00:03, 391.79it/s] 74%|███████▍  | 3327/4500 [00:09<00:03, 371.15it/s] 75%|███████▍  | 3366/4500 [00:09<00:03, 367.06it/s] 76%|███████▌  | 3404/4500 [00:09<00:03, 337.38it/s] 76%|███████▋  | 3439/4500 [00:09<00:03, 276.63it/s] 77%|███████▋  | 3485/4500 [00:09<00:03, 316.47it/s] 78%|███████▊  | 3520/4500 [00:10<00:04, 210.26it/s] 79%|███████▉  | 3548/4500 [00:10<00:06, 144.74it/s] 79%|███████▉  | 3570/4500 [00:10<00:06, 149.33it/s] 80%|███████▉  | 3590/4500 [00:10<00:06, 146.49it/s] 80%|████████  | 3609/4500 [00:10<00:05, 151.61it/s] 81%|████████  | 3654/4500 [00:11<00:04, 208.23it/s] 82%|████████▏ | 3681/4500 [00:11<00:03, 221.52it/s] 82%|████████▏ | 3712/4500 [00:11<00:03, 241.41it/s] 84%|████████▎ | 3761/4500 [00:11<00:02, 297.62it/s] 85%|████████▍ | 3806/4500 [00:11<00:02, 327.99it/s] 86%|████████▌ | 3851/4500 [00:11<00:01, 356.72it/s] 87%|████████▋ | 3893/4500 [00:11<00:01, 370.00it/s] 87%|████████▋ | 3936/4500 [00:11<00:01, 374.12it/s] 88%|████████▊ | 3977/4500 [00:11<00:01, 382.13it/s] 89%|████████▉ | 4016/4500 [00:12<00:01, 349.63it/s] 90%|█████████ | 4071/4500 [00:12<00:01, 399.50it/s] 91%|█████████▏| 4113/4500 [00:12<00:01, 350.75it/s] 92%|█████████▏| 4150/4500 [00:12<00:01, 323.58it/s] 93%|█████████▎| 4184/4500 [00:12<00:01, 300.07it/s] 94%|█████████▍| 4241/4500 [00:12<00:00, 366.25it/s] 95%|█████████▌| 4280/4500 [00:12<00:00, 350.38it/s] 96%|█████████▌| 4324/4500 [00:12<00:00, 370.01it/s] 97%|█████████▋| 4363/4500 [00:13<00:00, 297.93it/s] 98%|█████████▊| 4413/4500 [00:13<00:00, 343.35it/s] 99%|█████████▉| 4456/4500 [00:13<00:00, 364.66it/s]100%|██████████| 4500/4500 [00:13<00:00, 335.65it/s]
test_p83 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p83
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p83.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.04s/it]evaluating model with Holmes:  28%|██▊       | 5/18 [00:01<00:02,  5.64it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 11.93it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 18.10it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.27it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p83_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p83_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p83_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p83_Holmes_probs.npy
{'Accuracy': 0.9876, 'Precision': 0.9877, 'Recall': 0.9876, 'F1-score': 0.9876}
starting gen taf script for test_p84
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 54/4500 [00:00<00:08, 537.84it/s]  2%|▏         | 108/4500 [00:00<00:09, 462.31it/s]  3%|▎         | 155/4500 [00:00<00:11, 374.11it/s]  4%|▍         | 200/4500 [00:00<00:10, 396.89it/s]  6%|▌         | 256/4500 [00:00<00:09, 441.33it/s]  7%|▋         | 302/4500 [00:00<00:09, 435.08it/s]  8%|▊         | 347/4500 [00:00<00:13, 316.15it/s]  9%|▊         | 384/4500 [00:01<00:15, 272.29it/s]  9%|▉         | 416/4500 [00:01<00:14, 280.09it/s] 10%|█         | 455/4500 [00:01<00:13, 303.05it/s] 11%|█         | 501/4500 [00:01<00:11, 341.67it/s] 12%|█▏        | 538/4500 [00:01<00:11, 345.19it/s] 13%|█▎        | 575/4500 [00:01<00:11, 349.36it/s] 14%|█▎        | 612/4500 [00:01<00:11, 336.24it/s] 14%|█▍        | 647/4500 [00:01<00:11, 328.91it/s] 15%|█▌        | 684/4500 [00:01<00:11, 335.89it/s] 16%|█▌        | 719/4500 [00:02<00:11, 317.80it/s] 17%|█▋        | 752/4500 [00:02<00:12, 306.39it/s] 17%|█▋        | 784/4500 [00:02<00:12, 304.77it/s] 19%|█▊        | 834/4500 [00:02<00:10, 357.05it/s] 20%|█▉        | 892/4500 [00:02<00:08, 409.17it/s] 21%|██        | 939/4500 [00:02<00:08, 423.95it/s] 22%|██▏       | 994/4500 [00:02<00:07, 453.10it/s] 23%|██▎       | 1040/4500 [00:02<00:08, 423.98it/s] 24%|██▍       | 1095/4500 [00:02<00:07, 458.64it/s] 26%|██▌       | 1173/4500 [00:03<00:06, 532.78it/s] 27%|██▋       | 1230/4500 [00:03<00:06, 537.71it/s] 29%|██▉       | 1304/4500 [00:03<00:05, 587.93it/s] 30%|███       | 1364/4500 [00:03<00:05, 571.05it/s] 32%|███▏      | 1422/4500 [00:03<00:06, 473.46it/s] 33%|███▎      | 1473/4500 [00:03<00:08, 373.43it/s] 34%|███▎      | 1516/4500 [00:03<00:07, 381.04it/s] 35%|███▍      | 1571/4500 [00:03<00:06, 419.00it/s] 36%|███▌      | 1617/4500 [00:04<00:07, 392.92it/s] 37%|███▋      | 1659/4500 [00:04<00:08, 346.70it/s] 38%|███▊      | 1697/4500 [00:04<00:08, 324.92it/s] 39%|███▉      | 1747/4500 [00:04<00:07, 355.91it/s] 40%|███▉      | 1785/4500 [00:04<00:07, 353.31it/s] 41%|████      | 1843/4500 [00:04<00:06, 405.80it/s] 42%|████▏     | 1896/4500 [00:04<00:06, 428.12it/s] 43%|████▎     | 1953/4500 [00:04<00:05, 456.91it/s] 45%|████▍     | 2017/4500 [00:05<00:05, 491.21it/s] 46%|████▌     | 2067/4500 [00:05<00:05, 476.46it/s] 47%|████▋     | 2116/4500 [00:05<00:05, 456.66it/s] 48%|████▊     | 2163/4500 [00:05<00:05, 404.57it/s] 49%|████▉     | 2209/4500 [00:05<00:05, 418.17it/s] 50%|█████     | 2252/4500 [00:05<00:06, 359.63it/s] 51%|█████     | 2290/4500 [00:05<00:07, 307.40it/s] 52%|█████▏    | 2324/4500 [00:06<00:07, 297.26it/s] 52%|█████▏    | 2356/4500 [00:06<00:07, 284.94it/s] 53%|█████▎    | 2393/4500 [00:06<00:06, 301.48it/s] 54%|█████▍    | 2425/4500 [00:06<00:07, 288.86it/s] 56%|█████▌    | 2500/4500 [00:06<00:04, 406.09it/s] 57%|█████▋    | 2544/4500 [00:06<00:04, 410.23it/s] 58%|█████▊    | 2596/4500 [00:06<00:04, 436.93it/s] 59%|█████▊    | 2642/4500 [00:06<00:04, 392.73it/s] 60%|█████▉    | 2694/4500 [00:06<00:04, 415.29it/s] 61%|██████    | 2737/4500 [00:07<00:04, 383.86it/s] 62%|██████▏   | 2794/4500 [00:07<00:04, 420.66it/s] 63%|██████▎   | 2841/4500 [00:07<00:03, 430.86it/s] 64%|██████▍   | 2886/4500 [00:07<00:03, 423.21it/s] 65%|██████▌   | 2929/4500 [00:07<00:03, 405.70it/s] 66%|██████▋   | 2984/4500 [00:07<00:03, 439.95it/s] 67%|██████▋   | 3029/4500 [00:07<00:03, 404.59it/s] 69%|██████▊   | 3085/4500 [00:07<00:03, 439.90it/s] 70%|██████▉   | 3130/4500 [00:08<00:03, 366.59it/s] 70%|███████   | 3170/4500 [00:08<00:04, 308.06it/s] 71%|███████▏  | 3210/4500 [00:08<00:03, 325.76it/s] 72%|███████▏  | 3247/4500 [00:08<00:03, 332.56it/s] 73%|███████▎  | 3299/4500 [00:08<00:03, 379.62it/s] 74%|███████▍  | 3340/4500 [00:08<00:03, 374.90it/s] 75%|███████▌  | 3380/4500 [00:08<00:03, 312.71it/s] 76%|███████▋  | 3432/4500 [00:08<00:02, 358.10it/s] 77%|███████▋  | 3471/4500 [00:09<00:03, 304.64it/s] 78%|███████▊  | 3505/4500 [00:09<00:04, 222.66it/s] 79%|███████▊  | 3533/4500 [00:09<00:05, 188.00it/s] 79%|███████▉  | 3556/4500 [00:09<00:05, 167.32it/s] 79%|███████▉  | 3576/4500 [00:10<00:06, 150.58it/s] 80%|████████  | 3601/4500 [00:10<00:05, 167.28it/s] 81%|████████▏ | 3660/4500 [00:10<00:03, 250.73it/s] 82%|████████▏ | 3699/4500 [00:10<00:02, 277.45it/s] 83%|████████▎ | 3739/4500 [00:10<00:02, 306.81it/s] 84%|████████▍ | 3774/4500 [00:10<00:02, 282.61it/s] 85%|████████▌ | 3837/4500 [00:10<00:01, 365.06it/s] 87%|████████▋ | 3893/4500 [00:10<00:01, 392.72it/s] 87%|████████▋ | 3935/4500 [00:10<00:01, 395.04it/s] 88%|████████▊ | 3980/4500 [00:11<00:01, 400.04it/s] 89%|████████▉ | 4022/4500 [00:11<00:01, 399.01it/s] 90%|█████████ | 4064/4500 [00:11<00:01, 395.63it/s] 91%|█████████ | 4105/4500 [00:11<00:01, 337.77it/s] 92%|█████████▏| 4144/4500 [00:11<00:01, 348.26it/s] 93%|█████████▎| 4181/4500 [00:11<00:00, 324.09it/s] 94%|█████████▍| 4240/4500 [00:11<00:00, 390.84it/s] 95%|█████████▌| 4281/4500 [00:11<00:00, 379.12it/s] 96%|█████████▌| 4321/4500 [00:11<00:00, 361.26it/s] 97%|█████████▋| 4359/4500 [00:12<00:00, 358.11it/s] 98%|█████████▊| 4396/4500 [00:12<00:00, 332.95it/s] 99%|█████████▊| 4435/4500 [00:12<00:00, 347.10it/s]100%|██████████| 4500/4500 [00:12<00:00, 362.86it/s]
test_p84 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p84
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p84.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.08s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.53it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.52it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.59it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.19it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p84_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p84_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p84_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p84_Holmes_probs.npy
{'Accuracy': 0.9876, 'Precision': 0.9877, 'Recall': 0.9876, 'F1-score': 0.9876}
starting gen taf script for test_p85
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 68/4500 [00:00<00:06, 641.41it/s]  3%|▎         | 133/4500 [00:00<00:11, 374.53it/s]  4%|▍         | 177/4500 [00:00<00:11, 362.25it/s]  5%|▍         | 217/4500 [00:00<00:11, 363.66it/s]  6%|▌         | 268/4500 [00:00<00:10, 406.07it/s]  7%|▋         | 311/4500 [00:00<00:12, 344.17it/s]  8%|▊         | 348/4500 [00:01<00:15, 265.07it/s]  8%|▊         | 379/4500 [00:01<00:16, 253.24it/s]  9%|▉         | 407/4500 [00:01<00:18, 224.48it/s] 10%|▉         | 441/4500 [00:01<00:16, 249.02it/s] 10%|█         | 469/4500 [00:01<00:18, 214.30it/s] 11%|█         | 493/4500 [00:01<00:18, 211.16it/s] 12%|█▏        | 524/4500 [00:01<00:16, 233.97it/s] 12%|█▏        | 551/4500 [00:01<00:16, 237.76it/s] 13%|█▎        | 580/4500 [00:02<00:15, 246.49it/s] 14%|█▍        | 626/4500 [00:02<00:13, 294.27it/s] 15%|█▍        | 663/4500 [00:02<00:12, 312.72it/s] 15%|█▌        | 696/4500 [00:02<00:13, 281.18it/s] 16%|█▌        | 726/4500 [00:02<00:13, 275.70it/s] 17%|█▋        | 755/4500 [00:02<00:16, 225.58it/s] 17%|█▋        | 780/4500 [00:02<00:17, 217.98it/s] 18%|█▊        | 827/4500 [00:02<00:13, 277.69it/s] 19%|█▉        | 877/4500 [00:03<00:10, 330.08it/s] 20%|██        | 913/4500 [00:03<00:10, 337.39it/s] 21%|██▏       | 961/4500 [00:03<00:09, 361.22it/s] 22%|██▏       | 999/4500 [00:03<00:10, 340.48it/s] 24%|██▎       | 1058/4500 [00:03<00:08, 406.49it/s] 24%|██▍       | 1101/4500 [00:03<00:09, 345.38it/s] 26%|██▌       | 1164/4500 [00:03<00:08, 413.75it/s] 28%|██▊       | 1245/4500 [00:03<00:06, 515.57it/s] 29%|██▉       | 1301/4500 [00:04<00:06, 498.89it/s] 30%|███       | 1366/4500 [00:04<00:05, 531.08it/s] 32%|███▏      | 1422/4500 [00:04<00:06, 447.36it/s] 33%|███▎      | 1471/4500 [00:04<00:09, 304.14it/s] 34%|███▍      | 1534/4500 [00:04<00:08, 357.39it/s] 35%|███▌      | 1583/4500 [00:04<00:07, 381.74it/s] 36%|███▌      | 1628/4500 [00:04<00:08, 350.06it/s] 37%|███▋      | 1668/4500 [00:05<00:08, 341.87it/s] 38%|███▊      | 1706/4500 [00:05<00:08, 327.32it/s] 39%|███▉      | 1750/4500 [00:05<00:07, 349.62it/s] 40%|███▉      | 1792/4500 [00:05<00:07, 363.05it/s] 41%|████      | 1848/4500 [00:05<00:06, 403.89it/s] 42%|████▏     | 1904/4500 [00:05<00:05, 436.21it/s] 43%|████▎     | 1949/4500 [00:05<00:06, 405.72it/s] 44%|████▍     | 1994/4500 [00:05<00:06, 408.79it/s] 46%|████▌     | 2060/4500 [00:06<00:05, 473.97it/s] 47%|████▋     | 2109/4500 [00:06<00:05, 441.03it/s] 48%|████▊     | 2155/4500 [00:06<00:05, 431.71it/s] 49%|████▉     | 2199/4500 [00:06<00:05, 416.06it/s] 50%|████▉     | 2242/4500 [00:06<00:06, 374.39it/s] 51%|█████     | 2281/4500 [00:06<00:06, 331.21it/s] 51%|█████▏    | 2316/4500 [00:06<00:07, 281.05it/s] 52%|█████▏    | 2346/4500 [00:06<00:07, 278.69it/s] 53%|█████▎    | 2376/4500 [00:07<00:07, 274.19it/s] 54%|█████▍    | 2432/4500 [00:07<00:06, 336.83it/s] 55%|█████▌    | 2495/4500 [00:07<00:04, 403.72it/s] 57%|█████▋    | 2543/4500 [00:07<00:04, 410.25it/s] 58%|█████▊    | 2596/4500 [00:07<00:04, 430.12it/s] 59%|█████▊    | 2640/4500 [00:07<00:04, 400.97it/s] 60%|█████▉    | 2681/4500 [00:07<00:04, 366.21it/s] 61%|██████    | 2727/4500 [00:07<00:04, 383.98it/s] 61%|██████▏   | 2767/4500 [00:08<00:04, 363.65it/s] 62%|██████▏   | 2812/4500 [00:08<00:04, 383.03it/s] 64%|██████▎   | 2858/4500 [00:08<00:04, 403.27it/s] 64%|██████▍   | 2900/4500 [00:08<00:04, 375.19it/s] 66%|██████▌   | 2951/4500 [00:08<00:03, 408.99it/s] 67%|██████▋   | 2999/4500 [00:08<00:03, 426.88it/s] 68%|██████▊   | 3043/4500 [00:08<00:03, 395.12it/s] 69%|██████▊   | 3087/4500 [00:08<00:03, 392.49it/s] 69%|██████▉   | 3127/4500 [00:08<00:03, 379.59it/s] 70%|███████   | 3166/4500 [00:09<00:04, 299.11it/s] 71%|███████   | 3201/4500 [00:09<00:04, 310.55it/s] 72%|███████▏  | 3235/4500 [00:09<00:04, 315.21it/s] 73%|███████▎  | 3285/4500 [00:09<00:03, 363.37it/s] 74%|███████▍  | 3324/4500 [00:09<00:03, 328.93it/s] 75%|███████▍  | 3359/4500 [00:09<00:03, 321.02it/s] 75%|███████▌  | 3393/4500 [00:09<00:03, 319.72it/s] 76%|███████▌  | 3426/4500 [00:09<00:03, 288.42it/s] 77%|███████▋  | 3476/4500 [00:10<00:03, 338.33it/s] 78%|███████▊  | 3512/4500 [00:10<00:04, 238.30it/s] 79%|███████▊  | 3541/4500 [00:10<00:05, 189.73it/s] 79%|███████▉  | 3565/4500 [00:10<00:06, 153.32it/s] 80%|███████▉  | 3585/4500 [00:10<00:05, 158.26it/s] 80%|████████  | 3604/4500 [00:11<00:05, 160.33it/s] 81%|████████  | 3642/4500 [00:11<00:04, 205.05it/s] 82%|████████▏ | 3688/4500 [00:11<00:03, 257.41it/s] 83%|████████▎ | 3736/4500 [00:11<00:02, 307.72it/s] 84%|████████▍ | 3771/4500 [00:11<00:02, 309.61it/s] 85%|████████▍ | 3805/4500 [00:11<00:02, 313.21it/s] 86%|████████▌ | 3863/4500 [00:11<00:01, 381.13it/s] 87%|████████▋ | 3903/4500 [00:11<00:01, 382.95it/s] 88%|████████▊ | 3943/4500 [00:11<00:01, 383.90it/s] 89%|████████▉ | 3995/4500 [00:11<00:01, 422.59it/s] 90%|████████▉ | 4039/4500 [00:12<00:01, 413.03it/s] 91%|█████████ | 4081/4500 [00:12<00:01, 346.31it/s] 92%|█████████▏| 4118/4500 [00:12<00:01, 345.11it/s] 92%|█████████▏| 4154/4500 [00:12<00:01, 302.91it/s] 93%|█████████▎| 4187/4500 [00:12<00:01, 305.66it/s] 95%|█████████▌| 4275/4500 [00:12<00:00, 450.74it/s] 96%|█████████▌| 4324/4500 [00:12<00:00, 366.27it/s] 97%|█████████▋| 4366/4500 [00:13<00:00, 303.19it/s] 98%|█████████▊| 4409/4500 [00:13<00:00, 322.59it/s] 99%|█████████▉| 4475/4500 [00:13<00:00, 395.16it/s]100%|██████████| 4500/4500 [00:13<00:00, 335.93it/s]
test_p85 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p85
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p85.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.23it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.03it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.01it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.72it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p85_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p85_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p85_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p85_Holmes_probs.npy
{'Accuracy': 0.9878, 'Precision': 0.988, 'Recall': 0.9878, 'F1-score': 0.9878}
starting gen taf script for test_p86
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 55/4500 [00:00<00:08, 534.32it/s]  2%|▏         | 109/4500 [00:00<00:11, 399.03it/s]  3%|▎         | 151/4500 [00:00<00:12, 347.75it/s]  4%|▍         | 188/4500 [00:00<00:12, 342.35it/s]  5%|▌         | 237/4500 [00:00<00:11, 383.97it/s]  6%|▋         | 286/4500 [00:00<00:10, 415.69it/s]  7%|▋         | 329/4500 [00:00<00:13, 302.99it/s]  8%|▊         | 364/4500 [00:01<00:15, 274.70it/s]  9%|▉         | 395/4500 [00:01<00:15, 258.25it/s] 10%|▉         | 441/4500 [00:01<00:13, 302.72it/s] 11%|█         | 475/4500 [00:01<00:13, 297.10it/s] 11%|█▏        | 514/4500 [00:01<00:12, 306.90it/s] 12%|█▏        | 547/4500 [00:01<00:12, 305.59it/s] 13%|█▎        | 586/4500 [00:01<00:12, 321.05it/s] 14%|█▍        | 619/4500 [00:01<00:12, 321.85it/s] 15%|█▍        | 654/4500 [00:02<00:11, 327.31it/s] 15%|█▌        | 688/4500 [00:02<00:11, 327.72it/s] 16%|█▌        | 722/4500 [00:02<00:13, 289.14it/s] 17%|█▋        | 752/4500 [00:02<00:13, 282.60it/s] 17%|█▋        | 781/4500 [00:02<00:13, 271.38it/s] 18%|█▊        | 809/4500 [00:02<00:13, 268.89it/s] 19%|█▉        | 868/4500 [00:02<00:10, 346.05it/s] 20%|██        | 915/4500 [00:02<00:09, 373.20it/s] 21%|██▏       | 961/4500 [00:02<00:09, 375.97it/s] 23%|██▎       | 1014/4500 [00:03<00:08, 405.44it/s] 23%|██▎       | 1055/4500 [00:03<00:09, 381.05it/s] 25%|██▍       | 1108/4500 [00:03<00:08, 415.77it/s] 26%|██▋       | 1186/4500 [00:03<00:06, 514.34it/s] 28%|██▊       | 1271/4500 [00:03<00:05, 606.85it/s] 30%|██▉       | 1334/4500 [00:03<00:06, 504.82it/s] 31%|███       | 1389/4500 [00:03<00:06, 491.20it/s] 32%|███▏      | 1441/4500 [00:03<00:07, 391.41it/s] 33%|███▎      | 1485/4500 [00:04<00:08, 358.93it/s] 34%|███▍      | 1525/4500 [00:04<00:08, 348.41it/s] 35%|███▌      | 1584/4500 [00:04<00:07, 402.90it/s] 36%|███▌      | 1628/4500 [00:04<00:08, 326.05it/s] 37%|███▋      | 1665/4500 [00:04<00:09, 314.65it/s] 38%|███▊      | 1700/4500 [00:04<00:09, 304.91it/s] 39%|███▉      | 1756/4500 [00:04<00:07, 362.17it/s] 40%|████      | 1810/4500 [00:05<00:06, 400.66it/s] 41%|████▏     | 1861/4500 [00:05<00:06, 426.98it/s] 42%|████▏     | 1908/4500 [00:05<00:06, 430.34it/s] 44%|████▍     | 1978/4500 [00:05<00:05, 490.49it/s] 45%|████▌     | 2029/4500 [00:05<00:05, 483.27it/s] 46%|████▌     | 2079/4500 [00:05<00:05, 462.59it/s] 47%|████▋     | 2126/4500 [00:05<00:05, 449.96it/s] 48%|████▊     | 2172/4500 [00:05<00:05, 419.05it/s] 49%|████▉     | 2215/4500 [00:05<00:06, 379.08it/s] 50%|█████     | 2254/4500 [00:06<00:06, 351.63it/s] 51%|█████     | 2290/4500 [00:06<00:08, 256.87it/s] 52%|█████▏    | 2324/4500 [00:06<00:08, 271.20it/s] 52%|█████▏    | 2355/4500 [00:06<00:07, 273.89it/s] 53%|█████▎    | 2387/4500 [00:06<00:07, 280.68it/s] 54%|█████▍    | 2440/4500 [00:06<00:06, 338.11it/s] 55%|█████▌    | 2476/4500 [00:06<00:06, 322.57it/s] 56%|█████▌    | 2519/4500 [00:07<00:05, 346.06it/s] 57%|█████▋    | 2574/4500 [00:07<00:04, 397.56it/s] 58%|█████▊    | 2621/4500 [00:07<00:04, 393.31it/s] 59%|█████▉    | 2662/4500 [00:07<00:04, 370.87it/s] 60%|██████    | 2700/4500 [00:07<00:04, 363.13it/s] 61%|██████    | 2740/4500 [00:07<00:04, 352.92it/s] 62%|██████▏   | 2778/4500 [00:07<00:04, 352.62it/s] 63%|██████▎   | 2842/4500 [00:07<00:03, 421.51it/s] 64%|██████▍   | 2889/4500 [00:07<00:03, 416.82it/s] 65%|██████▌   | 2932/4500 [00:08<00:04, 389.54it/s] 66%|██████▌   | 2973/4500 [00:08<00:03, 393.57it/s] 67%|██████▋   | 3027/4500 [00:08<00:03, 402.47it/s] 68%|██████▊   | 3068/4500 [00:08<00:03, 385.32it/s] 69%|██████▉   | 3115/4500 [00:08<00:03, 385.30it/s] 70%|███████   | 3154/4500 [00:08<00:04, 336.17it/s] 71%|███████   | 3189/4500 [00:08<00:04, 325.33it/s] 72%|███████▏  | 3223/4500 [00:08<00:04, 296.15it/s] 73%|███████▎  | 3272/4500 [00:09<00:03, 328.56it/s] 74%|███████▍  | 3321/4500 [00:09<00:03, 358.78it/s] 75%|███████▍  | 3358/4500 [00:09<00:03, 336.75it/s] 76%|███████▌  | 3399/4500 [00:09<00:03, 340.37it/s] 76%|███████▋  | 3434/4500 [00:09<00:03, 313.26it/s] 77%|███████▋  | 3466/4500 [00:09<00:03, 283.81it/s] 78%|███████▊  | 3495/4500 [00:09<00:03, 265.84it/s] 78%|███████▊  | 3522/4500 [00:10<00:04, 213.07it/s] 79%|███████▉  | 3545/4500 [00:10<00:05, 178.36it/s] 79%|███████▉  | 3565/4500 [00:10<00:06, 135.16it/s] 80%|███████▉  | 3584/4500 [00:10<00:06, 144.03it/s] 80%|████████  | 3601/4500 [00:10<00:06, 148.13it/s] 81%|████████  | 3643/4500 [00:10<00:04, 206.88it/s] 82%|████████▏ | 3695/4500 [00:10<00:02, 277.90it/s] 83%|████████▎ | 3732/4500 [00:11<00:02, 298.87it/s] 84%|████████▎ | 3765/4500 [00:11<00:02, 292.71it/s] 84%|████████▍ | 3797/4500 [00:11<00:02, 294.67it/s] 85%|████████▌ | 3840/4500 [00:11<00:02, 326.91it/s] 87%|████████▋ | 3893/4500 [00:11<00:01, 380.15it/s] 87%|████████▋ | 3934/4500 [00:11<00:01, 383.14it/s] 89%|████████▊ | 3990/4500 [00:11<00:01, 423.71it/s] 90%|████████▉ | 4033/4500 [00:11<00:01, 399.03it/s] 91%|█████████ | 4074/4500 [00:11<00:01, 366.07it/s] 91%|█████████▏| 4112/4500 [00:12<00:01, 332.81it/s] 92%|█████████▏| 4147/4500 [00:12<00:01, 319.29it/s] 93%|█████████▎| 4180/4500 [00:12<00:01, 310.16it/s] 94%|█████████▎| 4218/4500 [00:12<00:00, 317.73it/s] 95%|█████████▌| 4283/4500 [00:12<00:00, 405.55it/s] 96%|█████████▌| 4325/4500 [00:12<00:00, 392.47it/s] 97%|█████████▋| 4366/4500 [00:12<00:00, 334.61it/s] 98%|█████████▊| 4402/4500 [00:12<00:00, 304.40it/s] 99%|█████████▉| 4462/4500 [00:13<00:00, 370.19it/s]100%|██████████| 4500/4500 [00:13<00:00, 343.34it/s]
test_p86 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p86
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p86.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.10it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.59it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 14.20it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.60it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.77it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p86_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p86_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p86_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p86_Holmes_probs.npy
{'Accuracy': 0.9876, 'Precision': 0.9877, 'Recall': 0.9876, 'F1-score': 0.9876}
starting gen taf script for test_p87
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 43/4500 [00:00<00:10, 414.34it/s]  2%|▏         | 85/4500 [00:00<00:13, 326.47it/s]  3%|▎         | 124/4500 [00:00<00:12, 337.88it/s]  4%|▎         | 160/4500 [00:00<00:12, 337.90it/s]  4%|▍         | 195/4500 [00:00<00:14, 298.66it/s]  6%|▌         | 252/4500 [00:00<00:11, 373.24it/s]  6%|▋         | 292/4500 [00:00<00:11, 376.49it/s]  7%|▋         | 331/4500 [00:01<00:16, 252.50it/s]  8%|▊         | 362/4500 [00:01<00:17, 232.35it/s]  9%|▊         | 390/4500 [00:01<00:20, 203.75it/s]  9%|▉         | 418/4500 [00:01<00:18, 215.12it/s] 10%|█         | 454/4500 [00:01<00:16, 244.65it/s] 11%|█         | 499/4500 [00:01<00:13, 291.48it/s] 12%|█▏        | 532/4500 [00:01<00:14, 274.27it/s] 12%|█▏        | 562/4500 [00:02<00:14, 279.03it/s] 13%|█▎        | 592/4500 [00:02<00:14, 272.92it/s] 14%|█▍        | 628/4500 [00:02<00:13, 284.20it/s] 15%|█▍        | 662/4500 [00:02<00:12, 298.63it/s] 15%|█▌        | 693/4500 [00:02<00:12, 295.88it/s] 16%|█▌        | 724/4500 [00:02<00:13, 280.80it/s] 17%|█▋        | 753/4500 [00:02<00:13, 270.06it/s] 17%|█▋        | 781/4500 [00:02<00:14, 252.14it/s] 18%|█▊        | 832/4500 [00:02<00:11, 313.62it/s] 20%|█▉        | 898/4500 [00:03<00:08, 406.61it/s] 21%|██        | 941/4500 [00:03<00:10, 348.48it/s] 22%|██▏       | 980/4500 [00:03<00:09, 352.19it/s] 23%|██▎       | 1018/4500 [00:03<00:10, 336.19it/s] 23%|██▎       | 1057/4500 [00:03<00:10, 337.84it/s] 25%|██▍       | 1114/4500 [00:03<00:08, 393.55it/s] 27%|██▋       | 1194/4500 [00:03<00:06, 499.98it/s] 28%|██▊       | 1251/4500 [00:03<00:06, 516.48it/s] 29%|██▉       | 1305/4500 [00:03<00:06, 515.88it/s] 30%|███       | 1358/4500 [00:04<00:06, 516.71it/s] 31%|███▏      | 1411/4500 [00:04<00:06, 482.10it/s] 32%|███▏      | 1461/4500 [00:04<00:08, 357.07it/s] 33%|███▎      | 1502/4500 [00:04<00:09, 328.34it/s] 35%|███▍      | 1561/4500 [00:04<00:07, 386.14it/s] 36%|███▌      | 1610/4500 [00:04<00:07, 400.12it/s] 37%|███▋      | 1654/4500 [00:04<00:08, 338.68it/s] 38%|███▊      | 1692/4500 [00:05<00:09, 291.95it/s] 39%|███▊      | 1737/4500 [00:05<00:08, 320.88it/s] 40%|███▉      | 1793/4500 [00:05<00:07, 374.54it/s] 41%|████      | 1852/4500 [00:05<00:06, 417.84it/s] 42%|████▏     | 1897/4500 [00:05<00:06, 413.63it/s] 44%|████▎     | 1962/4500 [00:05<00:05, 466.24it/s] 45%|████▍     | 2011/4500 [00:05<00:06, 414.19it/s] 46%|████▋     | 2086/4500 [00:05<00:04, 486.20it/s] 47%|████▋     | 2137/4500 [00:06<00:04, 485.47it/s] 49%|████▊     | 2188/4500 [00:06<00:05, 409.31it/s] 50%|████▉     | 2232/4500 [00:06<00:05, 407.38it/s] 51%|█████     | 2275/4500 [00:06<00:06, 348.60it/s] 51%|█████▏    | 2313/4500 [00:06<00:06, 316.71it/s] 52%|█████▏    | 2347/4500 [00:06<00:07, 282.45it/s] 53%|█████▎    | 2377/4500 [00:06<00:08, 260.37it/s] 54%|█████▎    | 2416/4500 [00:07<00:07, 289.44it/s] 55%|█████▍    | 2462/4500 [00:07<00:06, 328.14it/s] 56%|█████▌    | 2516/4500 [00:07<00:05, 381.72it/s] 57%|█████▋    | 2558/4500 [00:07<00:05, 385.68it/s] 58%|█████▊    | 2601/4500 [00:07<00:04, 395.44it/s] 59%|█████▊    | 2642/4500 [00:07<00:05, 365.55it/s] 60%|█████▉    | 2680/4500 [00:07<00:05, 357.91it/s] 60%|██████    | 2721/4500 [00:07<00:04, 368.64it/s] 61%|██████▏   | 2759/4500 [00:07<00:04, 360.17it/s] 62%|██████▏   | 2812/4500 [00:08<00:04, 400.32it/s] 63%|██████▎   | 2853/4500 [00:08<00:04, 367.50it/s] 64%|██████▍   | 2891/4500 [00:08<00:04, 361.52it/s] 65%|██████▌   | 2931/4500 [00:08<00:04, 368.90it/s] 66%|██████▌   | 2969/4500 [00:08<00:04, 354.87it/s] 67%|██████▋   | 3022/4500 [00:08<00:03, 388.70it/s] 68%|██████▊   | 3063/4500 [00:08<00:03, 371.89it/s] 69%|██████▉   | 3101/4500 [00:08<00:04, 334.38it/s] 70%|██████▉   | 3136/4500 [00:09<00:04, 313.81it/s] 71%|███████   | 3176/4500 [00:09<00:03, 332.42it/s] 71%|███████▏  | 3210/4500 [00:09<00:05, 253.14it/s] 73%|███████▎  | 3267/4500 [00:09<00:03, 321.83it/s] 73%|███████▎  | 3304/4500 [00:09<00:03, 322.39it/s] 74%|███████▍  | 3340/4500 [00:09<00:03, 316.47it/s] 75%|███████▍  | 3374/4500 [00:09<00:03, 318.67it/s] 76%|███████▌  | 3408/4500 [00:09<00:03, 308.86it/s] 76%|███████▋  | 3440/4500 [00:10<00:04, 263.71it/s] 77%|███████▋  | 3479/4500 [00:10<00:03, 265.81it/s] 78%|███████▊  | 3508/4500 [00:10<00:03, 269.06it/s] 79%|███████▊  | 3536/4500 [00:10<00:05, 174.88it/s] 79%|███████▉  | 3559/4500 [00:10<00:06, 149.94it/s] 80%|███████▉  | 3578/4500 [00:11<00:06, 133.63it/s] 80%|███████▉  | 3594/4500 [00:11<00:06, 133.99it/s] 81%|████████  | 3640/4500 [00:11<00:04, 198.47it/s] 82%|████████▏ | 3674/4500 [00:11<00:03, 226.23it/s] 83%|████████▎ | 3722/4500 [00:11<00:02, 279.71it/s] 84%|████████▎ | 3765/4500 [00:11<00:02, 312.77it/s] 85%|████████▍ | 3804/4500 [00:11<00:02, 331.22it/s] 86%|████████▌ | 3854/4500 [00:11<00:01, 375.61it/s] 87%|████████▋ | 3894/4500 [00:11<00:01, 366.53it/s] 88%|████████▊ | 3958/4500 [00:12<00:01, 436.53it/s] 89%|████████▉ | 4004/4500 [00:12<00:01, 411.93it/s] 90%|████████▉ | 4047/4500 [00:12<00:01, 371.44it/s] 91%|█████████ | 4086/4500 [00:12<00:01, 372.72it/s] 92%|█████████▏| 4125/4500 [00:12<00:01, 346.53it/s] 92%|█████████▏| 4161/4500 [00:12<00:01, 323.00it/s] 93%|█████████▎| 4195/4500 [00:12<00:01, 299.91it/s] 94%|█████████▍| 4251/4500 [00:12<00:00, 363.26it/s] 96%|█████████▌| 4303/4500 [00:13<00:00, 403.15it/s] 97%|█████████▋| 4346/4500 [00:13<00:00, 372.49it/s] 97%|█████████▋| 4385/4500 [00:13<00:00, 363.34it/s] 99%|█████████▊| 4435/4500 [00:13<00:00, 397.68it/s]100%|█████████▉| 4490/4500 [00:13<00:00, 439.04it/s]100%|██████████| 4500/4500 [00:13<00:00, 333.88it/s]
test_p87 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p87
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p87.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.00s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.97it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.07it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.20it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.70it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p87_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p87_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p87_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p87_Holmes_probs.npy
{'Accuracy': 0.9873, 'Precision': 0.9875, 'Recall': 0.9873, 'F1-score': 0.9874}
starting gen taf script for test_p88
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 69/4500 [00:00<00:06, 664.33it/s]  3%|▎         | 136/4500 [00:00<00:10, 408.00it/s]  4%|▍         | 183/4500 [00:00<00:11, 364.86it/s]  5%|▍         | 223/4500 [00:00<00:11, 358.13it/s]  6%|▋         | 284/4500 [00:00<00:09, 424.41it/s]  7%|▋         | 329/4500 [00:00<00:13, 299.08it/s]  8%|▊         | 365/4500 [00:01<00:15, 270.99it/s]  9%|▉         | 396/4500 [00:01<00:16, 255.45it/s]  9%|▉         | 424/4500 [00:01<00:15, 260.23it/s] 10%|█         | 465/4500 [00:01<00:13, 292.90it/s] 11%|█         | 497/4500 [00:01<00:14, 275.52it/s] 12%|█▏        | 527/4500 [00:01<00:16, 245.79it/s] 12%|█▏        | 553/4500 [00:01<00:15, 249.11it/s] 13%|█▎        | 579/4500 [00:01<00:16, 238.12it/s] 13%|█▎        | 604/4500 [00:02<00:16, 240.16it/s] 14%|█▍        | 643/4500 [00:02<00:14, 272.69it/s] 15%|█▌        | 676/4500 [00:02<00:13, 278.96it/s] 16%|█▌        | 708/4500 [00:02<00:13, 282.12it/s] 16%|█▋        | 737/4500 [00:02<00:13, 274.83it/s] 17%|█▋        | 766/4500 [00:02<00:13, 276.72it/s] 18%|█▊        | 804/4500 [00:02<00:12, 303.32it/s] 19%|█▉        | 863/4500 [00:02<00:09, 378.20it/s] 21%|██        | 923/4500 [00:02<00:08, 441.44it/s] 22%|██▏       | 968/4500 [00:03<00:08, 393.66it/s] 22%|██▏       | 1009/4500 [00:03<00:09, 350.00it/s] 23%|██▎       | 1048/4500 [00:03<00:09, 357.04it/s] 24%|██▍       | 1091/4500 [00:03<00:09, 365.21it/s] 26%|██▌       | 1173/4500 [00:03<00:07, 473.74it/s] 28%|██▊       | 1243/4500 [00:03<00:06, 511.50it/s] 29%|██▉       | 1310/4500 [00:03<00:05, 546.30it/s] 30%|███       | 1366/4500 [00:03<00:06, 478.86it/s] 31%|███▏      | 1416/4500 [00:04<00:06, 443.00it/s] 32%|███▏      | 1462/4500 [00:04<00:07, 380.33it/s] 33%|███▎      | 1503/4500 [00:04<00:09, 323.06it/s] 35%|███▍      | 1562/4500 [00:04<00:07, 373.44it/s] 36%|███▌      | 1603/4500 [00:04<00:08, 350.39it/s] 36%|███▋      | 1641/4500 [00:04<00:09, 309.04it/s] 37%|███▋      | 1674/4500 [00:05<00:10, 273.98it/s] 38%|███▊      | 1709/4500 [00:05<00:09, 285.90it/s] 39%|███▉      | 1768/4500 [00:05<00:07, 356.45it/s] 41%|████      | 1823/4500 [00:05<00:06, 404.91it/s] 42%|████▏     | 1879/4500 [00:05<00:06, 434.38it/s] 43%|████▎     | 1925/4500 [00:05<00:06, 420.28it/s] 44%|████▍     | 1984/4500 [00:05<00:05, 447.32it/s] 45%|████▌     | 2031/4500 [00:05<00:05, 450.97it/s] 47%|████▋     | 2097/4500 [00:05<00:04, 492.79it/s] 48%|████▊     | 2147/4500 [00:06<00:05, 451.33it/s] 49%|████▉     | 2194/4500 [00:06<00:05, 421.45it/s] 50%|████▉     | 2237/4500 [00:06<00:06, 370.85it/s] 51%|█████     | 2276/4500 [00:06<00:07, 306.23it/s] 51%|█████▏    | 2309/4500 [00:06<00:07, 286.18it/s] 52%|█████▏    | 2342/4500 [00:06<00:07, 291.94it/s] 53%|█████▎    | 2373/4500 [00:06<00:07, 281.25it/s] 54%|█████▎    | 2408/4500 [00:06<00:07, 295.65it/s] 55%|█████▍    | 2463/4500 [00:07<00:06, 335.73it/s] 56%|█████▌    | 2509/4500 [00:07<00:05, 365.04it/s] 57%|█████▋    | 2571/4500 [00:07<00:04, 431.33it/s] 58%|█████▊    | 2616/4500 [00:07<00:04, 396.14it/s] 59%|█████▉    | 2657/4500 [00:07<00:04, 389.31it/s] 60%|█████▉    | 2697/4500 [00:07<00:04, 380.97it/s] 61%|██████    | 2736/4500 [00:07<00:04, 354.08it/s] 62%|██████▏   | 2781/4500 [00:07<00:04, 377.82it/s] 63%|██████▎   | 2836/4500 [00:07<00:03, 418.81it/s] 64%|██████▍   | 2879/4500 [00:08<00:03, 413.00it/s] 65%|██████▌   | 2931/4500 [00:08<00:03, 435.90it/s] 66%|██████▌   | 2976/4500 [00:08<00:03, 398.39it/s] 67%|██████▋   | 3026/4500 [00:08<00:03, 409.11it/s] 68%|██████▊   | 3070/4500 [00:08<00:03, 395.82it/s] 69%|██████▉   | 3111/4500 [00:08<00:03, 389.59it/s] 70%|███████   | 3151/4500 [00:08<00:03, 358.64it/s] 71%|███████   | 3188/4500 [00:08<00:03, 330.37it/s] 72%|███████▏  | 3222/4500 [00:09<00:04, 296.96it/s] 73%|███████▎  | 3275/4500 [00:09<00:03, 347.26it/s] 74%|███████▎  | 3317/4500 [00:09<00:03, 360.33it/s] 75%|███████▍  | 3355/4500 [00:09<00:03, 337.09it/s] 75%|███████▌  | 3390/4500 [00:09<00:03, 321.74it/s] 76%|███████▋  | 3433/4500 [00:09<00:03, 342.76it/s] 77%|███████▋  | 3468/4500 [00:09<00:03, 300.78it/s] 78%|███████▊  | 3500/4500 [00:10<00:04, 233.57it/s] 78%|███████▊  | 3527/4500 [00:10<00:05, 175.39it/s] 79%|███████▉  | 3549/4500 [00:10<00:05, 171.87it/s] 79%|███████▉  | 3569/4500 [00:10<00:06, 147.18it/s] 80%|███████▉  | 3586/4500 [00:10<00:06, 144.22it/s] 80%|████████  | 3616/4500 [00:10<00:05, 175.91it/s] 82%|████████▏ | 3668/4500 [00:11<00:03, 249.40it/s] 82%|████████▏ | 3711/4500 [00:11<00:02, 285.89it/s] 83%|████████▎ | 3746/4500 [00:11<00:02, 294.88it/s] 84%|████████▍ | 3791/4500 [00:11<00:02, 334.16it/s] 85%|████████▌ | 3827/4500 [00:11<00:02, 328.67it/s] 86%|████████▌ | 3875/4500 [00:11<00:01, 369.27it/s] 87%|████████▋ | 3914/4500 [00:11<00:01, 359.59it/s] 88%|████████▊ | 3967/4500 [00:11<00:01, 405.33it/s] 89%|████████▉ | 4011/4500 [00:11<00:01, 411.26it/s] 90%|█████████ | 4053/4500 [00:11<00:01, 389.19it/s] 91%|█████████ | 4095/4500 [00:12<00:01, 394.08it/s] 92%|█████████▏| 4135/4500 [00:12<00:01, 321.86it/s] 93%|█████████▎| 4172/4500 [00:12<00:01, 325.14it/s] 94%|█████████▎| 4211/4500 [00:12<00:00, 335.35it/s] 95%|█████████▍| 4256/4500 [00:12<00:00, 360.61it/s] 96%|█████████▌| 4299/4500 [00:12<00:00, 377.27it/s] 96%|█████████▋| 4338/4500 [00:12<00:00, 364.51it/s] 97%|█████████▋| 4376/4500 [00:12<00:00, 364.44it/s] 99%|█████████▊| 4439/4500 [00:13<00:00, 433.27it/s]100%|██████████| 4500/4500 [00:13<00:00, 343.08it/s]
test_p88 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p88
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p88.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.03s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.79it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.03it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.16it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.50it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p88_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p88_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p88_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p88_Holmes_probs.npy
{'Accuracy': 0.9873, 'Precision': 0.9875, 'Recall': 0.9873, 'F1-score': 0.9874}
starting gen taf script for test_p89
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 52/4500 [00:00<00:08, 496.70it/s]  2%|▏         | 102/4500 [00:00<00:11, 384.64it/s]  3%|▎         | 142/4500 [00:00<00:13, 321.80it/s]  4%|▍         | 176/4500 [00:00<00:13, 324.84it/s]  5%|▍         | 212/4500 [00:00<00:13, 329.52it/s]  6%|▌         | 257/4500 [00:00<00:11, 359.61it/s]  7%|▋         | 294/4500 [00:00<00:12, 326.80it/s]  7%|▋         | 328/4500 [00:01<00:14, 284.18it/s]  8%|▊         | 358/4500 [00:01<00:15, 262.15it/s]  9%|▊         | 386/4500 [00:01<00:16, 249.14it/s]  9%|▉         | 419/4500 [00:01<00:15, 265.22it/s] 10%|█         | 457/4500 [00:01<00:13, 294.84it/s] 11%|█         | 489/4500 [00:01<00:13, 295.18it/s] 12%|█▏        | 520/4500 [00:01<00:14, 281.10it/s] 12%|█▏        | 549/4500 [00:01<00:15, 261.99it/s] 13%|█▎        | 577/4500 [00:01<00:14, 264.44it/s] 14%|█▎        | 612/4500 [00:02<00:13, 286.43it/s] 14%|█▍        | 650/4500 [00:02<00:12, 306.81it/s] 15%|█▌        | 683/4500 [00:02<00:12, 310.62it/s] 16%|█▌        | 715/4500 [00:02<00:13, 272.37it/s] 17%|█▋        | 755/4500 [00:02<00:12, 303.44it/s] 17%|█▋        | 787/4500 [00:02<00:12, 290.33it/s] 19%|█▊        | 838/4500 [00:02<00:10, 345.01it/s] 20%|█▉        | 890/4500 [00:02<00:09, 386.55it/s] 21%|██        | 950/4500 [00:02<00:08, 433.19it/s] 22%|██▏       | 995/4500 [00:03<00:08, 428.31it/s] 23%|██▎       | 1039/4500 [00:03<00:08, 387.22it/s] 24%|██▍       | 1089/4500 [00:03<00:08, 411.34it/s] 26%|██▌       | 1178/4500 [00:03<00:06, 537.99it/s] 28%|██▊       | 1244/4500 [00:03<00:05, 571.68it/s] 29%|██▉       | 1303/4500 [00:03<00:06, 509.03it/s] 30%|███       | 1357/4500 [00:03<00:06, 451.23it/s] 31%|███       | 1405/4500 [00:03<00:07, 435.44it/s] 32%|███▏      | 1451/4500 [00:04<00:09, 330.47it/s] 33%|███▎      | 1489/4500 [00:04<00:09, 307.76it/s] 34%|███▍      | 1549/4500 [00:04<00:08, 364.90it/s] 36%|███▌      | 1612/4500 [00:04<00:06, 422.66it/s] 37%|███▋      | 1659/4500 [00:04<00:09, 306.85it/s] 38%|███▊      | 1697/4500 [00:04<00:09, 306.66it/s] 39%|███▉      | 1749/4500 [00:05<00:07, 345.63it/s] 40%|███▉      | 1789/4500 [00:05<00:07, 357.35it/s] 41%|████      | 1848/4500 [00:05<00:06, 401.68it/s] 42%|████▏     | 1892/4500 [00:05<00:06, 400.08it/s] 44%|████▎     | 1962/4500 [00:05<00:05, 470.72it/s] 45%|████▍     | 2012/4500 [00:05<00:05, 466.99it/s] 46%|████▌     | 2061/4500 [00:05<00:05, 432.14it/s] 47%|████▋     | 2106/4500 [00:05<00:05, 429.79it/s] 48%|████▊     | 2170/4500 [00:05<00:04, 485.12it/s] 49%|████▉     | 2220/4500 [00:06<00:05, 408.99it/s] 50%|█████     | 2264/4500 [00:06<00:06, 337.72it/s] 51%|█████     | 2302/4500 [00:06<00:07, 283.84it/s] 52%|█████▏    | 2334/4500 [00:06<00:07, 279.86it/s] 53%|█████▎    | 2377/4500 [00:06<00:06, 307.30it/s] 54%|█████▎    | 2411/4500 [00:06<00:07, 285.80it/s] 55%|█████▍    | 2471/4500 [00:06<00:05, 358.69it/s] 56%|█████▌    | 2513/4500 [00:07<00:05, 367.15it/s] 57%|█████▋    | 2562/4500 [00:07<00:04, 391.52it/s] 58%|█████▊    | 2612/4500 [00:07<00:04, 415.69it/s] 59%|█████▉    | 2656/4500 [00:07<00:04, 400.73it/s] 60%|█████▉    | 2698/4500 [00:07<00:04, 368.00it/s] 61%|██████    | 2742/4500 [00:07<00:04, 377.61it/s] 62%|██████▏   | 2781/4500 [00:07<00:04, 369.31it/s] 63%|██████▎   | 2825/4500 [00:07<00:04, 379.24it/s] 64%|██████▍   | 2874/4500 [00:07<00:04, 401.70it/s] 65%|██████▍   | 2922/4500 [00:08<00:03, 423.36it/s] 66%|██████▌   | 2965/4500 [00:08<00:03, 385.47it/s] 67%|██████▋   | 3011/4500 [00:08<00:03, 399.91it/s] 68%|██████▊   | 3052/4500 [00:08<00:03, 377.98it/s] 69%|██████▉   | 3104/4500 [00:08<00:03, 410.99it/s] 70%|██████▉   | 3146/4500 [00:08<00:03, 370.91it/s] 71%|███████   | 3185/4500 [00:08<00:04, 312.71it/s] 72%|███████▏  | 3219/4500 [00:09<00:04, 293.10it/s] 72%|███████▏  | 3262/4500 [00:09<00:03, 322.66it/s] 73%|███████▎  | 3305/4500 [00:09<00:03, 342.00it/s] 74%|███████▍  | 3341/4500 [00:09<00:03, 334.13it/s] 75%|███████▌  | 3376/4500 [00:09<00:03, 308.74it/s] 76%|███████▌  | 3408/4500 [00:09<00:03, 301.45it/s] 76%|███████▋  | 3442/4500 [00:09<00:03, 305.74it/s] 77%|███████▋  | 3474/4500 [00:09<00:03, 285.23it/s] 78%|███████▊  | 3503/4500 [00:10<00:04, 211.12it/s] 78%|███████▊  | 3527/4500 [00:10<00:04, 198.20it/s] 79%|███████▉  | 3549/4500 [00:10<00:05, 165.26it/s] 79%|███████▉  | 3568/4500 [00:10<00:06, 149.81it/s] 80%|███████▉  | 3585/4500 [00:10<00:06, 133.96it/s] 80%|████████  | 3600/4500 [00:10<00:07, 128.06it/s] 81%|████████  | 3649/4500 [00:10<00:04, 202.31it/s] 82%|████████▏ | 3695/4500 [00:11<00:03, 261.07it/s] 83%|████████▎ | 3735/4500 [00:11<00:02, 294.43it/s] 84%|████████▎ | 3768/4500 [00:11<00:02, 285.32it/s] 85%|████████▍ | 3803/4500 [00:11<00:02, 294.41it/s] 86%|████████▌ | 3853/4500 [00:11<00:01, 345.64it/s] 87%|████████▋ | 3899/4500 [00:11<00:01, 365.17it/s] 88%|████████▊ | 3948/4500 [00:11<00:01, 378.05it/s] 89%|████████▉ | 4005/4500 [00:11<00:01, 400.46it/s] 90%|████████▉ | 4049/4500 [00:11<00:01, 410.09it/s] 91%|█████████ | 4091/4500 [00:12<00:01, 376.60it/s] 92%|█████████▏| 4130/4500 [00:12<00:01, 315.78it/s] 93%|█████████▎| 4169/4500 [00:12<00:01, 324.14it/s] 93%|█████████▎| 4203/4500 [00:12<00:00, 302.83it/s] 95%|█████████▍| 4263/4500 [00:12<00:00, 376.14it/s] 96%|█████████▌| 4303/4500 [00:12<00:00, 377.30it/s] 97%|█████████▋| 4343/4500 [00:12<00:00, 362.82it/s] 97%|█████████▋| 4381/4500 [00:13<00:00, 303.14it/s] 98%|█████████▊| 4431/4500 [00:13<00:00, 347.21it/s] 99%|█████████▉| 4477/4500 [00:13<00:00, 374.49it/s]100%|██████████| 4500/4500 [00:13<00:00, 339.22it/s]
test_p89 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p89
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p89.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:15,  1.09it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.48it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.99it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.48it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.68it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p89_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p89_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p89_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p89_Holmes_probs.npy
{'Accuracy': 0.9871, 'Precision': 0.9873, 'Recall': 0.9871, 'F1-score': 0.9872}
starting gen taf script for test_p90
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 62/4500 [00:00<00:08, 536.45it/s]  3%|▎         | 116/4500 [00:00<00:10, 419.56it/s]  4%|▎         | 160/4500 [00:00<00:11, 384.58it/s]  4%|▍         | 199/4500 [00:00<00:12, 343.48it/s]  6%|▌         | 248/4500 [00:00<00:11, 382.15it/s]  7%|▋         | 300/4500 [00:00<00:10, 413.76it/s]  8%|▊         | 343/4500 [00:00<00:13, 298.04it/s]  8%|▊         | 378/4500 [00:01<00:16, 252.39it/s]  9%|▉         | 408/4500 [00:01<00:16, 243.23it/s] 10%|▉         | 448/4500 [00:01<00:14, 277.27it/s] 11%|█         | 486/4500 [00:01<00:13, 299.47it/s] 12%|█▏        | 519/4500 [00:01<00:13, 305.48it/s] 12%|█▏        | 558/4500 [00:01<00:12, 324.59it/s] 13%|█▎        | 593/4500 [00:01<00:11, 329.85it/s] 14%|█▍        | 629/4500 [00:01<00:11, 333.52it/s] 15%|█▍        | 665/4500 [00:02<00:11, 332.47it/s] 16%|█▌        | 706/4500 [00:02<00:10, 353.32it/s] 16%|█▋        | 742/4500 [00:02<00:12, 300.54it/s] 17%|█▋        | 774/4500 [00:02<00:12, 301.56it/s] 18%|█▊        | 812/4500 [00:02<00:11, 318.31it/s] 19%|█▉        | 850/4500 [00:02<00:10, 335.12it/s] 20%|██        | 903/4500 [00:02<00:09, 378.43it/s] 21%|██▏       | 957/4500 [00:02<00:08, 411.96it/s] 22%|██▏       | 999/4500 [00:03<00:09, 352.26it/s] 23%|██▎       | 1036/4500 [00:03<00:11, 314.46it/s] 24%|██▍       | 1075/4500 [00:03<00:10, 322.06it/s] 25%|██▌       | 1128/4500 [00:03<00:09, 373.34it/s] 27%|██▋       | 1217/4500 [00:03<00:06, 504.83it/s] 29%|██▉       | 1301/4500 [00:03<00:05, 583.61it/s] 30%|███       | 1362/4500 [00:03<00:06, 485.87it/s] 31%|███▏      | 1415/4500 [00:03<00:06, 445.69it/s] 33%|███▎      | 1463/4500 [00:04<00:09, 331.25it/s] 33%|███▎      | 1503/4500 [00:04<00:08, 336.41it/s] 35%|███▍      | 1553/4500 [00:04<00:08, 366.10it/s] 35%|███▌      | 1595/4500 [00:04<00:07, 372.17it/s] 36%|███▋      | 1636/4500 [00:04<00:08, 337.43it/s] 37%|███▋      | 1673/4500 [00:04<00:08, 344.99it/s] 38%|███▊      | 1710/4500 [00:04<00:08, 329.54it/s] 39%|███▉      | 1745/4500 [00:04<00:08, 319.22it/s] 40%|███▉      | 1784/4500 [00:05<00:08, 332.54it/s] 41%|████      | 1838/4500 [00:05<00:06, 386.87it/s] 42%|████▏     | 1884/4500 [00:05<00:06, 406.10it/s] 43%|████▎     | 1940/4500 [00:05<00:05, 444.03it/s] 44%|████▍     | 1987/4500 [00:05<00:05, 446.78it/s] 45%|████▌     | 2039/4500 [00:05<00:05, 460.71it/s] 46%|████▋     | 2086/4500 [00:05<00:05, 445.76it/s] 47%|████▋     | 2131/4500 [00:05<00:06, 387.92it/s] 48%|████▊     | 2173/4500 [00:05<00:05, 389.20it/s] 49%|████▉     | 2213/4500 [00:06<00:06, 368.03it/s] 50%|█████     | 2251/4500 [00:06<00:07, 300.71it/s] 51%|█████     | 2284/4500 [00:06<00:07, 289.70it/s] 52%|█████▏    | 2323/4500 [00:06<00:06, 313.52it/s] 52%|█████▏    | 2357/4500 [00:06<00:07, 268.62it/s] 53%|█████▎    | 2386/4500 [00:06<00:07, 269.11it/s] 54%|█████▍    | 2420/4500 [00:06<00:07, 280.13it/s] 55%|█████▍    | 2467/4500 [00:07<00:06, 328.59it/s] 56%|█████▌    | 2521/4500 [00:07<00:05, 365.84it/s] 57%|█████▋    | 2578/4500 [00:07<00:04, 412.88it/s] 58%|█████▊    | 2621/4500 [00:07<00:04, 399.40it/s] 59%|█████▉    | 2662/4500 [00:07<00:05, 357.54it/s] 60%|█████▉    | 2699/4500 [00:07<00:05, 342.62it/s] 61%|██████    | 2735/4500 [00:07<00:05, 318.04it/s] 62%|██████▏   | 2773/4500 [00:07<00:05, 325.59it/s] 63%|██████▎   | 2826/4500 [00:07<00:04, 372.06it/s] 64%|██████▍   | 2880/4500 [00:08<00:03, 415.84it/s] 65%|██████▍   | 2923/4500 [00:08<00:03, 404.39it/s] 66%|██████▌   | 2965/4500 [00:08<00:04, 368.86it/s] 67%|██████▋   | 3015/4500 [00:08<00:03, 393.89it/s] 68%|██████▊   | 3063/4500 [00:08<00:03, 401.52it/s] 69%|██████▉   | 3104/4500 [00:08<00:03, 399.58it/s] 70%|██████▉   | 3145/4500 [00:08<00:04, 306.16it/s] 71%|███████   | 3180/4500 [00:09<00:04, 276.88it/s] 72%|███████▏  | 3230/4500 [00:09<00:03, 323.13it/s] 73%|███████▎  | 3277/4500 [00:09<00:03, 350.91it/s] 74%|███████▎  | 3315/4500 [00:09<00:03, 337.67it/s] 74%|███████▍  | 3351/4500 [00:09<00:03, 340.18it/s] 75%|███████▌  | 3387/4500 [00:09<00:03, 326.05it/s] 76%|███████▌  | 3422/4500 [00:09<00:03, 323.68it/s] 77%|███████▋  | 3456/4500 [00:09<00:03, 274.04it/s] 78%|███████▊  | 3492/4500 [00:09<00:03, 290.22it/s] 78%|███████▊  | 3523/4500 [00:10<00:04, 208.84it/s] 79%|███████▉  | 3548/4500 [00:10<00:05, 160.91it/s] 79%|███████▉  | 3569/4500 [00:10<00:06, 149.34it/s] 80%|███████▉  | 3587/4500 [00:10<00:07, 128.19it/s] 81%|████████  | 3635/4500 [00:11<00:04, 188.86it/s] 81%|████████▏ | 3664/4500 [00:11<00:04, 207.26it/s] 83%|████████▎ | 3722/4500 [00:11<00:02, 276.87it/s] 84%|████████▎ | 3758/4500 [00:11<00:02, 296.10it/s] 84%|████████▍ | 3792/4500 [00:11<00:02, 274.84it/s] 85%|████████▌ | 3844/4500 [00:11<00:01, 330.04it/s] 87%|████████▋ | 3893/4500 [00:11<00:01, 368.89it/s] 87%|████████▋ | 3933/4500 [00:11<00:01, 358.10it/s] 89%|████████▊ | 3983/4500 [00:11<00:01, 372.31it/s] 90%|████████▉ | 4031/4500 [00:12<00:01, 394.16it/s] 90%|█████████ | 4072/4500 [00:12<00:01, 381.94it/s] 91%|█████████▏| 4111/4500 [00:12<00:01, 318.94it/s] 92%|█████████▏| 4145/4500 [00:12<00:01, 320.46it/s] 93%|█████████▎| 4179/4500 [00:12<00:01, 306.80it/s] 94%|█████████▎| 4211/4500 [00:12<00:00, 300.57it/s] 95%|█████████▍| 4270/4500 [00:12<00:00, 375.19it/s] 96%|█████████▌| 4310/4500 [00:12<00:00, 380.53it/s] 97%|█████████▋| 4350/4500 [00:13<00:00, 296.49it/s] 97%|█████████▋| 4384/4500 [00:13<00:00, 297.86it/s] 99%|█████████▊| 4442/4500 [00:13<00:00, 365.94it/s]100%|██████████| 4500/4500 [00:13<00:00, 335.75it/s]
test_p90 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p90
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p90.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:18,  1.10s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.48it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.41it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 18.55it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.03it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p90_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p90_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p90_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p90_Holmes_probs.npy
{'Accuracy': 0.9873, 'Precision': 0.9875, 'Recall': 0.9873, 'F1-score': 0.9874}
starting gen taf script for test_p91
  0%|          | 0/4500 [00:00<?, ?it/s]  2%|▏         | 75/4500 [00:00<00:06, 730.35it/s]  3%|▎         | 149/4500 [00:00<00:08, 487.83it/s]  5%|▍         | 203/4500 [00:00<00:10, 415.48it/s]  6%|▌         | 256/4500 [00:00<00:09, 445.58it/s]  7%|▋         | 306/4500 [00:00<00:09, 459.05it/s]  8%|▊         | 354/4500 [00:00<00:14, 294.23it/s]  9%|▊         | 392/4500 [00:01<00:16, 253.80it/s]  9%|▉         | 426/4500 [00:01<00:15, 269.42it/s] 10%|█         | 458/4500 [00:01<00:14, 273.02it/s] 11%|█         | 490/4500 [00:01<00:14, 280.02it/s] 12%|█▏        | 528/4500 [00:01<00:13, 297.88it/s] 12%|█▏        | 562/4500 [00:01<00:12, 306.36it/s] 13%|█▎        | 600/4500 [00:01<00:11, 325.36it/s] 14%|█▍        | 642/4500 [00:01<00:11, 343.89it/s] 15%|█▌        | 678/4500 [00:02<00:11, 343.07it/s] 16%|█▌        | 714/4500 [00:02<00:11, 338.22it/s] 17%|█▋        | 749/4500 [00:02<00:11, 317.39it/s] 17%|█▋        | 782/4500 [00:02<00:12, 294.01it/s] 18%|█▊        | 812/4500 [00:02<00:13, 275.18it/s] 19%|█▉        | 848/4500 [00:02<00:12, 293.99it/s] 20%|█▉        | 889/4500 [00:02<00:11, 323.28it/s] 21%|██        | 944/4500 [00:02<00:09, 385.45it/s] 22%|██▏       | 984/4500 [00:02<00:09, 363.10it/s] 23%|██▎       | 1022/4500 [00:03<00:09, 358.51it/s] 24%|██▎       | 1066/4500 [00:03<00:09, 378.61it/s] 26%|██▌       | 1156/4500 [00:03<00:06, 521.77it/s] 28%|██▊       | 1242/4500 [00:03<00:05, 608.50it/s] 29%|██▉       | 1305/4500 [00:03<00:05, 611.02it/s] 30%|███       | 1367/4500 [00:03<00:06, 480.34it/s] 32%|███▏      | 1420/4500 [00:03<00:06, 445.29it/s] 33%|███▎      | 1468/4500 [00:04<00:08, 343.73it/s] 34%|███▎      | 1508/4500 [00:04<00:08, 339.92it/s] 35%|███▍      | 1562/4500 [00:04<00:07, 380.00it/s] 36%|███▌      | 1606/4500 [00:04<00:07, 381.00it/s] 37%|███▋      | 1647/4500 [00:04<00:09, 313.37it/s] 37%|███▋      | 1682/4500 [00:04<00:09, 308.29it/s] 38%|███▊      | 1717/4500 [00:04<00:08, 311.70it/s] 39%|███▉      | 1761/4500 [00:04<00:08, 341.86it/s] 40%|████      | 1804/4500 [00:05<00:07, 357.16it/s] 42%|████▏     | 1873/4500 [00:05<00:05, 440.25it/s] 43%|████▎     | 1945/4500 [00:05<00:04, 515.24it/s] 44%|████▍     | 1999/4500 [00:05<00:05, 459.13it/s] 46%|████▌     | 2048/4500 [00:05<00:05, 448.58it/s] 47%|████▋     | 2095/4500 [00:05<00:05, 449.90it/s] 48%|████▊     | 2142/4500 [00:05<00:05, 409.79it/s] 49%|████▊     | 2188/4500 [00:05<00:05, 420.64it/s] 50%|████▉     | 2232/4500 [00:06<00:06, 331.78it/s] 50%|█████     | 2269/4500 [00:06<00:07, 296.90it/s] 51%|█████     | 2302/4500 [00:06<00:08, 264.64it/s] 52%|█████▏    | 2331/4500 [00:06<00:08, 268.86it/s] 53%|█████▎    | 2371/4500 [00:06<00:07, 299.34it/s] 53%|█████▎    | 2403/4500 [00:06<00:07, 287.73it/s] 54%|█████▍    | 2448/4500 [00:06<00:06, 318.86it/s] 56%|█████▌    | 2508/4500 [00:06<00:05, 391.43it/s] 57%|█████▋    | 2550/4500 [00:07<00:05, 374.40it/s] 58%|█████▊    | 2609/4500 [00:07<00:04, 430.35it/s] 59%|█████▉    | 2654/4500 [00:07<00:04, 382.15it/s] 60%|█████▉    | 2695/4500 [00:07<00:05, 360.39it/s] 61%|██████    | 2737/4500 [00:07<00:04, 368.93it/s] 62%|██████▏   | 2776/4500 [00:07<00:05, 337.10it/s] 62%|██████▏   | 2811/4500 [00:07<00:04, 339.43it/s] 64%|██████▎   | 2866/4500 [00:07<00:04, 391.31it/s] 65%|██████▍   | 2907/4500 [00:07<00:04, 388.16it/s] 65%|██████▌   | 2947/4500 [00:08<00:04, 380.36it/s] 66%|██████▋   | 2988/4500 [00:08<00:03, 380.88it/s] 67%|██████▋   | 3032/4500 [00:08<00:03, 392.31it/s] 68%|██████▊   | 3072/4500 [00:08<00:03, 368.28it/s] 69%|██████▉   | 3110/4500 [00:08<00:04, 329.70it/s] 70%|███████   | 3150/4500 [00:08<00:04, 336.45it/s] 71%|███████   | 3185/4500 [00:08<00:03, 330.64it/s] 72%|███████▏  | 3219/4500 [00:08<00:04, 308.92it/s] 72%|███████▏  | 3260/4500 [00:09<00:03, 327.48it/s] 73%|███████▎  | 3304/4500 [00:09<00:03, 357.50it/s] 74%|███████▍  | 3341/4500 [00:09<00:03, 317.60it/s] 75%|███████▌  | 3389/4500 [00:09<00:03, 358.00it/s] 76%|███████▌  | 3427/4500 [00:09<00:03, 316.20it/s] 77%|███████▋  | 3461/4500 [00:09<00:03, 287.89it/s] 78%|███████▊  | 3492/4500 [00:09<00:03, 290.14it/s] 78%|███████▊  | 3523/4500 [00:10<00:04, 196.99it/s] 79%|███████▉  | 3548/4500 [00:10<00:06, 156.00it/s] 79%|███████▉  | 3568/4500 [00:10<00:07, 128.59it/s] 80%|███████▉  | 3588/4500 [00:10<00:06, 140.23it/s] 80%|████████  | 3616/4500 [00:10<00:05, 161.81it/s] 81%|████████▏ | 3662/4500 [00:10<00:03, 222.59it/s] 82%|████████▏ | 3701/4500 [00:11<00:03, 254.57it/s] 83%|████████▎ | 3734/4500 [00:11<00:02, 265.74it/s] 84%|████████▍ | 3787/4500 [00:11<00:02, 327.72it/s] 85%|████████▍ | 3823/4500 [00:11<00:02, 335.48it/s] 86%|████████▌ | 3868/4500 [00:11<00:01, 359.25it/s] 87%|████████▋ | 3919/4500 [00:11<00:01, 400.31it/s] 88%|████████▊ | 3961/4500 [00:11<00:01, 395.72it/s] 89%|████████▉ | 4004/4500 [00:11<00:01, 381.78it/s] 90%|████████▉ | 4044/4500 [00:11<00:01, 366.29it/s] 91%|█████████ | 4093/4500 [00:12<00:01, 399.01it/s] 92%|█████████▏| 4134/4500 [00:12<00:01, 326.44it/s] 93%|█████████▎| 4170/4500 [00:12<00:01, 321.61it/s] 93%|█████████▎| 4204/4500 [00:12<00:00, 310.46it/s] 95%|█████████▍| 4274/4500 [00:12<00:00, 407.62it/s] 96%|█████████▌| 4318/4500 [00:12<00:00, 377.31it/s] 97%|█████████▋| 4358/4500 [00:12<00:00, 338.90it/s] 98%|█████████▊| 4394/4500 [00:12<00:00, 314.76it/s] 99%|█████████▉| 4447/4500 [00:13<00:00, 359.96it/s]100%|██████████| 4500/4500 [00:13<00:00, 342.53it/s]
test_p91 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p91
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p91.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.19it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.02it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 17.99it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.66it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p91_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p91_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p91_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p91_Holmes_probs.npy
{'Accuracy': 0.9878, 'Precision': 0.9879, 'Recall': 0.9878, 'F1-score': 0.9878}
starting gen taf script for test_p92
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 40/4500 [00:00<00:11, 399.18it/s]  2%|▏         | 80/4500 [00:00<00:11, 398.27it/s]  3%|▎         | 120/4500 [00:00<00:11, 366.84it/s]  3%|▎         | 157/4500 [00:00<00:12, 340.22it/s]  4%|▍         | 192/4500 [00:00<00:13, 323.87it/s]  5%|▌         | 236/4500 [00:00<00:12, 353.34it/s]  7%|▋         | 296/4500 [00:00<00:09, 424.32it/s]  8%|▊         | 340/4500 [00:01<00:14, 281.06it/s]  8%|▊         | 375/4500 [00:01<00:17, 232.11it/s]  9%|▉         | 404/4500 [00:01<00:18, 226.74it/s] 10%|▉         | 432/4500 [00:01<00:17, 234.87it/s] 11%|█         | 479/4500 [00:01<00:13, 287.25it/s] 11%|█▏        | 514/4500 [00:01<00:13, 295.52it/s] 12%|█▏        | 547/4500 [00:01<00:13, 298.53it/s] 13%|█▎        | 579/4500 [00:01<00:13, 292.92it/s] 14%|█▎        | 610/4500 [00:02<00:13, 294.10it/s] 14%|█▍        | 641/4500 [00:02<00:13, 287.43it/s] 15%|█▍        | 673/4500 [00:02<00:12, 295.69it/s] 16%|█▌        | 707/4500 [00:02<00:12, 299.92it/s] 16%|█▋        | 738/4500 [00:02<00:14, 251.94it/s] 17%|█▋        | 768/4500 [00:02<00:14, 263.78it/s] 18%|█▊        | 806/4500 [00:02<00:12, 289.72it/s] 19%|█▉        | 849/4500 [00:02<00:11, 327.52it/s] 20%|██        | 919/4500 [00:02<00:08, 430.19it/s] 21%|██▏       | 964/4500 [00:03<00:08, 429.40it/s] 23%|██▎       | 1021/4500 [00:03<00:07, 463.18it/s] 24%|██▍       | 1069/4500 [00:03<00:08, 411.66it/s] 25%|██▌       | 1129/4500 [00:03<00:07, 458.67it/s] 27%|██▋       | 1193/4500 [00:03<00:06, 496.10it/s] 28%|██▊       | 1244/4500 [00:03<00:06, 475.57it/s] 29%|██▉       | 1307/4500 [00:03<00:06, 502.39it/s] 30%|███       | 1359/4500 [00:03<00:06, 488.32it/s] 31%|███▏      | 1409/4500 [00:04<00:08, 382.64it/s] 32%|███▏      | 1451/4500 [00:04<00:08, 377.76it/s] 33%|███▎      | 1492/4500 [00:04<00:09, 306.58it/s] 34%|███▍      | 1532/4500 [00:04<00:09, 322.97it/s] 35%|███▍      | 1568/4500 [00:04<00:09, 316.84it/s] 36%|███▌      | 1602/4500 [00:04<00:10, 284.41it/s] 36%|███▋      | 1633/4500 [00:04<00:10, 261.05it/s] 37%|███▋      | 1661/4500 [00:05<00:10, 259.44it/s] 38%|███▊      | 1690/4500 [00:05<00:11, 253.37it/s] 39%|███▊      | 1738/4500 [00:05<00:09, 302.87it/s] 40%|███▉      | 1793/4500 [00:05<00:07, 363.47it/s] 41%|████      | 1846/4500 [00:05<00:06, 407.78it/s] 42%|████▏     | 1897/4500 [00:05<00:06, 428.84it/s] 43%|████▎     | 1948/4500 [00:05<00:05, 441.60it/s] 44%|████▍     | 1994/4500 [00:05<00:05, 445.13it/s] 45%|████▌     | 2040/4500 [00:05<00:05, 447.44it/s] 46%|████▋     | 2086/4500 [00:05<00:05, 442.67it/s] 47%|████▋     | 2131/4500 [00:06<00:05, 397.43it/s] 49%|████▊     | 2183/4500 [00:06<00:05, 427.07it/s] 49%|████▉     | 2227/4500 [00:06<00:06, 348.17it/s] 50%|█████     | 2265/4500 [00:06<00:07, 302.67it/s] 51%|█████     | 2298/4500 [00:06<00:07, 275.60it/s] 52%|█████▏    | 2330/4500 [00:06<00:07, 274.66it/s] 52%|█████▏    | 2359/4500 [00:07<00:08, 252.16it/s] 53%|█████▎    | 2387/4500 [00:07<00:08, 258.40it/s] 54%|█████▎    | 2416/4500 [00:07<00:07, 262.38it/s] 55%|█████▍    | 2471/4500 [00:07<00:06, 333.43it/s] 56%|█████▌    | 2515/4500 [00:07<00:05, 352.98it/s] 57%|█████▋    | 2567/4500 [00:07<00:04, 398.33it/s] 58%|█████▊    | 2608/4500 [00:07<00:05, 348.94it/s] 59%|█████▉    | 2651/4500 [00:07<00:05, 363.15it/s] 60%|█████▉    | 2689/4500 [00:07<00:05, 331.65it/s] 61%|██████    | 2728/4500 [00:08<00:05, 335.99it/s] 61%|██████▏   | 2763/4500 [00:08<00:05, 335.66it/s] 62%|██████▏   | 2798/4500 [00:08<00:05, 338.37it/s] 63%|██████▎   | 2847/4500 [00:08<00:04, 370.03it/s] 64%|██████▍   | 2902/4500 [00:08<00:03, 405.40it/s] 66%|██████▌   | 2962/4500 [00:08<00:03, 430.89it/s] 67%|██████▋   | 3006/4500 [00:08<00:03, 386.35it/s] 68%|██████▊   | 3061/4500 [00:08<00:03, 424.68it/s] 69%|██████▉   | 3105/4500 [00:09<00:03, 364.55it/s] 70%|██████▉   | 3144/4500 [00:09<00:04, 313.99it/s] 71%|███████   | 3180/4500 [00:09<00:04, 320.10it/s] 71%|███████▏  | 3215/4500 [00:09<00:03, 325.62it/s] 72%|███████▏  | 3256/4500 [00:09<00:03, 345.06it/s] 73%|███████▎  | 3306/4500 [00:09<00:03, 372.70it/s] 74%|███████▍  | 3345/4500 [00:09<00:03, 364.22it/s] 75%|███████▌  | 3383/4500 [00:09<00:03, 330.02it/s] 76%|███████▌  | 3417/4500 [00:10<00:03, 302.17it/s] 77%|███████▋  | 3450/4500 [00:10<00:03, 308.06it/s] 77%|███████▋  | 3482/4500 [00:10<00:03, 306.00it/s] 78%|███████▊  | 3514/4500 [00:10<00:04, 207.25it/s] 79%|███████▊  | 3540/4500 [00:10<00:05, 190.81it/s] 79%|███████▉  | 3563/4500 [00:10<00:05, 160.29it/s] 80%|███████▉  | 3582/4500 [00:11<00:06, 138.79it/s] 80%|███████▉  | 3598/4500 [00:11<00:06, 137.43it/s] 81%|████████  | 3638/4500 [00:11<00:04, 189.86it/s] 82%|████████▏ | 3697/4500 [00:11<00:02, 272.33it/s] 83%|████████▎ | 3739/4500 [00:11<00:02, 293.82it/s] 84%|████████▍ | 3778/4500 [00:11<00:02, 308.53it/s] 85%|████████▍ | 3820/4500 [00:11<00:02, 331.66it/s] 86%|████████▌ | 3861/4500 [00:11<00:01, 345.33it/s] 87%|████████▋ | 3901/4500 [00:11<00:01, 352.56it/s] 88%|████████▊ | 3959/4500 [00:12<00:01, 414.71it/s] 89%|████████▉ | 4002/4500 [00:12<00:01, 379.54it/s] 90%|████████▉ | 4049/4500 [00:12<00:01, 401.60it/s] 91%|█████████ | 4091/4500 [00:12<00:01, 348.29it/s] 92%|█████████▏| 4128/4500 [00:12<00:01, 351.35it/s] 93%|█████████▎| 4165/4500 [00:12<00:01, 334.81it/s] 93%|█████████▎| 4200/4500 [00:12<00:00, 318.76it/s] 94%|█████████▍| 4242/4500 [00:12<00:00, 339.89it/s] 96%|█████████▌| 4302/4500 [00:13<00:00, 404.15it/s] 97%|█████████▋| 4344/4500 [00:13<00:00, 371.26it/s] 97%|█████████▋| 4383/4500 [00:13<00:00, 342.19it/s] 98%|█████████▊| 4419/4500 [00:13<00:00, 339.48it/s] 99%|█████████▉| 4470/4500 [00:13<00:00, 376.22it/s]100%|██████████| 4500/4500 [00:13<00:00, 332.55it/s]
test_p92 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p92
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p92.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.00it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.96it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.27it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.58it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.88it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p92_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p92_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p92_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p92_Holmes_probs.npy
{'Accuracy': 0.9876, 'Precision': 0.9877, 'Recall': 0.9876, 'F1-score': 0.9876}
starting gen taf script for test_p93
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 44/4500 [00:00<00:10, 422.53it/s]  2%|▏         | 87/4500 [00:00<00:19, 230.89it/s]  3%|▎         | 119/4500 [00:00<00:17, 249.21it/s]  3%|▎         | 148/4500 [00:00<00:16, 256.82it/s]  4%|▍         | 176/4500 [00:00<00:18, 236.85it/s]  4%|▍         | 202/4500 [00:00<00:17, 241.24it/s]  5%|▌         | 237/4500 [00:00<00:15, 268.28it/s]  6%|▌         | 265/4500 [00:01<00:16, 261.17it/s]  6%|▋         | 292/4500 [00:01<00:16, 256.13it/s]  7%|▋         | 319/4500 [00:01<00:20, 206.43it/s]  8%|▊         | 342/4500 [00:01<00:21, 191.01it/s]  8%|▊         | 363/4500 [00:01<00:22, 183.66it/s]  9%|▊         | 383/4500 [00:01<00:23, 177.03it/s]  9%|▉         | 402/4500 [00:01<00:23, 176.97it/s] 10%|▉         | 432/4500 [00:01<00:19, 208.08it/s] 10%|█         | 459/4500 [00:02<00:18, 224.36it/s] 11%|█         | 483/4500 [00:02<00:17, 228.47it/s] 11%|█▏        | 517/4500 [00:02<00:15, 254.87it/s] 12%|█▏        | 543/4500 [00:02<00:15, 248.17it/s] 13%|█▎        | 575/4500 [00:02<00:14, 265.27it/s] 13%|█▎        | 603/4500 [00:02<00:14, 263.95it/s] 14%|█▍        | 637/4500 [00:02<00:13, 285.16it/s] 15%|█▍        | 667/4500 [00:02<00:13, 278.03it/s] 15%|█▌        | 696/4500 [00:02<00:13, 280.64it/s] 16%|█▌        | 725/4500 [00:02<00:13, 283.30it/s] 17%|█▋        | 754/4500 [00:03<00:14, 263.82it/s] 17%|█▋        | 781/4500 [00:03<00:15, 237.92it/s] 19%|█▊        | 842/4500 [00:03<00:10, 335.57it/s] 20%|██        | 902/4500 [00:03<00:09, 399.73it/s] 21%|██        | 945/4500 [00:03<00:08, 405.87it/s] 22%|██▏       | 988/4500 [00:03<00:08, 395.93it/s] 23%|██▎       | 1029/4500 [00:03<00:08, 399.62it/s] 24%|██▍       | 1074/4500 [00:03<00:08, 391.89it/s] 25%|██▌       | 1133/4500 [00:04<00:07, 444.69it/s] 27%|██▋       | 1217/4500 [00:04<00:05, 550.68it/s] 28%|██▊       | 1273/4500 [00:04<00:07, 441.32it/s] 29%|██▉       | 1327/4500 [00:04<00:06, 456.54it/s] 31%|███       | 1376/4500 [00:04<00:07, 430.56it/s] 32%|███▏      | 1422/4500 [00:04<00:08, 343.70it/s] 32%|███▏      | 1461/4500 [00:04<00:09, 318.83it/s] 33%|███▎      | 1496/4500 [00:05<00:10, 287.53it/s] 35%|███▍      | 1553/4500 [00:05<00:08, 343.09it/s] 36%|███▌      | 1603/4500 [00:05<00:07, 376.46it/s] 37%|███▋      | 1644/4500 [00:05<00:09, 293.60it/s] 37%|███▋      | 1678/4500 [00:05<00:10, 281.66it/s] 38%|███▊      | 1710/4500 [00:05<00:10, 277.03it/s] 39%|███▉      | 1755/4500 [00:05<00:08, 313.03it/s] 40%|███▉      | 1789/4500 [00:05<00:08, 311.53it/s] 42%|████▏     | 1869/4500 [00:06<00:06, 427.72it/s] 43%|████▎     | 1926/4500 [00:06<00:05, 459.60it/s] 44%|████▍     | 1974/4500 [00:06<00:05, 431.80it/s] 45%|████▌     | 2033/4500 [00:06<00:05, 464.85it/s] 46%|████▌     | 2081/4500 [00:06<00:05, 419.18it/s] 47%|████▋     | 2125/4500 [00:06<00:05, 408.38it/s] 48%|████▊     | 2167/4500 [00:06<00:05, 406.02it/s] 49%|████▉     | 2209/4500 [00:06<00:05, 384.51it/s] 50%|████▉     | 2249/4500 [00:07<00:07, 286.05it/s] 51%|█████     | 2285/4500 [00:07<00:07, 289.50it/s] 51%|█████▏    | 2317/4500 [00:07<00:08, 268.04it/s] 52%|█████▏    | 2346/4500 [00:07<00:08, 241.59it/s] 53%|█████▎    | 2372/4500 [00:07<00:08, 240.85it/s] 53%|█████▎    | 2401/4500 [00:07<00:08, 252.06it/s] 54%|█████▍    | 2428/4500 [00:07<00:08, 251.86it/s] 55%|█████▍    | 2472/4500 [00:07<00:06, 299.29it/s] 56%|█████▌    | 2523/4500 [00:08<00:05, 347.01it/s] 58%|█████▊    | 2597/4500 [00:08<00:04, 425.45it/s] 59%|█████▊    | 2640/4500 [00:08<00:04, 391.26it/s] 60%|█████▉    | 2680/4500 [00:08<00:04, 379.68it/s] 60%|██████    | 2719/4500 [00:08<00:04, 358.61it/s] 61%|██████    | 2756/4500 [00:08<00:05, 348.10it/s] 62%|██████▏   | 2794/4500 [00:08<00:04, 351.38it/s] 63%|██████▎   | 2850/4500 [00:08<00:04, 405.73it/s] 64%|██████▍   | 2892/4500 [00:09<00:03, 408.59it/s] 65%|██████▌   | 2944/4500 [00:09<00:03, 429.60it/s] 66%|██████▋   | 2988/4500 [00:09<00:03, 421.43it/s] 67%|██████▋   | 3031/4500 [00:09<00:03, 407.39it/s] 68%|██████▊   | 3072/4500 [00:09<00:03, 386.30it/s] 69%|██████▉   | 3111/4500 [00:09<00:04, 342.38it/s] 70%|██████▉   | 3147/4500 [00:09<00:03, 340.34it/s] 71%|███████   | 3182/4500 [00:09<00:04, 267.92it/s] 72%|███████▏  | 3225/4500 [00:10<00:04, 296.64it/s] 73%|███████▎  | 3269/4500 [00:10<00:03, 324.24it/s] 73%|███████▎  | 3304/4500 [00:10<00:03, 325.19it/s] 74%|███████▍  | 3339/4500 [00:10<00:03, 308.17it/s] 75%|███████▌  | 3392/4500 [00:10<00:03, 350.86it/s] 76%|███████▌  | 3429/4500 [00:10<00:03, 338.03it/s] 77%|███████▋  | 3464/4500 [00:10<00:03, 324.73it/s] 78%|███████▊  | 3497/4500 [00:10<00:03, 298.89it/s] 78%|███████▊  | 3528/4500 [00:11<00:05, 182.49it/s] 79%|███████▉  | 3552/4500 [00:11<00:06, 147.26it/s] 79%|███████▉  | 3572/4500 [00:11<00:07, 129.36it/s] 80%|███████▉  | 3591/4500 [00:11<00:06, 138.52it/s] 81%|████████  | 3635/4500 [00:11<00:04, 192.60it/s] 82%|████████▏ | 3674/4500 [00:12<00:03, 225.57it/s] 83%|████████▎ | 3713/4500 [00:12<00:03, 258.17it/s] 83%|████████▎ | 3744/4500 [00:12<00:02, 262.07it/s] 84%|████████▍ | 3787/4500 [00:12<00:02, 300.43it/s] 85%|████████▌ | 3832/4500 [00:12<00:02, 326.09it/s] 86%|████████▌ | 3876/4500 [00:12<00:01, 354.67it/s] 87%|████████▋ | 3932/4500 [00:12<00:01, 407.83it/s] 89%|████████▊ | 3990/4500 [00:12<00:01, 452.75it/s] 90%|████████▉ | 4037/4500 [00:12<00:01, 369.24it/s] 91%|█████████ | 4087/4500 [00:13<00:01, 400.86it/s] 92%|█████████▏| 4131/4500 [00:13<00:01, 360.72it/s] 93%|█████████▎| 4170/4500 [00:13<00:00, 335.42it/s] 93%|█████████▎| 4206/4500 [00:13<00:00, 308.84it/s] 94%|█████████▍| 4245/4500 [00:13<00:00, 326.88it/s] 96%|█████████▌| 4302/4500 [00:13<00:00, 386.68it/s] 97%|█████████▋| 4343/4500 [00:13<00:00, 385.56it/s] 97%|█████████▋| 4383/4500 [00:13<00:00, 343.37it/s] 98%|█████████▊| 4420/4500 [00:14<00:00, 348.82it/s]100%|█████████▉| 4495/4500 [00:14<00:00, 454.59it/s]100%|██████████| 4500/4500 [00:14<00:00, 317.25it/s]
test_p93 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p93
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p93.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:20,  1.18s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.02it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 11.72it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 17.66it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 11.39it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p93_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p93_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p93_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p93_Holmes_probs.npy
{'Accuracy': 0.9876, 'Precision': 0.9877, 'Recall': 0.9876, 'F1-score': 0.9876}
starting gen taf script for test_p94
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 45/4500 [00:00<00:10, 440.83it/s]  2%|▏         | 90/4500 [00:00<00:11, 385.30it/s]  3%|▎         | 129/4500 [00:00<00:11, 368.13it/s]  4%|▎         | 167/4500 [00:00<00:11, 370.04it/s]  5%|▍         | 205/4500 [00:00<00:11, 373.40it/s]  6%|▌         | 264/4500 [00:00<00:09, 437.23it/s]  7%|▋         | 308/4500 [00:00<00:10, 399.88it/s]  8%|▊         | 349/4500 [00:00<00:13, 299.87it/s]  9%|▊         | 383/4500 [00:01<00:17, 240.74it/s]  9%|▉         | 416/4500 [00:01<00:16, 253.45it/s] 10%|█         | 459/4500 [00:01<00:14, 287.23it/s] 11%|█         | 504/4500 [00:01<00:12, 323.66it/s] 12%|█▏        | 540/4500 [00:01<00:12, 323.26it/s] 13%|█▎        | 590/4500 [00:01<00:10, 367.10it/s] 14%|█▍        | 629/4500 [00:01<00:11, 336.68it/s] 15%|█▍        | 672/4500 [00:02<00:10, 353.73it/s] 16%|█▌        | 709/4500 [00:02<00:12, 310.33it/s] 17%|█▋        | 752/4500 [00:02<00:11, 338.99it/s] 18%|█▊        | 792/4500 [00:02<00:10, 352.93it/s] 19%|█▊        | 836/4500 [00:02<00:09, 376.38it/s] 20%|█▉        | 899/4500 [00:02<00:08, 428.50it/s] 21%|██        | 943/4500 [00:02<00:08, 410.67it/s] 22%|██▏       | 988/4500 [00:02<00:08, 407.53it/s] 23%|██▎       | 1038/4500 [00:02<00:08, 420.86it/s] 24%|██▍       | 1081/4500 [00:03<00:09, 377.38it/s] 26%|██▌       | 1156/4500 [00:03<00:07, 472.07it/s] 27%|██▋       | 1231/4500 [00:03<00:06, 536.38it/s] 29%|██▉       | 1309/4500 [00:03<00:05, 602.91it/s] 30%|███       | 1372/4500 [00:03<00:06, 495.02it/s] 32%|███▏      | 1426/4500 [00:03<00:08, 379.26it/s] 33%|███▎      | 1471/4500 [00:03<00:09, 327.76it/s] 34%|███▎      | 1510/4500 [00:04<00:09, 317.05it/s] 35%|███▌      | 1577/4500 [00:04<00:07, 383.97it/s] 36%|███▌      | 1621/4500 [00:04<00:07, 380.59it/s] 37%|███▋      | 1663/4500 [00:04<00:10, 267.93it/s] 38%|███▊      | 1699/4500 [00:04<00:09, 280.29it/s] 39%|███▊      | 1742/4500 [00:04<00:08, 306.62it/s] 40%|███▉      | 1786/4500 [00:04<00:08, 333.08it/s] 41%|████      | 1831/4500 [00:05<00:07, 358.39it/s] 43%|████▎     | 1914/4500 [00:05<00:05, 470.88it/s] 44%|████▎     | 1965/4500 [00:05<00:05, 478.17it/s] 45%|████▍     | 2016/4500 [00:05<00:05, 464.69it/s] 46%|████▌     | 2075/4500 [00:05<00:04, 491.12it/s] 47%|████▋     | 2126/4500 [00:05<00:05, 451.59it/s] 48%|████▊     | 2173/4500 [00:05<00:05, 441.07it/s] 49%|████▉     | 2219/4500 [00:05<00:05, 385.88it/s] 50%|█████     | 2260/4500 [00:06<00:07, 303.88it/s] 51%|█████     | 2294/4500 [00:06<00:07, 298.25it/s] 52%|█████▏    | 2327/4500 [00:06<00:07, 278.35it/s] 52%|█████▏    | 2357/4500 [00:06<00:08, 266.76it/s] 53%|█████▎    | 2385/4500 [00:06<00:07, 267.30it/s] 54%|█████▍    | 2448/4500 [00:06<00:05, 350.07it/s] 55%|█████▌    | 2487/4500 [00:06<00:05, 359.59it/s] 56%|█████▋    | 2535/4500 [00:06<00:05, 385.60it/s] 58%|█████▊    | 2590/4500 [00:07<00:04, 428.61it/s] 59%|█████▊    | 2634/4500 [00:07<00:04, 388.99it/s] 59%|█████▉    | 2675/4500 [00:07<00:04, 381.60it/s] 60%|██████    | 2715/4500 [00:07<00:05, 353.50it/s] 61%|██████    | 2752/4500 [00:07<00:05, 339.46it/s] 62%|██████▏   | 2794/4500 [00:07<00:04, 354.56it/s] 64%|██████▎   | 2860/4500 [00:07<00:03, 434.91it/s] 65%|██████▍   | 2908/4500 [00:07<00:03, 441.56it/s] 66%|██████▌   | 2954/4500 [00:07<00:03, 438.22it/s] 67%|██████▋   | 3000/4500 [00:08<00:03, 440.54it/s] 68%|██████▊   | 3045/4500 [00:08<00:03, 423.57it/s] 69%|██████▊   | 3088/4500 [00:08<00:03, 424.20it/s] 70%|██████▉   | 3131/4500 [00:08<00:04, 318.62it/s] 70%|███████   | 3167/4500 [00:08<00:04, 294.67it/s] 71%|███████   | 3204/4500 [00:08<00:04, 302.54it/s] 72%|███████▏  | 3256/4500 [00:08<00:03, 354.86it/s] 74%|███████▎  | 3308/4500 [00:08<00:03, 387.17it/s] 74%|███████▍  | 3349/4500 [00:09<00:02, 391.73it/s] 75%|███████▌  | 3390/4500 [00:09<00:03, 342.83it/s] 76%|███████▌  | 3427/4500 [00:09<00:03, 345.62it/s] 77%|███████▋  | 3464/4500 [00:09<00:03, 312.12it/s] 78%|███████▊  | 3497/4500 [00:09<00:04, 242.54it/s] 78%|███████▊  | 3525/4500 [00:09<00:04, 205.87it/s] 79%|███████▉  | 3549/4500 [00:10<00:06, 156.26it/s] 79%|███████▉  | 3568/4500 [00:10<00:06, 152.72it/s] 80%|███████▉  | 3586/4500 [00:10<00:07, 122.81it/s] 80%|████████  | 3620/4500 [00:10<00:05, 159.02it/s] 82%|████████▏ | 3670/4500 [00:10<00:03, 221.93it/s] 82%|████████▏ | 3709/4500 [00:10<00:03, 257.01it/s] 83%|████████▎ | 3740/4500 [00:11<00:02, 268.12it/s] 84%|████████▍ | 3778/4500 [00:11<00:02, 287.72it/s] 85%|████████▍ | 3812/4500 [00:11<00:02, 294.49it/s] 86%|████████▌ | 3873/4500 [00:11<00:01, 369.29it/s] 87%|████████▋ | 3912/4500 [00:11<00:01, 323.62it/s] 88%|████████▊ | 3979/4500 [00:11<00:01, 400.02it/s] 89%|████████▉ | 4022/4500 [00:11<00:01, 392.54it/s] 90%|█████████ | 4063/4500 [00:11<00:01, 364.46it/s] 91%|█████████ | 4101/4500 [00:11<00:01, 367.41it/s] 92%|█████████▏| 4139/4500 [00:12<00:01, 342.78it/s] 93%|█████████▎| 4175/4500 [00:12<00:01, 319.06it/s] 94%|█████████▎| 4208/4500 [00:12<00:00, 296.61it/s] 95%|█████████▍| 4264/4500 [00:12<00:00, 362.46it/s] 96%|█████████▌| 4302/4500 [00:12<00:00, 363.92it/s] 96%|█████████▋| 4340/4500 [00:12<00:00, 342.06it/s] 97%|█████████▋| 4376/4500 [00:12<00:00, 292.19it/s] 99%|█████████▊| 4437/4500 [00:12<00:00, 359.83it/s]100%|██████████| 4500/4500 [00:13<00:00, 344.73it/s]
test_p94 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p94
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p94.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.02s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.83it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.90it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.03it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.58it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p94_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p94_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p94_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p94_Holmes_probs.npy
{'Accuracy': 0.988, 'Precision': 0.9881, 'Recall': 0.988, 'F1-score': 0.988}
starting gen taf script for test_p95
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 50/4500 [00:00<00:09, 471.62it/s]  2%|▏         | 98/4500 [00:00<00:11, 388.25it/s]  3%|▎         | 138/4500 [00:00<00:13, 329.50it/s]  4%|▍         | 172/4500 [00:00<00:14, 302.49it/s]  5%|▍         | 203/4500 [00:00<00:15, 279.43it/s]  6%|▌         | 248/4500 [00:00<00:13, 322.35it/s]  7%|▋         | 293/4500 [00:00<00:11, 356.96it/s]  7%|▋         | 330/4500 [00:01<00:15, 265.40it/s]  8%|▊         | 361/4500 [00:01<00:17, 236.35it/s]  9%|▊         | 388/4500 [00:01<00:20, 205.57it/s]  9%|▉         | 414/4500 [00:01<00:18, 216.98it/s] 10%|█         | 452/4500 [00:01<00:15, 253.57it/s] 11%|█         | 484/4500 [00:01<00:14, 268.41it/s] 11%|█▏        | 514/4500 [00:01<00:14, 276.57it/s] 12%|█▏        | 549/4500 [00:01<00:13, 287.12it/s] 13%|█▎        | 579/4500 [00:02<00:13, 287.46it/s] 14%|█▎        | 611/4500 [00:02<00:13, 289.20it/s] 14%|█▍        | 647/4500 [00:02<00:12, 306.10it/s] 15%|█▌        | 679/4500 [00:02<00:12, 301.05it/s] 16%|█▌        | 710/4500 [00:02<00:13, 275.81it/s] 16%|█▋        | 739/4500 [00:02<00:14, 263.78it/s] 17%|█▋        | 766/4500 [00:02<00:14, 262.83it/s] 18%|█▊        | 793/4500 [00:02<00:15, 245.89it/s] 19%|█▉        | 861/4500 [00:02<00:10, 359.94it/s] 21%|██        | 931/4500 [00:03<00:08, 438.36it/s] 22%|██▏       | 976/4500 [00:03<00:08, 396.62it/s] 23%|██▎       | 1023/4500 [00:03<00:08, 410.26it/s] 24%|██▎       | 1066/4500 [00:03<00:08, 411.56it/s] 25%|██▍       | 1108/4500 [00:03<00:08, 388.99it/s] 27%|██▋       | 1202/4500 [00:03<00:06, 530.95it/s] 28%|██▊       | 1278/4500 [00:03<00:05, 588.16it/s] 30%|██▉       | 1339/4500 [00:03<00:07, 446.59it/s] 31%|███       | 1390/4500 [00:04<00:06, 445.78it/s] 32%|███▏      | 1439/4500 [00:04<00:08, 369.02it/s] 33%|███▎      | 1481/4500 [00:04<00:10, 294.00it/s] 35%|███▍      | 1568/4500 [00:04<00:07, 403.85it/s] 36%|███▌      | 1618/4500 [00:04<00:08, 353.16it/s] 37%|███▋      | 1661/4500 [00:04<00:08, 333.50it/s] 38%|███▊      | 1700/4500 [00:05<00:09, 303.02it/s] 39%|███▊      | 1734/4500 [00:05<00:09, 300.94it/s] 40%|████      | 1804/4500 [00:05<00:07, 374.80it/s] 41%|████      | 1850/4500 [00:05<00:06, 394.03it/s] 42%|████▏     | 1902/4500 [00:05<00:06, 425.60it/s] 43%|████▎     | 1948/4500 [00:05<00:05, 429.65it/s] 45%|████▍     | 2007/4500 [00:05<00:05, 463.39it/s] 46%|████▌     | 2058/4500 [00:05<00:05, 464.39it/s] 47%|████▋     | 2106/4500 [00:06<00:05, 405.94it/s] 48%|████▊     | 2156/4500 [00:06<00:05, 420.38it/s] 49%|████▉     | 2200/4500 [00:06<00:06, 355.44it/s] 50%|████▉     | 2238/4500 [00:06<00:06, 332.48it/s] 51%|█████     | 2273/4500 [00:06<00:06, 331.54it/s] 51%|█████▏    | 2308/4500 [00:06<00:07, 308.08it/s] 52%|█████▏    | 2340/4500 [00:06<00:07, 286.81it/s] 53%|█████▎    | 2370/4500 [00:07<00:08, 250.24it/s] 53%|█████▎    | 2403/4500 [00:07<00:07, 263.69it/s] 54%|█████▍    | 2442/4500 [00:07<00:07, 290.98it/s] 55%|█████▌    | 2491/4500 [00:07<00:05, 339.22it/s] 56%|█████▋    | 2540/4500 [00:07<00:05, 373.38it/s] 57%|█████▋    | 2582/4500 [00:07<00:05, 380.72it/s] 58%|█████▊    | 2631/4500 [00:07<00:04, 401.04it/s] 59%|█████▉    | 2672/4500 [00:07<00:05, 316.94it/s] 61%|██████    | 2730/4500 [00:07<00:04, 379.58it/s] 62%|██████▏   | 2772/4500 [00:08<00:04, 378.50it/s] 63%|██████▎   | 2813/4500 [00:08<00:04, 376.89it/s] 63%|██████▎   | 2853/4500 [00:08<00:04, 375.04it/s] 65%|██████▍   | 2904/4500 [00:08<00:03, 411.57it/s] 65%|██████▌   | 2947/4500 [00:08<00:03, 409.04it/s] 66%|██████▋   | 2989/4500 [00:08<00:03, 397.75it/s] 67%|██████▋   | 3033/4500 [00:08<00:03, 399.14it/s] 68%|██████▊   | 3076/4500 [00:08<00:03, 396.30it/s] 69%|██████▉   | 3116/4500 [00:08<00:03, 390.23it/s] 70%|███████   | 3156/4500 [00:09<00:04, 280.24it/s] 71%|███████   | 3192/4500 [00:09<00:04, 295.74it/s] 72%|███████▏  | 3226/4500 [00:09<00:04, 304.67it/s] 72%|███████▏  | 3260/4500 [00:09<00:04, 295.41it/s] 73%|███████▎  | 3301/4500 [00:09<00:03, 318.58it/s] 74%|███████▍  | 3335/4500 [00:09<00:03, 314.25it/s] 75%|███████▍  | 3371/4500 [00:09<00:03, 318.10it/s] 76%|███████▌  | 3404/4500 [00:09<00:03, 310.26it/s] 76%|███████▋  | 3436/4500 [00:10<00:03, 298.04it/s] 77%|███████▋  | 3467/4500 [00:10<00:03, 291.42it/s] 78%|███████▊  | 3497/4500 [00:10<00:04, 246.09it/s] 78%|███████▊  | 3523/4500 [00:10<00:05, 164.66it/s] 79%|███████▉  | 3549/4500 [00:10<00:05, 173.37it/s] 79%|███████▉  | 3570/4500 [00:11<00:06, 144.97it/s] 80%|███████▉  | 3588/4500 [00:11<00:06, 139.53it/s] 80%|████████  | 3608/4500 [00:11<00:05, 151.35it/s] 81%|████████  | 3638/4500 [00:11<00:04, 183.92it/s] 82%|████████▏ | 3696/4500 [00:11<00:02, 272.74it/s] 83%|████████▎ | 3735/4500 [00:11<00:02, 294.92it/s] 84%|████████▎ | 3767/4500 [00:11<00:02, 285.06it/s] 84%|████████▍ | 3800/4500 [00:11<00:02, 296.60it/s] 85%|████████▌ | 3841/4500 [00:11<00:02, 316.63it/s] 86%|████████▋ | 3883/4500 [00:12<00:01, 340.75it/s] 87%|████████▋ | 3935/4500 [00:12<00:01, 379.00it/s] 88%|████████▊ | 3982/4500 [00:12<00:01, 396.52it/s] 89%|████████▉ | 4023/4500 [00:12<00:01, 372.20it/s] 90%|█████████ | 4069/4500 [00:12<00:01, 388.61it/s] 91%|█████████▏| 4109/4500 [00:12<00:01, 381.00it/s] 92%|█████████▏| 4148/4500 [00:12<00:01, 342.34it/s] 93%|█████████▎| 4184/4500 [00:12<00:00, 317.89it/s] 94%|█████████▎| 4217/4500 [00:12<00:00, 317.31it/s] 94%|█████████▍| 4250/4500 [00:13<00:00, 291.58it/s] 95%|█████████▌| 4287/4500 [00:13<00:00, 306.94it/s] 96%|█████████▋| 4335/4500 [00:13<00:00, 344.41it/s] 97%|█████████▋| 4371/4500 [00:13<00:00, 292.86it/s] 98%|█████████▊| 4402/4500 [00:13<00:00, 280.03it/s] 99%|█████████▉| 4461/4500 [00:13<00:00, 348.85it/s]100%|██████████| 4500/4500 [00:13<00:00, 326.55it/s]
test_p95 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p95
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p95.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.04it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.19it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.65it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.03it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.20it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p95_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p95_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p95_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p95_Holmes_probs.npy
{'Accuracy': 0.9878, 'Precision': 0.9879, 'Recall': 0.9878, 'F1-score': 0.9878}
starting gen taf script for test_p96
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 50/4500 [00:00<00:08, 497.71it/s]  2%|▏         | 100/4500 [00:00<00:11, 376.96it/s]  3%|▎         | 140/4500 [00:00<00:12, 348.37it/s]  4%|▍         | 176/4500 [00:00<00:12, 341.80it/s]  5%|▍         | 211/4500 [00:00<00:12, 343.60it/s]  6%|▌         | 266/4500 [00:00<00:10, 405.20it/s]  7%|▋         | 308/4500 [00:00<00:10, 388.05it/s]  8%|▊         | 348/4500 [00:01<00:14, 287.47it/s]  8%|▊         | 381/4500 [00:01<00:17, 235.24it/s]  9%|▉         | 411/4500 [00:01<00:16, 244.98it/s] 10%|▉         | 449/4500 [00:01<00:14, 271.60it/s] 11%|█         | 479/4500 [00:01<00:14, 270.09it/s] 11%|█▏        | 508/4500 [00:01<00:15, 263.83it/s] 12%|█▏        | 536/4500 [00:01<00:15, 260.79it/s] 13%|█▎        | 564/4500 [00:01<00:14, 264.70it/s] 13%|█▎        | 604/4500 [00:02<00:13, 293.06it/s] 14%|█▍        | 642/4500 [00:02<00:12, 310.37it/s] 15%|█▍        | 674/4500 [00:02<00:13, 291.15it/s] 16%|█▌        | 704/4500 [00:02<00:14, 267.50it/s] 16%|█▋        | 736/4500 [00:02<00:13, 280.88it/s] 17%|█▋        | 765/4500 [00:02<00:14, 249.07it/s] 18%|█▊        | 791/4500 [00:02<00:15, 246.74it/s] 19%|█▉        | 848/4500 [00:02<00:11, 329.25it/s] 20%|██        | 908/4500 [00:02<00:09, 398.24it/s] 21%|██▏       | 966/4500 [00:03<00:08, 439.78it/s] 22%|██▏       | 1012/4500 [00:03<00:08, 409.23it/s] 23%|██▎       | 1055/4500 [00:03<00:09, 381.73it/s] 24%|██▍       | 1095/4500 [00:03<00:08, 382.42it/s] 26%|██▋       | 1186/4500 [00:03<00:06, 522.22it/s] 28%|██▊       | 1241/4500 [00:03<00:06, 529.66it/s] 29%|██▉       | 1296/4500 [00:03<00:07, 438.84it/s] 30%|██▉       | 1344/4500 [00:03<00:07, 440.74it/s] 31%|███       | 1395/4500 [00:04<00:06, 446.16it/s] 32%|███▏      | 1442/4500 [00:04<00:08, 356.18it/s] 33%|███▎      | 1482/4500 [00:04<00:09, 301.95it/s] 34%|███▎      | 1516/4500 [00:04<00:09, 299.44it/s] 35%|███▌      | 1575/4500 [00:04<00:08, 360.89it/s] 36%|███▌      | 1615/4500 [00:04<00:08, 345.32it/s] 37%|███▋      | 1652/4500 [00:04<00:10, 270.14it/s] 37%|███▋      | 1683/4500 [00:05<00:11, 253.49it/s] 38%|███▊      | 1720/4500 [00:05<00:10, 277.99it/s] 39%|███▉      | 1767/4500 [00:05<00:08, 318.53it/s] 41%|████      | 1826/4500 [00:05<00:07, 379.04it/s] 41%|████▏     | 1867/4500 [00:05<00:06, 382.48it/s] 43%|████▎     | 1918/4500 [00:05<00:06, 416.56it/s] 44%|████▍     | 1977/4500 [00:05<00:05, 459.22it/s] 45%|████▌     | 2030/4500 [00:05<00:05, 478.28it/s] 46%|████▌     | 2080/4500 [00:06<00:05, 428.27it/s] 47%|████▋     | 2137/4500 [00:06<00:05, 463.01it/s] 49%|████▊     | 2185/4500 [00:06<00:05, 403.80it/s] 50%|████▉     | 2228/4500 [00:06<00:06, 368.59it/s] 50%|█████     | 2267/4500 [00:06<00:06, 345.67it/s] 51%|█████     | 2303/4500 [00:06<00:07, 301.76it/s] 52%|█████▏    | 2335/4500 [00:06<00:08, 256.80it/s] 53%|█████▎    | 2368/4500 [00:06<00:07, 272.43it/s] 53%|█████▎    | 2398/4500 [00:07<00:08, 256.21it/s] 54%|█████▍    | 2435/4500 [00:07<00:07, 273.57it/s] 55%|█████▌    | 2487/4500 [00:07<00:06, 325.40it/s] 56%|█████▌    | 2525/4500 [00:07<00:05, 336.87it/s] 57%|█████▋    | 2575/4500 [00:07<00:05, 373.39it/s] 58%|█████▊    | 2624/4500 [00:07<00:04, 396.22it/s] 59%|█████▉    | 2665/4500 [00:07<00:04, 388.31it/s] 60%|██████    | 2705/4500 [00:07<00:04, 360.23it/s] 61%|██████    | 2742/4500 [00:08<00:05, 345.91it/s] 62%|██████▏   | 2781/4500 [00:08<00:05, 340.23it/s] 63%|██████▎   | 2819/4500 [00:08<00:04, 337.54it/s] 64%|██████▍   | 2872/4500 [00:08<00:04, 388.94it/s] 65%|██████▍   | 2916/4500 [00:08<00:04, 391.29it/s] 66%|██████▌   | 2956/4500 [00:08<00:04, 377.99it/s] 67%|██████▋   | 2999/4500 [00:08<00:03, 383.26it/s] 68%|██████▊   | 3058/4500 [00:08<00:03, 425.97it/s] 69%|██████▉   | 3101/4500 [00:08<00:03, 398.39it/s] 70%|██████▉   | 3142/4500 [00:09<00:04, 308.03it/s] 71%|███████   | 3176/4500 [00:09<00:04, 303.25it/s] 71%|███████▏  | 3209/4500 [00:09<00:04, 303.76it/s] 72%|███████▏  | 3261/4500 [00:09<00:03, 353.38it/s] 73%|███████▎  | 3299/4500 [00:09<00:03, 342.03it/s] 74%|███████▍  | 3335/4500 [00:09<00:03, 322.04it/s] 75%|███████▌  | 3386/4500 [00:09<00:03, 359.05it/s] 76%|███████▌  | 3423/4500 [00:10<00:03, 290.10it/s] 77%|███████▋  | 3472/4500 [00:10<00:03, 336.29it/s] 78%|███████▊  | 3509/4500 [00:10<00:04, 231.80it/s] 79%|███████▊  | 3539/4500 [00:10<00:04, 200.68it/s] 79%|███████▉  | 3564/4500 [00:10<00:05, 171.14it/s] 80%|███████▉  | 3585/4500 [00:11<00:06, 142.63it/s] 80%|████████  | 3617/4500 [00:11<00:05, 170.59it/s] 81%|████████▏ | 3661/4500 [00:11<00:03, 221.63it/s] 83%|████████▎ | 3714/4500 [00:11<00:02, 283.84it/s] 83%|████████▎ | 3749/4500 [00:11<00:02, 284.17it/s] 84%|████████▍ | 3782/4500 [00:11<00:02, 292.45it/s] 85%|████████▌ | 3837/4500 [00:11<00:01, 356.48it/s] 86%|████████▋ | 3886/4500 [00:11<00:01, 382.60it/s] 87%|████████▋ | 3929/4500 [00:11<00:01, 383.98it/s] 88%|████████▊ | 3970/4500 [00:12<00:01, 387.24it/s] 89%|████████▉ | 4014/4500 [00:12<00:01, 399.82it/s] 90%|█████████ | 4059/4500 [00:12<00:01, 401.75it/s] 91%|█████████ | 4100/4500 [00:12<00:01, 383.64it/s] 92%|█████████▏| 4139/4500 [00:12<00:01, 338.23it/s] 93%|█████████▎| 4175/4500 [00:12<00:01, 320.33it/s] 94%|█████████▎| 4208/4500 [00:12<00:00, 303.96it/s] 95%|█████████▍| 4261/4500 [00:12<00:00, 356.99it/s] 96%|█████████▌| 4299/4500 [00:13<00:00, 360.57it/s] 96%|█████████▋| 4336/4500 [00:13<00:00, 353.67it/s] 97%|█████████▋| 4372/4500 [00:13<00:00, 317.91it/s] 98%|█████████▊| 4411/4500 [00:13<00:00, 329.51it/s] 99%|█████████▉| 4462/4500 [00:13<00:00, 361.77it/s]100%|██████████| 4500/4500 [00:13<00:00, 332.50it/s]
test_p96 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p96
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p96.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:14,  1.16it/s]evaluating model with Holmes:  17%|█▋        | 3/18 [00:00<00:03,  3.77it/s]evaluating model with Holmes:  44%|████▍     | 8/18 [00:01<00:00, 11.28it/s]evaluating model with Holmes:  72%|███████▏  | 13/18 [00:01<00:00, 18.46it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 25.00it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.54it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p96_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p96_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p96_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p96_Holmes_probs.npy
{'Accuracy': 0.9878, 'Precision': 0.9879, 'Recall': 0.9878, 'F1-score': 0.9878}
starting gen taf script for test_p97
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 58/4500 [00:00<00:07, 562.85it/s]  3%|▎         | 115/4500 [00:00<00:10, 398.81it/s]  4%|▎         | 158/4500 [00:00<00:12, 361.64it/s]  4%|▍         | 196/4500 [00:00<00:12, 342.19it/s]  5%|▌         | 244/4500 [00:00<00:11, 380.11it/s]  7%|▋         | 297/4500 [00:00<00:09, 422.02it/s]  8%|▊         | 341/4500 [00:00<00:14, 295.91it/s]  8%|▊         | 377/4500 [00:01<00:15, 260.66it/s]  9%|▉         | 408/4500 [00:01<00:15, 259.14it/s] 10%|▉         | 437/4500 [00:01<00:15, 265.67it/s] 11%|█         | 481/4500 [00:01<00:13, 301.40it/s] 11%|█▏        | 514/4500 [00:01<00:13, 285.40it/s] 12%|█▏        | 545/4500 [00:01<00:14, 282.31it/s] 13%|█▎        | 575/4500 [00:01<00:14, 268.13it/s] 13%|█▎        | 603/4500 [00:02<00:15, 252.23it/s] 14%|█▍        | 630/4500 [00:02<00:15, 255.29it/s] 15%|█▍        | 663/4500 [00:02<00:14, 271.90it/s] 15%|█▌        | 691/4500 [00:02<00:14, 260.02it/s] 16%|█▌        | 720/4500 [00:02<00:14, 267.74it/s] 17%|█▋        | 748/4500 [00:02<00:14, 266.79it/s] 17%|█▋        | 775/4500 [00:02<00:14, 262.63it/s] 18%|█▊        | 802/4500 [00:02<00:14, 260.83it/s] 19%|█▉        | 860/4500 [00:02<00:10, 342.50it/s] 20%|█▉        | 896/4500 [00:02<00:10, 339.10it/s] 21%|██        | 930/4500 [00:03<00:10, 328.71it/s] 21%|██▏       | 964/4500 [00:03<00:10, 331.43it/s] 22%|██▏       | 998/4500 [00:03<00:10, 328.22it/s] 23%|██▎       | 1042/4500 [00:03<00:09, 355.26it/s] 24%|██▍       | 1078/4500 [00:03<00:09, 350.26it/s] 26%|██▌       | 1165/4500 [00:03<00:06, 498.76it/s] 27%|██▋       | 1220/4500 [00:03<00:06, 505.03it/s] 29%|██▊       | 1291/4500 [00:03<00:05, 563.51it/s] 30%|██▉       | 1348/4500 [00:03<00:06, 494.88it/s] 31%|███       | 1400/4500 [00:04<00:08, 372.68it/s] 32%|███▏      | 1443/4500 [00:04<00:08, 361.81it/s] 33%|███▎      | 1483/4500 [00:04<00:08, 336.49it/s] 34%|███▍      | 1527/4500 [00:04<00:08, 357.35it/s] 35%|███▌      | 1589/4500 [00:04<00:07, 411.48it/s] 36%|███▋      | 1633/4500 [00:04<00:07, 360.06it/s] 37%|███▋      | 1672/4500 [00:05<00:10, 278.43it/s] 38%|███▊      | 1726/4500 [00:05<00:08, 330.55it/s] 39%|███▉      | 1765/4500 [00:05<00:08, 337.30it/s] 41%|████      | 1828/4500 [00:05<00:06, 397.36it/s] 42%|████▏     | 1872/4500 [00:05<00:06, 401.26it/s] 43%|████▎     | 1932/4500 [00:05<00:05, 449.20it/s] 44%|████▍     | 1998/4500 [00:05<00:05, 488.89it/s] 46%|████▌     | 2049/4500 [00:05<00:05, 479.04it/s] 47%|████▋     | 2102/4500 [00:05<00:04, 491.80it/s] 48%|████▊     | 2153/4500 [00:06<00:05, 419.15it/s] 49%|████▉     | 2198/4500 [00:06<00:05, 396.67it/s] 50%|████▉     | 2240/4500 [00:06<00:06, 369.72it/s] 51%|█████     | 2279/4500 [00:06<00:07, 302.06it/s] 51%|█████▏    | 2312/4500 [00:06<00:07, 291.95it/s] 52%|█████▏    | 2343/4500 [00:06<00:08, 260.11it/s] 53%|█████▎    | 2374/4500 [00:06<00:07, 268.77it/s] 54%|█████▎    | 2410/4500 [00:07<00:07, 287.35it/s] 55%|█████▍    | 2458/4500 [00:07<00:06, 335.42it/s] 56%|█████▌    | 2503/4500 [00:07<00:05, 357.88it/s] 57%|█████▋    | 2547/4500 [00:07<00:05, 376.53it/s] 58%|█████▊    | 2601/4500 [00:07<00:04, 411.91it/s] 59%|█████▉    | 2644/4500 [00:07<00:04, 386.21it/s] 60%|█████▉    | 2684/4500 [00:07<00:05, 330.87it/s] 61%|██████    | 2731/4500 [00:07<00:05, 351.45it/s] 62%|██████▏   | 2768/4500 [00:08<00:05, 321.41it/s] 62%|██████▏   | 2802/4500 [00:08<00:05, 317.99it/s] 64%|██████▍   | 2874/4500 [00:08<00:04, 402.14it/s] 65%|██████▌   | 2925/4500 [00:08<00:03, 403.51it/s] 66%|██████▌   | 2970/4500 [00:08<00:03, 403.61it/s] 67%|██████▋   | 3011/4500 [00:08<00:03, 388.92it/s] 68%|██████▊   | 3051/4500 [00:08<00:03, 381.75it/s] 69%|██████▉   | 3104/4500 [00:08<00:03, 409.69it/s] 70%|██████▉   | 3146/4500 [00:08<00:03, 356.91it/s] 71%|███████   | 3183/4500 [00:09<00:04, 321.55it/s] 71%|███████▏  | 3217/4500 [00:09<00:04, 309.72it/s] 72%|███████▏  | 3261/4500 [00:09<00:03, 339.33it/s] 73%|███████▎  | 3299/4500 [00:09<00:03, 344.21it/s] 74%|███████▍  | 3335/4500 [00:09<00:03, 329.09it/s] 75%|███████▍  | 3373/4500 [00:09<00:03, 334.81it/s] 76%|███████▌  | 3407/4500 [00:09<00:03, 300.04it/s] 76%|███████▋  | 3438/4500 [00:09<00:03, 294.92it/s] 77%|███████▋  | 3473/4500 [00:10<00:03, 308.67it/s] 78%|███████▊  | 3505/4500 [00:10<00:04, 240.91it/s] 78%|███████▊  | 3532/4500 [00:10<00:05, 162.70it/s] 79%|███████▉  | 3554/4500 [00:10<00:06, 141.85it/s] 79%|███████▉  | 3572/4500 [00:10<00:06, 145.19it/s] 80%|███████▉  | 3590/4500 [00:11<00:06, 132.83it/s] 81%|████████  | 3625/4500 [00:11<00:05, 174.35it/s] 82%|████████▏ | 3669/4500 [00:11<00:03, 226.77it/s] 83%|████████▎ | 3721/4500 [00:11<00:02, 289.15it/s] 84%|████████▎ | 3759/4500 [00:11<00:02, 303.13it/s] 84%|████████▍ | 3795/4500 [00:11<00:02, 308.58it/s] 85%|████████▌ | 3828/4500 [00:11<00:02, 301.02it/s] 86%|████████▋ | 3882/4500 [00:11<00:01, 355.06it/s] 87%|████████▋ | 3936/4500 [00:11<00:01, 394.39it/s] 88%|████████▊ | 3977/4500 [00:12<00:01, 393.32it/s] 89%|████████▉ | 4018/4500 [00:12<00:01, 367.29it/s] 90%|█████████ | 4060/4500 [00:12<00:01, 379.26it/s] 91%|█████████ | 4100/4500 [00:12<00:01, 371.84it/s] 92%|█████████▏| 4138/4500 [00:12<00:01, 299.08it/s] 93%|█████████▎| 4171/4500 [00:12<00:01, 303.43it/s] 94%|█████████▍| 4222/4500 [00:12<00:00, 355.66it/s] 95%|█████████▍| 4260/4500 [00:12<00:00, 357.95it/s] 96%|█████████▌| 4310/4500 [00:13<00:00, 392.81it/s] 97%|█████████▋| 4351/4500 [00:13<00:00, 310.53it/s] 97%|█████████▋| 4386/4500 [00:13<00:00, 292.93it/s] 99%|█████████▉| 4447/4500 [00:13<00:00, 362.57it/s]100%|██████████| 4500/4500 [00:13<00:00, 332.64it/s]
test_p97 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p97
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p97.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.06it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.33it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.82it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 20.24it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.49it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p97_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p97_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p97_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p97_Holmes_probs.npy
{'Accuracy': 0.988, 'Precision': 0.9881, 'Recall': 0.988, 'F1-score': 0.988}
starting gen taf script for test_p98
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 49/4500 [00:00<00:09, 463.87it/s]  2%|▏         | 96/4500 [00:00<00:10, 413.40it/s]  3%|▎         | 138/4500 [00:00<00:12, 350.35it/s]  4%|▍         | 174/4500 [00:00<00:12, 344.89it/s]  5%|▍         | 214/4500 [00:00<00:11, 359.97it/s]  6%|▌         | 273/4500 [00:00<00:09, 427.12it/s]  7%|▋         | 317/4500 [00:00<00:11, 351.47it/s]  8%|▊         | 355/4500 [00:01<00:13, 299.43it/s]  9%|▊         | 388/4500 [00:01<00:15, 265.18it/s]  9%|▉         | 425/4500 [00:01<00:14, 288.66it/s] 10%|█         | 458/4500 [00:01<00:13, 290.27it/s] 11%|█         | 489/4500 [00:01<00:13, 289.96it/s] 12%|█▏        | 524/4500 [00:01<00:13, 300.89it/s] 12%|█▏        | 560/4500 [00:01<00:12, 314.82it/s] 13%|█▎        | 593/4500 [00:01<00:12, 310.74it/s] 14%|█▍        | 634/4500 [00:01<00:11, 335.03it/s] 15%|█▍        | 668/4500 [00:02<00:11, 331.26it/s] 16%|█▌        | 717/4500 [00:02<00:10, 354.37it/s] 17%|█▋        | 753/4500 [00:02<00:11, 335.08it/s] 17%|█▋        | 787/4500 [00:02<00:11, 331.56it/s] 18%|█▊        | 821/4500 [00:02<00:12, 305.15it/s] 20%|█▉        | 883/4500 [00:02<00:09, 388.29it/s] 21%|██        | 939/4500 [00:02<00:08, 420.95it/s] 22%|██▏       | 992/4500 [00:02<00:07, 450.80it/s] 23%|██▎       | 1039/4500 [00:02<00:07, 447.54it/s] 24%|██▍       | 1085/4500 [00:03<00:08, 388.03it/s] 26%|██▌       | 1166/4500 [00:03<00:06, 495.71it/s] 27%|██▋       | 1219/4500 [00:03<00:06, 494.78it/s] 28%|██▊       | 1271/4500 [00:03<00:06, 481.13it/s] 29%|██▉       | 1321/4500 [00:03<00:06, 462.06it/s] 30%|███       | 1369/4500 [00:03<00:07, 406.14it/s] 31%|███▏      | 1412/4500 [00:03<00:08, 379.19it/s] 32%|███▏      | 1452/4500 [00:04<00:09, 312.14it/s] 33%|███▎      | 1486/4500 [00:04<00:09, 316.37it/s] 34%|███▍      | 1534/4500 [00:04<00:08, 351.62it/s] 35%|███▍      | 1572/4500 [00:04<00:08, 355.00it/s] 36%|███▌      | 1609/4500 [00:04<00:08, 355.97it/s] 37%|███▋      | 1646/4500 [00:04<00:09, 310.24it/s] 37%|███▋      | 1679/4500 [00:04<00:09, 294.31it/s] 38%|███▊      | 1710/4500 [00:04<00:09, 286.57it/s] 39%|███▉      | 1754/4500 [00:04<00:08, 316.95it/s] 40%|███▉      | 1796/4500 [00:05<00:07, 342.88it/s] 42%|████▏     | 1876/4500 [00:05<00:05, 454.33it/s] 43%|████▎     | 1923/4500 [00:05<00:05, 454.27it/s] 44%|████▍     | 1977/4500 [00:05<00:05, 468.50it/s] 45%|████▌     | 2025/4500 [00:05<00:05, 461.66it/s] 46%|████▌     | 2072/4500 [00:05<00:05, 447.53it/s] 47%|████▋     | 2118/4500 [00:05<00:06, 396.14it/s] 48%|████▊     | 2159/4500 [00:05<00:06, 381.02it/s] 49%|████▉     | 2209/4500 [00:05<00:05, 409.96it/s] 50%|█████     | 2251/4500 [00:06<00:06, 350.80it/s] 51%|█████     | 2288/4500 [00:06<00:07, 306.15it/s] 52%|█████▏    | 2321/4500 [00:06<00:07, 297.94it/s] 52%|█████▏    | 2353/4500 [00:06<00:08, 257.24it/s] 53%|█████▎    | 2383/4500 [00:06<00:08, 261.34it/s] 54%|█████▎    | 2414/4500 [00:06<00:07, 270.91it/s] 54%|█████▍    | 2446/4500 [00:06<00:07, 275.87it/s] 56%|█████▌    | 2518/4500 [00:07<00:05, 391.83it/s] 57%|█████▋    | 2560/4500 [00:07<00:05, 378.35it/s] 58%|█████▊    | 2600/4500 [00:07<00:05, 374.66it/s] 59%|█████▊    | 2639/4500 [00:07<00:05, 341.61it/s] 60%|█████▉    | 2681/4500 [00:07<00:05, 361.94it/s] 60%|██████    | 2719/4500 [00:07<00:05, 337.86it/s] 61%|██████▏   | 2757/4500 [00:07<00:05, 345.25it/s] 62%|██████▏   | 2799/4500 [00:07<00:04, 361.40it/s] 63%|██████▎   | 2838/4500 [00:07<00:04, 365.07it/s] 64%|██████▍   | 2876/4500 [00:08<00:04, 367.97it/s] 65%|██████▍   | 2914/4500 [00:08<00:04, 363.20it/s] 66%|██████▌   | 2956/4500 [00:08<00:04, 373.46it/s] 67%|██████▋   | 2994/4500 [00:08<00:04, 370.62it/s] 67%|██████▋   | 3035/4500 [00:08<00:03, 373.29it/s] 69%|██████▊   | 3084/4500 [00:08<00:03, 405.24it/s] 69%|██████▉   | 3125/4500 [00:08<00:04, 323.09it/s] 70%|███████   | 3160/4500 [00:08<00:04, 324.01it/s] 71%|███████   | 3195/4500 [00:09<00:04, 298.39it/s] 72%|███████▏  | 3234/4500 [00:09<00:04, 304.40it/s] 73%|███████▎  | 3266/4500 [00:09<00:04, 305.98it/s] 73%|███████▎  | 3306/4500 [00:09<00:03, 321.79it/s] 74%|███████▍  | 3347/4500 [00:09<00:03, 331.24it/s] 76%|███████▌  | 3401/4500 [00:09<00:02, 386.70it/s] 76%|███████▋  | 3441/4500 [00:09<00:02, 360.34it/s] 77%|███████▋  | 3478/4500 [00:09<00:03, 315.56it/s] 78%|███████▊  | 3511/4500 [00:10<00:04, 231.89it/s] 79%|███████▊  | 3539/4500 [00:10<00:05, 181.41it/s] 79%|███████▉  | 3562/4500 [00:10<00:05, 172.07it/s] 80%|███████▉  | 3582/4500 [00:10<00:06, 131.69it/s] 80%|███████▉  | 3599/4500 [00:10<00:06, 137.43it/s] 81%|████████  | 3652/4500 [00:11<00:03, 212.38it/s] 82%|████████▏ | 3698/4500 [00:11<00:03, 262.30it/s] 83%|████████▎ | 3735/4500 [00:11<00:02, 285.94it/s] 84%|████████▍ | 3769/4500 [00:11<00:02, 258.38it/s] 85%|████████▍ | 3805/4500 [00:11<00:02, 281.43it/s] 86%|████████▌ | 3851/4500 [00:11<00:02, 321.18it/s] 87%|████████▋ | 3918/4500 [00:11<00:01, 401.63it/s] 88%|████████▊ | 3961/4500 [00:11<00:01, 401.07it/s] 89%|████████▉ | 4003/4500 [00:11<00:01, 373.53it/s] 90%|████████▉ | 4042/4500 [00:12<00:01, 356.51it/s] 91%|█████████ | 4082/4500 [00:12<00:01, 362.72it/s] 92%|█████████▏| 4120/4500 [00:12<00:01, 338.22it/s] 92%|█████████▏| 4155/4500 [00:12<00:01, 318.28it/s] 93%|█████████▎| 4188/4500 [00:12<00:01, 278.88it/s] 94%|█████████▍| 4237/4500 [00:12<00:00, 329.09it/s] 95%|█████████▌| 4294/4500 [00:12<00:00, 389.79it/s] 96%|█████████▋| 4336/4500 [00:13<00:00, 296.44it/s] 97%|█████████▋| 4373/4500 [00:13<00:00, 302.68it/s] 98%|█████████▊| 4421/4500 [00:13<00:00, 337.17it/s] 99%|█████████▉| 4462/4500 [00:13<00:00, 347.28it/s]100%|██████████| 4500/4500 [00:13<00:00, 336.52it/s]
test_p98 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p98
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p98.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:10,  1.66it/s]evaluating model with Holmes:  11%|█         | 2/18 [00:00<00:06,  2.48it/s]evaluating model with Holmes:  28%|██▊       | 5/18 [00:00<00:01,  7.09it/s]evaluating model with Holmes:  56%|█████▌    | 10/18 [00:01<00:00, 15.14it/s]evaluating model with Holmes:  83%|████████▎ | 15/18 [00:01<00:00, 22.23it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.99it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p98_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p98_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p98_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p98_Holmes_probs.npy
{'Accuracy': 0.9882, 'Precision': 0.9884, 'Recall': 0.9882, 'F1-score': 0.9883}
starting gen taf script for test_p99
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|          | 53/4500 [00:00<00:08, 519.70it/s]  2%|▏         | 105/4500 [00:00<00:10, 410.26it/s]  3%|▎         | 148/4500 [00:00<00:11, 374.21it/s]  4%|▍         | 187/4500 [00:00<00:13, 314.17it/s]  5%|▌         | 231/4500 [00:00<00:12, 347.30it/s]  6%|▋         | 285/4500 [00:00<00:10, 400.22it/s]  7%|▋         | 327/4500 [00:00<00:11, 363.53it/s]  8%|▊         | 366/4500 [00:01<00:14, 277.86it/s]  9%|▉         | 398/4500 [00:01<00:15, 267.16it/s] 10%|▉         | 428/4500 [00:01<00:15, 261.32it/s] 11%|█         | 476/4500 [00:01<00:12, 311.22it/s] 11%|█▏        | 510/4500 [00:01<00:13, 305.03it/s] 12%|█▏        | 547/4500 [00:01<00:12, 316.13it/s] 13%|█▎        | 585/4500 [00:01<00:11, 329.61it/s] 14%|█▍        | 619/4500 [00:01<00:11, 332.05it/s] 15%|█▍        | 653/4500 [00:02<00:11, 321.50it/s] 15%|█▌        | 686/4500 [00:02<00:12, 317.25it/s] 16%|█▌        | 719/4500 [00:02<00:13, 271.90it/s] 17%|█▋        | 748/4500 [00:02<00:14, 255.57it/s] 17%|█▋        | 777/4500 [00:02<00:14, 250.53it/s] 18%|█▊        | 824/4500 [00:02<00:12, 293.21it/s] 19%|█▉        | 876/4500 [00:02<00:10, 350.15it/s] 20%|██        | 915/4500 [00:02<00:10, 354.75it/s] 22%|██▏       | 971/4500 [00:02<00:08, 392.45it/s] 22%|██▏       | 1011/4500 [00:03<00:09, 364.20it/s] 24%|██▎       | 1063/4500 [00:03<00:08, 405.28it/s] 25%|██▍       | 1106/4500 [00:03<00:08, 408.23it/s] 26%|██▋       | 1189/4500 [00:03<00:06, 510.53it/s] 28%|██▊       | 1241/4500 [00:03<00:06, 491.24it/s] 29%|██▉       | 1296/4500 [00:03<00:06, 493.96it/s] 30%|██▉       | 1346/4500 [00:03<00:07, 421.27it/s] 31%|███       | 1397/4500 [00:03<00:07, 431.26it/s] 32%|███▏      | 1442/4500 [00:04<00:08, 345.06it/s] 33%|███▎      | 1480/4500 [00:04<00:10, 285.52it/s] 34%|███▍      | 1525/4500 [00:04<00:09, 315.03it/s] 35%|███▌      | 1578/4500 [00:04<00:08, 353.14it/s] 36%|███▌      | 1617/4500 [00:04<00:08, 352.54it/s] 37%|███▋      | 1655/4500 [00:04<00:09, 298.75it/s] 38%|███▊      | 1688/4500 [00:04<00:09, 286.22it/s] 39%|███▊      | 1733/4500 [00:05<00:08, 318.87it/s] 40%|███▉      | 1782/4500 [00:05<00:07, 360.72it/s] 41%|████      | 1823/4500 [00:05<00:07, 362.53it/s] 42%|████▏     | 1872/4500 [00:05<00:06, 376.23it/s] 43%|████▎     | 1930/4500 [00:05<00:06, 427.35it/s] 44%|████▍     | 1982/4500 [00:05<00:05, 444.95it/s] 45%|████▌     | 2036/4500 [00:05<00:05, 444.89it/s] 46%|████▋     | 2082/4500 [00:05<00:05, 419.20it/s] 47%|████▋     | 2133/4500 [00:05<00:05, 432.15it/s] 49%|████▊     | 2191/4500 [00:06<00:05, 456.62it/s] 50%|████▉     | 2238/4500 [00:06<00:06, 363.05it/s] 51%|█████     | 2278/4500 [00:06<00:07, 308.80it/s] 51%|█████▏    | 2312/4500 [00:06<00:08, 265.66it/s] 52%|█████▏    | 2342/4500 [00:06<00:09, 232.09it/s] 53%|█████▎    | 2386/4500 [00:06<00:07, 272.57it/s] 54%|█████▍    | 2432/4500 [00:07<00:06, 297.61it/s] 55%|█████▍    | 2469/4500 [00:07<00:06, 311.50it/s] 56%|█████▌    | 2528/4500 [00:07<00:05, 377.75it/s] 57%|█████▋    | 2569/4500 [00:07<00:05, 369.52it/s] 58%|█████▊    | 2608/4500 [00:07<00:05, 357.51it/s] 59%|█████▉    | 2646/4500 [00:07<00:05, 349.48it/s] 60%|█████▉    | 2682/4500 [00:07<00:05, 319.73it/s] 60%|██████    | 2715/4500 [00:07<00:06, 277.68it/s] 62%|██████▏   | 2771/4500 [00:08<00:05, 337.21it/s] 63%|██████▎   | 2814/4500 [00:08<00:04, 354.13it/s] 64%|██████▎   | 2862/4500 [00:08<00:04, 383.20it/s] 65%|██████▍   | 2904/4500 [00:08<00:04, 386.70it/s] 65%|██████▌   | 2945/4500 [00:08<00:04, 385.95it/s] 66%|██████▋   | 2985/4500 [00:08<00:04, 335.42it/s] 67%|██████▋   | 3034/4500 [00:08<00:03, 369.42it/s] 68%|██████▊   | 3073/4500 [00:08<00:03, 361.83it/s] 69%|██████▉   | 3111/4500 [00:08<00:04, 337.93it/s] 70%|██████▉   | 3146/4500 [00:09<00:04, 326.33it/s] 71%|███████   | 3180/4500 [00:09<00:04, 267.92it/s] 71%|███████▏  | 3216/4500 [00:09<00:04, 284.92it/s] 72%|███████▏  | 3247/4500 [00:09<00:04, 290.32it/s] 73%|███████▎  | 3287/4500 [00:09<00:03, 317.14it/s] 74%|███████▍  | 3320/4500 [00:09<00:03, 317.43it/s] 75%|███████▍  | 3359/4500 [00:09<00:03, 336.91it/s] 75%|███████▌  | 3394/4500 [00:09<00:03, 327.43it/s] 76%|███████▌  | 3428/4500 [00:10<00:04, 260.99it/s] 77%|███████▋  | 3473/4500 [00:10<00:03, 303.65it/s] 78%|███████▊  | 3507/4500 [00:10<00:04, 205.93it/s] 79%|███████▊  | 3534/4500 [00:10<00:05, 193.06it/s] 79%|███████▉  | 3558/4500 [00:10<00:05, 163.28it/s] 80%|███████▉  | 3578/4500 [00:11<00:07, 128.08it/s] 80%|████████  | 3605/4500 [00:11<00:05, 150.58it/s] 81%|████████▏ | 3659/4500 [00:11<00:03, 224.11it/s] 82%|████████▏ | 3693/4500 [00:11<00:03, 244.03it/s] 83%|████████▎ | 3739/4500 [00:11<00:02, 282.73it/s] 84%|████████▍ | 3783/4500 [00:11<00:02, 320.04it/s] 85%|████████▍ | 3819/4500 [00:11<00:02, 306.38it/s] 86%|████████▌ | 3857/4500 [00:11<00:02, 317.67it/s] 87%|████████▋ | 3916/4500 [00:12<00:01, 387.53it/s] 88%|████████▊ | 3958/4500 [00:12<00:01, 395.75it/s] 89%|████████▉ | 4000/4500 [00:12<00:01, 400.52it/s] 90%|████████▉ | 4042/4500 [00:12<00:01, 358.22it/s] 91%|█████████ | 4080/4500 [00:12<00:01, 324.15it/s] 91%|█████████▏| 4115/4500 [00:12<00:01, 317.11it/s] 92%|█████████▏| 4150/4500 [00:12<00:01, 318.45it/s] 93%|█████████▎| 4183/4500 [00:12<00:00, 319.76it/s] 94%|█████████▍| 4236/4500 [00:12<00:00, 374.21it/s] 95%|█████████▌| 4283/4500 [00:13<00:00, 386.75it/s] 96%|█████████▌| 4323/4500 [00:13<00:00, 299.92it/s] 97%|█████████▋| 4357/4500 [00:13<00:00, 296.68it/s] 98%|█████████▊| 4389/4500 [00:13<00:00, 296.41it/s] 99%|█████████▊| 4436/4500 [00:13<00:00, 336.09it/s]100%|██████████| 4500/4500 [00:13<00:00, 327.58it/s]
test_p99 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p99
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p99.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:00<00:16,  1.02it/s]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  7.07it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 13.51it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.88it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 13.05it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p99_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p99_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p99_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p99_Holmes_probs.npy
{'Accuracy': 0.9882, 'Precision': 0.9884, 'Recall': 0.9882, 'F1-score': 0.9883}
starting gen taf script for test_p100
  0%|          | 0/4500 [00:00<?, ?it/s]  1%|▏         | 61/4500 [00:00<00:07, 608.79it/s]  3%|▎         | 122/4500 [00:00<00:13, 336.30it/s]  4%|▎         | 163/4500 [00:00<00:12, 355.39it/s]  5%|▍         | 203/4500 [00:00<00:12, 340.84it/s]  6%|▌         | 252/4500 [00:00<00:11, 382.09it/s]  7%|▋         | 301/4500 [00:00<00:10, 396.06it/s]  8%|▊         | 343/4500 [00:01<00:13, 300.58it/s]  8%|▊         | 378/4500 [00:01<00:15, 262.91it/s]  9%|▉         | 414/4500 [00:01<00:14, 281.68it/s] 10%|▉         | 447/4500 [00:01<00:13, 290.75it/s] 11%|█         | 486/4500 [00:01<00:12, 312.01it/s] 12%|█▏        | 520/4500 [00:01<00:12, 311.01it/s] 12%|█▏        | 553/4500 [00:01<00:13, 297.61it/s] 13%|█▎        | 584/4500 [00:01<00:13, 287.22it/s] 14%|█▎        | 618/4500 [00:01<00:13, 294.50it/s] 15%|█▍        | 653/4500 [00:02<00:12, 307.64it/s] 15%|█▌        | 685/4500 [00:02<00:12, 305.50it/s] 16%|█▌        | 718/4500 [00:02<00:12, 303.55it/s] 17%|█▋        | 749/4500 [00:02<00:13, 288.36it/s] 17%|█▋        | 779/4500 [00:02<00:13, 272.87it/s] 18%|█▊        | 815/4500 [00:02<00:12, 294.85it/s] 19%|█▉        | 864/4500 [00:02<00:10, 347.97it/s] 20%|██        | 900/4500 [00:02<00:10, 346.86it/s] 21%|██        | 936/4500 [00:02<00:10, 326.89it/s] 22%|██▏       | 991/4500 [00:03<00:09, 373.20it/s] 23%|██▎       | 1031/4500 [00:03<00:09, 373.75it/s] 24%|██▍       | 1069/4500 [00:03<00:09, 344.65it/s] 25%|██▌       | 1125/4500 [00:03<00:08, 401.06it/s] 27%|██▋       | 1218/4500 [00:03<00:06, 546.34it/s] 28%|██▊       | 1279/4500 [00:03<00:05, 553.66it/s] 30%|██▉       | 1336/4500 [00:03<00:06, 464.11it/s] 31%|███       | 1386/4500 [00:03<00:06, 451.29it/s] 32%|███▏      | 1434/4500 [00:04<00:08, 367.11it/s] 33%|███▎      | 1475/4500 [00:04<00:09, 305.31it/s] 34%|███▎      | 1516/4500 [00:04<00:09, 322.65it/s] 35%|███▍      | 1560/4500 [00:04<00:08, 348.83it/s] 36%|███▌      | 1599/4500 [00:04<00:08, 356.10it/s] 36%|███▋      | 1637/4500 [00:04<00:08, 337.77it/s] 37%|███▋      | 1673/4500 [00:04<00:10, 268.73it/s] 38%|███▊      | 1707/4500 [00:05<00:10, 277.58it/s] 39%|███▉      | 1771/4500 [00:05<00:07, 354.60it/s] 41%|████      | 1831/4500 [00:05<00:06, 398.04it/s] 42%|████▏     | 1874/4500 [00:05<00:06, 394.88it/s] 43%|████▎     | 1921/4500 [00:05<00:06, 408.86it/s] 44%|████▎     | 1968/4500 [00:05<00:06, 417.56it/s] 45%|████▌     | 2025/4500 [00:05<00:05, 442.57it/s] 46%|████▌     | 2076/4500 [00:05<00:05, 460.79it/s] 47%|████▋     | 2123/4500 [00:05<00:05, 438.83it/s] 48%|████▊     | 2177/4500 [00:06<00:05, 457.51it/s] 49%|████▉     | 2224/4500 [00:06<00:05, 398.13it/s] 50%|█████     | 2266/4500 [00:06<00:06, 336.70it/s] 51%|█████     | 2303/4500 [00:06<00:06, 323.91it/s] 52%|█████▏    | 2337/4500 [00:06<00:07, 284.57it/s] 53%|█████▎    | 2368/4500 [00:06<00:08, 250.11it/s] 53%|█████▎    | 2397/4500 [00:06<00:08, 252.34it/s] 54%|█████▍    | 2435/4500 [00:07<00:07, 278.23it/s] 55%|█████▌    | 2484/4500 [00:07<00:06, 319.22it/s] 56%|█████▌    | 2521/4500 [00:07<00:06, 328.42it/s] 57%|█████▋    | 2573/4500 [00:07<00:05, 366.66it/s] 58%|█████▊    | 2618/4500 [00:07<00:04, 379.59it/s] 59%|█████▉    | 2657/4500 [00:07<00:05, 360.47it/s] 60%|█████▉    | 2694/4500 [00:07<00:05, 344.21it/s] 61%|██████    | 2733/4500 [00:07<00:05, 342.51it/s] 62%|██████▏   | 2768/4500 [00:07<00:05, 342.29it/s] 62%|██████▏   | 2803/4500 [00:08<00:05, 332.46it/s] 63%|██████▎   | 2854/4500 [00:08<00:04, 364.34it/s] 64%|██████▍   | 2895/4500 [00:08<00:04, 373.73it/s] 65%|██████▌   | 2944/4500 [00:08<00:03, 403.80it/s] 66%|██████▋   | 2989/4500 [00:08<00:03, 409.09it/s] 67%|██████▋   | 3031/4500 [00:08<00:03, 387.44it/s] 68%|██████▊   | 3071/4500 [00:08<00:03, 372.11it/s] 69%|██████▉   | 3109/4500 [00:08<00:04, 312.91it/s] 70%|██████▉   | 3148/4500 [00:09<00:04, 314.14it/s] 71%|███████   | 3181/4500 [00:09<00:04, 305.14it/s] 72%|███████▏  | 3218/4500 [00:09<00:04, 318.45it/s] 72%|███████▏  | 3251/4500 [00:09<00:04, 309.22it/s] 73%|███████▎  | 3296/4500 [00:09<00:03, 337.78it/s] 74%|███████▍  | 3337/4500 [00:09<00:03, 353.72it/s] 75%|███████▍  | 3373/4500 [00:09<00:03, 296.64it/s] 76%|███████▌  | 3405/4500 [00:09<00:03, 277.58it/s] 76%|███████▋  | 3442/4500 [00:10<00:03, 298.27it/s] 77%|███████▋  | 3478/4500 [00:10<00:03, 303.24it/s] 78%|███████▊  | 3510/4500 [00:10<00:04, 228.08it/s] 79%|███████▊  | 3537/4500 [00:10<00:05, 180.88it/s] 79%|███████▉  | 3559/4500 [00:10<00:06, 151.98it/s] 80%|███████▉  | 3578/4500 [00:11<00:07, 126.94it/s] 80%|███████▉  | 3597/4500 [00:11<00:06, 137.06it/s] 81%|████████  | 3647/4500 [00:11<00:04, 205.56it/s] 82%|████████▏ | 3699/4500 [00:11<00:02, 272.89it/s] 83%|████████▎ | 3733/4500 [00:11<00:02, 281.64it/s] 84%|████████▎ | 3766/4500 [00:11<00:02, 279.07it/s] 84%|████████▍ | 3800/4500 [00:11<00:02, 294.38it/s] 85%|████████▌ | 3840/4500 [00:11<00:02, 321.55it/s] 86%|████████▌ | 3875/4500 [00:11<00:02, 306.81it/s] 87%|████████▋ | 3909/4500 [00:12<00:01, 314.38it/s] 88%|████████▊ | 3965/4500 [00:12<00:01, 369.06it/s] 89%|████████▉ | 4004/4500 [00:12<00:01, 369.80it/s] 90%|████████▉ | 4042/4500 [00:12<00:01, 326.39it/s] 91%|█████████ | 4091/4500 [00:12<00:01, 359.70it/s] 92%|█████████▏| 4129/4500 [00:12<00:01, 312.93it/s] 92%|█████████▏| 4162/4500 [00:12<00:01, 308.74it/s] 93%|█████████▎| 4194/4500 [00:12<00:01, 290.44it/s] 95%|█████████▍| 4253/4500 [00:13<00:00, 363.32it/s] 95%|█████████▌| 4292/4500 [00:13<00:00, 365.31it/s] 96%|█████████▌| 4330/4500 [00:13<00:00, 339.43it/s] 97%|█████████▋| 4366/4500 [00:13<00:00, 317.27it/s] 98%|█████████▊| 4399/4500 [00:13<00:00, 282.13it/s] 99%|█████████▉| 4464/4500 [00:13<00:00, 368.69it/s]100%|██████████| 4500/4500 [00:13<00:00, 328.39it/s]
test_p100 process done: X = (4500, 3, 2, 2000), y = (4500,)

Size Analysis:
--------------
Total raw size: 412.02 MB
Estimated compressed size: 206.01 MB
Overhead: 1.50 KB

Size per array:
X: 411.99 MB
y: 35.16 KB
finished gen taf script for test_p100
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_p100.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([4500, 3, 2, 2000]), y=torch.Size([4500])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/18 [00:00<?, ?it/s]evaluating model with Holmes:   6%|▌         | 1/18 [00:01<00:17,  1.05s/it]evaluating model with Holmes:  33%|███▎      | 6/18 [00:01<00:01,  6.68it/s]evaluating model with Holmes:  61%|██████    | 11/18 [00:01<00:00, 12.84it/s]evaluating model with Holmes:  89%|████████▉ | 16/18 [00:01<00:00, 19.06it/s]evaluating model with Holmes: 100%|██████████| 18/18 [00:01<00:00, 12.51it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p100_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p100_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p100_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_p100_Holmes_probs.npy
{'Accuracy': 0.988, 'Precision': 0.9881, 'Recall': 0.988, 'F1-score': 0.988}
starting gen taf script for test_neglected_p20
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 102/10000 [00:00<00:09, 1015.41it/s]  2%|▏         | 204/10000 [00:00<00:17, 554.29it/s]   3%|▎         | 271/10000 [00:00<00:17, 549.27it/s]  3%|▎         | 332/10000 [00:00<00:17, 544.26it/s]  4%|▍         | 390/10000 [00:00<00:17, 534.23it/s]  5%|▍         | 452/10000 [00:00<00:17, 553.12it/s]  5%|▌         | 517/10000 [00:00<00:16, 579.46it/s]  6%|▌         | 577/10000 [00:01<00:16, 577.47it/s]  6%|▋         | 636/10000 [00:01<00:16, 568.00it/s]  7%|▋         | 694/10000 [00:01<00:19, 475.28it/s]  7%|▋         | 745/10000 [00:01<00:19, 473.74it/s]  8%|▊         | 796/10000 [00:01<00:19, 476.15it/s]  8%|▊         | 845/10000 [00:01<00:19, 460.81it/s]  9%|▉         | 909/10000 [00:01<00:17, 506.46it/s] 10%|█         | 1012/10000 [00:01<00:13, 646.96it/s] 11%|█         | 1107/10000 [00:01<00:12, 732.05it/s] 12%|█▏        | 1186/10000 [00:02<00:11, 742.92it/s] 13%|█▎        | 1306/10000 [00:02<00:09, 869.81it/s] 14%|█▍        | 1402/10000 [00:02<00:09, 876.16it/s] 15%|█▍        | 1491/10000 [00:02<00:11, 749.22it/s] 16%|█▌        | 1570/10000 [00:02<00:13, 619.41it/s] 16%|█▋        | 1649/10000 [00:02<00:12, 655.19it/s] 17%|█▋        | 1747/10000 [00:02<00:11, 734.14it/s] 19%|█▉        | 1882/10000 [00:02<00:09, 885.85it/s] 20%|█▉        | 1978/10000 [00:02<00:08, 905.10it/s] 21%|██        | 2087/10000 [00:03<00:08, 951.12it/s] 22%|██▏       | 2187/10000 [00:03<00:08, 961.60it/s] 23%|██▎       | 2286/10000 [00:03<00:08, 921.06it/s] 24%|██▍       | 2380/10000 [00:03<00:08, 873.07it/s] 25%|██▌       | 2500/10000 [00:03<00:07, 962.11it/s] 26%|██▌       | 2599/10000 [00:03<00:07, 938.98it/s] 27%|██▋       | 2695/10000 [00:03<00:09, 788.12it/s] 28%|██▊       | 2779/10000 [00:03<00:09, 739.75it/s] 29%|██▊       | 2867/10000 [00:04<00:09, 771.91it/s] 30%|██▉       | 2972/10000 [00:04<00:08, 844.16it/s] 31%|███       | 3060/10000 [00:04<00:08, 801.30it/s] 31%|███▏      | 3143/10000 [00:04<00:09, 741.85it/s] 33%|███▎      | 3252/10000 [00:04<00:08, 830.85it/s] 34%|███▎      | 3368/10000 [00:04<00:07, 918.95it/s] 35%|███▍      | 3463/10000 [00:04<00:07, 867.00it/s] 36%|███▌      | 3581/10000 [00:04<00:06, 950.97it/s] 37%|███▋      | 3725/10000 [00:04<00:05, 1086.99it/s] 38%|███▊      | 3837/10000 [00:05<00:06, 1011.84it/s] 39%|███▉      | 3942/10000 [00:05<00:06, 981.57it/s]  41%|████      | 4072/10000 [00:05<00:05, 1024.82it/s] 42%|████▏     | 4184/10000 [00:05<00:05, 1050.26it/s] 43%|████▎     | 4291/10000 [00:05<00:05, 994.52it/s]  44%|████▍     | 4420/10000 [00:05<00:05, 1067.42it/s] 45%|████▌     | 4529/10000 [00:05<00:06, 838.58it/s]  46%|████▋     | 4647/10000 [00:05<00:05, 912.50it/s] 47%|████▋     | 4746/10000 [00:06<00:06, 806.03it/s] 48%|████▊     | 4836/10000 [00:06<00:06, 811.93it/s] 49%|████▉     | 4923/10000 [00:06<00:06, 744.15it/s] 50%|█████     | 5002/10000 [00:06<00:07, 691.30it/s] 51%|█████     | 5101/10000 [00:06<00:06, 757.90it/s] 52%|█████▏    | 5213/10000 [00:06<00:05, 848.94it/s] 53%|█████▎    | 5302/10000 [00:06<00:07, 658.92it/s] 54%|█████▍    | 5377/10000 [00:07<00:07, 594.12it/s] 54%|█████▍    | 5444/10000 [00:07<00:07, 600.38it/s] 55%|█████▌    | 5534/10000 [00:07<00:06, 663.39it/s] 56%|█████▌    | 5615/10000 [00:07<00:06, 695.37it/s] 57%|█████▋    | 5723/10000 [00:07<00:05, 795.53it/s] 58%|█████▊    | 5807/10000 [00:07<00:05, 736.89it/s] 59%|█████▉    | 5885/10000 [00:07<00:05, 746.13it/s] 60%|█████▉    | 5963/10000 [00:07<00:06, 641.13it/s] 61%|██████    | 6060/10000 [00:07<00:05, 720.81it/s] 62%|██████▏   | 6175/10000 [00:08<00:04, 828.88it/s] 63%|██████▎   | 6263/10000 [00:08<00:04, 798.86it/s] 63%|██████▎   | 6347/10000 [00:08<00:04, 764.22it/s] 64%|██████▍   | 6444/10000 [00:08<00:04, 808.56it/s] 65%|██████▌   | 6527/10000 [00:08<00:04, 726.98it/s] 66%|██████▌   | 6607/10000 [00:08<00:04, 744.79it/s] 67%|██████▋   | 6710/10000 [00:08<00:04, 812.03it/s] 68%|██████▊   | 6794/10000 [00:08<00:04, 764.05it/s] 69%|██████▉   | 6895/10000 [00:08<00:03, 824.78it/s] 70%|███████   | 7015/10000 [00:09<00:03, 925.20it/s] 72%|███████▏  | 7154/10000 [00:09<00:02, 1047.26it/s] 73%|███████▎  | 7261/10000 [00:09<00:02, 995.66it/s]  74%|███████▎  | 7363/10000 [00:09<00:02, 985.52it/s] 75%|███████▍  | 7489/10000 [00:09<00:02, 1059.19it/s] 76%|███████▌  | 7602/10000 [00:09<00:02, 1072.53it/s] 77%|███████▋  | 7711/10000 [00:09<00:02, 1032.64it/s] 78%|███████▊  | 7816/10000 [00:09<00:02, 935.21it/s]  79%|███████▉  | 7920/10000 [00:09<00:02, 959.28it/s] 80%|████████  | 8018/10000 [00:10<00:02, 897.33it/s] 81%|████████  | 8110/10000 [00:10<00:02, 893.87it/s] 82%|████████▏ | 8206/10000 [00:10<00:01, 905.23it/s] 83%|████████▎ | 8298/10000 [00:10<00:02, 838.07it/s] 84%|████████▍ | 8384/10000 [00:10<00:02, 787.03it/s] 85%|████████▍ | 8472/10000 [00:10<00:01, 810.92it/s] 86%|████████▌ | 8555/10000 [00:10<00:01, 799.18it/s] 87%|████████▋ | 8667/10000 [00:10<00:01, 882.04it/s] 88%|████████▊ | 8807/10000 [00:10<00:01, 1019.91it/s] 89%|████████▉ | 8919/10000 [00:11<00:01, 1043.06it/s] 90%|█████████ | 9025/10000 [00:11<00:00, 1015.97it/s] 91%|█████████▏| 9128/10000 [00:11<00:00, 970.57it/s]  92%|█████████▏| 9226/10000 [00:11<00:00, 899.65it/s] 93%|█████████▎| 9318/10000 [00:11<00:00, 727.64it/s] 94%|█████████▍| 9400/10000 [00:11<00:00, 743.01it/s] 95%|█████████▍| 9479/10000 [00:11<00:00, 739.57it/s] 96%|█████████▌| 9556/10000 [00:11<00:00, 730.76it/s] 96%|█████████▋| 9636/10000 [00:12<00:00, 739.55it/s] 97%|█████████▋| 9732/10000 [00:12<00:00, 798.57it/s] 98%|█████████▊| 9830/10000 [00:12<00:00, 843.50it/s] 99%|█████████▉| 9933/10000 [00:12<00:00, 894.64it/s]100%|██████████| 10000/10000 [00:12<00:00, 805.27it/s]
test_neglected_p20 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p20
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p20.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:34,  1.14it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:00<00:04,  7.76it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 14.49it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 20.93it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 26.76it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.51it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.64it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.88it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 22.62it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p20_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p20_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p20_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p20_Holmes_probs.npy
{'Accuracy': 0.0248, 'Precision': 0.0207, 'Recall': 0.0248, 'F1-score': 0.0192}
starting gen taf script for test_neglected_p21
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 98/10000 [00:00<00:10, 961.65it/s]  2%|▏         | 195/10000 [00:00<00:13, 702.99it/s]  3%|▎         | 270/10000 [00:00<00:16, 602.49it/s]  3%|▎         | 333/10000 [00:00<00:19, 504.10it/s]  4%|▍         | 386/10000 [00:00<00:19, 496.91it/s]  4%|▍         | 438/10000 [00:00<00:20, 457.52it/s]  5%|▍         | 485/10000 [00:01<00:25, 367.30it/s]  5%|▌         | 525/10000 [00:01<00:30, 314.60it/s]  6%|▌         | 559/10000 [00:01<00:33, 279.83it/s]  6%|▌         | 599/10000 [00:01<00:30, 305.25it/s]  7%|▋         | 652/10000 [00:01<00:26, 354.05it/s]  7%|▋         | 719/10000 [00:01<00:21, 430.13it/s]  8%|▊         | 781/10000 [00:01<00:19, 479.47it/s]  9%|▊         | 854/10000 [00:01<00:16, 546.64it/s]  9%|▉         | 918/10000 [00:01<00:15, 572.07it/s] 10%|▉         | 978/10000 [00:02<00:15, 572.75it/s] 10%|█         | 1037/10000 [00:02<00:15, 562.86it/s] 11%|█         | 1109/10000 [00:02<00:14, 607.65it/s] 12%|█▏        | 1174/10000 [00:02<00:14, 619.88it/s] 13%|█▎        | 1277/10000 [00:02<00:11, 731.11it/s] 14%|█▍        | 1384/10000 [00:02<00:10, 812.84it/s] 15%|█▍        | 1466/10000 [00:02<00:10, 783.95it/s] 15%|█▌        | 1545/10000 [00:02<00:14, 593.71it/s] 16%|█▌        | 1614/10000 [00:03<00:13, 614.23it/s] 17%|█▋        | 1688/10000 [00:03<00:12, 640.30it/s] 18%|█▊        | 1800/10000 [00:03<00:10, 758.10it/s] 19%|█▉        | 1934/10000 [00:03<00:08, 908.66it/s] 20%|██        | 2044/10000 [00:03<00:08, 951.90it/s] 21%|██▏       | 2143/10000 [00:03<00:08, 957.31it/s] 23%|██▎       | 2253/10000 [00:03<00:07, 976.69it/s] 24%|██▎       | 2353/10000 [00:03<00:09, 849.44it/s] 24%|██▍       | 2442/10000 [00:03<00:09, 836.38it/s] 26%|██▌       | 2565/10000 [00:04<00:07, 931.33it/s] 27%|██▋       | 2661/10000 [00:04<00:08, 870.63it/s] 28%|██▊       | 2751/10000 [00:04<00:10, 681.23it/s] 28%|██▊       | 2838/10000 [00:04<00:09, 720.98it/s] 29%|██▉       | 2937/10000 [00:04<00:09, 778.19it/s] 30%|███       | 3021/10000 [00:04<00:08, 779.24it/s] 31%|███       | 3103/10000 [00:04<00:09, 721.33it/s] 32%|███▏      | 3179/10000 [00:04<00:09, 725.21it/s] 33%|███▎      | 3279/10000 [00:05<00:08, 798.24it/s] 34%|███▍      | 3392/10000 [00:05<00:07, 880.69it/s] 35%|███▍      | 3483/10000 [00:05<00:07, 882.54it/s] 36%|███▌      | 3581/10000 [00:05<00:07, 910.21it/s] 37%|███▋      | 3675/10000 [00:05<00:06, 911.76it/s] 38%|███▊      | 3812/10000 [00:05<00:05, 1041.70it/s] 39%|███▉      | 3918/10000 [00:05<00:06, 988.04it/s]  40%|████      | 4018/10000 [00:05<00:06, 970.15it/s] 41%|████      | 4119/10000 [00:05<00:06, 972.44it/s] 42%|████▏     | 4238/10000 [00:05<00:05, 1034.37it/s] 44%|████▎     | 4353/10000 [00:06<00:05, 1067.24it/s] 45%|████▍     | 4474/10000 [00:06<00:05, 1096.62it/s] 46%|████▌     | 4585/10000 [00:06<00:05, 1003.39it/s] 47%|████▋     | 4688/10000 [00:06<00:05, 966.47it/s]  48%|████▊     | 4786/10000 [00:06<00:05, 937.47it/s] 49%|████▉     | 4881/10000 [00:06<00:06, 830.78it/s] 50%|████▉     | 4967/10000 [00:06<00:07, 694.51it/s] 51%|█████     | 5091/10000 [00:06<00:06, 814.32it/s] 52%|█████▏    | 5212/10000 [00:07<00:05, 893.28it/s] 53%|█████▎    | 5307/10000 [00:07<00:07, 634.42it/s] 54%|█████▍    | 5385/10000 [00:07<00:07, 597.94it/s] 55%|█████▍    | 5468/10000 [00:07<00:07, 641.93it/s] 56%|█████▌    | 5586/10000 [00:07<00:05, 763.53it/s] 57%|█████▋    | 5716/10000 [00:07<00:04, 894.01it/s] 58%|█████▊    | 5815/10000 [00:07<00:04, 907.81it/s] 59%|█████▉    | 5913/10000 [00:08<00:05, 791.49it/s] 60%|██████    | 6000/10000 [00:08<00:05, 694.12it/s] 61%|██████    | 6094/10000 [00:08<00:05, 744.60it/s] 62%|██████▏   | 6197/10000 [00:08<00:04, 807.00it/s] 63%|██████▎   | 6296/10000 [00:08<00:04, 847.49it/s] 64%|██████▍   | 6385/10000 [00:08<00:04, 765.72it/s] 65%|██████▍   | 6467/10000 [00:08<00:04, 778.41it/s] 66%|██████▌   | 6563/10000 [00:08<00:04, 814.75it/s] 67%|██████▋   | 6665/10000 [00:09<00:03, 864.75it/s] 68%|██████▊   | 6764/10000 [00:09<00:03, 891.22it/s] 69%|██████▉   | 6896/10000 [00:09<00:03, 1003.29it/s] 70%|███████   | 7010/10000 [00:09<00:02, 1038.83it/s] 71%|███████   | 7116/10000 [00:09<00:02, 1044.09it/s] 72%|███████▏  | 7222/10000 [00:09<00:02, 1035.18it/s] 73%|███████▎  | 7327/10000 [00:09<00:02, 1039.04it/s] 74%|███████▍  | 7434/10000 [00:09<00:02, 1043.94it/s] 75%|███████▌  | 7549/10000 [00:09<00:02, 1049.90it/s] 77%|███████▋  | 7655/10000 [00:09<00:02, 950.22it/s]  78%|███████▊  | 7752/10000 [00:10<00:02, 906.94it/s] 78%|███████▊  | 7847/10000 [00:10<00:02, 911.85it/s] 80%|███████▉  | 7970/10000 [00:10<00:02, 993.77it/s] 81%|████████  | 8071/10000 [00:10<00:02, 949.02it/s] 82%|████████▏ | 8188/10000 [00:10<00:01, 980.29it/s] 83%|████████▎ | 8301/10000 [00:10<00:01, 1019.00it/s] 84%|████████▍ | 8404/10000 [00:10<00:01, 897.96it/s]  85%|████████▌ | 8534/10000 [00:10<00:01, 1003.10it/s] 86%|████████▋ | 8642/10000 [00:10<00:01, 1023.51it/s] 88%|████████▊ | 8755/10000 [00:11<00:01, 1053.18it/s] 89%|████████▊ | 8869/10000 [00:11<00:01, 1075.88it/s] 90%|█████████ | 9020/10000 [00:11<00:00, 1190.57it/s] 91%|█████████▏| 9141/10000 [00:11<00:00, 1149.18it/s] 93%|█████████▎| 9258/10000 [00:11<00:00, 1034.11it/s] 94%|█████████▎| 9365/10000 [00:11<00:00, 790.81it/s]  95%|█████████▍| 9454/10000 [00:11<00:00, 804.07it/s] 95%|█████████▌| 9543/10000 [00:11<00:00, 820.45it/s] 97%|█████████▋| 9655/10000 [00:12<00:00, 890.90it/s] 98%|█████████▊| 9762/10000 [00:12<00:00, 930.58it/s] 99%|█████████▊| 9862/10000 [00:12<00:00, 944.51it/s]100%|█████████▉| 9966/10000 [00:12<00:00, 970.97it/s]100%|██████████| 10000/10000 [00:12<00:00, 807.97it/s]
test_neglected_p21 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p21
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p21.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.02it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.12it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.45it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.80it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.68it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.31it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.51it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.61it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.53it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p21_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p21_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p21_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p21_Holmes_probs.npy
{'Accuracy': 0.0242, 'Precision': 0.0213, 'Recall': 0.0242, 'F1-score': 0.0194}
starting gen taf script for test_neglected_p22
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 104/10000 [00:00<00:09, 998.42it/s]  2%|▏         | 204/10000 [00:00<00:14, 679.34it/s]  3%|▎         | 278/10000 [00:00<00:16, 601.85it/s]  3%|▎         | 342/10000 [00:00<00:21, 456.20it/s]  4%|▍         | 393/10000 [00:00<00:24, 397.71it/s]  5%|▍         | 452/10000 [00:00<00:21, 437.18it/s]  5%|▌         | 502/10000 [00:01<00:21, 451.93it/s]  6%|▌         | 561/10000 [00:01<00:19, 487.11it/s]  6%|▌         | 613/10000 [00:01<00:19, 493.68it/s]  7%|▋         | 669/10000 [00:01<00:18, 507.26it/s]  7%|▋         | 735/10000 [00:01<00:16, 549.21it/s]  8%|▊         | 825/10000 [00:01<00:14, 643.16it/s]  9%|▉         | 928/10000 [00:01<00:12, 754.25it/s] 10%|█         | 1007/10000 [00:01<00:11, 764.63it/s] 11%|█         | 1106/10000 [00:01<00:10, 829.77it/s] 12%|█▏        | 1195/10000 [00:01<00:10, 835.10it/s] 13%|█▎        | 1330/10000 [00:02<00:08, 981.80it/s] 14%|█▍        | 1429/10000 [00:02<00:09, 892.18it/s] 15%|█▌        | 1521/10000 [00:02<00:10, 815.46it/s] 16%|█▌        | 1605/10000 [00:02<00:12, 681.13it/s] 17%|█▋        | 1704/10000 [00:02<00:11, 742.42it/s] 18%|█▊        | 1828/10000 [00:02<00:09, 861.96it/s] 19%|█▉        | 1929/10000 [00:02<00:09, 894.64it/s] 21%|██        | 2061/10000 [00:02<00:07, 994.76it/s] 22%|██▏       | 2164/10000 [00:03<00:07, 984.20it/s] 23%|██▎       | 2265/10000 [00:03<00:08, 864.63it/s] 24%|██▎       | 2356/10000 [00:03<00:08, 864.53it/s] 24%|██▍       | 2446/10000 [00:03<00:08, 856.78it/s] 25%|██▌       | 2542/10000 [00:03<00:08, 880.38it/s] 26%|██▋       | 2632/10000 [00:03<00:10, 716.65it/s] 27%|██▋       | 2710/10000 [00:03<00:10, 677.22it/s] 28%|██▊       | 2782/10000 [00:03<00:10, 667.32it/s] 29%|██▊       | 2852/10000 [00:04<00:10, 650.52it/s] 30%|██▉       | 2953/10000 [00:04<00:09, 739.84it/s] 30%|███       | 3030/10000 [00:04<00:09, 703.47it/s] 31%|███       | 3103/10000 [00:04<00:09, 706.86it/s] 32%|███▏      | 3195/10000 [00:04<00:08, 759.15it/s] 33%|███▎      | 3331/10000 [00:04<00:07, 917.11it/s] 35%|███▍      | 3451/10000 [00:04<00:06, 986.22it/s] 36%|███▌      | 3551/10000 [00:04<00:06, 982.11it/s] 37%|███▋      | 3651/10000 [00:04<00:06, 987.07it/s] 38%|███▊      | 3763/10000 [00:04<00:06, 1025.26it/s] 39%|███▊      | 3867/10000 [00:05<00:06, 983.56it/s]  40%|███▉      | 3967/10000 [00:05<00:06, 957.68it/s] 41%|████      | 4082/10000 [00:05<00:05, 1012.20it/s] 42%|████▏     | 4187/10000 [00:05<00:05, 1022.89it/s] 43%|████▎     | 4312/10000 [00:05<00:05, 1088.05it/s] 44%|████▍     | 4433/10000 [00:05<00:04, 1114.73it/s] 45%|████▌     | 4545/10000 [00:05<00:05, 1043.85it/s] 47%|████▋     | 4651/10000 [00:05<00:05, 927.75it/s]  47%|████▋     | 4747/10000 [00:05<00:05, 890.10it/s] 48%|████▊     | 4838/10000 [00:06<00:06, 812.04it/s] 49%|████▉     | 4922/10000 [00:06<00:07, 649.46it/s] 50%|████▉     | 4993/10000 [00:06<00:07, 657.45it/s] 51%|█████     | 5087/10000 [00:06<00:06, 717.15it/s] 52%|█████▏    | 5186/10000 [00:06<00:06, 772.15it/s] 53%|█████▎    | 5267/10000 [00:06<00:07, 662.19it/s] 53%|█████▎    | 5338/10000 [00:07<00:08, 552.17it/s] 54%|█████▍    | 5408/10000 [00:07<00:07, 584.62it/s] 55%|█████▍    | 5488/10000 [00:07<00:07, 635.85it/s] 56%|█████▌    | 5571/10000 [00:07<00:06, 685.20it/s] 57%|█████▋    | 5699/10000 [00:07<00:05, 839.35it/s] 58%|█████▊    | 5788/10000 [00:07<00:05, 824.86it/s] 59%|█████▊    | 5874/10000 [00:07<00:05, 771.17it/s] 60%|█████▉    | 5954/10000 [00:07<00:05, 750.29it/s] 60%|██████    | 6031/10000 [00:07<00:05, 692.72it/s] 61%|██████▏   | 6135/10000 [00:08<00:04, 773.61it/s] 62%|██████▏   | 6215/10000 [00:08<00:04, 766.92it/s] 63%|██████▎   | 6294/10000 [00:08<00:05, 733.75it/s] 64%|██████▍   | 6379/10000 [00:08<00:04, 761.21it/s] 65%|██████▍   | 6457/10000 [00:08<00:04, 757.85it/s] 65%|██████▌   | 6534/10000 [00:08<00:04, 696.86it/s] 66%|██████▌   | 6605/10000 [00:08<00:05, 651.29it/s] 67%|██████▋   | 6700/10000 [00:08<00:04, 723.71it/s] 68%|██████▊   | 6775/10000 [00:08<00:04, 704.36it/s] 69%|██████▉   | 6879/10000 [00:09<00:03, 795.38it/s] 70%|██████▉   | 6977/10000 [00:09<00:03, 843.71it/s] 71%|███████   | 7071/10000 [00:09<00:03, 870.26it/s] 72%|███████▏  | 7186/10000 [00:09<00:02, 950.47it/s] 73%|███████▎  | 7319/10000 [00:09<00:02, 1057.75it/s] 74%|███████▍  | 7426/10000 [00:09<00:02, 1028.82it/s] 75%|███████▌  | 7530/10000 [00:09<00:02, 973.83it/s]  76%|███████▋  | 7630/10000 [00:09<00:02, 980.08it/s] 77%|███████▋  | 7729/10000 [00:09<00:02, 860.72it/s] 78%|███████▊  | 7819/10000 [00:10<00:02, 793.74it/s] 79%|███████▉  | 7905/10000 [00:10<00:02, 805.72it/s] 80%|████████  | 8021/10000 [00:10<00:02, 892.32it/s] 82%|████████▏ | 8152/10000 [00:10<00:01, 1005.51it/s] 83%|████████▎ | 8256/10000 [00:10<00:01, 953.23it/s]  84%|████████▎ | 8359/10000 [00:10<00:01, 969.65it/s] 85%|████████▍ | 8458/10000 [00:10<00:01, 971.77it/s] 86%|████████▌ | 8557/10000 [00:10<00:01, 965.08it/s] 87%|████████▋ | 8655/10000 [00:10<00:01, 966.70it/s] 88%|████████▊ | 8776/10000 [00:10<00:01, 1025.91it/s] 89%|████████▉ | 8903/10000 [00:11<00:01, 1081.35it/s] 90%|█████████ | 9019/10000 [00:11<00:00, 1101.94it/s] 91%|█████████▏| 9134/10000 [00:11<00:00, 1099.25it/s] 92%|█████████▏| 9245/10000 [00:11<00:00, 976.86it/s]  93%|█████████▎| 9346/10000 [00:11<00:00, 817.55it/s] 94%|█████████▍| 9434/10000 [00:11<00:00, 770.48it/s] 95%|█████████▌| 9520/10000 [00:11<00:00, 783.55it/s] 96%|█████████▌| 9602/10000 [00:11<00:00, 771.02it/s] 97%|█████████▋| 9682/10000 [00:12<00:00, 774.18it/s] 98%|█████████▊| 9761/10000 [00:12<00:00, 735.98it/s] 99%|█████████▊| 9872/10000 [00:12<00:00, 823.42it/s]100%|█████████▉| 9971/10000 [00:12<00:00, 868.96it/s]100%|██████████| 10000/10000 [00:12<00:00, 806.59it/s]
test_neglected_p22 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p22
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p22.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.07s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.55it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.79it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 17.96it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 23.92it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.13it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.65it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.33it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.94it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.63it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p22_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p22_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p22_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p22_Holmes_probs.npy
{'Accuracy': 0.024, 'Precision': 0.0218, 'Recall': 0.024, 'F1-score': 0.0198}
starting gen taf script for test_neglected_p23
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 106/10000 [00:00<00:09, 1019.72it/s]  2%|▏         | 208/10000 [00:00<00:19, 513.08it/s]   3%|▎         | 273/10000 [00:00<00:19, 496.48it/s]  3%|▎         | 330/10000 [00:00<00:20, 477.94it/s]  4%|▍         | 398/10000 [00:00<00:18, 530.36it/s]  5%|▍         | 456/10000 [00:00<00:19, 500.57it/s]  5%|▌         | 509/10000 [00:01<00:19, 474.77it/s]  6%|▌         | 559/10000 [00:01<00:19, 478.63it/s]  6%|▌         | 609/10000 [00:01<00:20, 450.40it/s]  7%|▋         | 655/10000 [00:01<00:20, 452.27it/s]  7%|▋         | 724/10000 [00:01<00:17, 517.31it/s]  8%|▊         | 787/10000 [00:01<00:17, 537.73it/s]  8%|▊         | 842/10000 [00:01<00:18, 507.72it/s]  9%|▉         | 908/10000 [00:01<00:16, 540.02it/s] 10%|▉         | 986/10000 [00:01<00:15, 599.79it/s] 11%|█         | 1067/10000 [00:01<00:13, 659.08it/s] 11%|█▏        | 1134/10000 [00:02<00:13, 650.33it/s] 12%|█▏        | 1218/10000 [00:02<00:12, 687.82it/s] 13%|█▎        | 1302/10000 [00:02<00:12, 720.23it/s] 14%|█▍        | 1393/10000 [00:02<00:11, 768.66it/s] 15%|█▍        | 1471/10000 [00:02<00:13, 650.75it/s] 15%|█▌        | 1540/10000 [00:02<00:15, 553.27it/s] 16%|█▌        | 1600/10000 [00:02<00:15, 531.93it/s] 17%|█▋        | 1693/10000 [00:02<00:13, 627.54it/s] 18%|█▊        | 1803/10000 [00:03<00:11, 742.12it/s] 19%|█▉        | 1925/10000 [00:03<00:09, 860.01it/s] 20%|██        | 2016/10000 [00:03<00:10, 768.86it/s] 21%|██        | 2098/10000 [00:03<00:10, 751.62it/s] 22%|██▏       | 2205/10000 [00:03<00:09, 833.62it/s] 23%|██▎       | 2297/10000 [00:03<00:08, 856.57it/s] 24%|██▍       | 2386/10000 [00:03<00:09, 807.78it/s] 25%|██▌       | 2511/10000 [00:03<00:08, 925.75it/s] 26%|██▌       | 2607/10000 [00:03<00:08, 888.29it/s] 27%|██▋       | 2698/10000 [00:04<00:10, 725.55it/s] 28%|██▊       | 2777/10000 [00:04<00:10, 703.39it/s] 29%|██▊       | 2866/10000 [00:04<00:09, 738.66it/s] 30%|██▉       | 2952/10000 [00:04<00:09, 766.76it/s] 31%|███       | 3068/10000 [00:04<00:07, 870.95it/s] 32%|███▏      | 3159/10000 [00:04<00:08, 833.66it/s] 33%|███▎      | 3300/10000 [00:04<00:06, 989.91it/s] 34%|███▍      | 3414/10000 [00:04<00:06, 1031.85it/s] 35%|███▌      | 3520/10000 [00:05<00:06, 990.95it/s]  36%|███▌      | 3622/10000 [00:05<00:06, 984.86it/s] 38%|███▊      | 3760/10000 [00:05<00:05, 1095.86it/s] 39%|███▉      | 3886/10000 [00:05<00:05, 1142.24it/s] 40%|████      | 4002/10000 [00:05<00:05, 1042.69it/s] 41%|████▏     | 4133/10000 [00:05<00:05, 1110.45it/s] 42%|████▏     | 4247/10000 [00:05<00:05, 1060.89it/s] 44%|████▎     | 4363/10000 [00:05<00:05, 1082.23it/s] 45%|████▍     | 4473/10000 [00:05<00:05, 957.77it/s]  46%|████▌     | 4573/10000 [00:06<00:05, 929.06it/s] 47%|████▋     | 4669/10000 [00:06<00:06, 847.83it/s] 48%|████▊     | 4757/10000 [00:06<00:06, 812.49it/s] 48%|████▊     | 4840/10000 [00:06<00:06, 776.63it/s] 49%|████▉     | 4919/10000 [00:06<00:07, 698.79it/s] 50%|████▉     | 4991/10000 [00:06<00:07, 674.23it/s] 51%|█████     | 5060/10000 [00:06<00:07, 677.32it/s] 52%|█████▏    | 5174/10000 [00:06<00:06, 776.17it/s] 53%|█████▎    | 5253/10000 [00:07<00:07, 599.75it/s] 53%|█████▎    | 5320/10000 [00:07<00:08, 579.25it/s] 54%|█████▍    | 5383/10000 [00:07<00:08, 571.51it/s] 55%|█████▍    | 5460/10000 [00:07<00:07, 619.87it/s] 55%|█████▌    | 5529/10000 [00:07<00:07, 631.02it/s] 57%|█████▋    | 5673/10000 [00:07<00:05, 847.71it/s] 58%|█████▊    | 5779/10000 [00:07<00:04, 890.47it/s] 59%|█████▊    | 5872/10000 [00:07<00:05, 762.60it/s] 60%|█████▉    | 5954/10000 [00:08<00:05, 753.28it/s] 60%|██████    | 6033/10000 [00:08<00:05, 729.05it/s] 62%|██████▏   | 6150/10000 [00:08<00:04, 839.56it/s] 62%|██████▏   | 6238/10000 [00:08<00:04, 789.14it/s] 63%|██████▎   | 6320/10000 [00:08<00:05, 724.18it/s] 64%|██████▍   | 6414/10000 [00:08<00:04, 763.76it/s] 65%|██████▍   | 6493/10000 [00:08<00:04, 735.01it/s] 66%|██████▌   | 6568/10000 [00:08<00:04, 701.24it/s] 66%|██████▋   | 6644/10000 [00:08<00:04, 710.76it/s] 67%|██████▋   | 6722/10000 [00:09<00:04, 718.02it/s] 68%|██████▊   | 6795/10000 [00:09<00:04, 718.01it/s] 69%|██████▉   | 6885/10000 [00:09<00:04, 765.41it/s] 70%|██████▉   | 6974/10000 [00:09<00:03, 800.64it/s] 71%|███████   | 7076/10000 [00:09<00:03, 863.98it/s] 72%|███████▏  | 7166/10000 [00:09<00:03, 869.47it/s] 73%|███████▎  | 7259/10000 [00:09<00:03, 886.43it/s] 73%|███████▎  | 7348/10000 [00:09<00:03, 881.55it/s] 74%|███████▍  | 7443/10000 [00:09<00:02, 894.36it/s] 75%|███████▌  | 7533/10000 [00:10<00:02, 886.97it/s] 76%|███████▌  | 7623/10000 [00:10<00:02, 884.05it/s] 77%|███████▋  | 7712/10000 [00:10<00:02, 830.35it/s] 78%|███████▊  | 7796/10000 [00:10<00:02, 831.68it/s] 79%|███████▉  | 7919/10000 [00:10<00:02, 942.98it/s] 80%|████████  | 8035/10000 [00:10<00:01, 1001.64it/s] 81%|████████▏ | 8136/10000 [00:10<00:01, 986.39it/s]  82%|████████▏ | 8236/10000 [00:10<00:01, 974.89it/s] 83%|████████▎ | 8334/10000 [00:10<00:01, 935.68it/s] 84%|████████▍ | 8435/10000 [00:10<00:01, 956.76it/s] 85%|████████▌ | 8532/10000 [00:11<00:01, 954.29it/s] 87%|████████▋ | 8655/10000 [00:11<00:01, 1032.37it/s] 88%|████████▊ | 8759/10000 [00:11<00:01, 1015.01it/s] 89%|████████▉ | 8891/10000 [00:11<00:01, 1102.77it/s] 90%|█████████ | 9015/10000 [00:11<00:00, 1143.02it/s] 91%|█████████▏| 9130/10000 [00:11<00:00, 1088.34it/s] 92%|█████████▏| 9240/10000 [00:11<00:00, 946.20it/s]  93%|█████████▎| 9339/10000 [00:11<00:00, 789.38it/s] 94%|█████████▍| 9425/10000 [00:12<00:00, 786.31it/s] 95%|█████████▌| 9516/10000 [00:12<00:00, 808.87it/s] 96%|█████████▌| 9601/10000 [00:12<00:00, 812.97it/s] 97%|█████████▋| 9685/10000 [00:12<00:00, 796.69it/s] 98%|█████████▊| 9767/10000 [00:12<00:00, 788.58it/s] 99%|█████████▊| 9862/10000 [00:12<00:00, 832.79it/s]100%|█████████▉| 9966/10000 [00:12<00:00, 888.46it/s]100%|██████████| 10000/10000 [00:12<00:00, 788.41it/s]
test_neglected_p23 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p23
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p23.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.09s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.45it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.62it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 17.92it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 23.94it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.11it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.66it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.38it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.01it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.52it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p23_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p23_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p23_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p23_Holmes_probs.npy
{'Accuracy': 0.0236, 'Precision': 0.0226, 'Recall': 0.0236, 'F1-score': 0.0202}
starting gen taf script for test_neglected_p24
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 98/10000 [00:00<00:10, 958.84it/s]  2%|▏         | 194/10000 [00:00<00:16, 586.33it/s]  3%|▎         | 261/10000 [00:00<00:18, 515.50it/s]  3%|▎         | 317/10000 [00:00<00:19, 499.59it/s]  4%|▎         | 370/10000 [00:00<00:19, 496.31it/s]  4%|▍         | 426/10000 [00:00<00:18, 511.78it/s]  5%|▍         | 491/10000 [00:00<00:17, 549.97it/s]  5%|▌         | 548/10000 [00:01<00:18, 508.93it/s]  6%|▌         | 609/10000 [00:01<00:17, 529.35it/s]  7%|▋         | 675/10000 [00:01<00:16, 565.46it/s]  7%|▋         | 735/10000 [00:01<00:16, 569.94it/s]  8%|▊         | 823/10000 [00:01<00:13, 658.06it/s]  9%|▉         | 890/10000 [00:01<00:14, 642.63it/s] 10%|▉         | 987/10000 [00:01<00:12, 733.53it/s] 11%|█         | 1062/10000 [00:01<00:13, 684.13it/s] 11%|█▏        | 1132/10000 [00:01<00:13, 672.73it/s] 12%|█▏        | 1215/10000 [00:01<00:12, 711.71it/s] 13%|█▎        | 1316/10000 [00:02<00:11, 788.70it/s] 14%|█▍        | 1416/10000 [00:02<00:10, 828.18it/s] 15%|█▌        | 1500/10000 [00:02<00:12, 676.16it/s] 16%|█▌        | 1573/10000 [00:02<00:14, 576.33it/s] 17%|█▋        | 1658/10000 [00:02<00:13, 638.47it/s] 18%|█▊        | 1754/10000 [00:02<00:11, 714.89it/s] 19%|█▊        | 1861/10000 [00:02<00:10, 806.47it/s] 20%|█▉        | 1971/10000 [00:02<00:09, 880.81it/s] 21%|██        | 2064/10000 [00:03<00:09, 877.65it/s] 22%|██▏       | 2160/10000 [00:03<00:08, 890.44it/s] 23%|██▎       | 2252/10000 [00:03<00:09, 801.27it/s] 23%|██▎       | 2336/10000 [00:03<00:09, 792.47it/s] 24%|██▍       | 2430/10000 [00:03<00:09, 832.27it/s] 25%|██▌       | 2541/10000 [00:03<00:08, 908.65it/s] 26%|██▋       | 2634/10000 [00:03<00:08, 838.76it/s] 27%|██▋       | 2721/10000 [00:03<00:09, 775.17it/s] 28%|██▊       | 2801/10000 [00:04<00:11, 630.85it/s] 29%|██▉       | 2875/10000 [00:04<00:10, 650.56it/s] 30%|██▉       | 2961/10000 [00:04<00:10, 697.08it/s] 30%|███       | 3035/10000 [00:04<00:10, 683.24it/s] 31%|███       | 3106/10000 [00:04<00:10, 673.91it/s] 32%|███▏      | 3176/10000 [00:04<00:10, 666.71it/s] 33%|███▎      | 3278/10000 [00:04<00:08, 763.17it/s] 34%|███▎      | 3374/10000 [00:04<00:08, 818.27it/s] 35%|███▍      | 3458/10000 [00:04<00:08, 804.78it/s] 36%|███▌      | 3561/10000 [00:05<00:07, 866.58it/s] 37%|███▋      | 3674/10000 [00:05<00:06, 929.67it/s] 38%|███▊      | 3768/10000 [00:05<00:06, 902.69it/s] 39%|███▊      | 3859/10000 [00:05<00:06, 882.42it/s] 40%|███▉      | 3961/10000 [00:05<00:06, 921.55it/s] 41%|████      | 4054/10000 [00:05<00:06, 867.50it/s] 42%|████▏     | 4178/10000 [00:05<00:06, 968.27it/s] 43%|████▎     | 4290/10000 [00:05<00:05, 1002.99it/s] 44%|████▍     | 4396/10000 [00:05<00:05, 1012.03it/s] 45%|████▍     | 4498/10000 [00:06<00:06, 911.38it/s]  46%|████▌     | 4592/10000 [00:06<00:06, 795.48it/s] 47%|████▋     | 4676/10000 [00:06<00:07, 740.79it/s] 48%|████▊     | 4761/10000 [00:06<00:06, 766.66it/s] 48%|████▊     | 4841/10000 [00:06<00:07, 691.18it/s] 49%|████▉     | 4913/10000 [00:06<00:08, 634.61it/s] 50%|████▉     | 4979/10000 [00:06<00:09, 545.31it/s] 51%|█████     | 5085/10000 [00:06<00:07, 655.74it/s] 52%|█████▏    | 5179/10000 [00:07<00:06, 710.54it/s] 53%|█████▎    | 5255/10000 [00:07<00:07, 669.74it/s] 53%|█████▎    | 5326/10000 [00:07<00:08, 555.93it/s] 54%|█████▍    | 5387/10000 [00:07<00:09, 475.25it/s] 55%|█████▍    | 5463/10000 [00:07<00:08, 536.09it/s] 56%|█████▌    | 5559/10000 [00:07<00:07, 625.54it/s] 57%|█████▋    | 5652/10000 [00:07<00:06, 693.85it/s] 58%|█████▊    | 5769/10000 [00:08<00:05, 817.34it/s] 59%|█████▊    | 5857/10000 [00:08<00:05, 774.49it/s] 59%|█████▉    | 5939/10000 [00:08<00:06, 630.38it/s] 60%|██████    | 6009/10000 [00:08<00:06, 617.92it/s] 61%|██████▏   | 6133/10000 [00:08<00:05, 761.57it/s] 63%|██████▎   | 6251/10000 [00:08<00:04, 866.11it/s] 63%|██████▎   | 6344/10000 [00:08<00:04, 801.37it/s] 64%|██████▍   | 6430/10000 [00:08<00:04, 798.73it/s] 65%|██████▌   | 6514/10000 [00:09<00:04, 717.71it/s] 66%|██████▌   | 6595/10000 [00:09<00:04, 721.61it/s] 67%|██████▋   | 6689/10000 [00:09<00:04, 765.41it/s] 68%|██████▊   | 6768/10000 [00:09<00:04, 744.71it/s] 69%|██████▉   | 6879/10000 [00:09<00:03, 836.83it/s] 70%|██████▉   | 6971/10000 [00:09<00:03, 859.30it/s] 71%|███████   | 7072/10000 [00:09<00:03, 896.61it/s] 72%|███████▏  | 7163/10000 [00:09<00:03, 899.68it/s] 73%|███████▎  | 7254/10000 [00:09<00:03, 901.80it/s] 73%|███████▎  | 7349/10000 [00:09<00:02, 910.12it/s] 74%|███████▍  | 7446/10000 [00:10<00:02, 924.56it/s] 76%|███████▌  | 7550/10000 [00:10<00:02, 951.55it/s] 76%|███████▋  | 7646/10000 [00:10<00:02, 829.06it/s] 77%|███████▋  | 7732/10000 [00:10<00:02, 805.84it/s] 78%|███████▊  | 7841/10000 [00:10<00:02, 876.36it/s] 80%|███████▉  | 7984/10000 [00:10<00:01, 1026.07it/s] 81%|████████  | 8095/10000 [00:10<00:01, 1039.79it/s] 82%|████████▏ | 8203/10000 [00:10<00:01, 1034.04it/s] 83%|████████▎ | 8310/10000 [00:10<00:01, 1037.34it/s] 84%|████████▍ | 8415/10000 [00:11<00:01, 889.58it/s]  85%|████████▌ | 8526/10000 [00:11<00:01, 946.84it/s] 86%|████████▋ | 8630/10000 [00:11<00:01, 972.11it/s] 88%|████████▊ | 8755/10000 [00:11<00:01, 1041.81it/s] 89%|████████▉ | 8899/10000 [00:11<00:00, 1139.97it/s] 90%|█████████ | 9015/10000 [00:11<00:00, 1137.86it/s] 91%|█████████▏| 9131/10000 [00:11<00:00, 1104.16it/s] 92%|█████████▏| 9243/10000 [00:11<00:00, 918.23it/s]  93%|█████████▎| 9341/10000 [00:12<00:00, 829.46it/s] 94%|█████████▍| 9429/10000 [00:12<00:00, 714.33it/s] 95%|█████████▌| 9506/10000 [00:12<00:00, 711.20it/s] 96%|█████████▌| 9616/10000 [00:12<00:00, 804.81it/s] 97%|█████████▋| 9702/10000 [00:12<00:00, 783.06it/s] 98%|█████████▊| 9797/10000 [00:12<00:00, 820.62it/s] 99%|█████████▉| 9886/10000 [00:12<00:00, 835.11it/s]100%|██████████| 10000/10000 [00:12<00:00, 777.92it/s]
test_neglected_p24 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p24
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p24.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.09s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.47it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.39it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.41it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 23.89it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.03it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.11it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 36.46it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.28it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p24_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p24_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p24_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p24_Holmes_probs.npy
{'Accuracy': 0.0232, 'Precision': 0.0206, 'Recall': 0.0232, 'F1-score': 0.0193}
starting gen taf script for test_neglected_p25
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 89/10000 [00:00<00:11, 873.19it/s]  2%|▏         | 177/10000 [00:00<00:18, 539.83it/s]  2%|▏         | 238/10000 [00:00<00:20, 484.45it/s]  3%|▎         | 290/10000 [00:00<00:20, 478.26it/s]  3%|▎         | 340/10000 [00:00<00:25, 377.48it/s]  4%|▍         | 381/10000 [00:00<00:25, 375.80it/s]  4%|▍         | 422/10000 [00:00<00:24, 383.95it/s]  5%|▍         | 482/10000 [00:01<00:21, 440.85it/s]  5%|▌         | 542/10000 [00:01<00:19, 481.05it/s]  6%|▋         | 627/10000 [00:01<00:16, 578.83it/s]  7%|▋         | 736/10000 [00:01<00:12, 721.71it/s]  8%|▊         | 822/10000 [00:01<00:12, 753.90it/s]  9%|▉         | 905/10000 [00:01<00:11, 775.61it/s] 10%|▉         | 996/10000 [00:01<00:11, 799.65it/s] 11%|█         | 1077/10000 [00:01<00:12, 742.06it/s] 12%|█▏        | 1153/10000 [00:01<00:12, 713.38it/s] 12%|█▏        | 1230/10000 [00:02<00:12, 721.64it/s] 13%|█▎        | 1341/10000 [00:02<00:10, 826.63it/s] 14%|█▍        | 1425/10000 [00:02<00:10, 814.29it/s] 15%|█▌        | 1508/10000 [00:02<00:13, 643.16it/s] 16%|█▌        | 1579/10000 [00:02<00:14, 563.26it/s] 17%|█▋        | 1692/10000 [00:02<00:11, 692.37it/s] 18%|█▊        | 1771/10000 [00:02<00:11, 716.19it/s] 19%|█▉        | 1897/10000 [00:02<00:09, 857.37it/s] 20%|██        | 2019/10000 [00:03<00:08, 945.40it/s] 21%|██▏       | 2136/10000 [00:03<00:07, 993.26it/s] 22%|██▏       | 2240/10000 [00:03<00:09, 838.12it/s] 23%|██▎       | 2331/10000 [00:03<00:09, 827.88it/s] 24%|██▍       | 2419/10000 [00:03<00:09, 811.76it/s] 25%|██▌       | 2542/10000 [00:03<00:08, 909.03it/s] 26%|██▋       | 2637/10000 [00:03<00:09, 817.05it/s] 27%|██▋       | 2723/10000 [00:04<00:11, 631.95it/s] 28%|██▊       | 2795/10000 [00:04<00:11, 617.76it/s] 29%|██▊       | 2871/10000 [00:04<00:11, 646.85it/s] 30%|███       | 3006/10000 [00:04<00:08, 817.02it/s] 31%|███       | 3095/10000 [00:04<00:08, 776.68it/s] 32%|███▏      | 3178/10000 [00:04<00:09, 684.45it/s] 33%|███▎      | 3284/10000 [00:04<00:08, 770.30it/s] 34%|███▍      | 3401/10000 [00:04<00:07, 868.23it/s] 35%|███▌      | 3501/10000 [00:04<00:07, 891.22it/s] 36%|███▌      | 3604/10000 [00:05<00:06, 922.30it/s] 37%|███▋      | 3728/10000 [00:05<00:06, 1009.34it/s] 38%|███▊      | 3834/10000 [00:05<00:06, 1020.36it/s] 39%|███▉      | 3940/10000 [00:05<00:05, 1014.74it/s] 40%|████      | 4043/10000 [00:05<00:05, 1014.79it/s] 42%|████▏     | 4160/10000 [00:05<00:05, 1052.99it/s] 43%|████▎     | 4269/10000 [00:05<00:05, 1058.47it/s] 44%|████▍     | 4376/10000 [00:05<00:05, 1049.28it/s] 45%|████▍     | 4484/10000 [00:05<00:05, 1034.21it/s] 46%|████▌     | 4588/10000 [00:05<00:05, 954.84it/s]  47%|████▋     | 4685/10000 [00:06<00:06, 836.22it/s] 48%|████▊     | 4772/10000 [00:06<00:07, 738.55it/s] 48%|████▊     | 4850/10000 [00:06<00:07, 665.16it/s] 49%|████▉     | 4920/10000 [00:06<00:08, 576.58it/s] 50%|████▉     | 4981/10000 [00:06<00:08, 573.37it/s] 51%|█████     | 5077/10000 [00:06<00:07, 665.50it/s] 52%|█████▏    | 5176/10000 [00:06<00:06, 739.15it/s] 53%|█████▎    | 5254/10000 [00:07<00:07, 609.08it/s] 53%|█████▎    | 5321/10000 [00:07<00:08, 571.33it/s] 54%|█████▍    | 5383/10000 [00:07<00:09, 481.21it/s] 55%|█████▍    | 5453/10000 [00:07<00:08, 526.10it/s] 55%|█████▌    | 5526/10000 [00:07<00:07, 570.77it/s] 56%|█████▌    | 5610/10000 [00:07<00:06, 637.39it/s] 57%|█████▋    | 5714/10000 [00:07<00:05, 727.62it/s] 58%|█████▊    | 5799/10000 [00:07<00:05, 757.97it/s] 59%|█████▉    | 5878/10000 [00:08<00:05, 727.37it/s] 60%|█████▉    | 5953/10000 [00:08<00:06, 662.87it/s] 60%|██████    | 6022/10000 [00:08<00:05, 669.28it/s] 61%|██████    | 6123/10000 [00:08<00:05, 761.26it/s] 62%|██████▏   | 6202/10000 [00:08<00:04, 761.08it/s] 63%|██████▎   | 6280/10000 [00:08<00:05, 739.63it/s] 64%|██████▎   | 6356/10000 [00:08<00:05, 700.00it/s] 64%|██████▍   | 6428/10000 [00:08<00:05, 680.38it/s] 65%|██████▍   | 6497/10000 [00:09<00:05, 633.28it/s] 66%|██████▌   | 6563/10000 [00:09<00:05, 640.06it/s] 66%|██████▋   | 6635/10000 [00:09<00:05, 660.11it/s] 67%|██████▋   | 6713/10000 [00:09<00:04, 689.98it/s] 68%|██████▊   | 6809/10000 [00:09<00:04, 759.90it/s] 69%|██████▉   | 6905/10000 [00:09<00:03, 808.45it/s] 70%|██████▉   | 6995/10000 [00:09<00:03, 834.68it/s] 71%|███████   | 7081/10000 [00:09<00:03, 833.31it/s] 72%|███████▏  | 7214/10000 [00:09<00:02, 976.72it/s] 73%|███████▎  | 7319/10000 [00:09<00:02, 992.62it/s] 74%|███████▍  | 7419/10000 [00:10<00:02, 987.91it/s] 75%|███████▌  | 7519/10000 [00:10<00:02, 951.29it/s] 76%|███████▌  | 7616/10000 [00:10<00:02, 956.34it/s] 77%|███████▋  | 7712/10000 [00:10<00:02, 868.73it/s] 78%|███████▊  | 7801/10000 [00:10<00:02, 788.64it/s] 79%|███████▉  | 7891/10000 [00:10<00:02, 807.43it/s] 80%|████████  | 8027/10000 [00:10<00:02, 954.00it/s] 82%|████████▏ | 8157/10000 [00:10<00:01, 1035.67it/s] 83%|████████▎ | 8263/10000 [00:10<00:01, 875.22it/s]  84%|████████▎ | 8357/10000 [00:11<00:01, 822.13it/s] 84%|████████▍ | 8444/10000 [00:11<00:01, 832.20it/s] 85%|████████▌ | 8531/10000 [00:11<00:01, 839.65it/s] 86%|████████▌ | 8621/10000 [00:11<00:01, 846.87it/s] 88%|████████▊ | 8768/10000 [00:11<00:01, 1019.45it/s] 89%|████████▉ | 8911/10000 [00:11<00:00, 1124.61it/s] 90%|█████████ | 9048/10000 [00:11<00:00, 1187.05it/s] 92%|█████████▏| 9172/10000 [00:11<00:00, 1200.04it/s] 93%|█████████▎| 9294/10000 [00:12<00:00, 839.08it/s]  94%|█████████▍| 9394/10000 [00:12<00:00, 740.53it/s] 95%|█████████▍| 9481/10000 [00:12<00:00, 747.55it/s] 96%|█████████▌| 9565/10000 [00:12<00:00, 736.32it/s] 96%|█████████▋| 9648/10000 [00:12<00:00, 739.71it/s] 97%|█████████▋| 9727/10000 [00:12<00:00, 721.50it/s] 98%|█████████▊| 9834/10000 [00:12<00:00, 804.29it/s] 99%|█████████▉| 9927/10000 [00:12<00:00, 830.18it/s]100%|██████████| 10000/10000 [00:12<00:00, 770.11it/s]
test_neglected_p25 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p25
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p25.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:36,  1.07it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.22it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.94it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.53it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.64it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.75it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 35.08it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 38.48it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.88it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 22.15it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p25_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p25_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p25_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p25_Holmes_probs.npy
{'Accuracy': 0.0224, 'Precision': 0.0218, 'Recall': 0.0224, 'F1-score': 0.0191}
starting gen taf script for test_neglected_p26
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 89/10000 [00:00<00:11, 828.16it/s]  2%|▏         | 172/10000 [00:00<00:23, 426.75it/s]  2%|▏         | 225/10000 [00:00<00:25, 386.58it/s]  3%|▎         | 269/10000 [00:00<00:25, 379.91it/s]  3%|▎         | 310/10000 [00:00<00:25, 385.11it/s]  4%|▎         | 351/10000 [00:00<00:26, 364.89it/s]  4%|▍         | 389/10000 [00:00<00:26, 368.13it/s]  5%|▍         | 452/10000 [00:01<00:21, 438.31it/s]  5%|▍         | 498/10000 [00:01<00:26, 364.65it/s]  5%|▌         | 543/10000 [00:01<00:24, 382.45it/s]  6%|▌         | 584/10000 [00:01<00:24, 389.05it/s]  6%|▋         | 643/10000 [00:01<00:21, 442.54it/s]  7%|▋         | 699/10000 [00:01<00:19, 475.02it/s]  8%|▊         | 761/10000 [00:01<00:18, 506.85it/s]  8%|▊         | 818/10000 [00:01<00:17, 522.06it/s]  9%|▊         | 872/10000 [00:01<00:17, 520.77it/s]  9%|▉         | 939/10000 [00:02<00:16, 563.52it/s] 10%|▉         | 996/10000 [00:02<00:17, 508.92it/s] 11%|█         | 1097/10000 [00:02<00:13, 637.10it/s] 12%|█▏        | 1177/10000 [00:02<00:12, 679.07it/s] 13%|█▎        | 1262/10000 [00:02<00:12, 716.87it/s] 14%|█▎        | 1350/10000 [00:02<00:11, 761.92it/s] 14%|█▍        | 1428/10000 [00:02<00:11, 721.96it/s] 15%|█▌        | 1502/10000 [00:02<00:13, 636.07it/s] 16%|█▌        | 1568/10000 [00:03<00:14, 585.83it/s] 16%|█▋        | 1629/10000 [00:03<00:15, 554.37it/s] 17%|█▋        | 1724/10000 [00:03<00:12, 642.75it/s] 19%|█▊        | 1854/10000 [00:03<00:10, 810.89it/s] 20%|█▉        | 1979/10000 [00:03<00:08, 922.87it/s] 21%|██        | 2078/10000 [00:03<00:08, 939.24it/s] 22%|██▏       | 2175/10000 [00:03<00:08, 900.54it/s] 23%|██▎       | 2268/10000 [00:03<00:09, 803.92it/s] 24%|██▍       | 2381/10000 [00:03<00:08, 877.16it/s] 25%|██▍       | 2472/10000 [00:04<00:08, 859.86it/s] 26%|██▌       | 2582/10000 [00:04<00:08, 920.16it/s] 27%|██▋       | 2676/10000 [00:04<00:09, 770.06it/s] 28%|██▊       | 2759/10000 [00:04<00:10, 702.44it/s] 28%|██▊       | 2834/10000 [00:04<00:11, 648.50it/s] 29%|██▉       | 2914/10000 [00:04<00:10, 681.60it/s] 30%|██▉       | 2986/10000 [00:04<00:10, 681.21it/s] 31%|███       | 3057/10000 [00:04<00:10, 633.00it/s] 31%|███       | 3123/10000 [00:05<00:11, 592.18it/s] 32%|███▏      | 3186/10000 [00:05<00:11, 599.84it/s] 33%|███▎      | 3291/10000 [00:05<00:09, 714.25it/s] 34%|███▍      | 3385/10000 [00:05<00:08, 775.88it/s] 35%|███▍      | 3473/10000 [00:05<00:08, 798.12it/s] 36%|███▌      | 3560/10000 [00:05<00:07, 805.74it/s] 37%|███▋      | 3655/10000 [00:05<00:07, 835.07it/s] 38%|███▊      | 3776/10000 [00:05<00:06, 940.27it/s] 39%|███▊      | 3871/10000 [00:05<00:06, 885.78it/s] 40%|███▉      | 3961/10000 [00:06<00:07, 855.60it/s] 41%|████      | 4068/10000 [00:06<00:06, 906.65it/s] 42%|████▏     | 4162/10000 [00:06<00:06, 915.57it/s] 43%|████▎     | 4302/10000 [00:06<00:05, 1037.37it/s] 44%|████▍     | 4434/10000 [00:06<00:05, 1110.73it/s] 45%|████▌     | 4546/10000 [00:06<00:05, 1018.47it/s] 46%|████▋     | 4650/10000 [00:06<00:06, 881.15it/s]  47%|████▋     | 4743/10000 [00:06<00:07, 750.38it/s] 48%|████▊     | 4824/10000 [00:07<00:07, 701.30it/s] 49%|████▉     | 4898/10000 [00:07<00:07, 655.28it/s] 50%|████▉     | 4966/10000 [00:07<00:09, 532.29it/s] 51%|█████     | 5064/10000 [00:07<00:07, 623.06it/s] 52%|█████▏    | 5150/10000 [00:07<00:07, 677.91it/s] 52%|█████▏    | 5224/10000 [00:07<00:07, 657.70it/s] 53%|█████▎    | 5294/10000 [00:07<00:08, 539.80it/s] 54%|█████▎    | 5354/10000 [00:08<00:09, 481.84it/s] 54%|█████▍    | 5408/10000 [00:08<00:09, 487.99it/s] 55%|█████▍    | 5495/10000 [00:08<00:07, 577.86it/s] 56%|█████▌    | 5587/10000 [00:08<00:06, 663.78it/s] 57%|█████▋    | 5691/10000 [00:08<00:05, 757.22it/s] 58%|█████▊    | 5790/10000 [00:08<00:05, 813.16it/s] 59%|█████▉    | 5875/10000 [00:08<00:05, 757.58it/s] 60%|█████▉    | 5954/10000 [00:08<00:06, 663.32it/s] 60%|██████    | 6025/10000 [00:09<00:06, 610.84it/s] 61%|██████    | 6106/10000 [00:09<00:05, 654.33it/s] 62%|██████▏   | 6197/10000 [00:09<00:05, 700.75it/s] 63%|██████▎   | 6270/10000 [00:09<00:05, 687.92it/s] 63%|██████▎   | 6342/10000 [00:09<00:05, 682.70it/s] 64%|██████▍   | 6426/10000 [00:09<00:04, 723.04it/s] 65%|██████▌   | 6500/10000 [00:09<00:05, 618.26it/s] 66%|██████▌   | 6568/10000 [00:09<00:05, 625.33it/s] 67%|██████▋   | 6654/10000 [00:09<00:04, 683.54it/s] 68%|██████▊   | 6755/10000 [00:10<00:04, 771.87it/s] 68%|██████▊   | 6835/10000 [00:10<00:04, 779.73it/s] 70%|██████▉   | 6972/10000 [00:10<00:03, 937.80it/s] 71%|███████   | 7071/10000 [00:10<00:03, 946.73it/s] 72%|███████▏  | 7183/10000 [00:10<00:02, 990.09it/s] 73%|███████▎  | 7283/10000 [00:10<00:02, 990.56it/s] 74%|███████▍  | 7383/10000 [00:10<00:02, 895.52it/s] 75%|███████▍  | 7483/10000 [00:10<00:02, 915.58it/s] 76%|███████▌  | 7577/10000 [00:10<00:02, 889.68it/s] 77%|███████▋  | 7668/10000 [00:11<00:02, 854.26it/s] 78%|███████▊  | 7755/10000 [00:11<00:03, 732.44it/s] 79%|███████▊  | 7853/10000 [00:11<00:02, 779.67it/s] 80%|███████▉  | 7955/10000 [00:11<00:02, 829.50it/s] 80%|████████  | 8041/10000 [00:11<00:02, 817.50it/s] 82%|████████▏ | 8165/10000 [00:11<00:01, 922.81it/s] 83%|████████▎ | 8260/10000 [00:11<00:01, 889.26it/s] 84%|████████▎ | 8351/10000 [00:11<00:01, 884.51it/s] 85%|████████▍ | 8468/10000 [00:11<00:01, 956.20it/s] 86%|████████▌ | 8565/10000 [00:12<00:01, 879.21it/s] 87%|████████▋ | 8664/10000 [00:12<00:01, 897.71it/s] 88%|████████▊ | 8794/10000 [00:12<00:01, 993.82it/s] 89%|████████▉ | 8925/10000 [00:12<00:01, 1069.39it/s] 91%|█████████ | 9063/10000 [00:12<00:00, 1155.54it/s] 92%|█████████▏| 9180/10000 [00:12<00:00, 1046.08it/s] 93%|█████████▎| 9288/10000 [00:12<00:00, 866.63it/s]  94%|█████████▍| 9382/10000 [00:12<00:00, 730.28it/s] 95%|█████████▍| 9466/10000 [00:13<00:00, 746.97it/s] 95%|█████████▌| 9547/10000 [00:13<00:00, 734.01it/s] 96%|█████████▋| 9627/10000 [00:13<00:00, 736.85it/s] 97%|█████████▋| 9704/10000 [00:13<00:00, 719.34it/s] 98%|█████████▊| 9778/10000 [00:13<00:00, 709.62it/s] 99%|█████████▊| 9874/10000 [00:13<00:00, 776.71it/s]100%|██████████| 10000/10000 [00:13<00:00, 728.61it/s]
test_neglected_p26 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p26
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p26.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.00it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.88it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.34it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.76it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.74it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.88it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.21it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.70it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.11it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.38it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p26_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p26_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p26_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p26_Holmes_probs.npy
{'Accuracy': 0.0217, 'Precision': 0.02, 'Recall': 0.0218, 'F1-score': 0.0184}
starting gen taf script for test_neglected_p27
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 107/10000 [00:00<00:09, 1036.68it/s]  2%|▏         | 211/10000 [00:00<00:14, 654.08it/s]   3%|▎         | 285/10000 [00:00<00:16, 594.72it/s]  3%|▎         | 349/10000 [00:00<00:17, 552.48it/s]  4%|▍         | 407/10000 [00:00<00:18, 516.26it/s]  5%|▍         | 477/10000 [00:00<00:16, 563.65it/s]  5%|▌         | 546/10000 [00:00<00:15, 598.24it/s]  6%|▌         | 621/10000 [00:01<00:14, 641.22it/s]  7%|▋         | 687/10000 [00:01<00:14, 633.35it/s]  8%|▊         | 759/10000 [00:01<00:14, 649.65it/s]  8%|▊         | 831/10000 [00:01<00:13, 668.59it/s]  9%|▉         | 934/10000 [00:01<00:11, 773.54it/s] 10%|█         | 1027/10000 [00:01<00:10, 819.17it/s] 11%|█         | 1110/10000 [00:01<00:11, 756.60it/s] 12%|█▏        | 1195/10000 [00:01<00:11, 772.37it/s] 13%|█▎        | 1301/10000 [00:01<00:10, 849.14it/s] 14%|█▍        | 1396/10000 [00:01<00:10, 858.07it/s] 15%|█▍        | 1483/10000 [00:02<00:11, 734.89it/s] 16%|█▌        | 1560/10000 [00:02<00:14, 564.40it/s] 16%|█▋        | 1634/10000 [00:02<00:13, 601.15it/s] 17%|█▋        | 1704/10000 [00:02<00:13, 614.28it/s] 18%|█▊        | 1814/10000 [00:02<00:11, 727.76it/s] 19%|█▉        | 1929/10000 [00:02<00:09, 831.78it/s] 20%|██        | 2047/10000 [00:02<00:08, 923.33it/s] 21%|██▏       | 2144/10000 [00:03<00:09, 830.70it/s] 22%|██▏       | 2240/10000 [00:03<00:08, 863.81it/s] 23%|██▎       | 2331/10000 [00:03<00:09, 805.04it/s] 24%|██▍       | 2415/10000 [00:03<00:09, 763.18it/s] 25%|██▌       | 2539/10000 [00:03<00:08, 886.92it/s] 26%|██▋       | 2632/10000 [00:03<00:08, 852.45it/s] 27%|██▋       | 2720/10000 [00:03<00:10, 678.81it/s] 28%|██▊       | 2795/10000 [00:03<00:12, 586.62it/s] 29%|██▉       | 2885/10000 [00:04<00:10, 649.82it/s] 30%|██▉       | 2968/10000 [00:04<00:10, 691.57it/s] 30%|███       | 3050/10000 [00:04<00:09, 716.90it/s] 31%|███▏      | 3126/10000 [00:04<00:10, 644.75it/s] 32%|███▏      | 3195/10000 [00:04<00:10, 643.71it/s] 33%|███▎      | 3299/10000 [00:04<00:09, 741.26it/s] 34%|███▍      | 3387/10000 [00:04<00:08, 765.13it/s] 35%|███▍      | 3466/10000 [00:04<00:08, 755.69it/s] 36%|███▌      | 3572/10000 [00:04<00:07, 829.52it/s] 37%|███▋      | 3657/10000 [00:05<00:07, 834.88it/s] 38%|███▊      | 3768/10000 [00:05<00:06, 904.91it/s] 39%|███▊      | 3860/10000 [00:05<00:07, 866.20it/s] 39%|███▉      | 3948/10000 [00:05<00:07, 853.83it/s] 41%|████      | 4056/10000 [00:05<00:06, 911.91it/s] 42%|████▏     | 4170/10000 [00:05<00:06, 966.33it/s] 43%|████▎     | 4299/10000 [00:05<00:05, 1048.56it/s] 44%|████▍     | 4405/10000 [00:05<00:05, 993.52it/s]  45%|████▌     | 4506/10000 [00:05<00:05, 956.38it/s] 46%|████▌     | 4603/10000 [00:06<00:06, 817.27it/s] 47%|████▋     | 4689/10000 [00:06<00:06, 822.13it/s] 48%|████▊     | 4774/10000 [00:06<00:06, 816.56it/s] 49%|████▊     | 4858/10000 [00:06<00:07, 655.43it/s] 49%|████▉     | 4930/10000 [00:06<00:08, 614.95it/s] 50%|████▉     | 4996/10000 [00:06<00:08, 616.09it/s] 51%|█████     | 5075/10000 [00:06<00:07, 656.56it/s] 52%|█████▏    | 5200/10000 [00:06<00:06, 786.95it/s] 53%|█████▎    | 5282/10000 [00:07<00:07, 619.44it/s] 54%|█████▎    | 5351/10000 [00:07<00:08, 543.42it/s] 54%|█████▍    | 5412/10000 [00:07<00:08, 533.61it/s] 55%|█████▌    | 5503/10000 [00:07<00:07, 615.64it/s] 56%|█████▌    | 5570/10000 [00:07<00:07, 628.69it/s] 56%|█████▋    | 5647/10000 [00:07<00:06, 652.66it/s] 57%|█████▋    | 5740/10000 [00:07<00:05, 716.84it/s] 58%|█████▊    | 5821/10000 [00:08<00:06, 695.13it/s] 59%|█████▉    | 5909/10000 [00:08<00:05, 728.97it/s] 60%|█████▉    | 5984/10000 [00:08<00:06, 615.60it/s] 61%|██████    | 6072/10000 [00:08<00:05, 675.99it/s] 62%|██████▏   | 6161/10000 [00:08<00:05, 726.91it/s] 63%|██████▎   | 6264/10000 [00:08<00:04, 784.11it/s] 63%|██████▎   | 6345/10000 [00:08<00:05, 720.55it/s] 64%|██████▍   | 6420/10000 [00:08<00:05, 640.34it/s] 65%|██████▍   | 6489/10000 [00:08<00:05, 646.27it/s] 66%|██████▌   | 6556/10000 [00:09<00:05, 591.35it/s] 66%|██████▋   | 6637/10000 [00:09<00:05, 632.72it/s] 67%|██████▋   | 6714/10000 [00:09<00:04, 661.17it/s] 68%|██████▊   | 6782/10000 [00:09<00:04, 651.56it/s] 69%|██████▉   | 6888/10000 [00:09<00:04, 762.59it/s] 70%|███████   | 7011/10000 [00:09<00:03, 892.73it/s] 71%|███████   | 7107/10000 [00:09<00:03, 908.91it/s] 72%|███████▏  | 7223/10000 [00:09<00:02, 972.51it/s] 73%|███████▎  | 7322/10000 [00:09<00:02, 924.73it/s] 74%|███████▍  | 7416/10000 [00:10<00:02, 915.66it/s] 75%|███████▌  | 7510/10000 [00:10<00:02, 921.72it/s] 76%|███████▋  | 7631/10000 [00:10<00:02, 984.22it/s] 77%|███████▋  | 7730/10000 [00:10<00:02, 878.94it/s] 78%|███████▊  | 7821/10000 [00:10<00:02, 878.18it/s] 79%|███████▉  | 7911/10000 [00:10<00:02, 871.56it/s] 80%|████████  | 8020/10000 [00:10<00:02, 919.03it/s] 81%|████████▏ | 8134/10000 [00:10<00:01, 963.01it/s] 82%|████████▏ | 8231/10000 [00:10<00:01, 939.35it/s] 83%|████████▎ | 8326/10000 [00:11<00:01, 902.56it/s] 84%|████████▍ | 8417/10000 [00:11<00:01, 812.84it/s] 85%|████████▌ | 8510/10000 [00:11<00:01, 837.35it/s] 86%|████████▌ | 8616/10000 [00:11<00:01, 897.43it/s] 87%|████████▋ | 8728/10000 [00:11<00:01, 956.67it/s] 88%|████████▊ | 8826/10000 [00:11<00:01, 951.86it/s] 89%|████████▉ | 8925/10000 [00:11<00:01, 962.79it/s] 90%|█████████ | 9031/10000 [00:11<00:00, 987.68it/s] 91%|█████████▏| 9143/10000 [00:11<00:00, 1019.68it/s] 92%|█████████▏| 9246/10000 [00:12<00:00, 881.76it/s]  93%|█████████▎| 9338/10000 [00:12<00:00, 726.90it/s] 94%|█████████▍| 9418/10000 [00:12<00:00, 692.19it/s] 95%|█████████▍| 9492/10000 [00:12<00:00, 673.84it/s] 96%|█████████▌| 9563/10000 [00:12<00:00, 639.05it/s] 96%|█████████▋| 9629/10000 [00:12<00:00, 627.84it/s] 97%|█████████▋| 9733/10000 [00:12<00:00, 732.74it/s] 98%|█████████▊| 9817/10000 [00:12<00:00, 761.38it/s] 99%|█████████▉| 9905/10000 [00:13<00:00, 787.92it/s]100%|██████████| 10000/10000 [00:13<00:00, 762.07it/s]
test_neglected_p27 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p27
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p27.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.01s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.80it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.22it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.44it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.52it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.60it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.95it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.33it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.84it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.12it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p27_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p27_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p27_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p27_Holmes_probs.npy
{'Accuracy': 0.0217, 'Precision': 0.0189, 'Recall': 0.0218, 'F1-score': 0.0184}
starting gen taf script for test_neglected_p28
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 74/10000 [00:00<00:14, 700.61it/s]  1%|▏         | 145/10000 [00:00<00:18, 546.67it/s]  2%|▏         | 202/10000 [00:00<00:22, 434.45it/s]  2%|▏         | 248/10000 [00:00<00:24, 402.86it/s]  3%|▎         | 290/10000 [00:00<00:28, 345.74it/s]  3%|▎         | 332/10000 [00:00<00:26, 360.37it/s]  4%|▎         | 370/10000 [00:00<00:29, 329.63it/s]  4%|▍         | 422/10000 [00:01<00:25, 374.29it/s]  5%|▍         | 474/10000 [00:01<00:23, 412.42it/s]  5%|▌         | 534/10000 [00:01<00:20, 458.23it/s]  6%|▌         | 582/10000 [00:01<00:20, 459.89it/s]  6%|▋         | 641/10000 [00:01<00:19, 489.90it/s]  7%|▋         | 691/10000 [00:01<00:19, 466.20it/s]  7%|▋         | 746/10000 [00:01<00:19, 479.46it/s]  8%|▊         | 803/10000 [00:01<00:18, 501.52it/s]  9%|▊         | 854/10000 [00:01<00:19, 479.49it/s]  9%|▉         | 906/10000 [00:02<00:19, 476.53it/s] 10%|▉         | 960/10000 [00:02<00:18, 482.64it/s] 10%|█         | 1011/10000 [00:02<00:18, 478.23it/s] 11%|█         | 1090/10000 [00:02<00:15, 565.66it/s] 11%|█▏        | 1148/10000 [00:02<00:17, 519.39it/s] 12%|█▏        | 1227/10000 [00:02<00:14, 585.49it/s] 13%|█▎        | 1331/10000 [00:02<00:12, 707.97it/s] 14%|█▍        | 1421/10000 [00:02<00:11, 716.72it/s] 15%|█▍        | 1494/10000 [00:03<00:15, 545.90it/s] 16%|█▌        | 1556/10000 [00:03<00:18, 467.73it/s] 16%|█▌        | 1614/10000 [00:03<00:17, 484.61it/s] 17%|█▋        | 1717/10000 [00:03<00:13, 605.63it/s] 18%|█▊        | 1825/10000 [00:03<00:11, 713.32it/s] 19%|█▉        | 1927/10000 [00:03<00:10, 790.81it/s] 20%|██        | 2012/10000 [00:03<00:10, 795.71it/s] 21%|██        | 2096/10000 [00:03<00:10, 781.72it/s] 22%|██▏       | 2188/10000 [00:03<00:09, 803.74it/s] 23%|██▎       | 2271/10000 [00:04<00:11, 691.53it/s] 23%|██▎       | 2345/10000 [00:04<00:12, 624.06it/s] 24%|██▍       | 2429/10000 [00:04<00:11, 674.47it/s] 26%|██▌       | 2557/10000 [00:04<00:09, 823.79it/s] 26%|██▋       | 2644/10000 [00:04<00:10, 693.46it/s] 27%|██▋       | 2720/10000 [00:04<00:11, 613.71it/s] 28%|██▊       | 2787/10000 [00:05<00:13, 531.03it/s] 29%|██▊       | 2865/10000 [00:05<00:12, 583.32it/s] 29%|██▉       | 2942/10000 [00:05<00:11, 625.89it/s] 30%|███       | 3010/10000 [00:05<00:11, 632.57it/s] 31%|███       | 3088/10000 [00:05<00:10, 667.95it/s] 32%|███▏      | 3159/10000 [00:05<00:10, 670.23it/s] 32%|███▏      | 3245/10000 [00:05<00:09, 714.87it/s] 33%|███▎      | 3346/10000 [00:05<00:08, 792.50it/s] 34%|███▍      | 3433/10000 [00:05<00:08, 792.01it/s] 36%|███▌      | 3553/10000 [00:05<00:07, 904.55it/s] 36%|███▋      | 3647/10000 [00:06<00:06, 910.43it/s] 38%|███▊      | 3761/10000 [00:06<00:06, 967.04it/s] 39%|███▊      | 3859/10000 [00:06<00:06, 901.35it/s] 40%|███▉      | 3951/10000 [00:06<00:07, 858.19it/s] 40%|████      | 4045/10000 [00:06<00:06, 875.73it/s] 41%|████▏     | 4137/10000 [00:06<00:06, 887.66it/s] 43%|████▎     | 4274/10000 [00:06<00:05, 1013.14it/s] 44%|████▍     | 4398/10000 [00:06<00:05, 1048.92it/s] 45%|████▌     | 4504/10000 [00:06<00:05, 1000.22it/s] 46%|████▌     | 4605/10000 [00:07<00:06, 803.81it/s]  47%|████▋     | 4692/10000 [00:07<00:07, 728.61it/s] 48%|████▊     | 4770/10000 [00:07<00:07, 679.06it/s] 48%|████▊     | 4844/10000 [00:07<00:07, 682.43it/s] 49%|████▉     | 4915/10000 [00:07<00:08, 601.26it/s] 50%|████▉     | 4978/10000 [00:07<00:08, 600.00it/s] 50%|█████     | 5040/10000 [00:07<00:08, 575.30it/s] 52%|█████▏    | 5162/10000 [00:08<00:06, 731.72it/s] 52%|█████▏    | 5239/10000 [00:08<00:07, 659.37it/s] 53%|█████▎    | 5309/10000 [00:08<00:08, 539.25it/s] 54%|█████▎    | 5369/10000 [00:08<00:09, 509.40it/s] 54%|█████▍    | 5424/10000 [00:08<00:09, 477.74it/s] 55%|█████▍    | 5497/10000 [00:08<00:08, 530.55it/s] 56%|█████▌    | 5558/10000 [00:08<00:08, 543.08it/s] 57%|█████▋    | 5666/10000 [00:08<00:06, 674.21it/s] 58%|█████▊    | 5756/10000 [00:09<00:05, 728.90it/s] 58%|█████▊    | 5835/10000 [00:09<00:05, 743.64it/s] 59%|█████▉    | 5912/10000 [00:09<00:06, 626.63it/s] 60%|█████▉    | 5980/10000 [00:09<00:06, 603.31it/s] 61%|██████    | 6058/10000 [00:09<00:06, 638.75it/s] 62%|██████▏   | 6168/10000 [00:09<00:05, 756.77it/s] 62%|██████▏   | 6248/10000 [00:09<00:05, 644.75it/s] 63%|██████▎   | 6341/10000 [00:09<00:05, 696.75it/s] 64%|██████▍   | 6415/10000 [00:10<00:05, 667.70it/s] 65%|██████▍   | 6485/10000 [00:10<00:05, 596.11it/s] 66%|██████▌   | 6554/10000 [00:10<00:05, 602.18it/s] 66%|██████▋   | 6626/10000 [00:10<00:05, 631.51it/s] 67%|██████▋   | 6706/10000 [00:10<00:04, 675.18it/s] 68%|██████▊   | 6776/10000 [00:10<00:05, 623.23it/s] 69%|██████▉   | 6888/10000 [00:10<00:04, 742.33it/s] 70%|██████▉   | 6986/10000 [00:10<00:03, 800.05it/s] 71%|███████   | 7091/10000 [00:10<00:03, 865.82it/s] 72%|███████▏  | 7198/10000 [00:11<00:03, 922.81it/s] 73%|███████▎  | 7339/10000 [00:11<00:02, 1048.55it/s] 74%|███████▍  | 7446/10000 [00:11<00:02, 954.06it/s]  75%|███████▌  | 7544/10000 [00:11<00:02, 883.06it/s] 76%|███████▋  | 7635/10000 [00:11<00:02, 847.99it/s] 77%|███████▋  | 7722/10000 [00:11<00:03, 756.29it/s] 78%|███████▊  | 7807/10000 [00:11<00:02, 777.12it/s] 79%|███████▉  | 7899/10000 [00:11<00:02, 813.31it/s] 80%|███████▉  | 7983/10000 [00:12<00:02, 807.53it/s] 81%|████████  | 8088/10000 [00:12<00:02, 866.78it/s] 82%|████████▏ | 8187/10000 [00:12<00:02, 876.61it/s] 83%|████████▎ | 8276/10000 [00:12<00:02, 760.62it/s] 84%|████████▎ | 8356/10000 [00:12<00:02, 764.22it/s] 84%|████████▍ | 8435/10000 [00:12<00:02, 726.89it/s] 85%|████████▌ | 8510/10000 [00:12<00:02, 726.18it/s] 86%|████████▌ | 8584/10000 [00:12<00:01, 710.67it/s] 87%|████████▋ | 8692/10000 [00:12<00:01, 811.80it/s] 88%|████████▊ | 8799/10000 [00:13<00:01, 875.35it/s] 89%|████████▉ | 8938/10000 [00:13<00:01, 1021.32it/s] 90%|█████████ | 9042/10000 [00:13<00:00, 991.40it/s]  91%|█████████▏| 9147/10000 [00:13<00:00, 1005.39it/s] 92%|█████████▏| 9249/10000 [00:13<00:00, 843.14it/s]  93%|█████████▎| 9339/10000 [00:13<00:01, 601.83it/s] 94%|█████████▍| 9412/10000 [00:13<00:01, 586.70it/s] 95%|█████████▌| 9516/10000 [00:14<00:00, 680.18it/s] 96%|█████████▌| 9618/10000 [00:14<00:00, 748.36it/s] 97%|█████████▋| 9701/10000 [00:14<00:00, 709.79it/s] 98%|█████████▊| 9786/10000 [00:14<00:00, 744.26it/s] 99%|█████████▉| 9922/10000 [00:14<00:00, 896.95it/s]100%|██████████| 10000/10000 [00:14<00:00, 688.79it/s]
test_neglected_p28 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p28
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p28.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.04s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.73it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.85it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.00it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.75it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.79it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.99it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.56it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.88it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p28_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p28_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p28_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p28_Holmes_probs.npy
{'Accuracy': 0.0226, 'Precision': 0.0207, 'Recall': 0.0227, 'F1-score': 0.0191}
starting gen taf script for test_neglected_p29
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 90/10000 [00:00<00:11, 892.47it/s]  2%|▏         | 180/10000 [00:00<00:17, 577.17it/s]  2%|▏         | 244/10000 [00:00<00:17, 543.50it/s]  3%|▎         | 302/10000 [00:00<00:22, 428.42it/s]  3%|▎         | 349/10000 [00:00<00:23, 410.96it/s]  4%|▍         | 393/10000 [00:00<00:24, 390.84it/s]  4%|▍         | 447/10000 [00:00<00:22, 416.64it/s]  5%|▌         | 503/10000 [00:01<00:20, 453.49it/s]  6%|▌         | 564/10000 [00:01<00:19, 483.79it/s]  6%|▌         | 614/10000 [00:01<00:19, 469.46it/s]  7%|▋         | 665/10000 [00:01<00:19, 477.33it/s]  7%|▋         | 738/10000 [00:01<00:16, 547.29it/s]  8%|▊         | 794/10000 [00:01<00:17, 535.00it/s]  8%|▊         | 849/10000 [00:01<00:17, 533.07it/s]  9%|▉         | 903/10000 [00:01<00:17, 534.05it/s] 10%|▉         | 992/10000 [00:01<00:14, 631.84it/s] 11%|█         | 1056/10000 [00:02<00:14, 607.08it/s] 11%|█         | 1118/10000 [00:02<00:15, 560.01it/s] 12%|█▏        | 1195/10000 [00:02<00:14, 613.84it/s] 13%|█▎        | 1278/10000 [00:02<00:12, 671.26it/s] 14%|█▎        | 1374/10000 [00:02<00:11, 753.00it/s] 15%|█▍        | 1451/10000 [00:02<00:12, 707.39it/s] 15%|█▌        | 1524/10000 [00:02<00:15, 552.51it/s] 16%|█▌        | 1586/10000 [00:02<00:16, 513.65it/s] 16%|█▋        | 1642/10000 [00:03<00:16, 499.14it/s] 17%|█▋        | 1704/10000 [00:03<00:16, 514.32it/s] 18%|█▊        | 1822/10000 [00:03<00:12, 676.56it/s] 20%|█▉        | 1971/10000 [00:03<00:09, 889.85it/s] 21%|██        | 2067/10000 [00:03<00:09, 855.65it/s] 22%|██▏       | 2158/10000 [00:03<00:09, 861.02it/s] 22%|██▏       | 2248/10000 [00:03<00:09, 850.27it/s] 23%|██▎       | 2336/10000 [00:03<00:09, 807.04it/s] 24%|██▍       | 2419/10000 [00:03<00:09, 764.03it/s] 25%|██▌       | 2534/10000 [00:04<00:08, 863.80it/s] 26%|██▋       | 2627/10000 [00:04<00:08, 878.05it/s] 27%|██▋       | 2717/10000 [00:04<00:11, 632.39it/s] 28%|██▊       | 2791/10000 [00:04<00:12, 563.42it/s] 29%|██▊       | 2872/10000 [00:04<00:11, 616.12it/s] 29%|██▉       | 2942/10000 [00:04<00:11, 621.58it/s] 30%|███       | 3010/10000 [00:04<00:11, 627.51it/s] 31%|███       | 3077/10000 [00:05<00:11, 593.65it/s] 31%|███▏      | 3140/10000 [00:05<00:11, 580.28it/s] 32%|███▏      | 3214/10000 [00:05<00:11, 612.39it/s] 33%|███▎      | 3316/10000 [00:05<00:09, 721.35it/s] 34%|███▍      | 3404/10000 [00:05<00:08, 758.15it/s] 35%|███▌      | 3523/10000 [00:05<00:07, 877.05it/s] 36%|███▌      | 3613/10000 [00:05<00:07, 839.50it/s] 37%|███▋      | 3708/10000 [00:05<00:07, 867.86it/s] 38%|███▊      | 3819/10000 [00:05<00:06, 928.70it/s] 39%|███▉      | 3914/10000 [00:06<00:07, 833.27it/s] 40%|████      | 4000/10000 [00:06<00:07, 758.91it/s] 41%|████      | 4085/10000 [00:06<00:07, 781.32it/s] 42%|████▏     | 4171/10000 [00:06<00:07, 802.23it/s] 43%|████▎     | 4297/10000 [00:06<00:06, 917.61it/s] 44%|████▍     | 4391/10000 [00:06<00:06, 912.73it/s] 45%|████▍     | 4484/10000 [00:06<00:06, 837.29it/s] 46%|████▌     | 4570/10000 [00:06<00:06, 802.22it/s] 47%|████▋     | 4652/10000 [00:06<00:07, 730.98it/s] 47%|████▋     | 4727/10000 [00:07<00:07, 706.66it/s] 48%|████▊     | 4800/10000 [00:07<00:07, 691.74it/s] 49%|████▊     | 4870/10000 [00:07<00:07, 648.20it/s] 49%|████▉     | 4936/10000 [00:07<00:08, 586.95it/s] 50%|████▉     | 4996/10000 [00:07<00:09, 511.86it/s] 51%|█████     | 5094/10000 [00:07<00:07, 617.00it/s] 52%|█████▏    | 5160/10000 [00:07<00:07, 614.03it/s] 52%|█████▏    | 5233/10000 [00:07<00:07, 627.76it/s] 53%|█████▎    | 5298/10000 [00:08<00:09, 477.34it/s] 54%|█████▎    | 5352/10000 [00:08<00:10, 444.22it/s] 54%|█████▍    | 5401/10000 [00:08<00:11, 415.04it/s] 55%|█████▍    | 5478/10000 [00:08<00:09, 489.46it/s] 56%|█████▌    | 5553/10000 [00:08<00:08, 551.21it/s] 56%|█████▋    | 5630/10000 [00:08<00:07, 599.93it/s] 58%|█████▊    | 5751/10000 [00:08<00:05, 760.48it/s] 58%|█████▊    | 5832/10000 [00:08<00:05, 736.53it/s] 59%|█████▉    | 5909/10000 [00:09<00:07, 582.94it/s] 60%|█████▉    | 5975/10000 [00:09<00:07, 537.14it/s] 61%|██████    | 6051/10000 [00:09<00:06, 587.62it/s] 61%|██████▏   | 6135/10000 [00:09<00:05, 646.29it/s] 62%|██████▏   | 6214/10000 [00:09<00:05, 664.69it/s] 63%|██████▎   | 6297/10000 [00:09<00:05, 698.49it/s] 64%|██████▎   | 6370/10000 [00:09<00:05, 609.33it/s] 64%|██████▍   | 6435/10000 [00:10<00:06, 557.25it/s] 65%|██████▌   | 6519/10000 [00:10<00:05, 616.71it/s] 66%|██████▌   | 6584/10000 [00:10<00:06, 566.43it/s] 66%|██████▋   | 6646/10000 [00:10<00:05, 567.86it/s] 67%|██████▋   | 6708/10000 [00:10<00:05, 575.61it/s] 68%|██████▊   | 6776/10000 [00:10<00:05, 603.49it/s] 69%|██████▉   | 6882/10000 [00:10<00:04, 725.88it/s] 70%|██████▉   | 6987/10000 [00:10<00:03, 804.93it/s] 71%|███████   | 7069/10000 [00:10<00:03, 807.88it/s] 72%|███████▏  | 7160/10000 [00:11<00:03, 832.29it/s] 73%|███████▎  | 7259/10000 [00:11<00:03, 878.10it/s] 74%|███████▍  | 7377/10000 [00:11<00:02, 965.69it/s] 75%|███████▍  | 7479/10000 [00:11<00:02, 971.97it/s] 76%|███████▌  | 7578/10000 [00:11<00:02, 940.63it/s] 77%|███████▋  | 7673/10000 [00:11<00:02, 799.49it/s] 78%|███████▊  | 7757/10000 [00:11<00:03, 686.68it/s] 79%|███████▊  | 7860/10000 [00:11<00:02, 761.29it/s] 80%|███████▉  | 7980/10000 [00:11<00:02, 866.39it/s] 81%|████████  | 8090/10000 [00:12<00:02, 926.00it/s] 82%|████████▏ | 8188/10000 [00:12<00:01, 918.13it/s] 83%|████████▎ | 8283/10000 [00:12<00:02, 812.48it/s] 84%|████████▍ | 8392/10000 [00:12<00:01, 866.91it/s] 85%|████████▍ | 8483/10000 [00:12<00:01, 762.18it/s] 86%|████████▌ | 8564/10000 [00:12<00:01, 723.54it/s] 86%|████████▋ | 8643/10000 [00:12<00:01, 739.68it/s] 88%|████████▊ | 8755/10000 [00:12<00:01, 832.05it/s] 89%|████████▊ | 8863/10000 [00:13<00:01, 887.25it/s] 90%|████████▉ | 8995/10000 [00:13<00:01, 982.83it/s] 91%|█████████ | 9096/10000 [00:13<00:00, 966.14it/s] 92%|█████████▏| 9194/10000 [00:13<00:00, 968.56it/s] 93%|█████████▎| 9292/10000 [00:13<00:00, 767.79it/s] 94%|█████████▍| 9376/10000 [00:13<00:01, 600.73it/s] 95%|█████████▍| 9458/10000 [00:13<00:00, 645.80it/s] 95%|█████████▌| 9542/10000 [00:13<00:00, 684.12it/s] 96%|█████████▌| 9618/10000 [00:14<00:00, 659.49it/s] 97%|█████████▋| 9689/10000 [00:14<00:00, 641.53it/s] 98%|█████████▊| 9757/10000 [00:14<00:00, 610.77it/s] 98%|█████████▊| 9839/10000 [00:14<00:00, 657.12it/s] 99%|█████████▉| 9940/10000 [00:14<00:00, 749.54it/s]100%|██████████| 10000/10000 [00:14<00:00, 684.73it/s]
test_neglected_p29 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p29
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p29.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:31,  1.25it/s]evaluating model with Holmes:  10%|█         | 4/40 [00:00<00:06,  5.53it/s]evaluating model with Holmes:  22%|██▎       | 9/40 [00:01<00:02, 13.20it/s]evaluating model with Holmes:  35%|███▌      | 14/40 [00:01<00:01, 20.39it/s]evaluating model with Holmes:  48%|████▊     | 19/40 [00:01<00:00, 26.79it/s]evaluating model with Holmes:  60%|██████    | 24/40 [00:01<00:00, 31.65it/s]evaluating model with Holmes:  72%|███████▎  | 29/40 [00:01<00:00, 35.85it/s]evaluating model with Holmes:  85%|████████▌ | 34/40 [00:01<00:00, 38.73it/s]evaluating model with Holmes:  98%|█████████▊| 39/40 [00:01<00:00, 40.02it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 23.21it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p29_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p29_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p29_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p29_Holmes_probs.npy
{'Accuracy': 0.0226, 'Precision': 0.0216, 'Recall': 0.0226, 'F1-score': 0.0193}
starting gen taf script for test_neglected_p30
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 87/10000 [00:00<00:11, 861.86it/s]  2%|▏         | 174/10000 [00:00<00:21, 459.06it/s]  2%|▏         | 230/10000 [00:00<00:22, 426.60it/s]  3%|▎         | 278/10000 [00:00<00:22, 426.05it/s]  3%|▎         | 324/10000 [00:00<00:22, 422.05it/s]  4%|▎         | 369/10000 [00:00<00:23, 412.91it/s]  4%|▍         | 417/10000 [00:00<00:22, 430.83it/s]  5%|▍         | 468/10000 [00:01<00:21, 450.22it/s]  5%|▌         | 514/10000 [00:01<00:30, 306.03it/s]  6%|▌         | 551/10000 [00:01<00:32, 291.72it/s]  6%|▌         | 588/10000 [00:01<00:30, 308.35it/s]  6%|▋         | 636/10000 [00:01<00:26, 348.29it/s]  7%|▋         | 692/10000 [00:01<00:23, 398.50it/s]  7%|▋         | 746/10000 [00:01<00:21, 434.05it/s]  8%|▊         | 810/10000 [00:01<00:18, 484.19it/s]  9%|▉         | 889/10000 [00:02<00:16, 561.57it/s] 10%|▉         | 975/10000 [00:02<00:13, 645.13it/s] 11%|█         | 1064/10000 [00:02<00:12, 704.37it/s] 11%|█▏        | 1136/10000 [00:02<00:12, 699.66it/s] 12%|█▏        | 1216/10000 [00:02<00:12, 725.16it/s] 13%|█▎        | 1310/10000 [00:02<00:11, 787.09it/s] 14%|█▍        | 1394/10000 [00:02<00:10, 785.67it/s] 15%|█▍        | 1474/10000 [00:02<00:13, 627.68it/s] 15%|█▌        | 1543/10000 [00:03<00:16, 513.28it/s] 16%|█▌        | 1601/10000 [00:03<00:16, 497.11it/s] 17%|█▋        | 1668/10000 [00:03<00:15, 536.55it/s] 18%|█▊        | 1760/10000 [00:03<00:13, 626.98it/s] 19%|█▊        | 1851/10000 [00:03<00:11, 700.18it/s] 19%|█▉        | 1949/10000 [00:03<00:10, 769.75it/s] 20%|██        | 2045/10000 [00:03<00:09, 813.57it/s] 21%|██▏       | 2130/10000 [00:03<00:09, 805.70it/s] 22%|██▏       | 2213/10000 [00:03<00:09, 787.83it/s] 23%|██▎       | 2294/10000 [00:04<00:11, 685.86it/s] 24%|██▎       | 2366/10000 [00:04<00:11, 670.90it/s] 25%|██▍       | 2452/10000 [00:04<00:10, 717.50it/s] 25%|██▌       | 2545/10000 [00:04<00:09, 771.59it/s] 26%|██▋       | 2625/10000 [00:04<00:10, 732.21it/s] 27%|██▋       | 2700/10000 [00:04<00:11, 629.34it/s] 28%|██▊       | 2767/10000 [00:04<00:13, 544.66it/s] 28%|██▊       | 2826/10000 [00:04<00:13, 538.59it/s] 29%|██▉       | 2894/10000 [00:05<00:12, 573.02it/s] 30%|██▉       | 2967/10000 [00:05<00:11, 612.91it/s] 30%|███       | 3031/10000 [00:05<00:11, 605.45it/s] 31%|███       | 3108/10000 [00:05<00:11, 622.07it/s] 32%|███▏      | 3181/10000 [00:05<00:10, 637.90it/s] 33%|███▎      | 3275/10000 [00:05<00:09, 714.21it/s] 34%|███▎      | 3369/10000 [00:05<00:08, 772.51it/s] 35%|███▍      | 3457/10000 [00:05<00:08, 801.63it/s] 35%|███▌      | 3539/10000 [00:05<00:08, 794.36it/s] 36%|███▌      | 3620/10000 [00:06<00:08, 774.87it/s] 37%|███▋      | 3699/10000 [00:06<00:08, 762.54it/s] 38%|███▊      | 3800/10000 [00:06<00:07, 817.33it/s] 39%|███▉      | 3882/10000 [00:06<00:08, 757.61it/s] 40%|███▉      | 3959/10000 [00:06<00:08, 750.38it/s] 40%|████      | 4048/10000 [00:06<00:07, 776.59it/s] 42%|████▏     | 4153/10000 [00:06<00:06, 852.56it/s] 43%|████▎     | 4253/10000 [00:06<00:06, 894.35it/s] 44%|████▎     | 4350/10000 [00:06<00:06, 899.79it/s] 44%|████▍     | 4441/10000 [00:07<00:06, 888.68it/s] 45%|████▌     | 4531/10000 [00:07<00:07, 769.22it/s] 46%|████▌     | 4613/10000 [00:07<00:06, 782.24it/s] 47%|████▋     | 4694/10000 [00:07<00:07, 672.28it/s] 48%|████▊     | 4766/10000 [00:07<00:07, 673.41it/s] 48%|████▊     | 4837/10000 [00:07<00:09, 561.70it/s] 49%|████▉     | 4898/10000 [00:07<00:10, 484.88it/s] 50%|████▉     | 4951/10000 [00:08<00:10, 476.64it/s] 50%|█████     | 5013/10000 [00:08<00:09, 503.31it/s] 51%|█████     | 5095/10000 [00:08<00:08, 576.73it/s] 52%|█████▏    | 5176/10000 [00:08<00:07, 620.62it/s] 52%|█████▏    | 5241/10000 [00:08<00:08, 534.94it/s] 53%|█████▎    | 5298/10000 [00:08<00:09, 472.39it/s] 53%|█████▎    | 5349/10000 [00:08<00:09, 472.38it/s] 54%|█████▍    | 5399/10000 [00:08<00:10, 418.70it/s] 55%|█████▍    | 5463/10000 [00:09<00:09, 465.00it/s] 55%|█████▌    | 5535/10000 [00:09<00:08, 528.28it/s] 56%|█████▋    | 5626/10000 [00:09<00:06, 627.55it/s] 57%|█████▋    | 5725/10000 [00:09<00:05, 720.70it/s] 58%|█████▊    | 5829/10000 [00:09<00:05, 801.19it/s] 59%|█████▉    | 5912/10000 [00:09<00:06, 647.99it/s] 60%|█████▉    | 5984/10000 [00:09<00:06, 583.83it/s] 61%|██████    | 6054/10000 [00:09<00:06, 608.79it/s] 61%|██████▏   | 6138/10000 [00:09<00:05, 662.02it/s] 62%|██████▏   | 6228/10000 [00:10<00:05, 721.92it/s] 63%|██████▎   | 6304/10000 [00:10<00:05, 621.10it/s] 64%|██████▍   | 6385/10000 [00:10<00:05, 652.17it/s] 65%|██████▍   | 6454/10000 [00:10<00:05, 605.48it/s] 65%|██████▌   | 6518/10000 [00:10<00:06, 536.01it/s] 66%|██████▌   | 6575/10000 [00:10<00:06, 506.85it/s] 67%|██████▋   | 6658/10000 [00:10<00:05, 578.01it/s] 67%|██████▋   | 6720/10000 [00:10<00:05, 585.29it/s] 68%|██████▊   | 6807/10000 [00:11<00:04, 658.72it/s] 69%|██████▉   | 6913/10000 [00:11<00:04, 768.24it/s] 70%|███████   | 7036/10000 [00:11<00:03, 886.27it/s] 71%|███████▏  | 7127/10000 [00:11<00:03, 835.64it/s] 72%|███████▏  | 7223/10000 [00:11<00:03, 865.80it/s] 73%|███████▎  | 7312/10000 [00:11<00:03, 817.21it/s] 74%|███████▍  | 7408/10000 [00:11<00:03, 854.54it/s] 75%|███████▌  | 7501/10000 [00:11<00:02, 871.66it/s] 76%|███████▌  | 7598/10000 [00:11<00:02, 899.48it/s] 77%|███████▋  | 7689/10000 [00:12<00:02, 873.79it/s] 78%|███████▊  | 7778/10000 [00:12<00:02, 743.89it/s] 79%|███████▊  | 7869/10000 [00:12<00:02, 785.42it/s] 80%|████████  | 8012/10000 [00:12<00:02, 937.93it/s] 81%|████████  | 8110/10000 [00:12<00:02, 926.33it/s] 82%|████████▏ | 8205/10000 [00:12<00:02, 884.29it/s] 83%|████████▎ | 8296/10000 [00:12<00:01, 862.80it/s] 84%|████████▍ | 8384/10000 [00:12<00:01, 825.55it/s] 85%|████████▍ | 8468/10000 [00:13<00:02, 748.70it/s] 85%|████████▌ | 8545/10000 [00:13<00:02, 717.97it/s] 86%|████████▌ | 8618/10000 [00:13<00:01, 706.93it/s] 87%|████████▋ | 8746/10000 [00:13<00:01, 853.13it/s] 89%|████████▉ | 8880/10000 [00:13<00:01, 981.16it/s] 90%|████████▉ | 8981/10000 [00:13<00:01, 957.02it/s] 91%|█████████ | 9090/10000 [00:13<00:00, 988.08it/s] 92%|█████████▏| 9191/10000 [00:13<00:00, 934.30it/s] 93%|█████████▎| 9286/10000 [00:13<00:00, 767.12it/s] 94%|█████████▎| 9369/10000 [00:14<00:01, 619.93it/s] 95%|█████████▍| 9453/10000 [00:14<00:00, 655.35it/s] 95%|█████████▌| 9525/10000 [00:14<00:00, 601.55it/s] 96%|█████████▌| 9590/10000 [00:14<00:00, 605.42it/s] 97%|█████████▋| 9698/10000 [00:14<00:00, 721.08it/s] 98%|█████████▊| 9776/10000 [00:14<00:00, 656.24it/s] 99%|█████████▊| 9855/10000 [00:14<00:00, 682.39it/s]100%|█████████▉| 9956/10000 [00:15<00:00, 759.09it/s]100%|██████████| 10000/10000 [00:15<00:00, 665.08it/s]
test_neglected_p30 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p30
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p30.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.00s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.01it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.20it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.42it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.31it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.17it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.52it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.03it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.42it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p30_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p30_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p30_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p30_Holmes_probs.npy
{'Accuracy': 0.0221, 'Precision': 0.0216, 'Recall': 0.0221, 'F1-score': 0.0189}
starting gen taf script for test_neglected_p31
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 91/10000 [00:00<00:11, 851.45it/s]  2%|▏         | 177/10000 [00:00<00:22, 434.80it/s]  2%|▏         | 231/10000 [00:00<00:22, 437.33it/s]  3%|▎         | 281/10000 [00:00<00:22, 436.69it/s]  3%|▎         | 329/10000 [00:00<00:22, 433.91it/s]  4%|▍         | 375/10000 [00:00<00:22, 432.68it/s]  4%|▍         | 420/10000 [00:00<00:22, 428.19it/s]  5%|▍         | 464/10000 [00:01<00:30, 311.12it/s]  5%|▌         | 500/10000 [00:01<00:29, 318.97it/s]  5%|▌         | 536/10000 [00:01<00:28, 327.35it/s]  6%|▌         | 585/10000 [00:01<00:25, 363.23it/s]  6%|▋         | 645/10000 [00:01<00:22, 415.94it/s]  7%|▋         | 706/10000 [00:01<00:19, 466.42it/s]  8%|▊         | 755/10000 [00:01<00:19, 462.93it/s]  8%|▊         | 803/10000 [00:01<00:19, 465.52it/s]  9%|▊         | 857/10000 [00:02<00:19, 471.37it/s]  9%|▉         | 905/10000 [00:02<00:19, 466.42it/s] 10%|▉         | 966/10000 [00:02<00:17, 502.57it/s] 10%|█         | 1027/10000 [00:02<00:17, 526.23it/s] 11%|█         | 1098/10000 [00:02<00:15, 576.26it/s] 12%|█▏        | 1157/10000 [00:02<00:17, 506.45it/s] 12%|█▏        | 1233/10000 [00:02<00:15, 570.34it/s] 13%|█▎        | 1323/10000 [00:02<00:13, 653.16it/s] 14%|█▍        | 1409/10000 [00:02<00:12, 705.36it/s] 15%|█▍        | 1482/10000 [00:03<00:14, 602.01it/s] 15%|█▌        | 1546/10000 [00:03<00:17, 477.52it/s] 16%|█▌        | 1600/10000 [00:03<00:17, 475.43it/s] 17%|█▋        | 1681/10000 [00:03<00:15, 548.39it/s] 18%|█▊        | 1793/10000 [00:03<00:11, 689.13it/s] 19%|█▉        | 1888/10000 [00:03<00:10, 752.72it/s] 20%|██        | 2013/10000 [00:03<00:09, 887.40it/s] 21%|██        | 2107/10000 [00:03<00:10, 783.59it/s] 22%|██▏       | 2191/10000 [00:04<00:10, 744.02it/s] 23%|██▎       | 2270/10000 [00:04<00:11, 702.63it/s] 23%|██▎       | 2344/10000 [00:04<00:11, 681.75it/s] 24%|██▍       | 2415/10000 [00:04<00:11, 680.44it/s] 25%|██▌       | 2532/10000 [00:04<00:09, 803.15it/s] 26%|██▌       | 2615/10000 [00:04<00:11, 619.02it/s] 27%|██▋       | 2685/10000 [00:04<00:11, 611.81it/s] 28%|██▊       | 2752/10000 [00:05<00:13, 534.78it/s] 28%|██▊       | 2811/10000 [00:05<00:14, 498.69it/s] 29%|██▉       | 2895/10000 [00:05<00:12, 576.19it/s] 30%|██▉       | 2981/10000 [00:05<00:10, 644.58it/s] 31%|███       | 3061/10000 [00:05<00:10, 671.26it/s] 31%|███▏      | 3132/10000 [00:05<00:10, 653.53it/s] 32%|███▏      | 3200/10000 [00:05<00:10, 654.91it/s] 33%|███▎      | 3299/10000 [00:05<00:09, 743.69it/s] 34%|███▍      | 3387/10000 [00:05<00:08, 780.11it/s] 35%|███▍      | 3479/10000 [00:06<00:07, 820.07it/s] 36%|███▌      | 3563/10000 [00:06<00:07, 810.32it/s] 37%|███▋      | 3683/10000 [00:06<00:06, 921.51it/s] 38%|███▊      | 3777/10000 [00:06<00:07, 885.53it/s] 39%|███▊      | 3867/10000 [00:06<00:07, 827.64it/s] 40%|███▉      | 3952/10000 [00:06<00:07, 815.23it/s] 40%|████      | 4035/10000 [00:06<00:07, 788.41it/s] 41%|████▏     | 4133/10000 [00:06<00:07, 832.82it/s] 42%|████▏     | 4238/10000 [00:06<00:06, 883.50it/s] 43%|████▎     | 4328/10000 [00:07<00:06, 853.27it/s] 44%|████▍     | 4418/10000 [00:07<00:06, 845.46it/s] 45%|████▌     | 4503/10000 [00:07<00:06, 796.62it/s] 46%|████▌     | 4584/10000 [00:07<00:07, 773.31it/s] 47%|████▋     | 4662/10000 [00:07<00:07, 731.45it/s] 47%|████▋     | 4736/10000 [00:07<00:08, 647.66it/s] 48%|████▊     | 4803/10000 [00:07<00:08, 600.44it/s] 49%|████▊     | 4865/10000 [00:07<00:09, 566.18it/s] 49%|████▉     | 4923/10000 [00:08<00:09, 531.99it/s] 50%|████▉     | 4977/10000 [00:08<00:10, 474.41it/s] 51%|█████     | 5078/10000 [00:08<00:08, 603.30it/s] 52%|█████▏    | 5192/10000 [00:08<00:06, 730.25it/s] 53%|█████▎    | 5270/10000 [00:08<00:08, 576.43it/s] 53%|█████▎    | 5336/10000 [00:08<00:09, 504.76it/s] 54%|█████▍    | 5393/10000 [00:08<00:09, 479.92it/s] 55%|█████▍    | 5454/10000 [00:08<00:08, 505.92it/s] 55%|█████▌    | 5509/10000 [00:09<00:08, 511.20it/s] 56%|█████▌    | 5578/10000 [00:09<00:08, 550.74it/s] 57%|█████▋    | 5663/10000 [00:09<00:06, 629.57it/s] 58%|█████▊    | 5772/10000 [00:09<00:05, 754.98it/s] 59%|█████▊    | 5851/10000 [00:09<00:05, 719.54it/s] 59%|█████▉    | 5926/10000 [00:09<00:06, 588.99it/s] 60%|█████▉    | 5991/10000 [00:09<00:06, 576.23it/s] 61%|██████    | 6091/10000 [00:09<00:05, 674.35it/s] 62%|██████▏   | 6182/10000 [00:10<00:05, 734.15it/s] 63%|██████▎   | 6260/10000 [00:10<00:05, 679.45it/s] 63%|██████▎   | 6332/10000 [00:10<00:05, 637.42it/s] 64%|██████▍   | 6401/10000 [00:10<00:05, 643.64it/s] 65%|██████▍   | 6468/10000 [00:10<00:05, 593.72it/s] 66%|██████▌   | 6556/10000 [00:10<00:05, 664.25it/s] 66%|██████▋   | 6625/10000 [00:10<00:05, 623.32it/s] 67%|██████▋   | 6703/10000 [00:10<00:04, 663.56it/s] 68%|██████▊   | 6772/10000 [00:10<00:04, 646.32it/s] 69%|██████▉   | 6876/10000 [00:11<00:04, 750.47it/s] 70%|██████▉   | 6960/10000 [00:11<00:03, 775.22it/s] 71%|███████   | 7065/10000 [00:11<00:03, 832.26it/s] 72%|███████▏  | 7155/10000 [00:11<00:03, 850.70it/s] 73%|███████▎  | 7258/10000 [00:11<00:03, 899.67it/s] 74%|███████▎  | 7360/10000 [00:11<00:02, 915.01it/s] 75%|███████▍  | 7452/10000 [00:11<00:02, 852.34it/s] 75%|███████▌  | 7539/10000 [00:11<00:02, 837.44it/s] 76%|███████▌  | 7624/10000 [00:11<00:02, 792.62it/s] 77%|███████▋  | 7705/10000 [00:12<00:03, 707.41it/s] 78%|███████▊  | 7778/10000 [00:12<00:03, 662.12it/s] 79%|███████▉  | 7894/10000 [00:12<00:02, 788.77it/s] 80%|███████▉  | 7991/10000 [00:12<00:02, 835.86it/s] 81%|████████  | 8082/10000 [00:12<00:02, 855.83it/s] 82%|████████▏ | 8170/10000 [00:12<00:02, 827.77it/s] 83%|████████▎ | 8255/10000 [00:12<00:02, 715.94it/s] 83%|████████▎ | 8331/10000 [00:12<00:02, 674.22it/s] 84%|████████▍ | 8402/10000 [00:13<00:02, 677.13it/s] 85%|████████▍ | 8472/10000 [00:13<00:02, 676.83it/s] 85%|████████▌ | 8541/10000 [00:13<00:02, 663.95it/s] 86%|████████▌ | 8619/10000 [00:13<00:01, 691.59it/s] 87%|████████▋ | 8732/10000 [00:13<00:01, 810.97it/s] 88%|████████▊ | 8840/10000 [00:13<00:01, 882.98it/s] 89%|████████▉ | 8942/10000 [00:13<00:01, 913.53it/s] 90%|█████████ | 9035/10000 [00:13<00:01, 886.08it/s] 91%|█████████▏| 9136/10000 [00:13<00:00, 915.21it/s] 92%|█████████▏| 9229/10000 [00:14<00:00, 852.28it/s] 93%|█████████▎| 9316/10000 [00:14<00:00, 690.81it/s] 94%|█████████▍| 9391/10000 [00:14<00:01, 595.94it/s] 95%|█████████▍| 9467/10000 [00:14<00:00, 628.46it/s] 95%|█████████▌| 9535/10000 [00:14<00:00, 601.63it/s] 96%|█████████▌| 9608/10000 [00:14<00:00, 630.05it/s] 97%|█████████▋| 9688/10000 [00:14<00:00, 668.23it/s] 98%|█████████▊| 9758/10000 [00:14<00:00, 643.78it/s] 99%|█████████▊| 9869/10000 [00:15<00:00, 747.43it/s]100%|█████████▉| 9954/10000 [00:15<00:00, 770.02it/s]100%|██████████| 10000/10000 [00:15<00:00, 659.29it/s]
test_neglected_p31 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p31
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p31.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.00s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.85it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.46it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.98it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.08it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.31it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.56it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 38.10it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.51it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.46it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p31_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p31_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p31_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p31_Holmes_probs.npy
{'Accuracy': 0.0216, 'Precision': 0.0205, 'Recall': 0.0216, 'F1-score': 0.0182}
starting gen taf script for test_neglected_p32
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 117/10000 [00:00<00:08, 1167.59it/s]  2%|▏         | 234/10000 [00:00<00:19, 513.25it/s]   3%|▎         | 304/10000 [00:00<00:21, 446.40it/s]  4%|▎         | 359/10000 [00:00<00:22, 434.12it/s]  4%|▍         | 408/10000 [00:00<00:22, 428.09it/s]  5%|▍         | 456/10000 [00:00<00:21, 440.54it/s]  5%|▌         | 503/10000 [00:01<00:22, 430.74it/s]  6%|▌         | 555/10000 [00:01<00:21, 442.44it/s]  6%|▌         | 610/10000 [00:01<00:20, 459.59it/s]  7%|▋         | 666/10000 [00:01<00:19, 485.39it/s]  7%|▋         | 726/10000 [00:01<00:18, 511.92it/s]  8%|▊         | 779/10000 [00:01<00:18, 486.55it/s]  8%|▊         | 829/10000 [00:01<00:20, 458.54it/s]  9%|▉         | 876/10000 [00:01<00:19, 460.73it/s]  9%|▉         | 926/10000 [00:01<00:19, 465.66it/s] 10%|▉         | 984/10000 [00:02<00:18, 496.89it/s] 10%|█         | 1045/10000 [00:02<00:16, 529.18it/s] 11%|█         | 1118/10000 [00:02<00:15, 586.59it/s] 12%|█▏        | 1178/10000 [00:02<00:15, 562.85it/s] 13%|█▎        | 1298/10000 [00:02<00:11, 735.45it/s] 14%|█▍        | 1412/10000 [00:02<00:10, 848.52it/s] 15%|█▍        | 1498/10000 [00:02<00:14, 569.20it/s] 16%|█▌        | 1568/10000 [00:03<00:16, 503.25it/s] 16%|█▋        | 1628/10000 [00:03<00:16, 510.37it/s] 17%|█▋        | 1741/10000 [00:03<00:12, 642.50it/s] 18%|█▊        | 1824/10000 [00:03<00:11, 687.41it/s] 19%|█▉        | 1933/10000 [00:03<00:10, 790.20it/s] 20%|██        | 2019/10000 [00:03<00:09, 805.84it/s] 21%|██        | 2105/10000 [00:03<00:09, 818.78it/s] 22%|██▏       | 2191/10000 [00:03<00:09, 820.42it/s] 23%|██▎       | 2276/10000 [00:03<00:11, 678.05it/s] 24%|██▎       | 2350/10000 [00:04<00:11, 661.58it/s] 24%|██▍       | 2421/10000 [00:04<00:11, 668.09it/s] 25%|██▌       | 2524/10000 [00:04<00:09, 752.00it/s] 26%|██▌       | 2603/10000 [00:04<00:09, 743.32it/s] 27%|██▋       | 2680/10000 [00:04<00:11, 641.50it/s] 27%|██▋       | 2748/10000 [00:04<00:13, 523.98it/s] 28%|██▊       | 2806/10000 [00:04<00:13, 527.93it/s] 29%|██▉       | 2891/10000 [00:04<00:11, 600.21it/s] 30%|██▉       | 2984/10000 [00:05<00:10, 667.57it/s] 31%|███       | 3055/10000 [00:05<00:10, 657.11it/s] 31%|███       | 3124/10000 [00:05<00:11, 583.73it/s] 32%|███▏      | 3199/10000 [00:05<00:10, 622.47it/s] 33%|███▎      | 3307/10000 [00:05<00:09, 741.92it/s] 34%|███▍      | 3425/10000 [00:05<00:07, 852.46it/s] 35%|███▌      | 3514/10000 [00:05<00:07, 854.19it/s] 36%|███▌      | 3605/10000 [00:05<00:07, 862.01it/s] 37%|███▋      | 3727/10000 [00:05<00:06, 963.87it/s] 38%|███▊      | 3826/10000 [00:06<00:07, 873.86it/s] 39%|███▉      | 3917/10000 [00:06<00:07, 800.01it/s] 40%|████      | 4000/10000 [00:06<00:07, 777.02it/s] 41%|████▏     | 4127/10000 [00:06<00:06, 904.51it/s] 42%|████▏     | 4235/10000 [00:06<00:06, 943.43it/s] 44%|████▍     | 4382/10000 [00:06<00:05, 1089.41it/s] 45%|████▍     | 4494/10000 [00:06<00:06, 912.96it/s]  46%|████▌     | 4592/10000 [00:06<00:06, 810.53it/s] 47%|████▋     | 4680/10000 [00:07<00:07, 690.40it/s] 48%|████▊     | 4756/10000 [00:07<00:08, 641.99it/s] 48%|████▊     | 4830/10000 [00:07<00:07, 650.33it/s] 49%|████▉     | 4899/10000 [00:07<00:09, 554.71it/s] 50%|████▉     | 4959/10000 [00:07<00:10, 497.10it/s] 50%|█████     | 5016/10000 [00:07<00:09, 504.21it/s] 51%|█████     | 5096/10000 [00:07<00:08, 572.84it/s] 52%|█████▏    | 5179/10000 [00:08<00:07, 634.31it/s] 52%|█████▏    | 5246/10000 [00:08<00:08, 547.20it/s] 53%|█████▎    | 5305/10000 [00:08<00:09, 470.78it/s] 54%|█████▎    | 5357/10000 [00:08<00:10, 459.72it/s] 54%|█████▍    | 5417/10000 [00:08<00:09, 492.73it/s] 55%|█████▍    | 5488/10000 [00:08<00:08, 544.33it/s] 56%|█████▌    | 5563/10000 [00:08<00:07, 594.18it/s] 56%|█████▋    | 5639/10000 [00:08<00:06, 637.88it/s] 57%|█████▋    | 5717/10000 [00:09<00:06, 672.02it/s] 58%|█████▊    | 5813/10000 [00:09<00:05, 750.34it/s] 59%|█████▉    | 5890/10000 [00:09<00:07, 563.82it/s] 60%|█████▉    | 5955/10000 [00:09<00:07, 546.60it/s] 60%|██████    | 6016/10000 [00:09<00:07, 550.82it/s] 61%|██████    | 6109/10000 [00:09<00:06, 632.03it/s] 62%|██████▏   | 6191/10000 [00:09<00:05, 669.10it/s] 63%|██████▎   | 6261/10000 [00:09<00:05, 640.07it/s] 63%|██████▎   | 6328/10000 [00:10<00:05, 616.07it/s] 64%|██████▍   | 6392/10000 [00:10<00:06, 595.56it/s] 65%|██████▍   | 6453/10000 [00:10<00:06, 570.64it/s] 65%|██████▌   | 6516/10000 [00:10<00:06, 576.74it/s] 66%|██████▌   | 6575/10000 [00:10<00:06, 543.12it/s] 66%|██████▋   | 6630/10000 [00:10<00:06, 535.08it/s] 67%|██████▋   | 6688/10000 [00:10<00:06, 533.44it/s] 68%|██████▊   | 6774/10000 [00:10<00:05, 610.76it/s] 69%|██████▊   | 6854/10000 [00:10<00:04, 663.09it/s] 69%|██████▉   | 6939/10000 [00:11<00:04, 715.78it/s] 70%|███████   | 7038/10000 [00:11<00:03, 786.83it/s] 71%|███████   | 7118/10000 [00:11<00:03, 750.06it/s] 72%|███████▏  | 7194/10000 [00:11<00:03, 750.88it/s] 73%|███████▎  | 7298/10000 [00:11<00:03, 822.86it/s] 74%|███████▍  | 7381/10000 [00:11<00:03, 804.48it/s] 75%|███████▍  | 7462/10000 [00:11<00:03, 778.93it/s] 75%|███████▌  | 7541/10000 [00:11<00:03, 757.83it/s] 76%|███████▌  | 7618/10000 [00:11<00:03, 752.33it/s] 77%|███████▋  | 7694/10000 [00:12<00:03, 657.90it/s] 78%|███████▊  | 7777/10000 [00:12<00:03, 687.72it/s] 78%|███████▊  | 7848/10000 [00:12<00:03, 690.95it/s] 80%|███████▉  | 7979/10000 [00:12<00:02, 860.00it/s] 81%|████████  | 8068/10000 [00:12<00:02, 859.19it/s] 82%|████████▏ | 8156/10000 [00:12<00:02, 817.72it/s] 82%|████████▏ | 8240/10000 [00:12<00:02, 756.62it/s] 83%|████████▎ | 8318/10000 [00:12<00:02, 707.73it/s] 84%|████████▍ | 8398/10000 [00:12<00:02, 710.19it/s] 85%|████████▍ | 8476/10000 [00:13<00:02, 719.92it/s] 86%|████████▌ | 8587/10000 [00:13<00:01, 826.24it/s] 87%|████████▋ | 8694/10000 [00:13<00:01, 891.64it/s] 88%|████████▊ | 8786/10000 [00:13<00:01, 893.94it/s] 89%|████████▉ | 8927/10000 [00:13<00:01, 1025.91it/s] 90%|█████████ | 9031/10000 [00:13<00:00, 1002.05it/s] 92%|█████████▏| 9164/10000 [00:13<00:00, 1087.38it/s] 93%|█████████▎| 9274/10000 [00:13<00:00, 814.36it/s]  94%|█████████▎| 9366/10000 [00:14<00:00, 669.04it/s] 94%|█████████▍| 9444/10000 [00:14<00:00, 582.53it/s] 95%|█████████▌| 9511/10000 [00:14<00:00, 591.23it/s] 96%|█████████▌| 9578/10000 [00:14<00:00, 596.82it/s] 97%|█████████▋| 9652/10000 [00:14<00:00, 630.41it/s] 97%|█████████▋| 9720/10000 [00:14<00:00, 628.43it/s] 98%|█████████▊| 9789/10000 [00:14<00:00, 644.41it/s] 99%|█████████▊| 9871/10000 [00:14<00:00, 687.08it/s]100%|█████████▉| 9969/10000 [00:15<00:00, 768.14it/s]100%|██████████| 10000/10000 [00:15<00:00, 665.04it/s]
test_neglected_p32 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p32
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p32.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.02s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.89it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.10it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.36it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.19it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.19it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.52it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.96it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.35it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p32_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p32_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p32_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p32_Holmes_probs.npy
{'Accuracy': 0.0213, 'Precision': 0.0212, 'Recall': 0.0213, 'F1-score': 0.0181}
starting gen taf script for test_neglected_p33
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 84/10000 [00:00<00:12, 816.57it/s]  2%|▏         | 166/10000 [00:00<00:21, 460.78it/s]  2%|▏         | 221/10000 [00:00<00:23, 423.13it/s]  3%|▎         | 268/10000 [00:00<00:22, 423.34it/s]  3%|▎         | 313/10000 [00:00<00:26, 358.79it/s]  4%|▎         | 352/10000 [00:00<00:26, 364.05it/s]  4%|▍         | 391/10000 [00:00<00:26, 362.34it/s]  4%|▍         | 429/10000 [00:01<00:26, 365.89it/s]  5%|▍         | 482/10000 [00:01<00:23, 406.73it/s]  5%|▌         | 534/10000 [00:01<00:21, 435.46it/s]  6%|▌         | 579/10000 [00:01<00:22, 420.61it/s]  6%|▋         | 625/10000 [00:01<00:21, 431.55it/s]  7%|▋         | 670/10000 [00:01<00:21, 433.98it/s]  7%|▋         | 733/10000 [00:01<00:18, 490.31it/s]  8%|▊         | 784/10000 [00:01<00:18, 487.91it/s]  8%|▊         | 834/10000 [00:01<00:20, 458.02it/s]  9%|▉         | 891/10000 [00:02<00:18, 485.26it/s] 10%|▉         | 985/10000 [00:02<00:15, 595.35it/s] 10%|█         | 1050/10000 [00:02<00:15, 594.25it/s] 11%|█         | 1110/10000 [00:02<00:15, 582.12it/s] 12%|█▏        | 1174/10000 [00:02<00:14, 597.17it/s] 12%|█▏        | 1242/10000 [00:02<00:14, 611.03it/s] 13%|█▎        | 1335/10000 [00:02<00:12, 694.18it/s] 14%|█▍        | 1418/10000 [00:02<00:11, 731.13it/s] 15%|█▍        | 1492/10000 [00:02<00:14, 581.19it/s] 16%|█▌        | 1556/10000 [00:03<00:17, 487.74it/s] 16%|█▌        | 1611/10000 [00:03<00:16, 497.69it/s] 17%|█▋        | 1674/10000 [00:03<00:15, 526.73it/s] 17%|█▋        | 1742/10000 [00:03<00:14, 565.85it/s] 18%|█▊        | 1829/10000 [00:03<00:12, 638.67it/s] 19%|█▉        | 1934/10000 [00:03<00:10, 745.61it/s] 20%|██        | 2030/10000 [00:03<00:09, 802.25it/s] 21%|██        | 2113/10000 [00:03<00:11, 706.65it/s] 22%|██▏       | 2201/10000 [00:04<00:10, 741.38it/s] 23%|██▎       | 2278/10000 [00:04<00:12, 638.74it/s] 24%|██▎       | 2355/10000 [00:04<00:11, 653.72it/s] 24%|██▍       | 2434/10000 [00:04<00:11, 687.35it/s] 25%|██▌       | 2533/10000 [00:04<00:09, 758.52it/s] 26%|██▌       | 2612/10000 [00:04<00:09, 746.88it/s] 27%|██▋       | 2689/10000 [00:04<00:13, 530.24it/s] 28%|██▊       | 2752/10000 [00:05<00:14, 498.59it/s] 28%|██▊       | 2809/10000 [00:05<00:15, 457.82it/s] 29%|██▉       | 2875/10000 [00:05<00:14, 497.80it/s] 30%|██▉       | 2955/10000 [00:05<00:12, 567.74it/s] 30%|███       | 3017/10000 [00:05<00:12, 561.80it/s] 31%|███       | 3077/10000 [00:05<00:12, 534.79it/s] 31%|███▏      | 3133/10000 [00:05<00:13, 523.27it/s] 32%|███▏      | 3188/10000 [00:05<00:12, 524.29it/s] 33%|███▎      | 3271/10000 [00:05<00:11, 606.47it/s] 34%|███▎      | 3359/10000 [00:06<00:09, 678.76it/s] 34%|███▍      | 3431/10000 [00:06<00:09, 678.66it/s] 35%|███▌      | 3515/10000 [00:06<00:08, 722.98it/s] 36%|███▌      | 3589/10000 [00:06<00:08, 715.38it/s] 37%|███▋      | 3664/10000 [00:06<00:08, 725.19it/s] 38%|███▊      | 3755/10000 [00:06<00:08, 770.86it/s] 38%|███▊      | 3845/10000 [00:06<00:07, 781.60it/s] 39%|███▉      | 3926/10000 [00:06<00:07, 789.67it/s] 40%|████      | 4006/10000 [00:06<00:07, 766.30it/s] 41%|████      | 4094/10000 [00:06<00:07, 796.82it/s] 42%|████▏     | 4190/10000 [00:07<00:06, 839.54it/s] 43%|████▎     | 4285/10000 [00:07<00:06, 868.61it/s] 44%|████▍     | 4386/10000 [00:07<00:06, 902.20it/s] 45%|████▍     | 4477/10000 [00:07<00:07, 779.07it/s] 46%|████▌     | 4558/10000 [00:07<00:08, 652.19it/s] 46%|████▋     | 4629/10000 [00:07<00:08, 640.76it/s] 47%|████▋     | 4697/10000 [00:07<00:08, 640.30it/s] 48%|████▊     | 4765/10000 [00:07<00:08, 634.84it/s] 48%|████▊     | 4831/10000 [00:08<00:09, 567.24it/s] 49%|████▉     | 4890/10000 [00:08<00:10, 500.36it/s] 49%|████▉     | 4943/10000 [00:08<00:11, 433.19it/s] 50%|████▉     | 4995/10000 [00:08<00:11, 447.64it/s] 51%|█████     | 5085/10000 [00:08<00:09, 544.08it/s] 52%|█████▏    | 5189/10000 [00:08<00:07, 662.08it/s] 53%|█████▎    | 5260/10000 [00:08<00:08, 566.09it/s] 53%|█████▎    | 5322/10000 [00:09<00:09, 473.57it/s] 54%|█████▍    | 5375/10000 [00:09<00:10, 439.93it/s] 54%|█████▍    | 5423/10000 [00:09<00:10, 443.37it/s] 55%|█████▌    | 5508/10000 [00:09<00:08, 536.83it/s] 56%|█████▌    | 5566/10000 [00:09<00:08, 543.21it/s] 56%|█████▋    | 5647/10000 [00:09<00:07, 613.14it/s] 57%|█████▋    | 5739/10000 [00:09<00:06, 695.86it/s] 58%|█████▊    | 5812/10000 [00:09<00:06, 621.12it/s] 59%|█████▉    | 5878/10000 [00:10<00:06, 606.31it/s] 59%|█████▉    | 5941/10000 [00:10<00:07, 537.52it/s] 60%|█████▉    | 5998/10000 [00:10<00:07, 543.60it/s] 61%|██████    | 6073/10000 [00:10<00:06, 591.14it/s] 61%|██████▏   | 6141/10000 [00:10<00:06, 610.53it/s] 62%|██████▏   | 6212/10000 [00:10<00:06, 626.91it/s] 63%|██████▎   | 6276/10000 [00:10<00:06, 577.07it/s] 63%|██████▎   | 6336/10000 [00:10<00:06, 557.99it/s] 64%|██████▍   | 6400/10000 [00:10<00:06, 579.41it/s] 65%|██████▍   | 6459/10000 [00:11<00:06, 521.29it/s] 65%|██████▌   | 6522/10000 [00:11<00:06, 548.36it/s] 66%|██████▌   | 6580/10000 [00:11<00:06, 544.46it/s] 66%|██████▋   | 6636/10000 [00:11<00:06, 540.32it/s] 67%|██████▋   | 6691/10000 [00:11<00:06, 539.66it/s] 68%|██████▊   | 6772/10000 [00:11<00:05, 604.31it/s] 69%|██████▉   | 6895/10000 [00:11<00:04, 774.35it/s] 70%|██████▉   | 6976/10000 [00:11<00:03, 780.86it/s] 71%|███████   | 7070/10000 [00:11<00:03, 812.06it/s] 72%|███████▏  | 7156/10000 [00:12<00:03, 823.66it/s] 73%|███████▎  | 7259/10000 [00:12<00:03, 877.96it/s] 73%|███████▎  | 7348/10000 [00:12<00:03, 860.33it/s] 74%|███████▍  | 7435/10000 [00:12<00:02, 858.32it/s] 75%|███████▌  | 7522/10000 [00:12<00:02, 832.66it/s] 76%|███████▌  | 7609/10000 [00:12<00:02, 828.35it/s] 77%|███████▋  | 7693/10000 [00:12<00:03, 732.94it/s] 78%|███████▊  | 7769/10000 [00:12<00:03, 670.40it/s] 79%|███████▉  | 7888/10000 [00:12<00:02, 801.05it/s] 80%|███████▉  | 7972/10000 [00:13<00:02, 800.06it/s] 81%|████████  | 8055/10000 [00:13<00:02, 771.50it/s] 81%|████████▏ | 8145/10000 [00:13<00:02, 805.94it/s] 82%|████████▏ | 8228/10000 [00:13<00:02, 724.57it/s] 83%|████████▎ | 8303/10000 [00:13<00:02, 709.04it/s] 84%|████████▍ | 8376/10000 [00:13<00:02, 625.27it/s] 84%|████████▍ | 8450/10000 [00:13<00:02, 649.26it/s] 85%|████████▌ | 8531/10000 [00:13<00:02, 682.31it/s] 86%|████████▌ | 8607/10000 [00:14<00:01, 703.16it/s] 87%|████████▋ | 8703/10000 [00:14<00:01, 764.64it/s] 88%|████████▊ | 8804/10000 [00:14<00:01, 823.49it/s] 89%|████████▉ | 8906/10000 [00:14<00:01, 876.22it/s] 90%|█████████ | 9014/10000 [00:14<00:01, 930.01it/s] 91%|█████████ | 9108/10000 [00:14<00:01, 856.01it/s] 92%|█████████▏| 9196/10000 [00:14<00:01, 750.59it/s] 93%|█████████▎| 9275/10000 [00:14<00:01, 648.93it/s] 93%|█████████▎| 9344/10000 [00:15<00:01, 600.41it/s] 94%|█████████▍| 9407/10000 [00:15<00:01, 545.92it/s] 95%|█████████▍| 9494/10000 [00:15<00:00, 613.45it/s] 96%|█████████▌| 9559/10000 [00:15<00:00, 600.64it/s] 96%|█████████▌| 9622/10000 [00:15<00:00, 589.05it/s] 97%|█████████▋| 9683/10000 [00:15<00:00, 586.19it/s] 98%|█████████▊| 9752/10000 [00:15<00:00, 602.98it/s] 98%|█████████▊| 9836/10000 [00:15<00:00, 665.35it/s]100%|█████████▉| 9958/10000 [00:15<00:00, 815.85it/s]100%|██████████| 10000/10000 [00:15<00:00, 627.97it/s]
test_neglected_p33 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p33
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p33.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.05s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.71it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.64it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.80it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.66it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.72it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.11it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.64it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.88it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p33_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p33_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p33_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p33_Holmes_probs.npy
{'Accuracy': 0.0209, 'Precision': 0.0193, 'Recall': 0.0209, 'F1-score': 0.0178}
starting gen taf script for test_neglected_p34
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 84/10000 [00:00<00:12, 796.96it/s]  2%|▏         | 164/10000 [00:00<00:17, 546.70it/s]  2%|▏         | 223/10000 [00:00<00:19, 507.67it/s]  3%|▎         | 276/10000 [00:00<00:20, 473.16it/s]  3%|▎         | 325/10000 [00:00<00:21, 452.18it/s]  4%|▎         | 371/10000 [00:00<00:21, 440.95it/s]  4%|▍         | 423/10000 [00:00<00:20, 463.24it/s]  5%|▍         | 470/10000 [00:01<00:25, 369.73it/s]  5%|▌         | 513/10000 [00:01<00:24, 381.64it/s]  6%|▌         | 554/10000 [00:01<00:25, 373.15it/s]  6%|▌         | 601/10000 [00:01<00:23, 395.08it/s]  6%|▋         | 645/10000 [00:01<00:22, 406.86it/s]  7%|▋         | 687/10000 [00:01<00:22, 405.54it/s]  8%|▊         | 750/10000 [00:01<00:19, 467.21it/s]  8%|▊         | 817/10000 [00:01<00:18, 503.30it/s]  9%|▊         | 874/10000 [00:01<00:17, 510.52it/s]  9%|▉         | 927/10000 [00:02<00:17, 514.19it/s] 10%|▉         | 995/10000 [00:02<00:16, 553.62it/s] 11%|█         | 1069/10000 [00:02<00:15, 593.72it/s] 11%|█▏        | 1129/10000 [00:02<00:15, 563.47it/s] 12%|█▏        | 1186/10000 [00:02<00:16, 535.65it/s] 13%|█▎        | 1266/10000 [00:02<00:14, 602.78it/s] 14%|█▍        | 1375/10000 [00:02<00:11, 738.89it/s] 15%|█▍        | 1451/10000 [00:02<00:15, 557.89it/s] 15%|█▌        | 1515/10000 [00:03<00:16, 523.80it/s] 16%|█▌        | 1573/10000 [00:03<00:19, 439.16it/s] 16%|█▋        | 1638/10000 [00:03<00:17, 476.61it/s] 17%|█▋        | 1691/10000 [00:03<00:17, 482.47it/s] 18%|█▊        | 1783/10000 [00:03<00:14, 575.97it/s] 19%|█▉        | 1904/10000 [00:03<00:11, 729.92it/s] 20%|██        | 2027/10000 [00:03<00:09, 856.69it/s] 21%|██        | 2118/10000 [00:03<00:10, 720.17it/s] 22%|██▏       | 2197/10000 [00:04<00:11, 693.28it/s] 23%|██▎       | 2271/10000 [00:04<00:11, 669.23it/s] 23%|██▎       | 2342/10000 [00:04<00:12, 625.12it/s] 24%|██▍       | 2407/10000 [00:04<00:12, 591.12it/s] 25%|██▌       | 2506/10000 [00:04<00:11, 678.38it/s] 26%|██▌       | 2598/10000 [00:04<00:10, 720.60it/s] 27%|██▋       | 2673/10000 [00:04<00:11, 621.60it/s] 27%|██▋       | 2739/10000 [00:05<00:14, 508.15it/s] 28%|██▊       | 2795/10000 [00:05<00:15, 453.00it/s] 28%|██▊       | 2845/10000 [00:05<00:15, 458.66it/s] 29%|██▉       | 2925/10000 [00:05<00:13, 537.98it/s] 30%|██▉       | 2996/10000 [00:05<00:12, 580.45it/s] 31%|███       | 3058/10000 [00:05<00:12, 574.04it/s] 31%|███       | 3119/10000 [00:05<00:12, 570.30it/s] 32%|███▏      | 3178/10000 [00:05<00:12, 565.57it/s] 33%|███▎      | 3265/10000 [00:05<00:10, 649.23it/s] 34%|███▎      | 3353/10000 [00:06<00:09, 713.33it/s] 34%|███▍      | 3442/10000 [00:06<00:08, 758.76it/s] 35%|███▌      | 3523/10000 [00:06<00:08, 764.41it/s] 36%|███▌      | 3620/10000 [00:06<00:07, 820.57it/s] 37%|███▋      | 3717/10000 [00:06<00:07, 864.15it/s] 38%|███▊      | 3815/10000 [00:06<00:07, 883.04it/s] 39%|███▉      | 3904/10000 [00:06<00:07, 829.90it/s] 40%|███▉      | 3988/10000 [00:06<00:07, 823.24it/s] 41%|████      | 4074/10000 [00:06<00:07, 827.42it/s] 42%|████▏     | 4181/10000 [00:06<00:06, 896.69it/s] 43%|████▎     | 4272/10000 [00:07<00:06, 898.11it/s] 44%|████▎     | 4371/10000 [00:07<00:06, 910.93it/s] 45%|████▍     | 4463/10000 [00:07<00:06, 831.15it/s] 45%|████▌     | 4548/10000 [00:07<00:06, 779.98it/s] 46%|████▋     | 4628/10000 [00:07<00:07, 691.92it/s] 47%|████▋     | 4700/10000 [00:07<00:08, 647.13it/s] 48%|████▊     | 4767/10000 [00:07<00:08, 616.68it/s] 48%|████▊     | 4832/10000 [00:07<00:08, 616.22it/s] 49%|████▉     | 4895/10000 [00:08<00:10, 494.69it/s] 49%|████▉     | 4949/10000 [00:08<00:10, 486.22it/s] 50%|█████     | 5001/10000 [00:08<00:11, 444.31it/s] 51%|█████     | 5082/10000 [00:08<00:09, 522.60it/s] 52%|█████▏    | 5170/10000 [00:08<00:07, 610.39it/s] 52%|█████▏    | 5235/10000 [00:08<00:09, 506.00it/s] 53%|█████▎    | 5291/10000 [00:08<00:09, 500.65it/s] 53%|█████▎    | 5345/10000 [00:09<00:10, 434.14it/s] 54%|█████▍    | 5411/10000 [00:09<00:09, 481.94it/s] 55%|█████▍    | 5464/10000 [00:09<00:09, 478.25it/s] 55%|█████▌    | 5537/10000 [00:09<00:08, 537.83it/s] 56%|█████▌    | 5603/10000 [00:09<00:07, 569.48it/s] 57%|█████▋    | 5677/10000 [00:09<00:07, 615.75it/s] 58%|█████▊    | 5771/10000 [00:09<00:06, 704.36it/s] 58%|█████▊    | 5844/10000 [00:09<00:06, 654.46it/s] 59%|█████▉    | 5912/10000 [00:09<00:07, 583.53it/s] 60%|█████▉    | 5973/10000 [00:10<00:07, 506.26it/s] 60%|██████    | 6043/10000 [00:10<00:07, 552.16it/s] 62%|██████▏   | 6154/10000 [00:10<00:05, 685.32it/s] 62%|██████▏   | 6227/10000 [00:10<00:05, 694.06it/s] 63%|██████▎   | 6300/10000 [00:10<00:05, 652.71it/s] 64%|██████▎   | 6368/10000 [00:10<00:05, 607.45it/s] 64%|██████▍   | 6431/10000 [00:10<00:06, 572.97it/s] 65%|██████▍   | 6490/10000 [00:10<00:06, 577.09it/s] 65%|██████▌   | 6549/10000 [00:11<00:06, 525.20it/s] 66%|██████▌   | 6603/10000 [00:11<00:06, 501.15it/s] 67%|██████▋   | 6666/10000 [00:11<00:06, 525.03it/s] 67%|██████▋   | 6733/10000 [00:11<00:05, 558.79it/s] 68%|██████▊   | 6809/10000 [00:11<00:05, 613.26it/s] 69%|██████▉   | 6909/10000 [00:11<00:04, 706.21it/s] 70%|███████   | 7009/10000 [00:11<00:03, 778.11it/s] 71%|███████   | 7111/10000 [00:11<00:03, 832.29it/s] 72%|███████▏  | 7195/10000 [00:11<00:03, 810.17it/s] 73%|███████▎  | 7277/10000 [00:12<00:03, 796.53it/s] 74%|███████▍  | 7375/10000 [00:12<00:03, 842.69it/s] 75%|███████▍  | 7460/10000 [00:12<00:03, 807.10it/s] 75%|███████▌  | 7542/10000 [00:12<00:03, 773.99it/s] 76%|███████▌  | 7620/10000 [00:12<00:03, 684.09it/s] 77%|███████▋  | 7691/10000 [00:12<00:03, 657.61it/s] 78%|███████▊  | 7765/10000 [00:12<00:03, 676.82it/s] 78%|███████▊  | 7841/10000 [00:12<00:03, 686.34it/s] 79%|███████▉  | 7949/10000 [00:12<00:02, 793.77it/s] 80%|████████  | 8030/10000 [00:13<00:02, 773.17it/s] 81%|████████  | 8109/10000 [00:13<00:02, 743.56it/s] 82%|████████▏ | 8185/10000 [00:13<00:02, 713.83it/s] 83%|████████▎ | 8260/10000 [00:13<00:02, 715.38it/s] 83%|████████▎ | 8333/10000 [00:13<00:02, 694.86it/s] 84%|████████▍ | 8403/10000 [00:13<00:02, 663.08it/s] 85%|████████▍ | 8484/10000 [00:13<00:02, 693.35it/s] 86%|████████▌ | 8581/10000 [00:13<00:01, 769.16it/s] 87%|████████▋ | 8674/10000 [00:13<00:01, 802.54it/s] 88%|████████▊ | 8769/10000 [00:14<00:01, 843.46it/s] 89%|████████▉ | 8893/10000 [00:14<00:01, 949.83it/s] 90%|████████▉ | 8993/10000 [00:14<00:01, 964.41it/s] 91%|█████████ | 9096/10000 [00:14<00:00, 973.40it/s] 92%|█████████▏| 9194/10000 [00:14<00:00, 938.03it/s] 93%|█████████▎| 9289/10000 [00:14<00:00, 741.52it/s] 94%|█████████▎| 9370/10000 [00:14<00:01, 561.15it/s] 94%|█████████▍| 9437/10000 [00:15<00:00, 571.31it/s] 95%|█████████▌| 9502/10000 [00:15<00:00, 565.16it/s] 96%|█████████▌| 9583/10000 [00:15<00:00, 619.07it/s] 97%|█████████▋| 9663/10000 [00:15<00:00, 649.20it/s] 97%|█████████▋| 9736/10000 [00:15<00:00, 669.17it/s] 98%|█████████▊| 9829/10000 [00:15<00:00, 729.77it/s] 99%|█████████▉| 9930/10000 [00:15<00:00, 806.90it/s]100%|██████████| 10000/10000 [00:15<00:00, 636.38it/s]
test_neglected_p34 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p34
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p34.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.02it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.06it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.38it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.59it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.47it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.42it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.80it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.34it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.70it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p34_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p34_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p34_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p34_Holmes_probs.npy
{'Accuracy': 0.0208, 'Precision': 0.0208, 'Recall': 0.0208, 'F1-score': 0.0177}
starting gen taf script for test_neglected_p35
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 93/10000 [00:00<00:10, 902.93it/s]  2%|▏         | 184/10000 [00:00<00:21, 466.89it/s]  2%|▏         | 242/10000 [00:00<00:21, 453.39it/s]  3%|▎         | 293/10000 [00:00<00:22, 423.82it/s]  3%|▎         | 339/10000 [00:00<00:25, 386.28it/s]  4%|▍         | 380/10000 [00:00<00:25, 377.68it/s]  4%|▍         | 429/10000 [00:01<00:23, 401.52it/s]  5%|▍         | 480/10000 [00:01<00:22, 428.95it/s]  5%|▌         | 525/10000 [00:01<00:22, 427.23it/s]  6%|▌         | 580/10000 [00:01<00:20, 461.17it/s]  6%|▋         | 639/10000 [00:01<00:19, 491.43it/s]  7%|▋         | 689/10000 [00:01<00:20, 462.32it/s]  7%|▋         | 746/10000 [00:01<00:18, 490.14it/s]  8%|▊         | 796/10000 [00:01<00:19, 470.79it/s]  8%|▊         | 844/10000 [00:01<00:23, 395.54it/s]  9%|▉         | 886/10000 [00:02<00:23, 380.45it/s]  9%|▉         | 933/10000 [00:02<00:22, 397.31it/s] 10%|▉         | 982/10000 [00:02<00:21, 413.70it/s] 10%|█         | 1029/10000 [00:02<00:20, 428.68it/s] 11%|█         | 1100/10000 [00:02<00:17, 498.30it/s] 12%|█▏        | 1157/10000 [00:02<00:17, 515.85it/s] 13%|█▎        | 1254/10000 [00:02<00:13, 637.46it/s] 14%|█▎        | 1373/10000 [00:02<00:10, 794.64it/s] 15%|█▍        | 1454/10000 [00:02<00:13, 632.88it/s] 15%|█▌        | 1524/10000 [00:03<00:16, 513.07it/s] 16%|█▌        | 1583/10000 [00:03<00:19, 440.96it/s] 17%|█▋        | 1668/10000 [00:03<00:15, 524.93it/s] 18%|█▊        | 1765/10000 [00:03<00:13, 620.33it/s] 19%|█▉        | 1897/10000 [00:03<00:10, 786.89it/s] 20%|█▉        | 1999/10000 [00:03<00:09, 842.88it/s] 21%|██        | 2091/10000 [00:03<00:09, 796.69it/s] 22%|██▏       | 2186/10000 [00:04<00:09, 825.51it/s] 23%|██▎       | 2273/10000 [00:04<00:10, 706.76it/s] 24%|██▎       | 2350/10000 [00:04<00:11, 652.75it/s] 24%|██▍       | 2420/10000 [00:04<00:11, 639.53it/s] 25%|██▌       | 2540/10000 [00:04<00:09, 774.16it/s] 26%|██▌       | 2622/10000 [00:04<00:09, 781.46it/s] 27%|██▋       | 2704/10000 [00:04<00:13, 547.20it/s] 28%|██▊       | 2771/10000 [00:05<00:15, 469.76it/s] 28%|██▊       | 2828/10000 [00:05<00:15, 471.18it/s] 29%|██▉       | 2892/10000 [00:05<00:14, 507.26it/s] 30%|██▉       | 2992/10000 [00:05<00:11, 608.42it/s] 31%|███       | 3059/10000 [00:05<00:12, 562.66it/s] 31%|███▏      | 3129/10000 [00:05<00:11, 581.58it/s] 32%|███▏      | 3191/10000 [00:05<00:11, 580.97it/s] 33%|███▎      | 3274/10000 [00:05<00:10, 643.56it/s] 34%|███▎      | 3369/10000 [00:06<00:09, 718.63it/s] 35%|███▍      | 3456/10000 [00:06<00:08, 739.36it/s] 35%|███▌      | 3533/10000 [00:06<00:08, 739.39it/s] 36%|███▌      | 3622/10000 [00:06<00:08, 776.35it/s] 37%|███▋      | 3707/10000 [00:06<00:07, 789.75it/s] 38%|███▊      | 3787/10000 [00:06<00:07, 785.93it/s] 39%|███▊      | 3867/10000 [00:06<00:07, 785.94it/s] 39%|███▉      | 3946/10000 [00:06<00:08, 728.68it/s] 40%|████      | 4020/10000 [00:06<00:08, 727.02it/s] 41%|████      | 4094/10000 [00:06<00:08, 714.10it/s] 42%|████▏     | 4194/10000 [00:07<00:07, 781.87it/s] 43%|████▎     | 4280/10000 [00:07<00:07, 795.67it/s] 44%|████▍     | 4378/10000 [00:07<00:06, 834.42it/s] 45%|████▍     | 4462/10000 [00:07<00:07, 724.68it/s] 45%|████▌     | 4538/10000 [00:07<00:08, 665.12it/s] 46%|████▌     | 4607/10000 [00:07<00:08, 665.24it/s] 47%|████▋     | 4676/10000 [00:07<00:08, 628.99it/s] 47%|████▋     | 4741/10000 [00:07<00:08, 616.95it/s] 48%|████▊     | 4804/10000 [00:08<00:09, 568.69it/s] 49%|████▊     | 4862/10000 [00:08<00:09, 548.56it/s] 49%|████▉     | 4918/10000 [00:08<00:10, 496.14it/s] 50%|████▉     | 4969/10000 [00:08<00:10, 476.58it/s] 50%|█████     | 5018/10000 [00:08<00:10, 464.97it/s] 51%|█████     | 5082/10000 [00:08<00:09, 510.19it/s] 52%|█████▏    | 5164/10000 [00:08<00:08, 587.86it/s] 52%|█████▏    | 5225/10000 [00:08<00:08, 592.04it/s] 53%|█████▎    | 5286/10000 [00:09<00:09, 483.71it/s] 53%|█████▎    | 5339/10000 [00:09<00:10, 448.63it/s] 54%|█████▍    | 5387/10000 [00:09<00:11, 409.93it/s] 55%|█████▍    | 5459/10000 [00:09<00:09, 469.54it/s] 55%|█████▌    | 5533/10000 [00:09<00:08, 532.37it/s] 56%|█████▋    | 5633/10000 [00:09<00:06, 642.48it/s] 57%|█████▋    | 5722/10000 [00:09<00:06, 706.73it/s] 58%|█████▊    | 5800/10000 [00:09<00:06, 697.73it/s] 59%|█████▊    | 5872/10000 [00:09<00:06, 678.43it/s] 59%|█████▉    | 5942/10000 [00:10<00:07, 528.98it/s] 60%|██████    | 6001/10000 [00:10<00:07, 531.46it/s] 61%|██████    | 6110/10000 [00:10<00:05, 659.86it/s] 62%|██████▏   | 6199/10000 [00:10<00:05, 704.83it/s] 63%|██████▎   | 6278/10000 [00:10<00:05, 712.26it/s] 64%|██████▎   | 6353/10000 [00:10<00:05, 652.17it/s] 64%|██████▍   | 6421/10000 [00:10<00:06, 588.84it/s] 65%|██████▍   | 6483/10000 [00:11<00:06, 533.10it/s] 66%|██████▌   | 6553/10000 [00:11<00:06, 558.46it/s] 66%|██████▌   | 6611/10000 [00:11<00:06, 520.37it/s] 67%|██████▋   | 6683/10000 [00:11<00:05, 568.09it/s] 67%|██████▋   | 6746/10000 [00:11<00:05, 570.87it/s] 68%|██████▊   | 6839/10000 [00:11<00:04, 665.25it/s] 69%|██████▉   | 6944/10000 [00:11<00:03, 771.13it/s] 70%|███████   | 7033/10000 [00:11<00:03, 788.23it/s] 71%|███████   | 7115/10000 [00:11<00:03, 784.91it/s] 72%|███████▏  | 7203/10000 [00:12<00:03, 807.59it/s] 73%|███████▎  | 7314/10000 [00:12<00:03, 877.97it/s] 74%|███████▍  | 7411/10000 [00:12<00:02, 904.38it/s] 75%|███████▌  | 7508/10000 [00:12<00:02, 916.34it/s] 76%|███████▌  | 7601/10000 [00:12<00:02, 906.59it/s] 77%|███████▋  | 7692/10000 [00:12<00:03, 699.77it/s] 78%|███████▊  | 7770/10000 [00:12<00:03, 683.48it/s] 79%|███████▊  | 7858/10000 [00:12<00:02, 730.62it/s] 80%|███████▉  | 7961/10000 [00:12<00:02, 800.84it/s] 81%|████████  | 8051/10000 [00:13<00:02, 816.14it/s] 81%|████████▏ | 8136/10000 [00:13<00:02, 812.13it/s] 82%|████████▏ | 8220/10000 [00:13<00:02, 777.26it/s] 83%|████████▎ | 8300/10000 [00:13<00:02, 728.90it/s] 84%|████████▍ | 8375/10000 [00:13<00:02, 661.25it/s] 84%|████████▍ | 8443/10000 [00:13<00:02, 666.01it/s] 85%|████████▌ | 8515/10000 [00:13<00:02, 680.18it/s] 86%|████████▋ | 8635/10000 [00:13<00:01, 823.72it/s] 88%|████████▊ | 8756/10000 [00:13<00:01, 925.91it/s] 89%|████████▊ | 8867/10000 [00:14<00:01, 975.53it/s] 90%|████████▉ | 8988/10000 [00:14<00:00, 1036.68it/s] 91%|█████████ | 9093/10000 [00:14<00:00, 979.59it/s]  92%|█████████▏| 9193/10000 [00:14<00:00, 928.80it/s] 93%|█████████▎| 9288/10000 [00:14<00:00, 731.68it/s] 94%|█████████▎| 9369/10000 [00:14<00:00, 663.44it/s] 94%|█████████▍| 9441/10000 [00:14<00:00, 596.88it/s] 95%|█████████▌| 9505/10000 [00:15<00:00, 571.02it/s] 96%|█████████▌| 9579/10000 [00:15<00:00, 605.67it/s] 96%|█████████▋| 9643/10000 [00:15<00:00, 612.18it/s] 97%|█████████▋| 9707/10000 [00:15<00:00, 603.18it/s] 98%|█████████▊| 9769/10000 [00:15<00:00, 607.22it/s] 99%|█████████▉| 9877/10000 [00:15<00:00, 727.32it/s]100%|█████████▉| 9970/10000 [00:15<00:00, 782.67it/s]100%|██████████| 10000/10000 [00:15<00:00, 637.60it/s]
test_neglected_p35 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p35
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p35.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.05s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.68it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.71it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.84it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.71it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.77it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.06it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.64it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.85it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p35_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p35_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p35_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p35_Holmes_probs.npy
{'Accuracy': 0.0215, 'Precision': 0.0197, 'Recall': 0.0215, 'F1-score': 0.0183}
starting gen taf script for test_neglected_p36
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 91/10000 [00:00<00:11, 868.51it/s]  2%|▏         | 178/10000 [00:00<00:27, 362.43it/s]  2%|▏         | 229/10000 [00:00<00:27, 349.02it/s]  3%|▎         | 272/10000 [00:00<00:28, 341.85it/s]  3%|▎         | 311/10000 [00:00<00:31, 309.60it/s]  3%|▎         | 345/10000 [00:01<00:32, 295.13it/s]  4%|▍         | 376/10000 [00:01<00:32, 294.45it/s]  4%|▍         | 410/10000 [00:01<00:31, 305.43it/s]  5%|▍         | 471/10000 [00:01<00:24, 384.00it/s]  5%|▌         | 518/10000 [00:01<00:23, 403.36it/s]  6%|▌         | 569/10000 [00:01<00:22, 426.55it/s]  6%|▋         | 628/10000 [00:01<00:20, 467.43it/s]  7%|▋         | 720/10000 [00:01<00:15, 589.58it/s]  8%|▊         | 803/10000 [00:01<00:14, 651.85it/s]  9%|▉         | 901/10000 [00:01<00:12, 741.54it/s] 10%|▉         | 994/10000 [00:02<00:11, 771.63it/s] 11%|█         | 1072/10000 [00:02<00:12, 712.25it/s] 11%|█▏        | 1145/10000 [00:02<00:13, 637.01it/s] 12%|█▏        | 1211/10000 [00:02<00:14, 591.11it/s] 13%|█▎        | 1289/10000 [00:02<00:13, 636.90it/s] 14%|█▍        | 1389/10000 [00:02<00:11, 721.05it/s] 15%|█▍        | 1464/10000 [00:02<00:13, 646.03it/s] 15%|█▌        | 1532/10000 [00:03<00:16, 501.33it/s] 16%|█▌        | 1589/10000 [00:03<00:17, 487.56it/s] 17%|█▋        | 1674/10000 [00:03<00:14, 568.71it/s] 18%|█▊        | 1770/10000 [00:03<00:12, 662.52it/s] 19%|█▉        | 1908/10000 [00:03<00:09, 846.78it/s] 20%|██        | 2020/10000 [00:03<00:08, 920.19it/s] 21%|██        | 2118/10000 [00:03<00:09, 854.89it/s] 22%|██▏       | 2209/10000 [00:03<00:10, 735.51it/s] 23%|██▎       | 2289/10000 [00:03<00:10, 730.96it/s] 24%|██▎       | 2367/10000 [00:04<00:12, 622.01it/s] 24%|██▍       | 2450/10000 [00:04<00:11, 667.61it/s] 25%|██▌       | 2540/10000 [00:04<00:10, 719.30it/s] 26%|██▌       | 2617/10000 [00:04<00:11, 654.95it/s] 27%|██▋       | 2687/10000 [00:04<00:12, 575.92it/s] 27%|██▋       | 2749/10000 [00:04<00:14, 513.04it/s] 28%|██▊       | 2804/10000 [00:04<00:15, 478.13it/s] 29%|██▊       | 2861/10000 [00:05<00:14, 498.10it/s] 29%|██▉       | 2938/10000 [00:05<00:12, 553.32it/s] 30%|███       | 3003/10000 [00:05<00:12, 566.47it/s] 31%|███       | 3062/10000 [00:05<00:12, 569.84it/s] 31%|███       | 3123/10000 [00:05<00:11, 574.58it/s] 32%|███▏      | 3182/10000 [00:05<00:12, 554.12it/s] 33%|███▎      | 3255/10000 [00:05<00:11, 598.46it/s] 34%|███▎      | 3369/10000 [00:05<00:08, 750.23it/s] 34%|███▍      | 3446/10000 [00:05<00:08, 739.28it/s] 35%|███▌      | 3522/10000 [00:06<00:09, 713.46it/s] 36%|███▌      | 3595/10000 [00:06<00:09, 690.31it/s] 37%|███▋      | 3696/10000 [00:06<00:08, 774.69it/s] 38%|███▊      | 3796/10000 [00:06<00:07, 819.16it/s] 39%|███▉      | 3879/10000 [00:06<00:08, 759.11it/s] 40%|███▉      | 3957/10000 [00:06<00:08, 728.90it/s] 40%|████      | 4031/10000 [00:06<00:08, 712.34it/s] 41%|████▏     | 4128/10000 [00:06<00:07, 767.20it/s] 42%|████▏     | 4222/10000 [00:06<00:07, 806.84it/s] 43%|████▎     | 4321/10000 [00:07<00:06, 846.23it/s] 44%|████▍     | 4411/10000 [00:07<00:06, 843.54it/s] 45%|████▍     | 4496/10000 [00:07<00:06, 803.39it/s] 46%|████▌     | 4577/10000 [00:07<00:07, 766.11it/s] 47%|████▋     | 4655/10000 [00:07<00:07, 670.05it/s] 47%|████▋     | 4725/10000 [00:07<00:08, 617.01it/s] 48%|████▊     | 4789/10000 [00:07<00:09, 559.43it/s] 48%|████▊     | 4847/10000 [00:08<00:10, 483.14it/s] 49%|████▉     | 4898/10000 [00:08<00:11, 452.04it/s] 49%|████▉     | 4945/10000 [00:08<00:11, 438.79it/s] 50%|████▉     | 4992/10000 [00:08<00:11, 440.56it/s] 51%|█████     | 5067/10000 [00:08<00:09, 516.04it/s] 52%|█████▏    | 5152/10000 [00:08<00:08, 594.74it/s] 52%|█████▏    | 5214/10000 [00:08<00:08, 565.12it/s] 53%|█████▎    | 5272/10000 [00:08<00:10, 472.22it/s] 53%|█████▎    | 5323/10000 [00:09<00:11, 413.50it/s] 54%|█████▍    | 5377/10000 [00:09<00:10, 441.69it/s] 54%|█████▍    | 5425/10000 [00:09<00:10, 421.18it/s] 55%|█████▌    | 5503/10000 [00:09<00:08, 508.80it/s] 56%|█████▌    | 5580/10000 [00:09<00:07, 563.67it/s] 57%|█████▋    | 5664/10000 [00:09<00:06, 623.79it/s] 58%|█████▊    | 5755/10000 [00:09<00:06, 699.76it/s] 58%|█████▊    | 5828/10000 [00:09<00:06, 677.12it/s] 59%|█████▉    | 5898/10000 [00:09<00:07, 564.61it/s] 60%|█████▉    | 5959/10000 [00:10<00:07, 515.01it/s] 60%|██████    | 6019/10000 [00:10<00:07, 530.94it/s] 61%|██████    | 6106/10000 [00:10<00:06, 608.89it/s] 62%|██████▏   | 6203/10000 [00:10<00:05, 690.36it/s] 63%|██████▎   | 6275/10000 [00:10<00:06, 609.97it/s] 63%|██████▎   | 6340/10000 [00:10<00:06, 548.94it/s] 64%|██████▍   | 6398/10000 [00:10<00:06, 547.32it/s] 65%|██████▍   | 6455/10000 [00:11<00:07, 499.04it/s] 65%|██████▌   | 6526/10000 [00:11<00:06, 537.72it/s] 66%|██████▌   | 6582/10000 [00:11<00:06, 516.11it/s] 66%|██████▋   | 6639/10000 [00:11<00:06, 528.18it/s] 67%|██████▋   | 6706/10000 [00:11<00:06, 545.42it/s] 68%|██████▊   | 6768/10000 [00:11<00:05, 563.25it/s] 69%|██████▊   | 6865/10000 [00:11<00:04, 672.44it/s] 70%|███████   | 7005/10000 [00:11<00:03, 877.35it/s] 71%|███████   | 7095/10000 [00:11<00:03, 820.34it/s] 72%|███████▏  | 7211/10000 [00:11<00:03, 902.20it/s] 73%|███████▎  | 7327/10000 [00:12<00:02, 972.94it/s] 74%|███████▍  | 7427/10000 [00:12<00:02, 881.46it/s] 75%|███████▌  | 7518/10000 [00:12<00:02, 854.78it/s] 76%|███████▌  | 7606/10000 [00:12<00:02, 806.73it/s] 77%|███████▋  | 7689/10000 [00:12<00:03, 762.36it/s] 78%|███████▊  | 7767/10000 [00:12<00:03, 694.66it/s] 79%|███████▊  | 7859/10000 [00:12<00:02, 737.26it/s] 80%|███████▉  | 7964/10000 [00:12<00:02, 810.11it/s] 81%|████████  | 8064/10000 [00:13<00:02, 856.58it/s] 82%|████████▏ | 8152/10000 [00:13<00:02, 841.57it/s] 82%|████████▏ | 8238/10000 [00:13<00:02, 762.75it/s] 83%|████████▎ | 8317/10000 [00:13<00:02, 683.71it/s] 84%|████████▍ | 8402/10000 [00:13<00:02, 709.31it/s] 85%|████████▍ | 8487/10000 [00:13<00:02, 734.36it/s] 86%|████████▌ | 8563/10000 [00:13<00:01, 735.12it/s] 87%|████████▋ | 8662/10000 [00:13<00:01, 802.18it/s] 88%|████████▊ | 8764/10000 [00:13<00:01, 863.16it/s] 89%|████████▊ | 8871/10000 [00:14<00:01, 912.14it/s] 90%|████████▉ | 8964/10000 [00:14<00:01, 913.02it/s] 91%|█████████ | 9058/10000 [00:14<00:01, 902.74it/s] 91%|█████████▏| 9149/10000 [00:14<00:00, 880.23it/s] 92%|█████████▏| 9238/10000 [00:14<00:01, 744.17it/s] 93%|█████████▎| 9317/10000 [00:14<00:01, 567.71it/s] 94%|█████████▍| 9383/10000 [00:14<00:01, 560.91it/s] 94%|█████████▍| 9450/10000 [00:15<00:00, 575.06it/s] 95%|█████████▌| 9514/10000 [00:15<00:00, 589.51it/s] 96%|█████████▌| 9577/10000 [00:15<00:00, 527.38it/s] 97%|█████████▋| 9660/10000 [00:15<00:00, 600.91it/s] 97%|█████████▋| 9741/10000 [00:15<00:00, 644.64it/s] 98%|█████████▊| 9835/10000 [00:15<00:00, 716.04it/s] 99%|█████████▉| 9939/10000 [00:15<00:00, 800.68it/s]100%|██████████| 10000/10000 [00:15<00:00, 636.56it/s]
test_neglected_p36 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p36
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p36.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.06s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.58it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.83it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.12it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.15it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.28it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.77it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.32it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.88it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.77it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p36_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p36_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p36_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p36_Holmes_probs.npy
{'Accuracy': 0.0223, 'Precision': 0.0205, 'Recall': 0.0222, 'F1-score': 0.019}
starting gen taf script for test_neglected_p37
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 77/10000 [00:00<00:13, 712.75it/s]  1%|▏         | 149/10000 [00:00<00:18, 522.25it/s]  2%|▏         | 216/10000 [00:00<00:17, 567.86it/s]  3%|▎         | 295/10000 [00:00<00:15, 634.79it/s]  4%|▍         | 384/10000 [00:00<00:13, 700.67it/s]  5%|▌         | 513/10000 [00:00<00:10, 867.34it/s]  6%|▌         | 616/10000 [00:00<00:10, 901.21it/s]  7%|▋         | 708/10000 [00:00<00:10, 886.32it/s]  8%|▊         | 798/10000 [00:01<00:10, 852.94it/s]  9%|▉         | 902/10000 [00:01<00:10, 906.64it/s] 10%|▉         | 995/10000 [00:01<00:10, 891.75it/s] 11%|█         | 1085/10000 [00:01<00:11, 753.89it/s] 12%|█▏        | 1165/10000 [00:01<00:12, 706.65it/s] 12%|█▏        | 1239/10000 [00:01<00:12, 688.70it/s] 14%|█▎        | 1364/10000 [00:01<00:10, 833.87it/s] 15%|█▍        | 1452/10000 [00:01<00:12, 673.45it/s] 15%|█▌        | 1527/10000 [00:02<00:14, 571.87it/s] 16%|█▌        | 1591/10000 [00:02<00:16, 498.31it/s] 17%|█▋        | 1658/10000 [00:02<00:15, 533.79it/s] 17%|█▋        | 1717/10000 [00:02<00:15, 544.03it/s] 18%|█▊        | 1826/10000 [00:02<00:12, 670.63it/s] 19%|█▉        | 1941/10000 [00:02<00:10, 793.73it/s] 20%|██        | 2026/10000 [00:02<00:10, 761.26it/s] 21%|██        | 2107/10000 [00:02<00:10, 739.53it/s] 22%|██▏       | 2193/10000 [00:03<00:10, 752.23it/s] 23%|██▎       | 2271/10000 [00:03<00:11, 692.30it/s] 23%|██▎       | 2343/10000 [00:03<00:13, 575.85it/s] 24%|██▍       | 2423/10000 [00:03<00:12, 628.14it/s] 25%|██▌       | 2500/10000 [00:03<00:11, 659.88it/s] 26%|██▌       | 2590/10000 [00:03<00:10, 716.35it/s] 27%|██▋       | 2665/10000 [00:03<00:12, 569.39it/s] 27%|██▋       | 2729/10000 [00:04<00:15, 468.29it/s] 28%|██▊       | 2783/10000 [00:04<00:16, 439.45it/s] 28%|██▊       | 2837/10000 [00:04<00:15, 451.62it/s] 29%|██▉       | 2945/10000 [00:04<00:12, 587.57it/s] 30%|███       | 3027/10000 [00:04<00:10, 634.91it/s] 31%|███       | 3096/10000 [00:04<00:12, 543.28it/s] 32%|███▏      | 3156/10000 [00:04<00:12, 539.62it/s] 32%|███▏      | 3214/10000 [00:04<00:12, 537.77it/s] 33%|███▎      | 3315/10000 [00:05<00:10, 645.88it/s] 34%|███▍      | 3402/10000 [00:05<00:09, 697.56it/s] 35%|███▍      | 3480/10000 [00:05<00:09, 719.79it/s] 36%|███▌      | 3561/10000 [00:05<00:08, 744.57it/s] 36%|███▋      | 3643/10000 [00:05<00:08, 764.82it/s] 37%|███▋      | 3726/10000 [00:05<00:08, 780.75it/s] 38%|███▊      | 3818/10000 [00:05<00:07, 816.75it/s] 39%|███▉      | 3906/10000 [00:05<00:07, 832.15it/s] 40%|███▉      | 3990/10000 [00:05<00:07, 765.73it/s] 41%|████      | 4073/10000 [00:06<00:07, 783.38it/s] 42%|████▏     | 4180/10000 [00:06<00:06, 864.41it/s] 43%|████▎     | 4268/10000 [00:06<00:06, 835.31it/s] 44%|████▎     | 4353/10000 [00:06<00:06, 831.87it/s] 44%|████▍     | 4437/10000 [00:06<00:07, 735.88it/s] 45%|████▌     | 4516/10000 [00:06<00:07, 721.08it/s] 46%|████▌     | 4590/10000 [00:06<00:08, 612.23it/s] 47%|████▋     | 4655/10000 [00:06<00:09, 589.55it/s] 47%|████▋     | 4728/10000 [00:06<00:08, 624.28it/s] 48%|████▊     | 4793/10000 [00:07<00:08, 629.65it/s] 49%|████▊     | 4858/10000 [00:07<00:09, 569.22it/s] 49%|████▉     | 4917/10000 [00:07<00:11, 459.52it/s] 50%|████▉     | 4968/10000 [00:07<00:11, 436.37it/s] 50%|█████     | 5029/10000 [00:07<00:10, 469.86it/s] 51%|█████     | 5104/10000 [00:07<00:09, 530.94it/s] 52%|█████▏    | 5181/10000 [00:07<00:08, 573.69it/s] 52%|█████▏    | 5241/10000 [00:08<00:09, 510.13it/s] 53%|█████▎    | 5295/10000 [00:08<00:09, 498.98it/s] 53%|█████▎    | 5347/10000 [00:08<00:10, 439.42it/s] 54%|█████▍    | 5394/10000 [00:08<00:11, 387.27it/s] 55%|█████▍    | 5475/10000 [00:08<00:09, 481.35it/s] 56%|█████▌    | 5552/10000 [00:08<00:08, 552.25it/s] 56%|█████▌    | 5619/10000 [00:08<00:07, 571.37it/s] 57%|█████▋    | 5689/10000 [00:08<00:07, 599.06it/s] 58%|█████▊    | 5784/10000 [00:08<00:06, 684.62it/s] 59%|█████▊    | 5855/10000 [00:09<00:06, 592.40it/s] 59%|█████▉    | 5918/10000 [00:09<00:07, 557.23it/s] 60%|█████▉    | 5977/10000 [00:09<00:07, 525.37it/s] 61%|██████    | 6080/10000 [00:09<00:06, 646.21it/s] 62%|██████▏   | 6177/10000 [00:09<00:05, 713.37it/s] 63%|██████▎   | 6253/10000 [00:09<00:05, 710.60it/s] 63%|██████▎   | 6327/10000 [00:09<00:06, 600.97it/s] 64%|██████▍   | 6392/10000 [00:10<00:06, 587.84it/s] 65%|██████▍   | 6454/10000 [00:10<00:06, 543.21it/s] 65%|██████▌   | 6511/10000 [00:10<00:06, 532.92it/s] 66%|██████▌   | 6566/10000 [00:10<00:06, 507.92it/s] 66%|██████▌   | 6618/10000 [00:10<00:07, 472.32it/s] 67%|██████▋   | 6697/10000 [00:10<00:06, 538.57it/s] 68%|██████▊   | 6754/10000 [00:10<00:06, 537.63it/s] 68%|██████▊   | 6832/10000 [00:10<00:05, 602.17it/s] 69%|██████▉   | 6939/10000 [00:10<00:04, 730.86it/s] 70%|███████   | 7032/10000 [00:11<00:03, 787.09it/s] 71%|███████   | 7113/10000 [00:11<00:03, 726.53it/s] 72%|███████▏  | 7208/10000 [00:11<00:03, 785.61it/s] 73%|███████▎  | 7300/10000 [00:11<00:03, 815.68it/s] 74%|███████▍  | 7401/10000 [00:11<00:03, 863.09it/s] 75%|███████▌  | 7504/10000 [00:11<00:02, 900.19it/s] 76%|███████▌  | 7595/10000 [00:11<00:02, 838.64it/s] 77%|███████▋  | 7681/10000 [00:11<00:03, 717.77it/s] 78%|███████▊  | 7758/10000 [00:11<00:03, 730.67it/s] 78%|███████▊  | 7834/10000 [00:12<00:03, 685.99it/s] 79%|███████▉  | 7925/10000 [00:12<00:02, 735.64it/s] 80%|████████  | 8016/10000 [00:12<00:02, 777.81it/s] 81%|████████  | 8109/10000 [00:12<00:02, 819.71it/s] 82%|████████▏ | 8196/10000 [00:12<00:02, 827.14it/s] 83%|████████▎ | 8280/10000 [00:12<00:02, 696.46it/s] 84%|████████▎ | 8354/10000 [00:12<00:02, 680.59it/s] 84%|████████▍ | 8425/10000 [00:12<00:02, 638.71it/s] 85%|████████▍ | 8492/10000 [00:13<00:02, 623.39it/s] 86%|████████▌ | 8578/10000 [00:13<00:02, 676.49it/s] 87%|████████▋ | 8695/10000 [00:13<00:01, 808.41it/s] 88%|████████▊ | 8797/10000 [00:13<00:01, 861.24it/s] 89%|████████▉ | 8897/10000 [00:13<00:01, 893.36it/s] 90%|████████▉ | 8999/10000 [00:13<00:01, 928.96it/s] 91%|█████████ | 9094/10000 [00:13<00:01, 903.65it/s] 92%|█████████▏| 9186/10000 [00:13<00:00, 839.45it/s] 93%|█████████▎| 9272/10000 [00:13<00:01, 675.04it/s] 93%|█████████▎| 9346/10000 [00:14<00:01, 580.69it/s] 94%|█████████▍| 9410/10000 [00:14<00:01, 527.77it/s] 95%|█████████▍| 9479/10000 [00:14<00:00, 553.25it/s] 95%|█████████▌| 9538/10000 [00:14<00:00, 499.08it/s] 96%|█████████▌| 9597/10000 [00:14<00:00, 510.60it/s] 97%|█████████▋| 9651/10000 [00:14<00:00, 512.71it/s] 97%|█████████▋| 9713/10000 [00:14<00:00, 539.72it/s] 98%|█████████▊| 9796/10000 [00:15<00:00, 602.28it/s] 99%|█████████▉| 9899/10000 [00:15<00:00, 715.07it/s]100%|██████████| 10000/10000 [00:15<00:00, 657.80it/s]
test_neglected_p37 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p37
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p37.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.11s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.35it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.16it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.17it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 23.96it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 28.88it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.24it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 36.80it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.11it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p37_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p37_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p37_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p37_Holmes_probs.npy
{'Accuracy': 0.0221, 'Precision': 0.0204, 'Recall': 0.022, 'F1-score': 0.0189}
starting gen taf script for test_neglected_p38
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 56/10000 [00:00<00:18, 524.48it/s]  1%|          | 109/10000 [00:00<00:27, 358.46it/s]  1%|▏         | 148/10000 [00:00<00:30, 324.18it/s]  2%|▏         | 182/10000 [00:00<00:40, 241.37it/s]  2%|▏         | 209/10000 [00:00<00:46, 209.59it/s]  2%|▏         | 232/10000 [00:01<00:54, 180.61it/s]  3%|▎         | 266/10000 [00:01<00:45, 213.74it/s]  3%|▎         | 305/10000 [00:01<00:38, 254.47it/s]  3%|▎         | 336/10000 [00:01<00:36, 265.03it/s]  4%|▍         | 382/10000 [00:01<00:31, 307.42it/s]  4%|▍         | 415/10000 [00:01<00:32, 296.06it/s]  5%|▍         | 454/10000 [00:01<00:30, 314.88it/s]  5%|▍         | 487/10000 [00:01<00:31, 303.28it/s]  5%|▌         | 519/10000 [00:01<00:32, 294.68it/s]  6%|▌         | 560/10000 [00:01<00:29, 322.72it/s]  6%|▌         | 609/10000 [00:02<00:25, 363.22it/s]  7%|▋         | 663/10000 [00:02<00:22, 409.08it/s]  7%|▋         | 713/10000 [00:02<00:21, 432.89it/s]  8%|▊         | 763/10000 [00:02<00:21, 434.66it/s]  8%|▊         | 808/10000 [00:02<00:21, 436.61it/s]  9%|▊         | 855/10000 [00:02<00:20, 438.92it/s]  9%|▉         | 918/10000 [00:02<00:18, 492.24it/s] 10%|▉         | 997/10000 [00:02<00:15, 571.16it/s] 11%|█         | 1055/10000 [00:02<00:17, 508.20it/s] 11%|█         | 1116/10000 [00:03<00:16, 524.93it/s] 12%|█▏        | 1189/10000 [00:03<00:15, 571.68it/s] 13%|█▎        | 1284/10000 [00:03<00:12, 673.72it/s] 14%|█▎        | 1366/10000 [00:03<00:12, 705.97it/s] 14%|█▍        | 1438/10000 [00:03<00:14, 599.48it/s] 15%|█▌        | 1502/10000 [00:03<00:16, 510.61it/s] 16%|█▌        | 1558/10000 [00:03<00:20, 402.44it/s] 16%|█▌        | 1612/10000 [00:04<00:20, 419.30it/s] 17%|█▋        | 1669/10000 [00:04<00:18, 452.51it/s] 18%|█▊        | 1751/10000 [00:04<00:15, 539.49it/s] 18%|█▊        | 1843/10000 [00:04<00:12, 636.33it/s] 19%|█▉        | 1930/10000 [00:04<00:11, 698.49it/s] 20%|██        | 2005/10000 [00:04<00:11, 710.38it/s] 21%|██        | 2080/10000 [00:04<00:11, 662.32it/s] 22%|██▏       | 2150/10000 [00:04<00:11, 666.57it/s] 22%|██▏       | 2219/10000 [00:04<00:14, 549.79it/s] 23%|██▎       | 2279/10000 [00:05<00:14, 531.21it/s] 24%|██▎       | 2351/10000 [00:05<00:13, 562.50it/s] 24%|██▍       | 2414/10000 [00:05<00:13, 577.88it/s] 25%|██▌       | 2500/10000 [00:05<00:11, 648.58it/s] 26%|██▌       | 2602/10000 [00:05<00:09, 750.53it/s] 27%|██▋       | 2680/10000 [00:05<00:13, 541.76it/s] 27%|██▋       | 2744/10000 [00:05<00:15, 480.65it/s] 28%|██▊       | 2800/10000 [00:06<00:16, 435.94it/s] 29%|██▊       | 2861/10000 [00:06<00:15, 469.27it/s] 29%|██▉       | 2946/10000 [00:06<00:12, 556.62it/s] 30%|███       | 3017/10000 [00:06<00:11, 593.71it/s] 31%|███       | 3082/10000 [00:06<00:12, 540.95it/s] 31%|███▏      | 3141/10000 [00:06<00:13, 515.65it/s] 32%|███▏      | 3236/10000 [00:06<00:10, 623.79it/s] 33%|███▎      | 3320/10000 [00:06<00:09, 676.19it/s] 34%|███▍      | 3416/10000 [00:07<00:08, 740.21it/s] 35%|███▍      | 3493/10000 [00:07<00:09, 719.41it/s] 36%|███▌      | 3568/10000 [00:07<00:09, 652.40it/s] 37%|███▋      | 3658/10000 [00:07<00:08, 708.10it/s] 38%|███▊      | 3760/10000 [00:07<00:07, 789.19it/s] 38%|███▊      | 3842/10000 [00:07<00:07, 786.58it/s] 40%|███▉      | 3953/10000 [00:07<00:06, 876.62it/s] 40%|████      | 4043/10000 [00:07<00:07, 794.27it/s] 41%|████▏     | 4126/10000 [00:07<00:07, 801.55it/s] 42%|████▏     | 4234/10000 [00:08<00:06, 869.12it/s] 43%|████▎     | 4337/10000 [00:08<00:06, 913.94it/s] 44%|████▍     | 4430/10000 [00:08<00:07, 787.11it/s] 45%|████▌     | 4513/10000 [00:08<00:07, 702.70it/s] 46%|████▌     | 4588/10000 [00:08<00:09, 579.73it/s] 47%|████▋     | 4652/10000 [00:08<00:09, 577.55it/s] 47%|████▋     | 4717/10000 [00:08<00:08, 587.41it/s] 48%|████▊     | 4779/10000 [00:08<00:09, 576.30it/s] 48%|████▊     | 4839/10000 [00:09<00:09, 547.81it/s] 49%|████▉     | 4896/10000 [00:09<00:11, 458.13it/s] 49%|████▉     | 4945/10000 [00:09<00:12, 419.34it/s] 50%|████▉     | 4990/10000 [00:09<00:12, 410.20it/s] 50%|█████     | 5048/10000 [00:09<00:11, 449.67it/s] 51%|█████     | 5120/10000 [00:09<00:09, 518.47it/s] 52%|█████▏    | 5196/10000 [00:09<00:08, 538.26it/s] 53%|█████▎    | 5252/10000 [00:09<00:08, 538.53it/s] 53%|█████▎    | 5307/10000 [00:10<00:10, 441.60it/s] 54%|█████▎    | 5355/10000 [00:10<00:10, 430.74it/s] 54%|█████▍    | 5401/10000 [00:10<00:11, 394.90it/s] 55%|█████▍    | 5468/10000 [00:10<00:09, 460.90it/s] 55%|█████▌    | 5534/10000 [00:10<00:08, 506.50it/s] 56%|█████▌    | 5609/10000 [00:10<00:07, 570.81it/s] 57%|█████▋    | 5700/10000 [00:10<00:06, 663.94it/s] 58%|█████▊    | 5776/10000 [00:10<00:06, 687.71it/s] 58%|█████▊    | 5847/10000 [00:11<00:06, 598.28it/s] 59%|█████▉    | 5911/10000 [00:11<00:07, 557.71it/s] 60%|█████▉    | 5970/10000 [00:11<00:07, 534.37it/s] 60%|██████    | 6026/10000 [00:11<00:07, 536.36it/s] 61%|██████▏   | 6144/10000 [00:11<00:05, 707.07it/s] 62%|██████▏   | 6218/10000 [00:11<00:05, 643.57it/s] 63%|██████▎   | 6286/10000 [00:11<00:05, 635.60it/s] 64%|██████▎   | 6352/10000 [00:11<00:06, 596.62it/s] 64%|██████▍   | 6414/10000 [00:12<00:06, 519.46it/s] 65%|██████▍   | 6469/10000 [00:12<00:06, 524.09it/s] 65%|██████▌   | 6524/10000 [00:12<00:06, 497.87it/s] 66%|██████▌   | 6576/10000 [00:12<00:06, 500.31it/s] 66%|██████▋   | 6628/10000 [00:12<00:06, 499.51it/s] 67%|██████▋   | 6703/10000 [00:12<00:06, 548.13it/s] 68%|██████▊   | 6759/10000 [00:12<00:06, 530.08it/s] 68%|██████▊   | 6832/10000 [00:12<00:05, 584.43it/s] 69%|██████▉   | 6926/10000 [00:12<00:04, 679.07it/s] 70%|███████   | 7017/10000 [00:13<00:04, 740.89it/s] 71%|███████   | 7093/10000 [00:13<00:04, 710.74it/s] 72%|███████▏  | 7165/10000 [00:13<00:04, 703.01it/s] 72%|███████▏  | 7236/10000 [00:13<00:03, 694.42it/s] 73%|███████▎  | 7316/10000 [00:13<00:03, 709.09it/s] 74%|███████▍  | 7410/10000 [00:13<00:03, 774.16it/s] 75%|███████▍  | 7488/10000 [00:13<00:03, 727.42it/s] 76%|███████▌  | 7578/10000 [00:13<00:03, 765.08it/s] 77%|███████▋  | 7656/10000 [00:13<00:03, 730.75it/s] 77%|███████▋  | 7730/10000 [00:14<00:03, 664.82it/s] 78%|███████▊  | 7798/10000 [00:14<00:03, 654.88it/s] 79%|███████▊  | 7870/10000 [00:14<00:03, 668.19it/s] 80%|███████▉  | 7963/10000 [00:14<00:02, 739.37it/s] 80%|████████  | 8039/10000 [00:14<00:02, 692.80it/s] 81%|████████  | 8114/10000 [00:14<00:02, 701.54it/s] 82%|████████▏ | 8186/10000 [00:14<00:02, 698.20it/s] 83%|████████▎ | 8257/10000 [00:14<00:02, 669.46it/s] 83%|████████▎ | 8325/10000 [00:14<00:02, 643.03it/s] 84%|████████▍ | 8390/10000 [00:15<00:02, 606.26it/s] 85%|████████▍ | 8473/10000 [00:15<00:02, 657.17it/s] 85%|████████▌ | 8544/10000 [00:15<00:02, 658.68it/s] 86%|████████▋ | 8643/10000 [00:15<00:01, 742.24it/s] 87%|████████▋ | 8731/10000 [00:15<00:01, 767.52it/s] 88%|████████▊ | 8825/10000 [00:15<00:01, 805.24it/s] 89%|████████▉ | 8917/10000 [00:15<00:01, 825.35it/s] 90%|█████████ | 9019/10000 [00:15<00:01, 878.62it/s] 91%|█████████ | 9108/10000 [00:15<00:01, 867.41it/s] 92%|█████████▏| 9196/10000 [00:16<00:00, 806.68it/s] 93%|█████████▎| 9278/10000 [00:16<00:01, 674.84it/s] 94%|█████████▎| 9350/10000 [00:16<00:01, 540.58it/s] 94%|█████████▍| 9411/10000 [00:16<00:01, 530.68it/s] 95%|█████████▍| 9474/10000 [00:16<00:00, 547.17it/s] 95%|█████████▌| 9543/10000 [00:16<00:00, 579.63it/s] 96%|█████████▌| 9613/10000 [00:16<00:00, 607.85it/s] 97%|█████████▋| 9677/10000 [00:16<00:00, 603.97it/s] 97%|█████████▋| 9740/10000 [00:17<00:00, 595.74it/s] 98%|█████████▊| 9820/10000 [00:17<00:00, 640.31it/s] 99%|█████████▉| 9914/10000 [00:17<00:00, 722.89it/s]100%|██████████| 10000/10000 [00:17<00:00, 577.09it/s]
test_neglected_p38 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p38
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p38.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.02s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.84it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.08it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.32it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.21it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.18it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.54it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.73it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.27it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p38_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p38_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p38_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p38_Holmes_probs.npy
{'Accuracy': 0.0228, 'Precision': 0.021, 'Recall': 0.0227, 'F1-score': 0.0195}
starting gen taf script for test_neglected_p39
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 65/10000 [00:00<00:16, 619.15it/s]  1%|▏         | 127/10000 [00:00<00:20, 471.61it/s]  2%|▏         | 177/10000 [00:00<00:22, 431.25it/s]  2%|▏         | 222/10000 [00:00<00:23, 418.15it/s]  3%|▎         | 265/10000 [00:00<00:25, 377.93it/s]  3%|▎         | 304/10000 [00:00<00:27, 350.54it/s]  3%|▎         | 346/10000 [00:00<00:26, 363.72it/s]  4%|▍         | 383/10000 [00:01<00:31, 302.91it/s]  4%|▍         | 419/10000 [00:01<00:30, 316.50it/s]  5%|▍         | 455/10000 [00:01<00:29, 322.15it/s]  5%|▍         | 489/10000 [00:01<00:34, 272.83it/s]  5%|▌         | 522/10000 [00:01<00:33, 284.85it/s]  6%|▌         | 559/10000 [00:01<00:31, 302.72it/s]  6%|▌         | 598/10000 [00:01<00:29, 323.57it/s]  6%|▋         | 646/10000 [00:01<00:26, 357.47it/s]  7%|▋         | 683/10000 [00:01<00:26, 356.11it/s]  8%|▊         | 750/10000 [00:02<00:21, 427.66it/s]  8%|▊         | 832/10000 [00:02<00:17, 536.69it/s]  9%|▉         | 921/10000 [00:02<00:14, 636.89it/s] 10%|█         | 1004/10000 [00:02<00:13, 682.44it/s] 11%|█         | 1074/10000 [00:02<00:13, 640.93it/s] 12%|█▏        | 1150/10000 [00:02<00:13, 655.21it/s] 12%|█▏        | 1217/10000 [00:02<00:14, 593.22it/s] 13%|█▎        | 1303/10000 [00:02<00:13, 657.14it/s] 14%|█▍        | 1393/10000 [00:02<00:12, 710.02it/s] 15%|█▍        | 1466/10000 [00:03<00:15, 544.56it/s] 15%|█▌        | 1527/10000 [00:03<00:17, 485.60it/s] 16%|█▌        | 1581/10000 [00:03<00:18, 448.84it/s] 16%|█▋        | 1630/10000 [00:03<00:18, 449.32it/s] 17%|█▋        | 1683/10000 [00:03<00:17, 467.65it/s] 18%|█▊        | 1761/10000 [00:03<00:15, 546.23it/s] 18%|█▊        | 1850/10000 [00:03<00:12, 634.47it/s] 19%|█▉        | 1933/10000 [00:04<00:11, 687.56it/s] 20%|██        | 2005/10000 [00:04<00:11, 695.88it/s] 21%|██        | 2077/10000 [00:04<00:11, 696.06it/s] 22%|██▏       | 2172/10000 [00:04<00:10, 764.68it/s] 22%|██▎       | 2250/10000 [00:04<00:11, 686.72it/s] 23%|██▎       | 2321/10000 [00:04<00:12, 621.73it/s] 24%|██▍       | 2386/10000 [00:04<00:14, 514.35it/s] 25%|██▍       | 2485/10000 [00:04<00:12, 624.10it/s] 26%|██▌       | 2554/10000 [00:04<00:11, 628.60it/s] 26%|██▌       | 2622/10000 [00:05<00:11, 638.71it/s] 27%|██▋       | 2690/10000 [00:05<00:15, 479.11it/s] 27%|██▋       | 2746/10000 [00:05<00:16, 427.77it/s] 28%|██▊       | 2795/10000 [00:05<00:18, 395.79it/s] 28%|██▊       | 2843/10000 [00:05<00:17, 412.38it/s] 29%|██▉       | 2923/10000 [00:05<00:14, 498.07it/s] 30%|██▉       | 2978/10000 [00:05<00:14, 493.34it/s] 30%|███       | 3031/10000 [00:06<00:13, 499.38it/s] 31%|███       | 3093/10000 [00:06<00:13, 512.15it/s] 31%|███▏      | 3146/10000 [00:06<00:13, 510.08it/s] 32%|███▏      | 3199/10000 [00:06<00:13, 492.19it/s] 33%|███▎      | 3302/10000 [00:06<00:10, 624.99it/s] 34%|███▍      | 3419/10000 [00:06<00:08, 775.08it/s] 35%|███▍      | 3499/10000 [00:06<00:08, 765.63it/s] 36%|███▌      | 3578/10000 [00:06<00:08, 721.11it/s] 37%|███▋      | 3686/10000 [00:06<00:07, 818.88it/s] 38%|███▊      | 3770/10000 [00:07<00:07, 814.91it/s] 39%|███▊      | 3855/10000 [00:07<00:07, 816.05it/s] 39%|███▉      | 3938/10000 [00:07<00:07, 813.96it/s] 40%|████      | 4033/10000 [00:07<00:07, 851.54it/s] 41%|████▏     | 4147/10000 [00:07<00:06, 935.39it/s] 43%|████▎     | 4256/10000 [00:07<00:05, 977.12it/s] 44%|████▎     | 4367/10000 [00:07<00:05, 1004.31it/s] 45%|████▍     | 4468/10000 [00:07<00:06, 893.76it/s]  46%|████▌     | 4560/10000 [00:08<00:08, 664.99it/s] 46%|████▋     | 4637/10000 [00:08<00:08, 632.23it/s] 47%|████▋     | 4707/10000 [00:08<00:08, 638.18it/s] 48%|████▊     | 4776/10000 [00:08<00:09, 540.79it/s] 48%|████▊     | 4836/10000 [00:08<00:09, 527.03it/s] 49%|████▉     | 4893/10000 [00:08<00:10, 495.61it/s] 49%|████▉     | 4945/10000 [00:08<00:11, 426.54it/s] 50%|████▉     | 4991/10000 [00:09<00:11, 430.70it/s] 51%|█████     | 5064/10000 [00:09<00:09, 495.52it/s] 51%|█████     | 5122/10000 [00:09<00:09, 516.02it/s] 52%|█████▏    | 5184/10000 [00:09<00:09, 534.41it/s] 52%|█████▏    | 5240/10000 [00:09<00:10, 470.96it/s] 53%|█████▎    | 5290/10000 [00:09<00:10, 458.68it/s] 53%|█████▎    | 5338/10000 [00:09<00:10, 428.74it/s] 54%|█████▍    | 5383/10000 [00:09<00:11, 401.37it/s] 54%|█████▍    | 5425/10000 [00:09<00:12, 374.16it/s] 55%|█████▍    | 5464/10000 [00:10<00:12, 370.80it/s] 55%|█████▌    | 5535/10000 [00:10<00:09, 453.13it/s] 56%|█████▌    | 5614/10000 [00:10<00:08, 531.19it/s] 57%|█████▋    | 5696/10000 [00:10<00:07, 608.29it/s] 58%|█████▊    | 5780/10000 [00:10<00:06, 651.07it/s] 58%|█████▊    | 5847/10000 [00:10<00:07, 567.97it/s] 59%|█████▉    | 5907/10000 [00:10<00:07, 541.57it/s] 60%|█████▉    | 5963/10000 [00:10<00:08, 449.94it/s] 60%|██████    | 6041/10000 [00:11<00:07, 519.26it/s] 61%|██████▏   | 6144/10000 [00:11<00:05, 644.76it/s] 62%|██████▏   | 6215/10000 [00:11<00:05, 645.65it/s] 63%|██████▎   | 6284/10000 [00:11<00:06, 600.90it/s] 63%|██████▎   | 6348/10000 [00:11<00:06, 564.61it/s] 64%|██████▍   | 6407/10000 [00:11<00:07, 502.26it/s] 65%|██████▍   | 6460/10000 [00:11<00:07, 465.05it/s] 65%|██████▌   | 6514/10000 [00:11<00:07, 475.55it/s] 66%|██████▌   | 6564/10000 [00:12<00:07, 473.37it/s] 66%|██████▌   | 6624/10000 [00:12<00:06, 494.90it/s] 67%|██████▋   | 6693/10000 [00:12<00:06, 536.48it/s] 68%|██████▊   | 6755/10000 [00:12<00:05, 549.22it/s] 68%|██████▊   | 6836/10000 [00:12<00:05, 621.33it/s] 69%|██████▉   | 6931/10000 [00:12<00:04, 706.54it/s] 70%|███████   | 7003/10000 [00:12<00:04, 682.01it/s] 71%|███████   | 7073/10000 [00:12<00:04, 676.61it/s] 71%|███████▏  | 7142/10000 [00:12<00:04, 633.70it/s] 72%|███████▏  | 7216/10000 [00:13<00:04, 662.63it/s] 73%|███████▎  | 7333/10000 [00:13<00:03, 799.30it/s] 74%|███████▍  | 7420/10000 [00:13<00:03, 817.71it/s] 75%|███████▌  | 7509/10000 [00:13<00:03, 829.09it/s] 76%|███████▌  | 7608/10000 [00:13<00:02, 864.23it/s] 77%|███████▋  | 7695/10000 [00:13<00:03, 704.86it/s] 78%|███████▊  | 7771/10000 [00:13<00:03, 698.23it/s] 78%|███████▊  | 7845/10000 [00:13<00:03, 669.97it/s] 79%|███████▉  | 7930/10000 [00:13<00:02, 707.11it/s] 80%|████████  | 8017/10000 [00:14<00:02, 743.43it/s] 81%|████████  | 8094/10000 [00:14<00:02, 693.57it/s] 82%|████████▏ | 8166/10000 [00:14<00:02, 661.15it/s] 82%|████████▏ | 8234/10000 [00:14<00:03, 581.40it/s] 83%|████████▎ | 8295/10000 [00:14<00:02, 582.22it/s] 84%|████████▍ | 8377/10000 [00:14<00:02, 629.03it/s] 84%|████████▍ | 8449/10000 [00:14<00:02, 641.93it/s] 85%|████████▌ | 8528/10000 [00:14<00:02, 676.87it/s] 86%|████████▌ | 8604/10000 [00:15<00:02, 691.35it/s] 87%|████████▋ | 8705/10000 [00:15<00:01, 780.22it/s] 88%|████████▊ | 8808/10000 [00:15<00:01, 841.93it/s] 89%|████████▉ | 8919/10000 [00:15<00:01, 908.01it/s] 90%|█████████ | 9043/10000 [00:15<00:00, 998.54it/s] 91%|█████████▏| 9144/10000 [00:15<00:00, 985.08it/s] 92%|█████████▏| 9244/10000 [00:15<00:01, 747.94it/s] 93%|█████████▎| 9328/10000 [00:15<00:01, 611.56it/s] 94%|█████████▍| 9399/10000 [00:16<00:01, 550.67it/s] 95%|█████████▍| 9463/10000 [00:16<00:00, 564.66it/s] 95%|█████████▌| 9525/10000 [00:16<00:00, 520.90it/s] 96%|█████████▌| 9581/10000 [00:16<00:00, 513.13it/s] 96%|█████████▋| 9635/10000 [00:16<00:00, 506.28it/s] 97%|█████████▋| 9693/10000 [00:16<00:00, 508.15it/s] 98%|█████████▊| 9761/10000 [00:16<00:00, 539.00it/s] 99%|█████████▊| 9856/10000 [00:16<00:00, 647.08it/s] 99%|█████████▉| 9944/10000 [00:17<00:00, 708.65it/s]100%|██████████| 10000/10000 [00:17<00:00, 586.10it/s]
test_neglected_p39 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p39
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p39.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.04it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.05it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.79it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.32it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.38it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.49it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.76it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 38.16it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.17it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.74it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p39_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p39_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p39_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p39_Holmes_probs.npy
{'Accuracy': 0.0232, 'Precision': 0.0212, 'Recall': 0.0231, 'F1-score': 0.0198}
starting gen taf script for test_neglected_p40
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 111/10000 [00:00<00:09, 1090.84it/s]  2%|▏         | 221/10000 [00:00<00:19, 511.02it/s]   3%|▎         | 288/10000 [00:00<00:22, 439.47it/s]  3%|▎         | 341/10000 [00:00<00:23, 406.38it/s]  4%|▍         | 386/10000 [00:00<00:26, 368.11it/s]  4%|▍         | 440/10000 [00:01<00:23, 405.16it/s]  5%|▍         | 484/10000 [00:01<00:26, 361.69it/s]  5%|▌         | 523/10000 [00:01<00:29, 317.93it/s]  6%|▌         | 567/10000 [00:01<00:27, 345.17it/s]  6%|▌         | 612/10000 [00:01<00:25, 368.34it/s]  7%|▋         | 652/10000 [00:01<00:27, 340.51it/s]  7%|▋         | 702/10000 [00:01<00:24, 377.80it/s]  7%|▋         | 742/10000 [00:01<00:25, 366.08it/s]  8%|▊         | 780/10000 [00:02<00:25, 362.52it/s]  8%|▊         | 818/10000 [00:02<00:25, 360.67it/s]  9%|▊         | 861/10000 [00:02<00:24, 371.88it/s]  9%|▉         | 899/10000 [00:02<00:24, 366.90it/s] 10%|▉         | 958/10000 [00:02<00:21, 428.11it/s] 10%|█         | 1014/10000 [00:02<00:19, 462.82it/s] 11%|█         | 1072/10000 [00:02<00:19, 466.18it/s] 11%|█         | 1120/10000 [00:02<00:18, 468.44it/s] 12%|█▏        | 1176/10000 [00:02<00:17, 490.28it/s] 12%|█▏        | 1226/10000 [00:03<00:20, 433.34it/s] 13%|█▎        | 1313/10000 [00:03<00:15, 547.02it/s] 14%|█▍        | 1387/10000 [00:03<00:14, 585.28it/s] 14%|█▍        | 1448/10000 [00:03<00:16, 532.10it/s] 15%|█▌        | 1504/10000 [00:03<00:18, 455.97it/s] 16%|█▌        | 1553/10000 [00:03<00:23, 362.29it/s] 16%|█▌        | 1600/10000 [00:03<00:22, 380.54it/s] 16%|█▋        | 1649/10000 [00:03<00:20, 404.90it/s] 17%|█▋        | 1731/10000 [00:04<00:16, 499.04it/s] 18%|█▊        | 1831/10000 [00:04<00:13, 622.66it/s] 19%|█▉        | 1916/10000 [00:04<00:11, 678.43it/s] 20%|██        | 2020/10000 [00:04<00:10, 775.40it/s] 21%|██        | 2106/10000 [00:04<00:10, 779.96it/s] 22%|██▏       | 2187/10000 [00:04<00:11, 685.67it/s] 23%|██▎       | 2260/10000 [00:04<00:11, 684.85it/s] 23%|██▎       | 2331/10000 [00:04<00:13, 562.64it/s] 24%|██▍       | 2393/10000 [00:05<00:13, 565.32it/s] 25%|██▍       | 2473/10000 [00:05<00:12, 617.63it/s] 25%|██▌       | 2540/10000 [00:05<00:11, 625.34it/s] 26%|██▌       | 2605/10000 [00:05<00:12, 599.12it/s] 27%|██▋       | 2667/10000 [00:05<00:13, 527.46it/s] 27%|██▋       | 2723/10000 [00:05<00:16, 436.39it/s] 28%|██▊       | 2771/10000 [00:05<00:17, 422.65it/s] 28%|██▊       | 2816/10000 [00:05<00:17, 400.65it/s] 29%|██▉       | 2889/10000 [00:06<00:15, 469.88it/s] 30%|██▉       | 2953/10000 [00:06<00:13, 503.71it/s] 30%|███       | 3035/10000 [00:06<00:12, 566.48it/s] 31%|███       | 3094/10000 [00:06<00:12, 558.38it/s] 32%|███▏      | 3152/10000 [00:06<00:15, 428.09it/s] 32%|███▏      | 3225/10000 [00:06<00:13, 496.19it/s] 33%|███▎      | 3318/10000 [00:06<00:11, 601.86it/s] 34%|███▍      | 3387/10000 [00:06<00:10, 620.32it/s] 35%|███▍      | 3462/10000 [00:07<00:10, 651.55it/s] 35%|███▌      | 3532/10000 [00:07<00:09, 661.45it/s] 36%|███▌      | 3610/10000 [00:07<00:09, 694.31it/s] 37%|███▋      | 3682/10000 [00:07<00:09, 685.89it/s] 38%|███▊      | 3765/10000 [00:07<00:08, 726.65it/s] 38%|███▊      | 3844/10000 [00:07<00:08, 744.89it/s] 39%|███▉      | 3920/10000 [00:07<00:09, 615.50it/s] 40%|███▉      | 3986/10000 [00:07<00:10, 597.29it/s] 41%|████      | 4063/10000 [00:07<00:09, 635.89it/s] 41%|████▏     | 4143/10000 [00:08<00:08, 676.60it/s] 42%|████▏     | 4240/10000 [00:08<00:07, 750.82it/s] 43%|████▎     | 4321/10000 [00:08<00:07, 761.11it/s] 44%|████▍     | 4399/10000 [00:08<00:07, 746.77it/s] 45%|████▍     | 4475/10000 [00:08<00:08, 690.16it/s] 45%|████▌     | 4546/10000 [00:08<00:08, 662.68it/s] 46%|████▌     | 4614/10000 [00:08<00:09, 595.72it/s] 47%|████▋     | 4676/10000 [00:08<00:09, 557.88it/s] 47%|████▋     | 4734/10000 [00:08<00:09, 551.97it/s] 48%|████▊     | 4791/10000 [00:09<00:09, 543.03it/s] 48%|████▊     | 4846/10000 [00:09<00:11, 453.79it/s] 49%|████▉     | 4897/10000 [00:09<00:10, 467.35it/s] 49%|████▉     | 4946/10000 [00:09<00:12, 396.24it/s] 50%|████▉     | 4989/10000 [00:09<00:14, 351.21it/s] 51%|█████     | 5061/10000 [00:09<00:11, 432.73it/s] 52%|█████▏    | 5162/10000 [00:09<00:08, 572.73it/s] 52%|█████▏    | 5226/10000 [00:10<00:08, 545.11it/s] 53%|█████▎    | 5286/10000 [00:10<00:10, 460.84it/s] 53%|█████▎    | 5338/10000 [00:10<00:11, 397.50it/s] 54%|█████▍    | 5383/10000 [00:10<00:12, 379.08it/s] 54%|█████▍    | 5427/10000 [00:10<00:11, 388.64it/s] 55%|█████▍    | 5483/10000 [00:10<00:10, 428.80it/s] 55%|█████▌    | 5544/10000 [00:10<00:09, 464.35it/s] 56%|█████▌    | 5608/10000 [00:10<00:08, 509.75it/s] 57%|█████▋    | 5684/10000 [00:11<00:07, 572.66it/s] 58%|█████▊    | 5772/10000 [00:11<00:06, 654.53it/s] 58%|█████▊    | 5840/10000 [00:11<00:07, 586.78it/s] 59%|█████▉    | 5902/10000 [00:11<00:07, 522.81it/s] 60%|█████▉    | 5958/10000 [00:11<00:07, 507.75it/s] 60%|██████    | 6011/10000 [00:11<00:08, 484.71it/s] 61%|██████    | 6086/10000 [00:11<00:07, 544.95it/s] 62%|██████▏   | 6189/10000 [00:11<00:05, 656.84it/s] 63%|██████▎   | 6257/10000 [00:12<00:06, 582.29it/s] 63%|██████▎   | 6318/10000 [00:12<00:06, 550.89it/s] 64%|██████▍   | 6375/10000 [00:12<00:07, 471.47it/s] 64%|██████▍   | 6425/10000 [00:12<00:07, 448.74it/s] 65%|██████▍   | 6484/10000 [00:12<00:07, 472.85it/s] 65%|██████▌   | 6533/10000 [00:12<00:07, 434.88it/s] 66%|██████▌   | 6585/10000 [00:12<00:07, 452.91it/s] 66%|██████▋   | 6637/10000 [00:12<00:07, 467.86it/s] 67%|██████▋   | 6688/10000 [00:13<00:07, 467.07it/s] 67%|██████▋   | 6742/10000 [00:13<00:06, 483.84it/s] 68%|██████▊   | 6804/10000 [00:13<00:06, 517.66it/s] 69%|██████▉   | 6912/10000 [00:13<00:04, 670.34it/s] 70%|██████▉   | 6981/10000 [00:13<00:04, 662.71it/s] 70%|███████   | 7048/10000 [00:13<00:04, 645.70it/s] 71%|███████   | 7114/10000 [00:13<00:04, 647.52it/s] 72%|███████▏  | 7180/10000 [00:13<00:04, 632.13it/s] 73%|███████▎  | 7264/10000 [00:13<00:04, 668.80it/s] 74%|███████▎  | 7357/10000 [00:14<00:03, 742.57it/s] 74%|███████▍  | 7432/10000 [00:14<00:03, 739.62it/s] 75%|███████▌  | 7513/10000 [00:14<00:03, 749.84it/s] 76%|███████▌  | 7594/10000 [00:14<00:03, 732.87it/s] 77%|███████▋  | 7668/10000 [00:14<00:03, 674.61it/s] 77%|███████▋  | 7737/10000 [00:14<00:03, 608.79it/s] 78%|███████▊  | 7800/10000 [00:14<00:03, 610.06it/s] 79%|███████▊  | 7870/10000 [00:14<00:03, 630.69it/s] 80%|███████▉  | 7961/10000 [00:14<00:02, 699.89it/s] 80%|████████  | 8033/10000 [00:15<00:02, 700.01it/s] 81%|████████  | 8117/10000 [00:15<00:02, 730.08it/s] 82%|████████▏ | 8191/10000 [00:15<00:02, 655.51it/s] 83%|████████▎ | 8261/10000 [00:15<00:02, 660.06it/s] 83%|████████▎ | 8329/10000 [00:15<00:02, 611.29it/s] 84%|████████▍ | 8393/10000 [00:15<00:02, 618.75it/s] 85%|████████▍ | 8456/10000 [00:15<00:02, 617.98it/s] 85%|████████▌ | 8543/10000 [00:15<00:02, 684.13it/s] 87%|████████▋ | 8653/10000 [00:15<00:01, 795.01it/s] 87%|████████▋ | 8735/10000 [00:16<00:01, 801.64it/s] 88%|████████▊ | 8816/10000 [00:16<00:01, 795.61it/s] 89%|████████▉ | 8902/10000 [00:16<00:01, 814.23it/s] 90%|█████████ | 9021/10000 [00:16<00:01, 921.11it/s] 91%|█████████ | 9114/10000 [00:16<00:00, 908.75it/s] 92%|█████████▏| 9206/10000 [00:16<00:00, 839.63it/s] 93%|█████████▎| 9292/10000 [00:16<00:01, 620.07it/s] 94%|█████████▎| 9363/10000 [00:16<00:01, 539.63it/s] 94%|█████████▍| 9425/10000 [00:17<00:01, 500.55it/s] 95%|█████████▍| 9481/10000 [00:17<00:01, 513.04it/s] 95%|█████████▌| 9537/10000 [00:17<00:00, 496.16it/s] 96%|█████████▌| 9590/10000 [00:17<00:00, 503.96it/s] 97%|█████████▋| 9661/10000 [00:17<00:00, 543.16it/s] 97%|█████████▋| 9718/10000 [00:17<00:00, 537.13it/s] 98%|█████████▊| 9773/10000 [00:17<00:00, 533.28it/s] 99%|█████████▊| 9861/10000 [00:17<00:00, 622.43it/s]100%|█████████▉| 9950/10000 [00:17<00:00, 692.86it/s]100%|██████████| 10000/10000 [00:18<00:00, 555.29it/s]
test_neglected_p40 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p40
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p40.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.10s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.39it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.29it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.39it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.29it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.43it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.74it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.08it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.35it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p40_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p40_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p40_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p40_Holmes_probs.npy
{'Accuracy': 0.022, 'Precision': 0.0241, 'Recall': 0.0219, 'F1-score': 0.0191}
starting gen taf script for test_neglected_p41
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 98/10000 [00:00<00:10, 956.87it/s]  2%|▏         | 194/10000 [00:00<00:24, 402.69it/s]  3%|▎         | 251/10000 [00:00<00:26, 374.94it/s]  3%|▎         | 297/10000 [00:00<00:28, 340.98it/s]  3%|▎         | 336/10000 [00:00<00:27, 348.35it/s]  4%|▍         | 375/10000 [00:01<00:29, 326.97it/s]  4%|▍         | 418/10000 [00:01<00:27, 348.97it/s]  5%|▍         | 470/10000 [00:01<00:24, 389.24it/s]  5%|▌         | 521/10000 [00:01<00:22, 421.15it/s]  6%|▌         | 567/10000 [00:01<00:21, 431.29it/s]  6%|▌         | 616/10000 [00:01<00:21, 442.65it/s]  7%|▋         | 669/10000 [00:01<00:20, 463.59it/s]  7%|▋         | 717/10000 [00:01<00:20, 447.49it/s]  8%|▊         | 769/10000 [00:01<00:20, 461.01it/s]  8%|▊         | 816/10000 [00:01<00:20, 445.05it/s]  9%|▊         | 861/10000 [00:02<00:22, 411.75it/s]  9%|▉         | 928/10000 [00:02<00:19, 474.41it/s] 10%|▉         | 981/10000 [00:02<00:18, 488.00it/s] 10%|█         | 1031/10000 [00:02<00:18, 481.85it/s] 11%|█         | 1089/10000 [00:02<00:17, 499.04it/s] 12%|█▏        | 1161/10000 [00:02<00:15, 561.08it/s] 12%|█▏        | 1218/10000 [00:02<00:15, 550.10it/s] 13%|█▎        | 1309/10000 [00:02<00:13, 652.64it/s] 14%|█▍        | 1389/10000 [00:02<00:12, 682.15it/s] 15%|█▍        | 1458/10000 [00:03<00:16, 526.10it/s] 15%|█▌        | 1517/10000 [00:03<00:19, 424.43it/s] 16%|█▌        | 1567/10000 [00:03<00:22, 372.39it/s] 16%|█▌        | 1614/10000 [00:03<00:21, 391.89it/s] 17%|█▋        | 1691/10000 [00:03<00:17, 473.97it/s] 18%|█▊        | 1764/10000 [00:03<00:15, 534.31it/s] 19%|█▉        | 1879/10000 [00:03<00:11, 683.16it/s] 20%|█▉        | 1972/10000 [00:04<00:10, 746.27it/s] 21%|██        | 2052/10000 [00:04<00:11, 703.32it/s] 21%|██▏       | 2144/10000 [00:04<00:10, 753.94it/s] 22%|██▏       | 2223/10000 [00:04<00:11, 689.05it/s] 23%|██▎       | 2295/10000 [00:04<00:12, 599.01it/s] 24%|██▎       | 2359/10000 [00:04<00:13, 547.28it/s] 24%|██▍       | 2417/10000 [00:04<00:14, 507.01it/s] 25%|██▌       | 2527/10000 [00:04<00:11, 639.18it/s] 26%|██▌       | 2599/10000 [00:05<00:11, 650.37it/s] 27%|██▋       | 2668/10000 [00:05<00:15, 482.68it/s] 27%|██▋       | 2725/10000 [00:05<00:17, 417.99it/s] 28%|██▊       | 2774/10000 [00:05<00:16, 430.03it/s] 28%|██▊       | 2823/10000 [00:05<00:17, 406.96it/s] 29%|██▉       | 2877/10000 [00:05<00:16, 429.28it/s] 30%|██▉       | 2970/10000 [00:05<00:12, 541.66it/s] 30%|███       | 3029/10000 [00:06<00:13, 530.07it/s] 31%|███       | 3085/10000 [00:06<00:14, 466.05it/s] 32%|███▏      | 3160/10000 [00:06<00:12, 529.23it/s] 32%|███▏      | 3217/10000 [00:06<00:12, 522.74it/s] 33%|███▎      | 3325/10000 [00:06<00:10, 663.07it/s] 34%|███▍      | 3395/10000 [00:06<00:09, 666.73it/s] 35%|███▍      | 3486/10000 [00:06<00:08, 726.28it/s] 36%|███▌      | 3561/10000 [00:06<00:09, 658.22it/s] 36%|███▋      | 3630/10000 [00:07<00:09, 650.48it/s] 37%|███▋      | 3713/10000 [00:07<00:09, 691.10it/s] 38%|███▊      | 3806/10000 [00:07<00:08, 747.88it/s] 39%|███▉      | 3883/10000 [00:07<00:09, 658.62it/s] 40%|███▉      | 3957/10000 [00:07<00:08, 679.69it/s] 40%|████      | 4039/10000 [00:07<00:08, 717.32it/s] 41%|████▏     | 4140/10000 [00:07<00:07, 798.45it/s] 42%|████▏     | 4223/10000 [00:07<00:07, 799.48it/s] 43%|████▎     | 4305/10000 [00:07<00:07, 779.74it/s] 44%|████▍     | 4385/10000 [00:08<00:07, 775.91it/s] 45%|████▍     | 4464/10000 [00:08<00:07, 699.10it/s] 45%|████▌     | 4536/10000 [00:08<00:08, 613.92it/s] 46%|████▌     | 4601/10000 [00:08<00:09, 554.48it/s] 47%|████▋     | 4659/10000 [00:08<00:09, 543.03it/s] 47%|████▋     | 4715/10000 [00:08<00:10, 525.96it/s] 48%|████▊     | 4769/10000 [00:08<00:10, 508.13it/s] 48%|████▊     | 4821/10000 [00:08<00:10, 500.86it/s] 49%|████▊     | 4872/10000 [00:09<00:11, 463.65it/s] 49%|████▉     | 4919/10000 [00:09<00:12, 421.85it/s] 50%|████▉     | 4962/10000 [00:09<00:14, 355.64it/s] 50%|█████     | 5002/10000 [00:09<00:13, 364.16it/s] 51%|█████     | 5075/10000 [00:09<00:10, 453.45it/s] 52%|█████▏    | 5150/10000 [00:09<00:09, 522.32it/s] 52%|█████▏    | 5214/10000 [00:09<00:08, 549.77it/s] 53%|█████▎    | 5272/10000 [00:09<00:10, 454.99it/s] 53%|█████▎    | 5322/10000 [00:10<00:11, 404.27it/s] 54%|█████▎    | 5366/10000 [00:10<00:12, 362.11it/s] 54%|█████▍    | 5425/10000 [00:10<00:11, 406.52it/s] 55%|█████▍    | 5473/10000 [00:10<00:10, 420.80it/s] 55%|█████▌    | 5518/10000 [00:10<00:10, 427.60it/s] 56%|█████▌    | 5578/10000 [00:10<00:09, 463.10it/s] 57%|█████▋    | 5675/10000 [00:10<00:07, 585.05it/s] 58%|█████▊    | 5752/10000 [00:10<00:06, 632.10it/s] 58%|█████▊    | 5821/10000 [00:11<00:06, 615.70it/s] 59%|█████▉    | 5884/10000 [00:11<00:07, 587.16it/s] 59%|█████▉    | 5944/10000 [00:11<00:08, 501.85it/s] 60%|█████▉    | 5997/10000 [00:11<00:08, 447.67it/s] 61%|██████    | 6070/10000 [00:11<00:07, 509.02it/s] 61%|██████▏   | 6139/10000 [00:11<00:07, 545.76it/s] 62%|██████▏   | 6197/10000 [00:11<00:07, 530.19it/s] 63%|██████▎   | 6252/10000 [00:11<00:07, 534.73it/s] 63%|██████▎   | 6307/10000 [00:12<00:07, 487.26it/s] 64%|██████▎   | 6358/10000 [00:12<00:07, 460.02it/s] 64%|██████▍   | 6406/10000 [00:12<00:08, 447.30it/s] 65%|██████▍   | 6452/10000 [00:12<00:08, 426.41it/s] 65%|██████▍   | 6496/10000 [00:12<00:08, 417.20it/s] 65%|██████▌   | 6545/10000 [00:12<00:07, 436.43it/s] 66%|██████▌   | 6590/10000 [00:12<00:08, 410.16it/s] 66%|██████▋   | 6642/10000 [00:12<00:07, 437.94it/s] 67%|██████▋   | 6705/10000 [00:12<00:06, 488.40it/s] 68%|██████▊   | 6755/10000 [00:13<00:06, 479.13it/s] 68%|██████▊   | 6809/10000 [00:13<00:06, 483.43it/s] 69%|██████▉   | 6913/10000 [00:13<00:04, 627.77it/s] 70%|██████▉   | 6977/10000 [00:13<00:05, 602.23it/s] 70%|███████   | 7042/10000 [00:13<00:04, 607.66it/s] 71%|███████   | 7118/10000 [00:13<00:04, 646.69it/s] 72%|███████▏  | 7184/10000 [00:13<00:04, 633.25it/s] 73%|███████▎  | 7295/10000 [00:13<00:03, 768.19it/s] 74%|███████▍  | 7379/10000 [00:13<00:03, 778.46it/s] 75%|███████▍  | 7458/10000 [00:14<00:03, 717.17it/s] 75%|███████▌  | 7533/10000 [00:14<00:03, 713.42it/s] 76%|███████▌  | 7606/10000 [00:14<00:03, 710.97it/s] 77%|███████▋  | 7678/10000 [00:14<00:03, 693.07it/s] 77%|███████▋  | 7748/10000 [00:14<00:03, 585.90it/s] 78%|███████▊  | 7810/10000 [00:14<00:03, 570.31it/s] 79%|███████▉  | 7890/10000 [00:14<00:03, 629.47it/s] 80%|███████▉  | 7963/10000 [00:14<00:03, 647.17it/s] 81%|████████  | 8056/10000 [00:14<00:02, 712.53it/s] 81%|████████▏ | 8133/10000 [00:15<00:02, 726.31it/s] 82%|████████▏ | 8222/10000 [00:15<00:02, 761.56it/s] 83%|████████▎ | 8300/10000 [00:15<00:02, 633.27it/s] 84%|████████▎ | 8368/10000 [00:15<00:02, 635.49it/s] 84%|████████▍ | 8435/10000 [00:15<00:02, 613.46it/s] 85%|████████▍ | 8499/10000 [00:15<00:02, 609.88it/s] 86%|████████▌ | 8562/10000 [00:15<00:02, 574.51it/s] 87%|████████▋ | 8663/10000 [00:15<00:01, 685.43it/s] 87%|████████▋ | 8736/10000 [00:16<00:01, 689.15it/s] 88%|████████▊ | 8847/10000 [00:16<00:01, 801.57it/s] 89%|████████▉ | 8942/10000 [00:16<00:01, 836.07it/s] 90%|█████████ | 9027/10000 [00:16<00:01, 823.93it/s] 91%|█████████ | 9113/10000 [00:16<00:01, 825.55it/s] 92%|█████████▏| 9203/10000 [00:16<00:00, 835.47it/s] 93%|█████████▎| 9288/10000 [00:16<00:01, 598.52it/s] 94%|█████████▎| 9358/10000 [00:16<00:01, 480.21it/s] 94%|█████████▍| 9416/10000 [00:17<00:01, 466.68it/s] 95%|█████████▍| 9482/10000 [00:17<00:01, 500.98it/s] 95%|█████████▌| 9538/10000 [00:17<00:00, 501.31it/s] 96%|█████████▌| 9593/10000 [00:17<00:00, 494.18it/s] 96%|█████████▋| 9648/10000 [00:17<00:00, 497.36it/s] 97%|█████████▋| 9700/10000 [00:17<00:00, 499.65it/s] 98%|█████████▊| 9777/10000 [00:17<00:00, 571.17it/s] 99%|█████████▊| 9861/10000 [00:17<00:00, 632.46it/s] 99%|█████████▉| 9941/10000 [00:17<00:00, 677.46it/s]100%|██████████| 10000/10000 [00:18<00:00, 554.95it/s]
test_neglected_p41 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p41
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p41.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.10s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.39it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.22it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.27it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.10it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.05it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.53it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.14it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.34it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p41_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p41_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p41_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p41_Holmes_probs.npy
{'Accuracy': 0.0218, 'Precision': 0.026, 'Recall': 0.0217, 'F1-score': 0.0191}
starting gen taf script for test_neglected_p42
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 97/10000 [00:00<00:11, 893.74it/s]  2%|▏         | 187/10000 [00:00<00:20, 474.91it/s]  2%|▏         | 245/10000 [00:00<00:25, 382.20it/s]  3%|▎         | 289/10000 [00:00<00:26, 362.85it/s]  3%|▎         | 329/10000 [00:00<00:27, 355.70it/s]  4%|▎         | 367/10000 [00:00<00:27, 351.70it/s]  4%|▍         | 404/10000 [00:01<00:28, 339.95it/s]  5%|▍         | 464/10000 [00:01<00:23, 404.39it/s]  5%|▌         | 513/10000 [00:01<00:22, 422.57it/s]  6%|▌         | 557/10000 [00:01<00:22, 425.50it/s]  6%|▌         | 601/10000 [00:01<00:23, 396.28it/s]  7%|▋         | 653/10000 [00:01<00:21, 428.48it/s]  7%|▋         | 708/10000 [00:01<00:20, 447.56it/s]  8%|▊         | 754/10000 [00:01<00:20, 450.38it/s]  8%|▊         | 800/10000 [00:01<00:22, 408.98it/s]  8%|▊         | 842/10000 [00:02<00:22, 403.85it/s]  9%|▉         | 921/10000 [00:02<00:18, 501.49it/s] 10%|█         | 1000/10000 [00:02<00:15, 564.01it/s] 11%|█         | 1058/10000 [00:02<00:17, 522.81it/s] 11%|█         | 1120/10000 [00:02<00:16, 540.83it/s] 12%|█▏        | 1175/10000 [00:02<00:16, 542.70it/s] 12%|█▏        | 1236/10000 [00:02<00:15, 554.06it/s] 13%|█▎        | 1326/10000 [00:02<00:13, 650.87it/s] 14%|█▍        | 1392/10000 [00:02<00:13, 632.37it/s] 15%|█▍        | 1456/10000 [00:03<00:17, 498.52it/s] 15%|█▌        | 1511/10000 [00:03<00:19, 442.94it/s] 16%|█▌        | 1560/10000 [00:03<00:21, 390.56it/s] 16%|█▌        | 1603/10000 [00:03<00:21, 383.01it/s] 17%|█▋        | 1693/10000 [00:03<00:17, 486.26it/s] 18%|█▊        | 1782/10000 [00:03<00:14, 583.74it/s] 19%|█▉        | 1908/10000 [00:03<00:10, 748.92it/s] 20%|██        | 2010/10000 [00:04<00:09, 810.67it/s] 21%|██        | 2096/10000 [00:04<00:10, 747.10it/s] 22%|██▏       | 2175/10000 [00:04<00:10, 719.23it/s] 22%|██▎       | 2250/10000 [00:04<00:12, 633.46it/s] 23%|██▎       | 2317/10000 [00:04<00:14, 533.07it/s] 24%|██▍       | 2375/10000 [00:04<00:15, 496.47it/s] 25%|██▍       | 2464/10000 [00:04<00:12, 585.83it/s] 26%|██▌       | 2554/10000 [00:04<00:11, 656.52it/s] 26%|██▋       | 2625/10000 [00:05<00:11, 630.16it/s] 27%|██▋       | 2692/10000 [00:05<00:15, 461.91it/s] 27%|██▋       | 2747/10000 [00:05<00:17, 411.19it/s] 28%|██▊       | 2795/10000 [00:05<00:18, 393.09it/s] 28%|██▊       | 2849/10000 [00:05<00:17, 419.98it/s] 29%|██▉       | 2937/10000 [00:05<00:13, 518.87it/s] 30%|███       | 3000/10000 [00:05<00:13, 534.31it/s] 31%|███       | 3058/10000 [00:06<00:13, 498.89it/s] 31%|███       | 3112/10000 [00:06<00:13, 505.78it/s] 32%|███▏      | 3165/10000 [00:06<00:13, 495.01it/s] 32%|███▏      | 3233/10000 [00:06<00:12, 541.52it/s] 33%|███▎      | 3346/10000 [00:06<00:09, 697.72it/s] 34%|███▍      | 3424/10000 [00:06<00:09, 720.42it/s] 35%|███▍      | 3499/10000 [00:06<00:08, 726.69it/s] 36%|███▌      | 3573/10000 [00:06<00:09, 666.72it/s] 37%|███▋      | 3692/10000 [00:06<00:07, 809.76it/s] 38%|███▊      | 3810/10000 [00:07<00:07, 869.22it/s] 39%|███▉      | 3899/10000 [00:07<00:07, 870.40it/s] 40%|███▉      | 3988/10000 [00:07<00:07, 792.46it/s] 41%|████      | 4070/10000 [00:07<00:07, 772.33it/s] 42%|████▏     | 4177/10000 [00:07<00:06, 851.82it/s] 43%|████▎     | 4264/10000 [00:07<00:06, 822.36it/s] 44%|████▎     | 4357/10000 [00:07<00:06, 845.67it/s] 44%|████▍     | 4443/10000 [00:07<00:07, 743.58it/s] 45%|████▌     | 4521/10000 [00:08<00:08, 613.31it/s] 46%|████▌     | 4588/10000 [00:08<00:09, 594.30it/s] 47%|████▋     | 4651/10000 [00:08<00:09, 541.30it/s] 47%|████▋     | 4708/10000 [00:08<00:10, 523.84it/s] 48%|████▊     | 4768/10000 [00:08<00:09, 540.09it/s] 48%|████▊     | 4824/10000 [00:08<00:11, 440.30it/s] 49%|████▊     | 4872/10000 [00:08<00:12, 425.73it/s] 49%|████▉     | 4917/10000 [00:09<00:13, 368.01it/s] 50%|████▉     | 4974/10000 [00:09<00:12, 404.09it/s] 50%|█████     | 5023/10000 [00:09<00:12, 405.29it/s] 51%|█████     | 5097/10000 [00:09<00:10, 486.51it/s] 52%|█████▏    | 5171/10000 [00:09<00:08, 551.91it/s] 52%|█████▏    | 5230/10000 [00:09<00:09, 512.48it/s] 53%|█████▎    | 5284/10000 [00:09<00:12, 391.79it/s] 53%|█████▎    | 5329/10000 [00:09<00:11, 397.43it/s] 54%|█████▎    | 5373/10000 [00:10<00:12, 363.67it/s] 54%|█████▍    | 5413/10000 [00:10<00:12, 364.20it/s] 55%|█████▍    | 5496/10000 [00:10<00:09, 470.78it/s] 56%|█████▌    | 5559/10000 [00:10<00:08, 510.97it/s] 56%|█████▌    | 5622/10000 [00:10<00:08, 535.97it/s] 57%|█████▋    | 5718/10000 [00:10<00:06, 651.14it/s] 58%|█████▊    | 5786/10000 [00:10<00:06, 623.33it/s] 59%|█████▊    | 5851/10000 [00:10<00:07, 564.11it/s] 59%|█████▉    | 5910/10000 [00:11<00:07, 558.34it/s] 60%|█████▉    | 5968/10000 [00:11<00:08, 484.47it/s] 60%|██████    | 6019/10000 [00:11<00:08, 474.47it/s] 61%|██████    | 6082/10000 [00:11<00:07, 510.64it/s] 62%|██████▏   | 6175/10000 [00:11<00:06, 604.12it/s] 62%|██████▏   | 6240/10000 [00:11<00:06, 598.54it/s] 63%|██████▎   | 6302/10000 [00:11<00:07, 484.59it/s] 64%|██████▎   | 6361/10000 [00:11<00:07, 504.81it/s] 64%|██████▍   | 6415/10000 [00:12<00:07, 496.08it/s] 65%|██████▍   | 6467/10000 [00:12<00:08, 430.31it/s] 65%|██████▌   | 6515/10000 [00:12<00:07, 437.84it/s] 66%|██████▌   | 6561/10000 [00:12<00:07, 442.34it/s] 66%|██████▌   | 6616/10000 [00:12<00:07, 468.26it/s] 67%|██████▋   | 6679/10000 [00:12<00:06, 511.48it/s] 67%|██████▋   | 6732/10000 [00:12<00:06, 498.96it/s] 68%|██████▊   | 6802/10000 [00:12<00:05, 549.66it/s] 69%|██████▉   | 6900/10000 [00:12<00:04, 668.31it/s] 70%|██████▉   | 6995/10000 [00:13<00:04, 743.88it/s] 71%|███████   | 7071/10000 [00:13<00:04, 715.64it/s] 71%|███████▏  | 7144/10000 [00:13<00:03, 718.43it/s] 72%|███████▏  | 7230/10000 [00:13<00:03, 746.81it/s] 73%|███████▎  | 7313/10000 [00:13<00:03, 764.16it/s] 74%|███████▍  | 7395/10000 [00:13<00:03, 778.26it/s] 75%|███████▍  | 7474/10000 [00:13<00:03, 772.90it/s] 76%|███████▌  | 7562/10000 [00:13<00:03, 803.94it/s] 76%|███████▋  | 7643/10000 [00:13<00:03, 665.37it/s] 77%|███████▋  | 7714/10000 [00:14<00:03, 652.42it/s] 78%|███████▊  | 7783/10000 [00:14<00:03, 605.49it/s] 79%|███████▊  | 7852/10000 [00:14<00:03, 615.42it/s] 79%|███████▉  | 7923/10000 [00:14<00:03, 633.67it/s] 80%|████████  | 8006/10000 [00:14<00:02, 683.52it/s] 81%|████████  | 8086/10000 [00:14<00:02, 715.80it/s] 82%|████████▏ | 8178/10000 [00:14<00:02, 762.77it/s] 83%|████████▎ | 8256/10000 [00:14<00:02, 671.85it/s] 83%|████████▎ | 8326/10000 [00:14<00:02, 644.11it/s] 84%|████████▍ | 8393/10000 [00:15<00:02, 626.57it/s] 85%|████████▍ | 8457/10000 [00:15<00:02, 595.66it/s] 85%|████████▌ | 8518/10000 [00:15<00:02, 570.07it/s] 86%|████████▋ | 8631/10000 [00:15<00:01, 706.35it/s] 88%|████████▊ | 8750/10000 [00:15<00:01, 832.90it/s] 88%|████████▊ | 8836/10000 [00:15<00:01, 833.90it/s] 89%|████████▉ | 8922/10000 [00:15<00:01, 826.53it/s] 90%|█████████ | 9011/10000 [00:15<00:01, 842.15it/s] 91%|█████████▏| 9141/10000 [00:15<00:00, 973.25it/s] 92%|█████████▏| 9240/10000 [00:16<00:00, 792.75it/s] 93%|█████████▎| 9326/10000 [00:16<00:01, 638.61it/s] 94%|█████████▍| 9399/10000 [00:16<00:01, 520.68it/s] 95%|█████████▍| 9461/10000 [00:16<00:01, 533.66it/s] 95%|█████████▌| 9521/10000 [00:16<00:00, 527.36it/s] 96%|█████████▌| 9579/10000 [00:16<00:00, 501.47it/s] 96%|█████████▋| 9634/10000 [00:16<00:00, 507.79it/s] 97%|█████████▋| 9697/10000 [00:17<00:00, 538.28it/s] 98%|█████████▊| 9768/10000 [00:17<00:00, 568.60it/s] 99%|█████████▊| 9862/10000 [00:17<00:00, 666.11it/s] 99%|█████████▉| 9948/10000 [00:17<00:00, 711.73it/s]100%|██████████| 10000/10000 [00:17<00:00, 573.30it/s]
test_neglected_p42 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p42
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p42.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.01s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.88it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.16it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.39it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.31it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.25it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.61it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.04it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.35it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p42_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p42_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p42_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p42_Holmes_probs.npy
{'Accuracy': 0.0214, 'Precision': 0.0215, 'Recall': 0.0213, 'F1-score': 0.0186}
starting gen taf script for test_neglected_p43
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 89/10000 [00:00<00:12, 803.64it/s]  2%|▏         | 170/10000 [00:00<00:22, 436.43it/s]  2%|▏         | 223/10000 [00:00<00:25, 387.38it/s]  3%|▎         | 266/10000 [00:00<00:31, 310.61it/s]  3%|▎         | 301/10000 [00:00<00:32, 302.77it/s]  3%|▎         | 333/10000 [00:00<00:31, 304.35it/s]  4%|▎         | 365/10000 [00:01<00:35, 272.83it/s]  4%|▍         | 394/10000 [00:01<00:35, 274.28it/s]  4%|▍         | 433/10000 [00:01<00:31, 302.30it/s]  5%|▍         | 465/10000 [00:01<00:40, 236.53it/s]  5%|▍         | 495/10000 [00:01<00:38, 248.52it/s]  5%|▌         | 523/10000 [00:01<00:37, 250.36it/s]  6%|▌         | 556/10000 [00:01<00:35, 268.61it/s]  6%|▌         | 597/10000 [00:01<00:31, 300.68it/s]  6%|▋         | 629/10000 [00:02<00:30, 303.16it/s]  7%|▋         | 662/10000 [00:02<00:30, 308.97it/s]  7%|▋         | 730/10000 [00:02<00:22, 411.05it/s]  8%|▊         | 804/10000 [00:02<00:18, 496.52it/s]  9%|▊         | 855/10000 [00:02<00:22, 401.25it/s]  9%|▉         | 911/10000 [00:02<00:20, 440.35it/s] 10%|▉         | 979/10000 [00:02<00:17, 502.73it/s] 10%|█         | 1033/10000 [00:02<00:18, 493.67it/s] 11%|█         | 1085/10000 [00:02<00:18, 477.66it/s] 12%|█▏        | 1162/10000 [00:03<00:15, 555.99it/s] 12%|█▏        | 1220/10000 [00:03<00:15, 559.87it/s] 13%|█▎        | 1318/10000 [00:03<00:12, 678.34it/s] 14%|█▍        | 1388/10000 [00:03<00:12, 674.04it/s] 15%|█▍        | 1457/10000 [00:03<00:15, 564.89it/s] 15%|█▌        | 1518/10000 [00:03<00:18, 459.27it/s] 16%|█▌        | 1570/10000 [00:03<00:22, 376.57it/s] 16%|█▋        | 1628/10000 [00:04<00:20, 412.95it/s] 17%|█▋        | 1700/10000 [00:04<00:17, 476.84it/s] 18%|█▊        | 1799/10000 [00:04<00:13, 596.30it/s] 19%|█▉        | 1940/10000 [00:04<00:10, 801.86it/s] 20%|██        | 2029/10000 [00:04<00:09, 820.73it/s] 21%|██        | 2118/10000 [00:04<00:10, 735.59it/s] 22%|██▏       | 2198/10000 [00:04<00:11, 706.51it/s] 23%|██▎       | 2273/10000 [00:04<00:11, 671.49it/s] 23%|██▎       | 2343/10000 [00:05<00:12, 604.81it/s] 24%|██▍       | 2407/10000 [00:05<00:14, 530.53it/s] 25%|██▍       | 2481/10000 [00:05<00:13, 570.75it/s] 26%|██▌       | 2561/10000 [00:05<00:12, 619.16it/s] 26%|██▋       | 2626/10000 [00:05<00:13, 562.15it/s] 27%|██▋       | 2685/10000 [00:05<00:17, 407.16it/s] 27%|██▋       | 2733/10000 [00:05<00:17, 409.65it/s] 28%|██▊       | 2780/10000 [00:06<00:19, 368.47it/s] 28%|██▊       | 2841/10000 [00:06<00:17, 411.59it/s] 29%|██▉       | 2901/10000 [00:06<00:15, 449.08it/s] 30%|██▉       | 2978/10000 [00:06<00:13, 523.69it/s] 30%|███       | 3043/10000 [00:06<00:12, 543.67it/s] 31%|███       | 3101/10000 [00:06<00:13, 512.81it/s] 32%|███▏      | 3155/10000 [00:06<00:14, 464.85it/s] 32%|███▏      | 3213/10000 [00:06<00:13, 490.95it/s] 33%|███▎      | 3288/10000 [00:07<00:12, 555.34it/s] 34%|███▍      | 3394/10000 [00:07<00:09, 676.41it/s] 35%|███▍      | 3491/10000 [00:07<00:08, 745.25it/s] 36%|███▌      | 3572/10000 [00:07<00:08, 761.28it/s] 36%|███▋      | 3650/10000 [00:07<00:08, 712.90it/s] 37%|███▋      | 3740/10000 [00:07<00:08, 752.22it/s] 38%|███▊      | 3817/10000 [00:07<00:08, 749.24it/s] 39%|███▉      | 3893/10000 [00:07<00:08, 710.29it/s] 40%|███▉      | 3965/10000 [00:07<00:09, 620.87it/s] 41%|████      | 4051/10000 [00:08<00:08, 669.99it/s] 42%|████▏     | 4157/10000 [00:08<00:07, 772.89it/s] 43%|████▎     | 4272/10000 [00:08<00:06, 874.80it/s] 44%|████▎     | 4373/10000 [00:08<00:06, 912.44it/s] 45%|████▍     | 4467/10000 [00:08<00:06, 797.46it/s] 46%|████▌     | 4551/10000 [00:08<00:08, 643.93it/s] 46%|████▌     | 4623/10000 [00:08<00:09, 552.60it/s] 47%|████▋     | 4685/10000 [00:09<00:10, 513.91it/s] 47%|████▋     | 4743/10000 [00:09<00:10, 504.69it/s] 48%|████▊     | 4809/10000 [00:09<00:10, 501.77it/s] 49%|████▊     | 4862/10000 [00:09<00:10, 504.39it/s] 49%|████▉     | 4914/10000 [00:09<00:11, 435.79it/s] 50%|████▉     | 4960/10000 [00:09<00:12, 394.65it/s] 50%|█████     | 5012/10000 [00:09<00:11, 423.33it/s] 51%|█████     | 5059/10000 [00:09<00:11, 424.84it/s] 51%|█████     | 5124/10000 [00:10<00:10, 477.02it/s] 52%|█████▏    | 5188/10000 [00:10<00:09, 519.95it/s] 52%|█████▏    | 5242/10000 [00:10<00:10, 436.88it/s] 53%|█████▎    | 5289/10000 [00:10<00:11, 422.52it/s] 53%|█████▎    | 5334/10000 [00:10<00:12, 379.16it/s] 54%|█████▎    | 5374/10000 [00:10<00:12, 365.91it/s] 54%|█████▍    | 5413/10000 [00:10<00:12, 370.81it/s] 55%|█████▍    | 5472/10000 [00:10<00:10, 427.71it/s] 56%|█████▌    | 5556/10000 [00:10<00:08, 539.20it/s] 56%|█████▌    | 5613/10000 [00:11<00:08, 539.57it/s] 57%|█████▋    | 5706/10000 [00:11<00:06, 649.32it/s] 58%|█████▊    | 5773/10000 [00:11<00:06, 634.12it/s] 58%|█████▊    | 5838/10000 [00:11<00:06, 597.65it/s] 59%|█████▉    | 5900/10000 [00:11<00:08, 501.29it/s] 60%|█████▉    | 5957/10000 [00:11<00:07, 507.50it/s] 60%|██████    | 6011/10000 [00:11<00:07, 503.22it/s] 61%|██████    | 6102/10000 [00:11<00:06, 609.34it/s] 62%|██████▏   | 6206/10000 [00:12<00:05, 704.30it/s] 63%|██████▎   | 6279/10000 [00:12<00:06, 590.20it/s] 63%|██████▎   | 6343/10000 [00:12<00:06, 544.51it/s] 64%|██████▍   | 6401/10000 [00:12<00:07, 506.56it/s] 65%|██████▍   | 6454/10000 [00:12<00:07, 482.13it/s] 65%|██████▌   | 6504/10000 [00:12<00:07, 454.83it/s] 66%|██████▌   | 6562/10000 [00:12<00:07, 476.44it/s] 66%|██████▌   | 6623/10000 [00:12<00:06, 505.85it/s] 67%|██████▋   | 6679/10000 [00:13<00:06, 512.20it/s] 67%|██████▋   | 6732/10000 [00:13<00:07, 447.29it/s] 68%|██████▊   | 6779/10000 [00:13<00:07, 439.02it/s] 69%|██████▊   | 6851/10000 [00:13<00:06, 508.21it/s] 69%|██████▉   | 6936/10000 [00:13<00:05, 599.22it/s] 70%|███████   | 7018/10000 [00:13<00:04, 646.38it/s] 71%|███████   | 7095/10000 [00:13<00:04, 668.10it/s] 72%|███████▏  | 7164/10000 [00:13<00:04, 653.11it/s] 72%|███████▏  | 7249/10000 [00:13<00:03, 705.88it/s] 73%|███████▎  | 7332/10000 [00:14<00:03, 726.36it/s] 74%|███████▍  | 7406/10000 [00:14<00:03, 720.19it/s] 75%|███████▍  | 7490/10000 [00:14<00:03, 750.55it/s] 76%|███████▌  | 7566/10000 [00:14<00:03, 742.94it/s] 76%|███████▋  | 7641/10000 [00:14<00:03, 665.08it/s] 77%|███████▋  | 7710/10000 [00:14<00:04, 570.32it/s] 78%|███████▊  | 7778/10000 [00:14<00:03, 595.58it/s] 79%|███████▊  | 7854/10000 [00:14<00:03, 630.56it/s] 79%|███████▉  | 7932/10000 [00:15<00:03, 665.09it/s] 80%|████████  | 8002/10000 [00:15<00:02, 674.62it/s] 81%|████████  | 8071/10000 [00:15<00:02, 666.17it/s] 81%|████████▏ | 8147/10000 [00:15<00:02, 692.66it/s] 82%|████████▏ | 8218/10000 [00:15<00:02, 646.08it/s] 83%|████████▎ | 8284/10000 [00:15<00:02, 590.77it/s] 83%|████████▎ | 8345/10000 [00:15<00:03, 494.81it/s] 84%|████████▍ | 8398/10000 [00:15<00:03, 462.21it/s] 85%|████████▍ | 8476/10000 [00:16<00:02, 525.08it/s] 86%|████████▌ | 8571/10000 [00:16<00:02, 614.16it/s] 87%|████████▋ | 8664/10000 [00:16<00:01, 690.76it/s] 88%|████████▊ | 8753/10000 [00:16<00:01, 734.47it/s] 88%|████████▊ | 8842/10000 [00:16<00:01, 763.90it/s] 90%|████████▉ | 8969/10000 [00:16<00:01, 900.54it/s] 91%|█████████ | 9062/10000 [00:16<00:01, 902.75it/s] 92%|█████████▏| 9154/10000 [00:16<00:00, 905.36it/s] 92%|█████████▏| 9246/10000 [00:16<00:00, 780.38it/s] 93%|█████████▎| 9328/10000 [00:17<00:01, 568.49it/s] 94%|█████████▍| 9396/10000 [00:17<00:01, 484.06it/s] 95%|█████████▍| 9453/10000 [00:17<00:01, 479.82it/s] 95%|█████████▌| 9507/10000 [00:17<00:01, 476.79it/s] 96%|█████████▌| 9574/10000 [00:17<00:00, 520.46it/s] 96%|█████████▋| 9631/10000 [00:17<00:00, 496.55it/s] 97%|█████████▋| 9696/10000 [00:17<00:00, 524.62it/s] 98%|█████████▊| 9751/10000 [00:18<00:00, 523.33it/s] 98%|█████████▊| 9827/10000 [00:18<00:00, 585.77it/s]100%|█████████▉| 9954/10000 [00:18<00:00, 770.45it/s]100%|██████████| 10000/10000 [00:18<00:00, 547.65it/s]
test_neglected_p43 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p43
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p43.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.07s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.57it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.63it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.69it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.41it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.51it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.93it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.48it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.69it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p43_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p43_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p43_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p43_Holmes_probs.npy
{'Accuracy': 0.0205, 'Precision': 0.0221, 'Recall': 0.0204, 'F1-score': 0.0177}
starting gen taf script for test_neglected_p44
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 93/10000 [00:00<00:12, 809.99it/s]  2%|▏         | 174/10000 [00:00<00:17, 565.52it/s]  2%|▏         | 235/10000 [00:00<00:19, 502.17it/s]  3%|▎         | 287/10000 [00:00<00:22, 436.82it/s]  3%|▎         | 332/10000 [00:00<00:24, 393.05it/s]  4%|▎         | 372/10000 [00:00<00:25, 382.10it/s]  4%|▍         | 411/10000 [00:00<00:25, 375.94it/s]  5%|▍         | 453/10000 [00:01<00:24, 386.07it/s]  5%|▌         | 501/10000 [00:01<00:23, 404.35it/s]  5%|▌         | 542/10000 [00:01<00:23, 402.04it/s]  6%|▌         | 584/10000 [00:01<00:23, 406.85it/s]  6%|▋         | 635/10000 [00:01<00:21, 431.71it/s]  7%|▋         | 679/10000 [00:01<00:21, 432.94it/s]  7%|▋         | 723/10000 [00:01<00:22, 420.71it/s]  8%|▊         | 766/10000 [00:01<00:22, 413.74it/s]  8%|▊         | 809/10000 [00:01<00:22, 417.77it/s]  9%|▊         | 851/10000 [00:02<00:22, 402.08it/s]  9%|▉         | 901/10000 [00:02<00:21, 425.12it/s]  9%|▉         | 944/10000 [00:02<00:22, 399.56it/s] 10%|▉         | 985/10000 [00:02<00:22, 393.22it/s] 10%|█         | 1025/10000 [00:02<00:25, 349.28it/s] 11%|█         | 1078/10000 [00:02<00:22, 393.74it/s] 11%|█▏        | 1144/10000 [00:02<00:19, 463.24it/s] 12%|█▏        | 1193/10000 [00:02<00:18, 464.56it/s] 13%|█▎        | 1277/10000 [00:02<00:15, 561.20it/s] 14%|█▎        | 1360/10000 [00:03<00:13, 635.75it/s] 14%|█▍        | 1425/10000 [00:03<00:15, 571.04it/s] 15%|█▍        | 1485/10000 [00:03<00:17, 485.75it/s] 15%|█▌        | 1537/10000 [00:03<00:24, 347.29it/s] 16%|█▌        | 1579/10000 [00:03<00:24, 340.03it/s] 17%|█▋        | 1670/10000 [00:03<00:18, 454.92it/s] 17%|█▋        | 1744/10000 [00:03<00:15, 517.24it/s] 18%|█▊        | 1847/10000 [00:04<00:12, 642.48it/s] 20%|█▉        | 1953/10000 [00:04<00:10, 743.74it/s] 20%|██        | 2035/10000 [00:04<00:10, 752.66it/s] 21%|██        | 2116/10000 [00:04<00:12, 653.26it/s] 22%|██▏       | 2189/10000 [00:04<00:11, 672.13it/s] 23%|██▎       | 2261/10000 [00:04<00:12, 596.80it/s] 23%|██▎       | 2325/10000 [00:04<00:14, 517.59it/s] 24%|██▍       | 2381/10000 [00:04<00:15, 496.42it/s] 24%|██▍       | 2434/10000 [00:05<00:16, 455.83it/s] 25%|██▌       | 2510/10000 [00:05<00:14, 522.88it/s] 26%|██▌       | 2575/10000 [00:05<00:13, 551.07it/s] 26%|██▋       | 2633/10000 [00:05<00:13, 553.96it/s] 27%|██▋       | 2691/10000 [00:05<00:16, 445.52it/s] 27%|██▋       | 2741/10000 [00:05<00:18, 393.26it/s] 28%|██▊       | 2785/10000 [00:05<00:20, 345.84it/s] 28%|██▊       | 2847/10000 [00:06<00:17, 401.70it/s] 29%|██▉       | 2915/10000 [00:06<00:15, 464.66it/s] 30%|██▉       | 2972/10000 [00:06<00:14, 478.11it/s] 30%|███       | 3040/10000 [00:06<00:13, 523.24it/s] 31%|███       | 3096/10000 [00:06<00:13, 498.59it/s] 32%|███▏      | 3155/10000 [00:06<00:13, 519.64it/s] 32%|███▏      | 3232/10000 [00:06<00:11, 584.97it/s] 33%|███▎      | 3324/10000 [00:06<00:10, 666.80it/s] 34%|███▍      | 3394/10000 [00:06<00:09, 673.37it/s] 35%|███▍      | 3463/10000 [00:07<00:09, 668.77it/s] 35%|███▌      | 3531/10000 [00:07<00:10, 643.58it/s] 36%|███▌      | 3597/10000 [00:07<00:10, 630.70it/s] 37%|███▋      | 3697/10000 [00:07<00:08, 729.65it/s] 38%|███▊      | 3798/10000 [00:07<00:07, 805.36it/s] 39%|███▉      | 3880/10000 [00:07<00:08, 750.74it/s] 40%|███▉      | 3957/10000 [00:07<00:09, 661.40it/s] 41%|████      | 4052/10000 [00:07<00:08, 731.94it/s] 41%|████▏     | 4143/10000 [00:07<00:07, 756.15it/s] 42%|████▏     | 4248/10000 [00:08<00:06, 835.14it/s] 44%|████▎     | 4352/10000 [00:08<00:06, 880.74it/s] 44%|████▍     | 4442/10000 [00:08<00:07, 781.71it/s] 45%|████▌     | 4524/10000 [00:08<00:08, 640.22it/s] 46%|████▌     | 4594/10000 [00:08<00:09, 574.75it/s] 47%|████▋     | 4657/10000 [00:08<00:10, 491.86it/s] 47%|████▋     | 4718/10000 [00:08<00:10, 514.04it/s] 48%|████▊     | 4774/10000 [00:09<00:10, 480.27it/s] 48%|████▊     | 4825/10000 [00:09<00:13, 387.71it/s] 49%|████▊     | 4868/10000 [00:09<00:13, 366.86it/s] 49%|████▉     | 4908/10000 [00:09<00:14, 341.84it/s] 50%|████▉     | 4955/10000 [00:09<00:13, 368.69it/s] 50%|████▉     | 4994/10000 [00:09<00:13, 372.60it/s] 51%|█████     | 5062/10000 [00:09<00:11, 447.31it/s] 51%|█████▏    | 5148/10000 [00:09<00:08, 554.52it/s] 52%|█████▏    | 5215/10000 [00:10<00:08, 583.46it/s] 53%|█████▎    | 5276/10000 [00:10<00:11, 394.55it/s] 53%|█████▎    | 5326/10000 [00:10<00:13, 357.03it/s] 54%|█████▎    | 5369/10000 [00:10<00:13, 334.50it/s] 54%|█████▍    | 5408/10000 [00:10<00:13, 337.16it/s] 55%|█████▍    | 5465/10000 [00:10<00:11, 382.30it/s] 55%|█████▌    | 5513/10000 [00:11<00:11, 399.22it/s] 56%|█████▌    | 5567/10000 [00:11<00:10, 434.06it/s] 56%|█████▋    | 5638/10000 [00:11<00:08, 499.10it/s] 57%|█████▋    | 5713/10000 [00:11<00:07, 566.82it/s] 58%|█████▊    | 5780/10000 [00:11<00:07, 580.76it/s] 58%|█████▊    | 5840/10000 [00:11<00:07, 583.89it/s] 59%|█████▉    | 5900/10000 [00:11<00:07, 581.43it/s] 60%|█████▉    | 5959/10000 [00:11<00:08, 473.89it/s] 60%|██████    | 6016/10000 [00:11<00:08, 497.77it/s] 61%|██████    | 6086/10000 [00:12<00:07, 544.18it/s] 62%|██████▏   | 6168/10000 [00:12<00:06, 613.16it/s] 62%|██████▏   | 6232/10000 [00:12<00:06, 576.99it/s] 63%|██████▎   | 6292/10000 [00:12<00:06, 544.65it/s] 63%|██████▎   | 6349/10000 [00:12<00:07, 483.04it/s] 64%|██████▍   | 6400/10000 [00:12<00:07, 458.18it/s] 64%|██████▍   | 6448/10000 [00:12<00:08, 421.10it/s] 65%|██████▍   | 6495/10000 [00:12<00:08, 427.36it/s] 65%|██████▌   | 6539/10000 [00:13<00:08, 407.03it/s] 66%|██████▌   | 6581/10000 [00:13<00:08, 404.81it/s] 67%|██████▋   | 6659/10000 [00:13<00:06, 479.27it/s] 67%|██████▋   | 6708/10000 [00:13<00:06, 471.26it/s] 68%|██████▊   | 6765/10000 [00:13<00:06, 493.63it/s] 69%|██████▉   | 6877/10000 [00:13<00:04, 663.81it/s] 70%|██████▉   | 6991/10000 [00:13<00:03, 758.26it/s] 71%|███████   | 7068/10000 [00:13<00:03, 753.17it/s] 72%|███████▏  | 7160/10000 [00:13<00:03, 798.35it/s] 72%|███████▏  | 7241/10000 [00:14<00:03, 767.55it/s] 73%|███████▎  | 7344/10000 [00:14<00:03, 838.82it/s] 74%|███████▍  | 7429/10000 [00:14<00:03, 820.40it/s] 75%|███████▌  | 7512/10000 [00:14<00:03, 739.01it/s] 76%|███████▌  | 7588/10000 [00:14<00:03, 690.92it/s] 77%|███████▋  | 7659/10000 [00:14<00:03, 614.00it/s] 77%|███████▋  | 7723/10000 [00:14<00:03, 574.60it/s] 78%|███████▊  | 7786/10000 [00:14<00:03, 568.11it/s] 79%|███████▊  | 7857/10000 [00:14<00:03, 603.54it/s] 79%|███████▉  | 7930/10000 [00:15<00:03, 634.65it/s] 80%|████████  | 8021/10000 [00:15<00:02, 706.28it/s] 81%|████████  | 8097/10000 [00:15<00:02, 708.54it/s] 82%|████████▏ | 8169/10000 [00:15<00:02, 667.23it/s] 82%|████████▏ | 8237/10000 [00:15<00:02, 652.20it/s] 83%|████████▎ | 8303/10000 [00:15<00:02, 565.96it/s] 84%|████████▎ | 8362/10000 [00:15<00:02, 562.08it/s] 84%|████████▍ | 8420/10000 [00:15<00:02, 536.41it/s] 85%|████████▌ | 8513/10000 [00:16<00:02, 627.72it/s] 86%|████████▌ | 8578/10000 [00:16<00:02, 606.87it/s] 87%|████████▋ | 8671/10000 [00:16<00:01, 685.67it/s] 88%|████████▊ | 8753/10000 [00:16<00:01, 722.62it/s] 88%|████████▊ | 8847/10000 [00:16<00:01, 782.44it/s] 90%|████████▉ | 8971/10000 [00:16<00:01, 913.59it/s] 91%|█████████ | 9064/10000 [00:16<00:01, 887.15it/s] 92%|█████████▏| 9172/10000 [00:16<00:00, 924.46it/s] 93%|█████████▎| 9266/10000 [00:16<00:01, 698.43it/s] 93%|█████████▎| 9345/10000 [00:17<00:01, 569.89it/s] 94%|█████████▍| 9412/10000 [00:17<00:01, 503.87it/s] 95%|█████████▍| 9470/10000 [00:17<00:01, 516.24it/s] 95%|█████████▌| 9527/10000 [00:17<00:00, 479.78it/s] 96%|█████████▌| 9585/10000 [00:17<00:00, 497.70it/s] 97%|█████████▋| 9661/10000 [00:17<00:00, 543.42it/s] 97%|█████████▋| 9719/10000 [00:17<00:00, 542.57it/s] 98%|█████████▊| 9776/10000 [00:18<00:00, 540.76it/s] 99%|█████████▉| 9903/10000 [00:18<00:00, 728.28it/s]100%|██████████| 10000/10000 [00:18<00:00, 548.55it/s]
test_neglected_p44 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p44
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p44.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.05s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.65it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.77it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.91it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.77it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.92it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.30it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.97it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.92it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p44_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p44_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p44_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p44_Holmes_probs.npy
{'Accuracy': 0.0208, 'Precision': 0.0233, 'Recall': 0.0208, 'F1-score': 0.0182}
starting gen taf script for test_neglected_p45
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 96/10000 [00:00<00:12, 820.87it/s]  2%|▏         | 179/10000 [00:00<00:25, 378.46it/s]  2%|▏         | 229/10000 [00:00<00:29, 326.24it/s]  3%|▎         | 268/10000 [00:00<00:29, 328.39it/s]  3%|▎         | 305/10000 [00:00<00:30, 318.56it/s]  3%|▎         | 339/10000 [00:00<00:30, 319.62it/s]  4%|▎         | 373/10000 [00:01<00:30, 310.99it/s]  4%|▍         | 410/10000 [00:01<00:29, 324.60it/s]  5%|▍         | 456/10000 [00:01<00:26, 354.96it/s]  5%|▍         | 499/10000 [00:01<00:25, 373.65it/s]  5%|▌         | 548/10000 [00:01<00:23, 401.87it/s]  6%|▌         | 589/10000 [00:01<00:23, 402.61it/s]  6%|▋         | 630/10000 [00:01<00:23, 401.55it/s]  7%|▋         | 678/10000 [00:01<00:22, 422.42it/s]  7%|▋         | 721/10000 [00:01<00:23, 403.38it/s]  8%|▊         | 762/10000 [00:02<00:24, 383.90it/s]  8%|▊         | 826/10000 [00:02<00:20, 453.75it/s]  9%|▉         | 885/10000 [00:02<00:18, 481.88it/s]  9%|▉         | 939/10000 [00:02<00:18, 495.33it/s] 10%|█         | 1009/10000 [00:02<00:16, 551.95it/s] 11%|█         | 1065/10000 [00:02<00:17, 524.00it/s] 11%|█         | 1123/10000 [00:02<00:16, 538.17it/s] 12%|█▏        | 1178/10000 [00:02<00:16, 524.10it/s] 13%|█▎        | 1271/10000 [00:02<00:13, 634.49it/s] 13%|█▎        | 1336/10000 [00:03<00:14, 599.43it/s] 14%|█▍        | 1397/10000 [00:03<00:14, 602.01it/s] 15%|█▍        | 1458/10000 [00:03<00:18, 461.73it/s] 15%|█▌        | 1510/10000 [00:03<00:20, 409.91it/s] 16%|█▌        | 1556/10000 [00:03<00:23, 359.89it/s] 16%|█▌        | 1596/10000 [00:03<00:23, 355.70it/s] 17%|█▋        | 1676/10000 [00:03<00:18, 456.64it/s] 17%|█▋        | 1746/10000 [00:03<00:16, 508.28it/s] 18%|█▊        | 1829/10000 [00:04<00:13, 590.88it/s] 19%|█▉        | 1924/10000 [00:04<00:11, 678.84it/s] 20%|██        | 2018/10000 [00:04<00:10, 750.36it/s] 21%|██        | 2097/10000 [00:04<00:11, 681.68it/s] 22%|██▏       | 2169/10000 [00:04<00:12, 621.02it/s] 22%|██▏       | 2235/10000 [00:04<00:13, 586.30it/s] 23%|██▎       | 2296/10000 [00:04<00:13, 587.02it/s] 24%|██▎       | 2357/10000 [00:04<00:15, 498.10it/s] 24%|██▍       | 2410/10000 [00:05<00:16, 456.02it/s] 25%|██▍       | 2470/10000 [00:05<00:15, 489.80it/s] 26%|██▌       | 2573/10000 [00:05<00:12, 617.50it/s] 26%|██▋       | 2639/10000 [00:05<00:15, 472.06it/s] 27%|██▋       | 2694/10000 [00:05<00:17, 414.62it/s] 27%|██▋       | 2742/10000 [00:05<00:18, 392.86it/s] 28%|██▊       | 2786/10000 [00:06<00:18, 383.99it/s] 28%|██▊       | 2847/10000 [00:06<00:16, 429.78it/s] 29%|██▉       | 2915/10000 [00:06<00:14, 482.83it/s] 30%|██▉       | 2974/10000 [00:06<00:13, 507.90it/s] 30%|███       | 3032/10000 [00:06<00:13, 524.65it/s] 31%|███       | 3087/10000 [00:06<00:13, 509.63it/s] 31%|███▏      | 3140/10000 [00:06<00:13, 503.18it/s] 32%|███▏      | 3192/10000 [00:06<00:13, 499.20it/s] 33%|███▎      | 3270/10000 [00:06<00:11, 574.75it/s] 33%|███▎      | 3348/10000 [00:06<00:10, 628.72it/s] 34%|███▍      | 3430/10000 [00:07<00:09, 671.15it/s] 35%|███▌      | 3503/10000 [00:07<00:09, 673.84it/s] 36%|███▌      | 3578/10000 [00:07<00:09, 676.43it/s] 37%|███▋      | 3669/10000 [00:07<00:08, 733.10it/s] 38%|███▊      | 3783/10000 [00:07<00:07, 844.11it/s] 39%|███▊      | 3868/10000 [00:07<00:07, 816.06it/s] 40%|███▉      | 3951/10000 [00:07<00:07, 815.76it/s] 40%|████      | 4033/10000 [00:07<00:07, 799.64it/s] 41%|████      | 4114/10000 [00:07<00:07, 797.10it/s] 42%|████▏     | 4225/10000 [00:08<00:06, 885.76it/s] 43%|████▎     | 4314/10000 [00:08<00:07, 787.43it/s] 44%|████▍     | 4401/10000 [00:08<00:06, 805.70it/s] 45%|████▍     | 4484/10000 [00:08<00:07, 693.13it/s] 46%|████▌     | 4557/10000 [00:08<00:09, 580.38it/s] 46%|████▌     | 4621/10000 [00:08<00:09, 585.51it/s] 47%|████▋     | 4684/10000 [00:08<00:09, 561.11it/s] 47%|████▋     | 4743/10000 [00:08<00:10, 510.02it/s] 48%|████▊     | 4797/10000 [00:09<00:10, 514.09it/s] 48%|████▊     | 4850/10000 [00:09<00:10, 493.90it/s] 49%|████▉     | 4901/10000 [00:09<00:12, 417.32it/s] 49%|████▉     | 4946/10000 [00:09<00:12, 389.62it/s] 50%|████▉     | 4987/10000 [00:09<00:13, 363.08it/s] 50%|█████     | 5025/10000 [00:09<00:13, 365.93it/s] 51%|█████     | 5108/10000 [00:09<00:10, 456.44it/s] 52%|█████▏    | 5183/10000 [00:09<00:09, 522.68it/s] 52%|█████▏    | 5237/10000 [00:10<00:10, 434.52it/s] 53%|█████▎    | 5284/10000 [00:10<00:11, 428.48it/s] 53%|█████▎    | 5329/10000 [00:10<00:11, 404.01it/s] 54%|█████▎    | 5371/10000 [00:10<00:12, 371.09it/s] 54%|█████▍    | 5410/10000 [00:10<00:13, 337.11it/s] 55%|█████▍    | 5463/10000 [00:10<00:11, 380.48it/s] 55%|█████▌    | 5518/10000 [00:10<00:11, 401.49it/s] 56%|█████▌    | 5566/10000 [00:11<00:10, 415.98it/s] 56%|█████▋    | 5642/10000 [00:11<00:08, 501.99it/s] 57%|█████▋    | 5727/10000 [00:11<00:07, 596.62it/s] 58%|█████▊    | 5801/10000 [00:11<00:06, 604.67it/s] 59%|█████▊    | 5863/10000 [00:11<00:07, 539.97it/s] 59%|█████▉    | 5920/10000 [00:11<00:08, 463.66it/s] 60%|█████▉    | 5973/10000 [00:11<00:08, 461.14it/s] 60%|██████    | 6029/10000 [00:11<00:08, 479.48it/s] 61%|██████    | 6113/10000 [00:12<00:06, 566.01it/s] 62%|██████▏   | 6184/10000 [00:12<00:06, 598.70it/s] 62%|██████▏   | 6246/10000 [00:12<00:06, 568.46it/s] 63%|██████▎   | 6305/10000 [00:12<00:06, 550.06it/s] 64%|██████▎   | 6362/10000 [00:12<00:07, 501.47it/s] 64%|██████▍   | 6414/10000 [00:12<00:08, 432.27it/s] 65%|██████▍   | 6460/10000 [00:12<00:08, 416.66it/s] 65%|██████▌   | 6516/10000 [00:12<00:07, 442.13it/s] 66%|██████▌   | 6564/10000 [00:12<00:07, 443.93it/s] 66%|██████▌   | 6610/10000 [00:13<00:07, 444.84it/s] 67%|██████▋   | 6676/10000 [00:13<00:06, 493.70it/s] 67%|██████▋   | 6727/10000 [00:13<00:06, 493.39it/s] 68%|██████▊   | 6803/10000 [00:13<00:05, 561.88it/s] 69%|██████▊   | 6873/10000 [00:13<00:05, 596.47it/s] 69%|██████▉   | 6944/10000 [00:13<00:04, 628.83it/s] 71%|███████   | 7053/10000 [00:13<00:03, 755.30it/s] 71%|███████▏  | 7133/10000 [00:13<00:03, 765.35it/s] 72%|███████▏  | 7211/10000 [00:13<00:03, 763.91it/s] 73%|███████▎  | 7308/10000 [00:14<00:03, 810.49it/s] 74%|███████▍  | 7390/10000 [00:14<00:03, 793.03it/s] 75%|███████▍  | 7470/10000 [00:14<00:03, 726.68it/s] 75%|███████▌  | 7544/10000 [00:14<00:03, 697.58it/s] 76%|███████▌  | 7615/10000 [00:14<00:03, 634.83it/s] 77%|███████▋  | 7680/10000 [00:14<00:04, 551.94it/s] 77%|███████▋  | 7738/10000 [00:14<00:04, 528.45it/s] 78%|███████▊  | 7807/10000 [00:14<00:03, 567.85it/s] 79%|███████▉  | 7890/10000 [00:15<00:03, 626.92it/s] 80%|███████▉  | 7990/10000 [00:15<00:02, 724.99it/s] 81%|████████  | 8065/10000 [00:15<00:02, 702.33it/s] 81%|████████▏ | 8143/10000 [00:15<00:02, 720.60it/s] 82%|████████▏ | 8217/10000 [00:15<00:02, 697.59it/s] 83%|████████▎ | 8288/10000 [00:15<00:02, 620.27it/s] 84%|████████▎ | 8353/10000 [00:15<00:02, 586.24it/s] 84%|████████▍ | 8414/10000 [00:15<00:03, 518.50it/s] 85%|████████▍ | 8474/10000 [00:15<00:02, 535.12it/s] 86%|████████▌ | 8576/10000 [00:16<00:02, 646.78it/s] 87%|████████▋ | 8682/10000 [00:16<00:01, 749.94it/s] 88%|████████▊ | 8760/10000 [00:16<00:01, 755.36it/s] 89%|████████▉ | 8882/10000 [00:16<00:01, 878.32it/s] 90%|████████▉ | 8972/10000 [00:16<00:01, 877.88it/s] 91%|█████████ | 9062/10000 [00:16<00:01, 826.03it/s] 91%|█████████▏| 9147/10000 [00:16<00:01, 765.98it/s] 92%|█████████▏| 9226/10000 [00:16<00:01, 681.89it/s] 93%|█████████▎| 9297/10000 [00:17<00:01, 554.12it/s] 94%|█████████▎| 9358/10000 [00:17<00:01, 502.66it/s] 94%|█████████▍| 9412/10000 [00:17<00:01, 469.92it/s] 95%|█████████▍| 9470/10000 [00:17<00:01, 493.78it/s] 95%|█████████▌| 9522/10000 [00:17<00:00, 484.55it/s] 96%|█████████▌| 9573/10000 [00:17<00:00, 473.58it/s] 96%|█████████▌| 9622/10000 [00:17<00:00, 469.16it/s] 97%|█████████▋| 9708/10000 [00:17<00:00, 563.97it/s] 98%|█████████▊| 9766/10000 [00:18<00:00, 482.60it/s] 99%|█████████▊| 9867/10000 [00:18<00:00, 611.87it/s]100%|█████████▉| 9957/10000 [00:18<00:00, 682.41it/s]100%|██████████| 10000/10000 [00:18<00:00, 545.28it/s]
test_neglected_p45 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p45
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p45.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.12s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.30it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.41it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 17.61it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 23.54it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 28.70it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.08it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 36.87it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.47it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.03it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p45_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p45_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p45_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p45_Holmes_probs.npy
{'Accuracy': 0.0207, 'Precision': 0.0239, 'Recall': 0.0207, 'F1-score': 0.0179}
starting gen taf script for test_neglected_p46
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 68/10000 [00:00<00:14, 673.83it/s]  1%|▏         | 136/10000 [00:00<00:27, 359.20it/s]  2%|▏         | 180/10000 [00:00<00:28, 340.15it/s]  2%|▏         | 218/10000 [00:00<00:29, 326.33it/s]  3%|▎         | 253/10000 [00:00<00:30, 321.69it/s]  3%|▎         | 288/10000 [00:00<00:29, 325.06it/s]  3%|▎         | 322/10000 [00:00<00:32, 298.27it/s]  4%|▎         | 353/10000 [00:01<00:34, 283.55it/s]  4%|▍         | 385/10000 [00:01<00:33, 287.13it/s]  4%|▍         | 428/10000 [00:01<00:29, 323.00it/s]  5%|▍         | 476/10000 [00:01<00:26, 366.20it/s]  5%|▌         | 514/10000 [00:01<00:26, 364.19it/s]  6%|▌         | 552/10000 [00:01<00:25, 366.66it/s]  6%|▌         | 615/10000 [00:01<00:21, 440.99it/s]  7%|▋         | 660/10000 [00:01<00:21, 429.07it/s]  7%|▋         | 704/10000 [00:01<00:23, 401.31it/s]  8%|▊         | 787/10000 [00:02<00:17, 512.75it/s]  9%|▊         | 852/10000 [00:02<00:16, 549.08it/s]  9%|▉         | 908/10000 [00:02<00:17, 527.13it/s] 10%|▉         | 973/10000 [00:02<00:16, 555.95it/s] 10%|█         | 1030/10000 [00:02<00:16, 542.76it/s] 11%|█         | 1087/10000 [00:02<00:16, 530.29it/s] 12%|█▏        | 1157/10000 [00:02<00:15, 569.74it/s] 12%|█▏        | 1215/10000 [00:02<00:16, 531.77it/s] 13%|█▎        | 1269/10000 [00:02<00:16, 533.38it/s] 14%|█▎        | 1355/10000 [00:03<00:13, 624.40it/s] 14%|█▍        | 1419/10000 [00:03<00:13, 623.08it/s] 15%|█▍        | 1482/10000 [00:03<00:18, 468.01it/s] 15%|█▌        | 1535/10000 [00:03<00:21, 386.31it/s] 16%|█▌        | 1580/10000 [00:03<00:22, 370.93it/s] 16%|█▌        | 1622/10000 [00:03<00:24, 346.06it/s] 17%|█▋        | 1707/10000 [00:03<00:18, 452.89it/s] 18%|█▊        | 1783/10000 [00:04<00:15, 525.99it/s] 19%|█▊        | 1852/10000 [00:04<00:14, 563.11it/s] 19%|█▉        | 1941/10000 [00:04<00:12, 648.28it/s] 20%|██        | 2011/10000 [00:04<00:12, 631.37it/s] 21%|██        | 2078/10000 [00:04<00:12, 609.84it/s] 22%|██▏       | 2154/10000 [00:04<00:12, 640.14it/s] 22%|██▏       | 2221/10000 [00:04<00:12, 625.85it/s] 23%|██▎       | 2285/10000 [00:04<00:13, 558.11it/s] 23%|██▎       | 2343/10000 [00:05<00:16, 472.15it/s] 24%|██▍       | 2394/10000 [00:05<00:16, 453.13it/s] 25%|██▍       | 2472/10000 [00:05<00:14, 528.56it/s] 25%|██▌       | 2528/10000 [00:05<00:14, 533.70it/s] 26%|██▌       | 2591/10000 [00:05<00:13, 542.00it/s] 26%|██▋       | 2647/10000 [00:05<00:16, 434.67it/s] 27%|██▋       | 2695/10000 [00:05<00:17, 421.75it/s] 27%|██▋       | 2740/10000 [00:05<00:19, 380.05it/s] 28%|██▊       | 2781/10000 [00:06<00:21, 335.56it/s] 28%|██▊       | 2817/10000 [00:06<00:21, 333.78it/s] 29%|██▉       | 2886/10000 [00:06<00:17, 408.94it/s] 29%|██▉       | 2942/10000 [00:06<00:15, 441.66it/s] 30%|██▉       | 2997/10000 [00:06<00:15, 455.58it/s] 30%|███       | 3045/10000 [00:06<00:16, 422.45it/s] 31%|███       | 3089/10000 [00:06<00:16, 416.11it/s] 31%|███▏      | 3136/10000 [00:06<00:16, 426.05it/s] 32%|███▏      | 3194/10000 [00:07<00:14, 454.36it/s] 33%|███▎      | 3285/10000 [00:07<00:11, 575.00it/s] 34%|███▍      | 3377/10000 [00:07<00:09, 671.02it/s] 34%|███▍      | 3446/10000 [00:07<00:09, 665.49it/s] 35%|███▌      | 3529/10000 [00:07<00:09, 711.28it/s] 36%|███▌      | 3602/10000 [00:07<00:09, 706.69it/s] 37%|███▋      | 3675/10000 [00:07<00:08, 704.18it/s] 38%|███▊      | 3778/10000 [00:07<00:07, 784.44it/s] 39%|███▊      | 3860/10000 [00:07<00:07, 792.36it/s] 39%|███▉      | 3940/10000 [00:08<00:09, 671.36it/s] 40%|████      | 4031/10000 [00:08<00:08, 732.47it/s] 41%|████      | 4108/10000 [00:08<00:07, 738.69it/s] 42%|████▏     | 4199/10000 [00:08<00:07, 781.71it/s] 43%|████▎     | 4280/10000 [00:08<00:07, 758.43it/s] 44%|████▎     | 4358/10000 [00:08<00:07, 716.98it/s] 44%|████▍     | 4431/10000 [00:08<00:08, 642.37it/s] 45%|████▍     | 4498/10000 [00:08<00:09, 595.27it/s] 46%|████▌     | 4560/10000 [00:08<00:10, 526.89it/s] 46%|████▌     | 4618/10000 [00:09<00:10, 537.74it/s] 47%|████▋     | 4674/10000 [00:09<00:10, 514.37it/s] 47%|████▋     | 4727/10000 [00:09<00:10, 505.13it/s] 48%|████▊     | 4789/10000 [00:09<00:10, 509.65it/s] 48%|████▊     | 4841/10000 [00:09<00:11, 431.85it/s] 49%|████▉     | 4895/10000 [00:09<00:11, 457.49it/s] 49%|████▉     | 4943/10000 [00:09<00:11, 421.89it/s] 50%|████▉     | 4987/10000 [00:09<00:13, 376.83it/s] 50%|█████     | 5049/10000 [00:10<00:11, 432.60it/s] 51%|█████     | 5113/10000 [00:10<00:10, 484.56it/s] 52%|█████▏    | 5174/10000 [00:10<00:09, 501.14it/s] 52%|█████▏    | 5227/10000 [00:10<00:11, 413.87it/s] 53%|█████▎    | 5272/10000 [00:10<00:11, 406.97it/s] 53%|█████▎    | 5316/10000 [00:10<00:13, 339.27it/s] 54%|█████▎    | 5356/10000 [00:10<00:13, 342.34it/s] 54%|█████▍    | 5396/10000 [00:11<00:13, 337.94it/s] 55%|█████▍    | 5472/10000 [00:11<00:10, 427.96it/s] 55%|█████▌    | 5532/10000 [00:11<00:09, 462.63it/s] 56%|█████▌    | 5609/10000 [00:11<00:08, 537.01it/s] 57%|█████▋    | 5674/10000 [00:11<00:07, 556.84it/s] 57%|█████▋    | 5746/10000 [00:11<00:07, 595.96it/s] 58%|█████▊    | 5808/10000 [00:11<00:07, 594.59it/s] 59%|█████▊    | 5869/10000 [00:11<00:07, 575.51it/s] 59%|█████▉    | 5928/10000 [00:11<00:09, 450.83it/s] 60%|█████▉    | 5978/10000 [00:12<00:09, 440.84it/s] 60%|██████    | 6036/10000 [00:12<00:08, 469.65it/s] 61%|██████    | 6103/10000 [00:12<00:07, 514.44it/s] 62%|██████▏   | 6172/10000 [00:12<00:06, 559.36it/s] 62%|██████▏   | 6231/10000 [00:12<00:06, 555.76it/s] 63%|██████▎   | 6289/10000 [00:12<00:08, 458.58it/s] 63%|██████▎   | 6339/10000 [00:12<00:08, 454.11it/s] 64%|██████▍   | 6387/10000 [00:12<00:07, 459.78it/s] 64%|██████▍   | 6435/10000 [00:13<00:07, 447.51it/s] 65%|██████▍   | 6482/10000 [00:13<00:08, 410.13it/s] 65%|██████▌   | 6530/10000 [00:13<00:08, 416.67it/s] 66%|██████▌   | 6591/10000 [00:13<00:07, 459.49it/s] 66%|██████▋   | 6650/10000 [00:13<00:06, 489.67it/s] 67%|██████▋   | 6713/10000 [00:13<00:06, 488.18it/s] 68%|██████▊   | 6763/10000 [00:13<00:07, 457.18it/s] 69%|██████▊   | 6853/10000 [00:13<00:05, 566.28it/s] 70%|██████▉   | 6965/10000 [00:13<00:04, 712.22it/s] 70%|███████   | 7047/10000 [00:14<00:04, 732.73it/s] 71%|███████▏  | 7146/10000 [00:14<00:03, 791.16it/s] 72%|███████▏  | 7227/10000 [00:14<00:03, 695.04it/s] 73%|███████▎  | 7300/10000 [00:14<00:04, 672.24it/s] 74%|███████▍  | 7387/10000 [00:14<00:03, 705.54it/s] 75%|███████▍  | 7462/10000 [00:14<00:03, 717.23it/s] 75%|███████▌  | 7543/10000 [00:14<00:03, 727.05it/s] 76%|███████▌  | 7617/10000 [00:14<00:03, 703.05it/s] 77%|███████▋  | 7688/10000 [00:15<00:03, 618.27it/s] 78%|███████▊  | 7752/10000 [00:15<00:03, 586.17it/s] 78%|███████▊  | 7814/10000 [00:15<00:03, 592.56it/s] 79%|███████▉  | 7901/10000 [00:15<00:03, 658.42it/s] 80%|███████▉  | 7985/10000 [00:15<00:02, 706.88it/s] 81%|████████  | 8058/10000 [00:15<00:02, 699.92it/s] 81%|████████▏ | 8129/10000 [00:15<00:02, 638.79it/s] 82%|████████▏ | 8220/10000 [00:15<00:02, 710.92it/s] 83%|████████▎ | 8293/10000 [00:15<00:02, 597.21it/s] 84%|████████▎ | 8357/10000 [00:16<00:03, 539.89it/s] 84%|████████▍ | 8415/10000 [00:16<00:02, 543.15it/s] 85%|████████▍ | 8475/10000 [00:16<00:02, 540.41it/s] 85%|████████▌ | 8531/10000 [00:16<00:02, 535.79it/s] 86%|████████▌ | 8606/10000 [00:16<00:02, 587.89it/s] 87%|████████▋ | 8693/10000 [00:16<00:01, 663.86it/s] 88%|████████▊ | 8770/10000 [00:16<00:01, 689.26it/s] 88%|████████▊ | 8841/10000 [00:16<00:01, 668.88it/s] 90%|████████▉ | 8952/10000 [00:16<00:01, 789.49it/s] 90%|█████████ | 9033/10000 [00:17<00:01, 781.77it/s] 91%|█████████ | 9119/10000 [00:17<00:01, 790.09it/s] 92%|█████████▏| 9215/10000 [00:17<00:00, 805.70it/s] 93%|█████████▎| 9296/10000 [00:17<00:01, 580.60it/s] 94%|█████████▎| 9363/10000 [00:17<00:01, 503.27it/s] 94%|█████████▍| 9421/10000 [00:17<00:01, 455.62it/s] 95%|█████████▍| 9478/10000 [00:18<00:01, 469.04it/s] 95%|█████████▌| 9537/10000 [00:18<00:00, 495.99it/s] 96%|█████████▌| 9591/10000 [00:18<00:00, 491.50it/s] 97%|█████████▋| 9655/10000 [00:18<00:00, 514.34it/s] 97%|█████████▋| 9709/10000 [00:18<00:00, 504.36it/s] 98%|█████████▊| 9761/10000 [00:18<00:00, 503.43it/s] 99%|█████████▊| 9856/10000 [00:18<00:00, 617.66it/s] 99%|█████████▉| 9937/10000 [00:18<00:00, 654.62it/s]100%|██████████| 10000/10000 [00:18<00:00, 531.87it/s]
test_neglected_p46 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p46
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p46.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.01it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.88it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.46it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.90it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.02it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.26it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.67it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.90it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.30it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.45it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p46_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p46_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p46_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p46_Holmes_probs.npy
{'Accuracy': 0.0205, 'Precision': 0.024, 'Recall': 0.0204, 'F1-score': 0.0178}
starting gen taf script for test_neglected_p47
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 105/10000 [00:00<00:09, 1028.02it/s]  2%|▏         | 208/10000 [00:00<00:24, 398.02it/s]   3%|▎         | 267/10000 [00:00<00:27, 352.84it/s]  3%|▎         | 312/10000 [00:00<00:29, 325.96it/s]  4%|▎         | 350/10000 [00:01<00:34, 282.34it/s]  4%|▍         | 382/10000 [00:01<00:38, 248.82it/s]  4%|▍         | 413/10000 [00:01<00:37, 258.02it/s]  4%|▍         | 441/10000 [00:01<00:37, 252.67it/s]  5%|▍         | 468/10000 [00:01<00:41, 227.03it/s]  5%|▌         | 508/10000 [00:01<00:35, 265.04it/s]  6%|▌         | 554/10000 [00:01<00:30, 312.41it/s]  6%|▌         | 604/10000 [00:01<00:26, 354.29it/s]  6%|▋         | 646/10000 [00:02<00:25, 368.40it/s]  7%|▋         | 693/10000 [00:02<00:24, 385.19it/s]  8%|▊         | 758/10000 [00:02<00:20, 452.72it/s]  8%|▊         | 805/10000 [00:02<00:24, 379.37it/s]  9%|▊         | 871/10000 [00:02<00:20, 447.88it/s]  9%|▉         | 924/10000 [00:02<00:19, 457.68it/s] 10%|▉         | 980/10000 [00:02<00:18, 475.28it/s] 10%|█         | 1037/10000 [00:02<00:18, 487.50it/s] 11%|█         | 1088/10000 [00:02<00:19, 459.61it/s] 12%|█▏        | 1155/10000 [00:03<00:17, 510.51it/s] 12%|█▏        | 1208/10000 [00:03<00:17, 510.68it/s] 13%|█▎        | 1268/10000 [00:03<00:16, 528.93it/s] 14%|█▎        | 1359/10000 [00:03<00:13, 631.61it/s] 14%|█▍        | 1424/10000 [00:03<00:14, 591.60it/s] 15%|█▍        | 1485/10000 [00:03<00:18, 455.92it/s] 15%|█▌        | 1536/10000 [00:03<00:20, 418.92it/s] 16%|█▌        | 1582/10000 [00:04<00:24, 348.16it/s] 16%|█▋        | 1628/10000 [00:04<00:22, 368.54it/s] 17%|█▋        | 1701/10000 [00:04<00:18, 447.98it/s] 18%|█▊        | 1763/10000 [00:04<00:16, 486.63it/s] 19%|█▊        | 1852/10000 [00:04<00:13, 590.57it/s] 20%|█▉        | 1965/10000 [00:04<00:11, 724.82it/s] 20%|██        | 2042/10000 [00:04<00:11, 685.81it/s] 21%|██        | 2114/10000 [00:04<00:11, 689.97it/s] 22%|██▏       | 2186/10000 [00:04<00:12, 634.35it/s] 23%|██▎       | 2252/10000 [00:05<00:15, 489.17it/s] 23%|██▎       | 2316/10000 [00:05<00:15, 488.42it/s] 24%|██▎       | 2370/10000 [00:05<00:15, 488.10it/s] 24%|██▍       | 2422/10000 [00:05<00:15, 487.46it/s] 25%|██▍       | 2473/10000 [00:05<00:15, 492.04it/s] 26%|██▌       | 2550/10000 [00:05<00:13, 559.46it/s] 26%|██▌       | 2608/10000 [00:05<00:14, 502.55it/s] 27%|██▋       | 2661/10000 [00:06<00:16, 450.31it/s] 27%|██▋       | 2709/10000 [00:06<00:17, 411.12it/s] 28%|██▊       | 2752/10000 [00:06<00:20, 353.54it/s] 28%|██▊       | 2790/10000 [00:06<00:21, 337.48it/s] 28%|██▊       | 2826/10000 [00:06<00:20, 342.56it/s] 29%|██▉       | 2892/10000 [00:06<00:16, 418.76it/s] 30%|██▉       | 2955/10000 [00:06<00:14, 471.66it/s] 30%|███       | 3005/10000 [00:06<00:14, 476.97it/s] 31%|███       | 3055/10000 [00:06<00:15, 457.22it/s] 31%|███       | 3102/10000 [00:07<00:15, 433.13it/s] 32%|███▏      | 3174/10000 [00:07<00:13, 496.75it/s] 32%|███▏      | 3225/10000 [00:07<00:13, 499.20it/s] 33%|███▎      | 3304/10000 [00:07<00:11, 580.37it/s] 34%|███▎      | 3372/10000 [00:07<00:10, 605.38it/s] 34%|███▍      | 3437/10000 [00:07<00:10, 618.00it/s] 35%|███▌      | 3507/10000 [00:07<00:10, 621.84it/s] 36%|███▌      | 3583/10000 [00:07<00:09, 654.07it/s] 37%|███▋      | 3670/10000 [00:07<00:08, 714.41it/s] 38%|███▊      | 3779/10000 [00:08<00:07, 807.44it/s] 39%|███▊      | 3860/10000 [00:08<00:08, 697.08it/s] 39%|███▉      | 3933/10000 [00:08<00:09, 670.08it/s] 40%|████      | 4002/10000 [00:08<00:09, 665.20it/s] 41%|████      | 4074/10000 [00:08<00:08, 678.79it/s] 42%|████▏     | 4172/10000 [00:08<00:07, 757.50it/s] 43%|████▎     | 4265/10000 [00:08<00:07, 800.86it/s] 43%|████▎     | 4348/10000 [00:08<00:07, 798.49it/s] 44%|████▍     | 4429/10000 [00:09<00:08, 684.72it/s] 45%|████▌     | 4501/10000 [00:09<00:08, 632.04it/s] 46%|████▌     | 4567/10000 [00:09<00:10, 522.91it/s] 46%|████▌     | 4624/10000 [00:09<00:11, 462.56it/s] 47%|████▋     | 4697/10000 [00:09<00:10, 515.59it/s] 48%|████▊     | 4753/10000 [00:09<00:11, 471.05it/s] 48%|████▊     | 4808/10000 [00:09<00:10, 473.83it/s] 49%|████▊     | 4858/10000 [00:10<00:12, 426.29it/s] 49%|████▉     | 4903/10000 [00:10<00:12, 393.01it/s] 49%|████▉     | 4944/10000 [00:10<00:13, 377.30it/s] 50%|████▉     | 4983/10000 [00:10<00:14, 349.63it/s] 50%|█████     | 5020/10000 [00:10<00:14, 350.25it/s] 51%|█████     | 5098/10000 [00:10<00:10, 447.15it/s] 52%|█████▏    | 5164/10000 [00:10<00:09, 490.98it/s] 52%|█████▏    | 5215/10000 [00:10<00:09, 483.74it/s] 53%|█████▎    | 5265/10000 [00:11<00:12, 389.83it/s] 53%|█████▎    | 5308/10000 [00:11<00:12, 368.70it/s] 53%|█████▎    | 5348/10000 [00:11<00:13, 348.76it/s] 54%|█████▍    | 5385/10000 [00:11<00:13, 338.46it/s] 54%|█████▍    | 5420/10000 [00:11<00:13, 338.21it/s] 55%|█████▍    | 5460/10000 [00:11<00:12, 352.50it/s] 55%|█████▌    | 5521/10000 [00:11<00:10, 418.84it/s] 56%|█████▌    | 5579/10000 [00:11<00:09, 463.04it/s] 56%|█████▋    | 5635/10000 [00:11<00:08, 488.38it/s] 57%|█████▋    | 5718/10000 [00:12<00:07, 585.08it/s] 58%|█████▊    | 5782/10000 [00:12<00:07, 590.49it/s] 58%|█████▊    | 5842/10000 [00:12<00:08, 489.69it/s] 59%|█████▉    | 5895/10000 [00:12<00:09, 455.33it/s] 60%|█████▉    | 5959/10000 [00:12<00:08, 486.86it/s] 60%|██████    | 6010/10000 [00:12<00:08, 456.10it/s] 61%|██████    | 6082/10000 [00:12<00:07, 514.65it/s] 61%|██████▏   | 6138/10000 [00:12<00:07, 525.36it/s] 62%|██████▏   | 6212/10000 [00:13<00:06, 569.76it/s] 63%|██████▎   | 6271/10000 [00:13<00:06, 543.15it/s] 63%|██████▎   | 6327/10000 [00:13<00:07, 477.85it/s] 64%|██████▍   | 6377/10000 [00:13<00:08, 421.08it/s] 64%|██████▍   | 6422/10000 [00:13<00:08, 400.03it/s] 65%|██████▍   | 6464/10000 [00:13<00:08, 394.88it/s] 65%|██████▌   | 6510/10000 [00:13<00:08, 397.35it/s] 66%|██████▌   | 6551/10000 [00:13<00:09, 378.47it/s] 66%|██████▌   | 6597/10000 [00:14<00:08, 397.67it/s] 67%|██████▋   | 6654/10000 [00:14<00:07, 443.33it/s] 67%|██████▋   | 6713/10000 [00:14<00:06, 475.10it/s] 68%|██████▊   | 6774/10000 [00:14<00:06, 511.51it/s] 68%|██████▊   | 6834/10000 [00:14<00:05, 533.25it/s] 69%|██████▉   | 6914/10000 [00:14<00:05, 608.95it/s] 70%|███████   | 7001/10000 [00:14<00:04, 680.64it/s] 71%|███████   | 7070/10000 [00:14<00:04, 655.52it/s] 71%|███████▏  | 7137/10000 [00:14<00:04, 604.28it/s] 72%|███████▏  | 7201/10000 [00:14<00:04, 613.71it/s] 73%|███████▎  | 7296/10000 [00:15<00:03, 699.57it/s] 74%|███████▎  | 7372/10000 [00:15<00:03, 715.57it/s] 74%|███████▍  | 7445/10000 [00:15<00:03, 707.74it/s] 75%|███████▌  | 7525/10000 [00:15<00:03, 715.80it/s] 76%|███████▌  | 7597/10000 [00:15<00:03, 654.23it/s] 77%|███████▋  | 7674/10000 [00:15<00:03, 670.47it/s] 77%|███████▋  | 7742/10000 [00:15<00:04, 522.15it/s] 78%|███████▊  | 7805/10000 [00:15<00:04, 545.72it/s] 79%|███████▉  | 7891/10000 [00:16<00:03, 608.04it/s] 80%|███████▉  | 7967/10000 [00:16<00:03, 638.06it/s] 80%|████████  | 8040/10000 [00:16<00:03, 649.73it/s] 81%|████████  | 8108/10000 [00:16<00:02, 641.07it/s] 82%|████████▏ | 8186/10000 [00:16<00:02, 670.12it/s] 83%|████████▎ | 8255/10000 [00:16<00:02, 635.98it/s] 83%|████████▎ | 8320/10000 [00:16<00:02, 564.43it/s] 84%|████████▍ | 8379/10000 [00:16<00:03, 491.91it/s] 84%|████████▍ | 8431/10000 [00:17<00:03, 480.52it/s] 85%|████████▍ | 8481/10000 [00:17<00:03, 462.40it/s] 85%|████████▌ | 8545/10000 [00:17<00:02, 507.17it/s] 86%|████████▌ | 8618/10000 [00:17<00:02, 561.56it/s] 87%|████████▋ | 8703/10000 [00:17<00:02, 629.89it/s] 88%|████████▊ | 8781/10000 [00:17<00:01, 671.48it/s] 89%|████████▉ | 8889/10000 [00:17<00:01, 786.82it/s] 90%|████████▉ | 8970/10000 [00:17<00:01, 789.11it/s] 91%|█████████ | 9055/10000 [00:17<00:01, 798.15it/s] 91%|█████████▏| 9142/10000 [00:17<00:01, 816.49it/s] 92%|█████████▏| 9225/10000 [00:18<00:01, 699.99it/s] 93%|█████████▎| 9299/10000 [00:18<00:01, 545.34it/s] 94%|█████████▎| 9361/10000 [00:18<00:01, 529.54it/s] 94%|█████████▍| 9419/10000 [00:18<00:01, 474.50it/s] 95%|█████████▍| 9471/10000 [00:18<00:01, 480.55it/s] 95%|█████████▌| 9525/10000 [00:18<00:00, 475.77it/s] 96%|█████████▌| 9581/10000 [00:18<00:00, 491.83it/s] 96%|█████████▋| 9634/10000 [00:19<00:00, 500.97it/s] 97%|█████████▋| 9686/10000 [00:19<00:00, 414.32it/s] 97%|█████████▋| 9731/10000 [00:19<00:00, 408.32it/s] 98%|█████████▊| 9788/10000 [00:19<00:00, 448.60it/s] 99%|█████████▊| 9861/10000 [00:19<00:00, 521.96it/s] 99%|█████████▉| 9928/10000 [00:19<00:00, 559.27it/s]100%|██████████| 10000/10000 [00:19<00:00, 506.43it/s]
test_neglected_p47 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p47
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p47.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.04it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.22it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.53it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.82it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.69it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.68it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.90it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.30it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.83it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p47_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p47_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p47_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p47_Holmes_probs.npy
{'Accuracy': 0.0203, 'Precision': 0.0237, 'Recall': 0.0202, 'F1-score': 0.0178}
starting gen taf script for test_neglected_p48
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 59/10000 [00:00<00:16, 587.56it/s]  1%|          | 118/10000 [00:00<00:22, 448.38it/s]  2%|▏         | 165/10000 [00:00<00:27, 359.19it/s]  2%|▏         | 204/10000 [00:00<00:29, 332.89it/s]  2%|▏         | 240/10000 [00:00<00:29, 334.64it/s]  3%|▎         | 275/10000 [00:00<00:34, 286.00it/s]  3%|▎         | 308/10000 [00:00<00:32, 295.47it/s]  3%|▎         | 339/10000 [00:01<00:38, 248.04it/s]  4%|▎         | 366/10000 [00:01<00:39, 241.21it/s]  4%|▍         | 392/10000 [00:01<00:39, 241.36it/s]  4%|▍         | 437/10000 [00:01<00:32, 290.57it/s]  5%|▍         | 482/10000 [00:01<00:28, 331.99it/s]  5%|▌         | 544/10000 [00:01<00:23, 407.47it/s]  6%|▌         | 591/10000 [00:01<00:22, 422.51it/s]  6%|▋         | 635/10000 [00:01<00:22, 423.68it/s]  7%|▋         | 689/10000 [00:01<00:20, 456.69it/s]  8%|▊         | 756/10000 [00:02<00:18, 503.87it/s]  8%|▊         | 821/10000 [00:02<00:16, 544.01it/s]  9%|▉         | 876/10000 [00:02<00:21, 431.23it/s]  9%|▉         | 923/10000 [00:02<00:20, 436.89it/s] 10%|▉         | 993/10000 [00:02<00:18, 497.37it/s] 10%|█         | 1046/10000 [00:02<00:21, 424.43it/s] 11%|█         | 1100/10000 [00:02<00:20, 444.57it/s] 12%|█▏        | 1151/10000 [00:02<00:19, 459.93it/s] 12%|█▏        | 1200/10000 [00:03<00:18, 467.67it/s] 13%|█▎        | 1263/10000 [00:03<00:17, 506.80it/s] 13%|█▎        | 1334/10000 [00:03<00:15, 556.07it/s] 14%|█▍        | 1391/10000 [00:03<00:15, 558.19it/s] 14%|█▍        | 1448/10000 [00:03<00:19, 428.27it/s] 15%|█▍        | 1496/10000 [00:03<00:21, 387.51it/s] 15%|█▌        | 1539/10000 [00:03<00:24, 342.98it/s] 16%|█▌        | 1577/10000 [00:04<00:27, 309.32it/s] 16%|█▋        | 1626/10000 [00:04<00:24, 346.34it/s] 17%|█▋        | 1700/10000 [00:04<00:18, 438.47it/s] 18%|█▊        | 1768/10000 [00:04<00:16, 499.19it/s] 19%|█▉        | 1875/10000 [00:04<00:12, 649.84it/s] 20%|█▉        | 1960/10000 [00:04<00:11, 698.28it/s] 20%|██        | 2034/10000 [00:04<00:12, 635.37it/s] 21%|██        | 2102/10000 [00:04<00:12, 619.25it/s] 22%|██▏       | 2172/10000 [00:04<00:12, 636.76it/s] 22%|██▏       | 2238/10000 [00:05<00:14, 537.39it/s] 23%|██▎       | 2296/10000 [00:05<00:15, 484.80it/s] 23%|██▎       | 2348/10000 [00:05<00:17, 433.35it/s] 24%|██▍       | 2400/10000 [00:05<00:16, 452.23it/s] 25%|██▍       | 2486/10000 [00:05<00:13, 547.01it/s] 25%|██▌       | 2547/10000 [00:05<00:13, 559.83it/s] 26%|██▌       | 2610/10000 [00:05<00:12, 570.73it/s] 27%|██▋       | 2669/10000 [00:06<00:18, 398.53it/s] 27%|██▋       | 2718/10000 [00:06<00:18, 387.45it/s] 28%|██▊       | 2763/10000 [00:06<00:22, 328.69it/s] 28%|██▊       | 2803/10000 [00:06<00:21, 335.71it/s] 29%|██▊       | 2869/10000 [00:06<00:17, 404.04it/s] 29%|██▉       | 2917/10000 [00:06<00:16, 419.98it/s] 30%|██▉       | 2998/10000 [00:06<00:13, 509.88it/s] 31%|███       | 3053/10000 [00:06<00:13, 516.65it/s] 31%|███       | 3108/10000 [00:07<00:15, 438.58it/s] 32%|███▏      | 3163/10000 [00:07<00:14, 465.80it/s] 32%|███▏      | 3213/10000 [00:07<00:14, 459.72it/s] 33%|███▎      | 3308/10000 [00:07<00:11, 587.50it/s] 34%|███▍      | 3385/10000 [00:07<00:10, 634.90it/s] 35%|███▍      | 3452/10000 [00:07<00:10, 599.23it/s] 35%|███▌      | 3529/10000 [00:07<00:10, 638.65it/s] 36%|███▌      | 3595/10000 [00:07<00:10, 622.21it/s] 37%|███▋      | 3691/10000 [00:07<00:08, 707.68it/s] 38%|███▊      | 3764/10000 [00:08<00:09, 689.59it/s] 38%|███▊      | 3838/10000 [00:08<00:08, 684.76it/s] 39%|███▉      | 3908/10000 [00:08<00:09, 658.79it/s] 40%|███▉      | 3975/10000 [00:08<00:10, 583.80it/s] 40%|████      | 4038/10000 [00:08<00:10, 595.54it/s] 41%|████      | 4108/10000 [00:08<00:09, 620.79it/s] 42%|████▏     | 4187/10000 [00:08<00:08, 657.82it/s] 43%|████▎     | 4263/10000 [00:08<00:08, 677.56it/s] 44%|████▎     | 4356/10000 [00:08<00:07, 736.56it/s] 44%|████▍     | 4431/10000 [00:09<00:07, 709.83it/s] 45%|████▌     | 4503/10000 [00:09<00:09, 593.12it/s] 46%|████▌     | 4566/10000 [00:09<00:10, 524.34it/s] 46%|████▌     | 4622/10000 [00:09<00:10, 496.08it/s] 47%|████▋     | 4674/10000 [00:09<00:10, 489.74it/s] 47%|████▋     | 4725/10000 [00:09<00:11, 462.18it/s] 48%|████▊     | 4773/10000 [00:09<00:11, 463.55it/s] 48%|████▊     | 4821/10000 [00:10<00:13, 397.64it/s] 49%|████▊     | 4874/10000 [00:10<00:12, 416.09it/s] 49%|████▉     | 4918/10000 [00:10<00:12, 410.92it/s] 50%|████▉     | 4961/10000 [00:10<00:14, 359.17it/s] 50%|████▉     | 4999/10000 [00:10<00:14, 349.68it/s] 51%|█████     | 5067/10000 [00:10<00:11, 426.56it/s] 51%|█████▏    | 5136/10000 [00:10<00:09, 495.00it/s] 52%|█████▏    | 5188/10000 [00:10<00:09, 487.59it/s] 52%|█████▏    | 5239/10000 [00:11<00:10, 447.81it/s] 53%|█████▎    | 5286/10000 [00:11<00:11, 424.04it/s] 53%|█████▎    | 5330/10000 [00:11<00:13, 341.86it/s] 54%|█████▎    | 5368/10000 [00:11<00:14, 327.44it/s] 54%|█████▍    | 5403/10000 [00:11<00:14, 322.60it/s] 55%|█████▍    | 5471/10000 [00:11<00:11, 404.72it/s] 55%|█████▌    | 5545/10000 [00:11<00:09, 488.60it/s] 56%|█████▌    | 5597/10000 [00:11<00:08, 490.54it/s] 57%|█████▋    | 5692/10000 [00:12<00:07, 610.97it/s] 58%|█████▊    | 5782/10000 [00:12<00:06, 684.42it/s] 59%|█████▊    | 5853/10000 [00:12<00:07, 542.27it/s] 59%|█████▉    | 5914/10000 [00:12<00:07, 536.11it/s] 60%|█████▉    | 5972/10000 [00:12<00:09, 432.56it/s] 61%|██████    | 6057/10000 [00:12<00:07, 516.37it/s] 61%|██████▏   | 6147/10000 [00:12<00:06, 597.87it/s] 62%|██████▏   | 6216/10000 [00:12<00:06, 619.21it/s] 63%|██████▎   | 6283/10000 [00:13<00:07, 526.33it/s] 63%|██████▎   | 6342/10000 [00:13<00:07, 495.84it/s] 64%|██████▍   | 6396/10000 [00:13<00:07, 451.77it/s] 64%|██████▍   | 6445/10000 [00:13<00:08, 439.61it/s] 65%|██████▍   | 6492/10000 [00:13<00:07, 438.67it/s] 65%|██████▌   | 6538/10000 [00:13<00:08, 421.52it/s] 66%|██████▌   | 6589/10000 [00:13<00:08, 418.64it/s] 66%|██████▋   | 6638/10000 [00:13<00:07, 431.29it/s] 67%|██████▋   | 6713/10000 [00:14<00:06, 515.37it/s] 68%|██████▊   | 6767/10000 [00:14<00:06, 477.32it/s] 68%|██████▊   | 6832/10000 [00:14<00:06, 517.69it/s] 69%|██████▉   | 6923/10000 [00:14<00:04, 624.16it/s] 70%|███████   | 7022/10000 [00:14<00:04, 706.25it/s] 71%|███████   | 7095/10000 [00:14<00:04, 692.22it/s] 72%|███████▏  | 7166/10000 [00:14<00:04, 676.61it/s] 72%|███████▏  | 7238/10000 [00:14<00:04, 682.68it/s] 73%|███████▎  | 7338/10000 [00:14<00:03, 762.19it/s] 74%|███████▍  | 7429/10000 [00:15<00:03, 781.99it/s] 75%|███████▌  | 7508/10000 [00:15<00:03, 731.97it/s] 76%|███████▌  | 7582/10000 [00:15<00:03, 672.42it/s] 77%|███████▋  | 7651/10000 [00:15<00:04, 581.51it/s] 77%|███████▋  | 7712/10000 [00:15<00:04, 549.36it/s] 78%|███████▊  | 7769/10000 [00:15<00:04, 529.87it/s] 78%|███████▊  | 7838/10000 [00:15<00:03, 559.28it/s] 79%|███████▉  | 7909/10000 [00:15<00:03, 594.16it/s] 80%|███████▉  | 7974/10000 [00:16<00:03, 595.46it/s] 81%|████████  | 8054/10000 [00:16<00:03, 645.21it/s] 81%|████████  | 8120/10000 [00:16<00:02, 638.98it/s] 82%|████████▏ | 8207/10000 [00:16<00:02, 679.15it/s] 83%|████████▎ | 8276/10000 [00:16<00:02, 597.70it/s] 83%|████████▎ | 8338/10000 [00:16<00:03, 541.87it/s] 84%|████████▍ | 8395/10000 [00:16<00:03, 490.31it/s] 85%|████████▍ | 8459/10000 [00:16<00:02, 525.20it/s] 85%|████████▌ | 8523/10000 [00:17<00:02, 554.51it/s] 86%|████████▌ | 8581/10000 [00:17<00:02, 548.02it/s] 87%|████████▋ | 8682/10000 [00:17<00:01, 664.94it/s] 88%|████████▊ | 8781/10000 [00:17<00:01, 754.85it/s] 89%|████████▉ | 8880/10000 [00:17<00:01, 816.25it/s] 90%|████████▉ | 8983/10000 [00:17<00:01, 862.82it/s] 91%|█████████ | 9081/10000 [00:17<00:01, 881.30it/s] 92%|█████████▏| 9181/10000 [00:17<00:00, 896.91it/s] 93%|█████████▎| 9272/10000 [00:17<00:01, 661.98it/s] 93%|█████████▎| 9348/10000 [00:18<00:01, 524.41it/s] 94%|█████████▍| 9411/10000 [00:18<00:01, 493.50it/s] 95%|█████████▍| 9468/10000 [00:18<00:01, 493.16it/s] 95%|█████████▌| 9523/10000 [00:18<00:00, 494.72it/s] 96%|█████████▌| 9576/10000 [00:18<00:00, 474.54it/s] 96%|█████████▋| 9626/10000 [00:18<00:00, 459.00it/s] 97%|█████████▋| 9691/10000 [00:18<00:00, 505.37it/s] 97%|█████████▋| 9747/10000 [00:19<00:00, 508.65it/s] 98%|█████████▊| 9822/10000 [00:19<00:00, 566.21it/s] 99%|█████████▉| 9890/10000 [00:19<00:00, 597.05it/s]100%|█████████▉| 9952/10000 [00:19<00:00, 602.35it/s]100%|██████████| 10000/10000 [00:19<00:00, 515.74it/s]
test_neglected_p48 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p48
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p48.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.08s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.51it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.54it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.63it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.48it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.33it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.75it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.34it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.61it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p48_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p48_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p48_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p48_Holmes_probs.npy
{'Accuracy': 0.0195, 'Precision': 0.0228, 'Recall': 0.0194, 'F1-score': 0.017}
starting gen taf script for test_neglected_p49
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 94/10000 [00:00<00:11, 865.28it/s]  2%|▏         | 181/10000 [00:00<00:24, 401.86it/s]  2%|▏         | 234/10000 [00:00<00:29, 332.46it/s]  3%|▎         | 274/10000 [00:00<00:31, 306.30it/s]  3%|▎         | 308/10000 [00:00<00:32, 293.94it/s]  3%|▎         | 340/10000 [00:01<00:35, 271.85it/s]  4%|▎         | 369/10000 [00:01<00:35, 270.44it/s]  4%|▍         | 397/10000 [00:01<00:35, 271.67it/s]  4%|▍         | 437/10000 [00:01<00:31, 301.81it/s]  5%|▍         | 479/10000 [00:01<00:28, 330.39it/s]  5%|▌         | 536/10000 [00:01<00:23, 395.35it/s]  6%|▋         | 627/10000 [00:01<00:17, 536.92it/s]  7%|▋         | 695/10000 [00:01<00:16, 553.40it/s]  8%|▊         | 752/10000 [00:01<00:16, 558.02it/s]  8%|▊         | 815/10000 [00:02<00:16, 568.17it/s]  9%|▊         | 873/10000 [00:02<00:16, 563.27it/s] 10%|▉         | 954/10000 [00:02<00:14, 633.24it/s] 10%|█         | 1018/10000 [00:02<00:16, 543.33it/s] 11%|█         | 1075/10000 [00:02<00:18, 471.54it/s] 11%|█▏        | 1136/10000 [00:02<00:17, 502.63it/s] 12%|█▏        | 1190/10000 [00:02<00:18, 484.14it/s] 12%|█▏        | 1246/10000 [00:02<00:17, 500.85it/s] 13%|█▎        | 1315/10000 [00:02<00:15, 545.06it/s] 14%|█▍        | 1388/10000 [00:03<00:14, 586.60it/s] 14%|█▍        | 1448/10000 [00:03<00:18, 465.92it/s] 15%|█▌        | 1500/10000 [00:03<00:19, 441.73it/s] 15%|█▌        | 1548/10000 [00:03<00:22, 373.75it/s] 16%|█▌        | 1589/10000 [00:03<00:25, 334.79it/s] 16%|█▋        | 1638/10000 [00:03<00:23, 360.59it/s] 17%|█▋        | 1728/10000 [00:03<00:17, 484.53it/s] 18%|█▊        | 1821/10000 [00:04<00:13, 588.89it/s] 19%|█▉        | 1925/10000 [00:04<00:11, 696.36it/s] 20%|██        | 2025/10000 [00:04<00:10, 765.25it/s] 21%|██        | 2106/10000 [00:04<00:11, 707.87it/s] 22%|██▏       | 2181/10000 [00:04<00:11, 657.69it/s] 22%|██▎       | 2250/10000 [00:04<00:13, 555.42it/s] 23%|██▎       | 2310/10000 [00:04<00:15, 511.29it/s] 24%|██▎       | 2365/10000 [00:05<00:16, 476.06it/s] 24%|██▍       | 2415/10000 [00:05<00:16, 462.97it/s] 25%|██▍       | 2477/10000 [00:05<00:15, 498.78it/s] 26%|██▌       | 2551/10000 [00:05<00:13, 554.57it/s] 26%|██▌       | 2609/10000 [00:05<00:14, 494.62it/s] 27%|██▋       | 2661/10000 [00:05<00:15, 463.23it/s] 27%|██▋       | 2709/10000 [00:05<00:18, 393.24it/s] 28%|██▊       | 2751/10000 [00:05<00:22, 328.81it/s] 28%|██▊       | 2787/10000 [00:06<00:23, 306.47it/s] 28%|██▊       | 2844/10000 [00:06<00:19, 360.82it/s] 29%|██▉       | 2895/10000 [00:06<00:18, 375.02it/s] 29%|██▉       | 2946/10000 [00:06<00:17, 405.08it/s] 30%|██▉       | 2990/10000 [00:06<00:17, 408.43it/s] 31%|███       | 3067/10000 [00:06<00:14, 490.47it/s] 31%|███       | 3118/10000 [00:06<00:14, 464.51it/s] 32%|███▏      | 3166/10000 [00:06<00:15, 439.81it/s] 32%|███▏      | 3211/10000 [00:07<00:15, 429.80it/s] 33%|███▎      | 3302/10000 [00:07<00:12, 555.32it/s] 34%|███▍      | 3385/10000 [00:07<00:10, 622.54it/s] 35%|███▍      | 3462/10000 [00:07<00:09, 658.99it/s] 35%|███▌      | 3530/10000 [00:07<00:10, 634.71it/s] 36%|███▌      | 3595/10000 [00:07<00:10, 629.30it/s] 37%|███▋      | 3676/10000 [00:07<00:09, 678.70it/s] 38%|███▊      | 3756/10000 [00:07<00:08, 700.95it/s] 38%|███▊      | 3827/10000 [00:07<00:09, 684.97it/s] 39%|███▉      | 3896/10000 [00:08<00:10, 579.61it/s] 40%|███▉      | 3957/10000 [00:08<00:10, 582.88it/s] 40%|████      | 4039/10000 [00:08<00:09, 637.56it/s] 41%|████      | 4105/10000 [00:08<00:09, 633.62it/s] 42%|████▏     | 4197/10000 [00:08<00:08, 710.01it/s] 43%|████▎     | 4271/10000 [00:08<00:07, 718.19it/s] 44%|████▎     | 4369/10000 [00:08<00:07, 779.22it/s] 44%|████▍     | 4448/10000 [00:08<00:08, 650.97it/s] 45%|████▌     | 4517/10000 [00:08<00:09, 593.55it/s] 46%|████▌     | 4580/10000 [00:09<00:10, 520.77it/s] 46%|████▋     | 4640/10000 [00:09<00:09, 538.65it/s] 47%|████▋     | 4697/10000 [00:09<00:10, 483.15it/s] 47%|████▋     | 4748/10000 [00:09<00:11, 457.76it/s] 48%|████▊     | 4803/10000 [00:09<00:10, 476.43it/s] 49%|████▊     | 4853/10000 [00:09<00:11, 432.11it/s] 49%|████▉     | 4898/10000 [00:09<00:13, 381.71it/s] 49%|████▉     | 4938/10000 [00:10<00:13, 365.34it/s] 50%|████▉     | 4976/10000 [00:10<00:13, 368.32it/s] 50%|█████     | 5014/10000 [00:10<00:13, 357.30it/s] 51%|█████     | 5085/10000 [00:10<00:11, 431.39it/s] 51%|█████▏    | 5136/10000 [00:10<00:11, 441.24it/s] 52%|█████▏    | 5201/10000 [00:10<00:10, 479.44it/s] 52%|█████▎    | 5250/10000 [00:10<00:10, 441.41it/s] 53%|█████▎    | 5295/10000 [00:10<00:12, 382.53it/s] 53%|█████▎    | 5335/10000 [00:11<00:14, 324.59it/s] 54%|█████▍    | 5376/10000 [00:11<00:13, 340.59it/s] 54%|█████▍    | 5417/10000 [00:11<00:13, 351.05it/s] 55%|█████▍    | 5473/10000 [00:11<00:11, 400.87it/s] 55%|█████▌    | 5517/10000 [00:11<00:10, 410.77it/s] 56%|█████▌    | 5579/10000 [00:11<00:09, 460.99it/s] 57%|█████▋    | 5676/10000 [00:11<00:07, 595.00it/s] 58%|█████▊    | 5785/10000 [00:11<00:05, 730.55it/s] 59%|█████▊    | 5860/10000 [00:12<00:07, 570.32it/s] 59%|█████▉    | 5924/10000 [00:12<00:08, 483.73it/s] 60%|█████▉    | 5979/10000 [00:12<00:08, 460.75it/s] 61%|██████    | 6069/10000 [00:12<00:07, 550.06it/s] 61%|██████▏   | 6146/10000 [00:12<00:06, 594.53it/s] 62%|██████▏   | 6210/10000 [00:12<00:06, 550.31it/s] 63%|██████▎   | 6269/10000 [00:12<00:07, 522.38it/s] 63%|██████▎   | 6324/10000 [00:12<00:07, 470.96it/s] 64%|██████▎   | 6374/10000 [00:13<00:08, 450.79it/s] 64%|██████▍   | 6421/10000 [00:13<00:08, 424.54it/s] 65%|██████▍   | 6465/10000 [00:13<00:09, 391.11it/s] 65%|██████▌   | 6518/10000 [00:13<00:08, 406.49it/s] 66%|██████▌   | 6560/10000 [00:13<00:08, 394.04it/s] 66%|██████▌   | 6614/10000 [00:13<00:07, 430.51it/s] 67%|██████▋   | 6675/10000 [00:13<00:07, 467.28it/s] 67%|██████▋   | 6723/10000 [00:13<00:07, 441.60it/s] 68%|██████▊   | 6791/10000 [00:14<00:06, 502.34it/s] 69%|██████▉   | 6875/10000 [00:14<00:05, 583.84it/s] 70%|███████   | 7002/10000 [00:14<00:04, 749.27it/s] 71%|███████   | 7081/10000 [00:14<00:03, 753.30it/s] 72%|███████▏  | 7169/10000 [00:14<00:03, 778.65it/s] 73%|███████▎  | 7258/10000 [00:14<00:03, 790.87it/s] 73%|███████▎  | 7338/10000 [00:14<00:03, 776.47it/s] 74%|███████▍  | 7422/10000 [00:14<00:03, 788.92it/s] 75%|███████▌  | 7502/10000 [00:14<00:03, 789.70it/s] 76%|███████▌  | 7582/10000 [00:15<00:03, 750.67it/s] 77%|███████▋  | 7658/10000 [00:15<00:03, 682.65it/s] 77%|███████▋  | 7728/10000 [00:15<00:04, 560.60it/s] 78%|███████▊  | 7795/10000 [00:15<00:03, 585.99it/s] 79%|███████▊  | 7858/10000 [00:15<00:03, 588.38it/s] 79%|███████▉  | 7921/10000 [00:15<00:03, 595.17it/s] 80%|████████  | 8026/10000 [00:15<00:02, 695.60it/s] 81%|████████  | 8100/10000 [00:15<00:02, 698.16it/s] 82%|████████▏ | 8182/10000 [00:15<00:02, 729.42it/s] 83%|████████▎ | 8256/10000 [00:16<00:03, 565.49it/s] 83%|████████▎ | 8319/10000 [00:16<00:02, 567.39it/s] 84%|████████▍ | 8380/10000 [00:16<00:03, 520.65it/s] 84%|████████▍ | 8436/10000 [00:16<00:03, 509.04it/s] 85%|████████▌ | 8505/10000 [00:16<00:02, 545.29it/s] 86%|████████▌ | 8562/10000 [00:16<00:02, 533.29it/s] 87%|████████▋ | 8669/10000 [00:16<00:01, 666.23it/s] 88%|████████▊ | 8771/10000 [00:16<00:01, 757.73it/s] 89%|████████▉ | 8898/10000 [00:17<00:01, 894.85it/s] 90%|████████▉ | 8991/10000 [00:17<00:01, 879.28it/s] 91%|█████████ | 9081/10000 [00:17<00:01, 840.43it/s] 92%|█████████▏| 9167/10000 [00:17<00:01, 747.05it/s] 92%|█████████▏| 9245/10000 [00:17<00:01, 583.90it/s] 93%|█████████▎| 9311/10000 [00:17<00:01, 487.58it/s] 94%|█████████▎| 9367/10000 [00:18<00:01, 450.52it/s] 94%|█████████▍| 9417/10000 [00:18<00:01, 441.05it/s] 95%|█████████▍| 9464/10000 [00:18<00:01, 437.07it/s] 95%|█████████▌| 9513/10000 [00:18<00:01, 448.71it/s] 96%|█████████▌| 9560/10000 [00:18<00:01, 422.93it/s] 96%|█████████▌| 9617/10000 [00:18<00:00, 448.67it/s] 97%|█████████▋| 9674/10000 [00:18<00:00, 467.17it/s] 97%|█████████▋| 9746/10000 [00:18<00:00, 521.04it/s] 98%|█████████▊| 9824/10000 [00:18<00:00, 590.70it/s] 99%|█████████▉| 9904/10000 [00:19<00:00, 634.67it/s]100%|██████████| 10000/10000 [00:19<00:00, 523.54it/s]
test_neglected_p49 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p49
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p49.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.10s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.39it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.15it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.15it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 23.96it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.15it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.62it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.29it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.21it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p49_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p49_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p49_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p49_Holmes_probs.npy
{'Accuracy': 0.0199, 'Precision': 0.0252, 'Recall': 0.0198, 'F1-score': 0.0175}
starting gen taf script for test_neglected_p50
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 67/10000 [00:00<00:15, 638.07it/s]  1%|▏         | 131/10000 [00:00<00:28, 341.57it/s]  2%|▏         | 173/10000 [00:00<00:30, 318.38it/s]  2%|▏         | 209/10000 [00:00<00:31, 312.72it/s]  2%|▎         | 250/10000 [00:00<00:28, 339.07it/s]  3%|▎         | 287/10000 [00:00<00:31, 308.87it/s]  3%|▎         | 320/10000 [00:01<00:34, 280.36it/s]  4%|▎         | 350/10000 [00:01<00:34, 278.64it/s]  4%|▍         | 379/10000 [00:01<00:35, 270.21it/s]  4%|▍         | 407/10000 [00:01<00:37, 256.10it/s]  5%|▍         | 453/10000 [00:01<00:31, 306.61it/s]  5%|▍         | 491/10000 [00:01<00:29, 325.03it/s]  5%|▌         | 541/10000 [00:01<00:25, 371.88it/s]  6%|▌         | 580/10000 [00:01<00:28, 332.01it/s]  6%|▌         | 615/10000 [00:01<00:28, 333.23it/s]  7%|▋         | 653/10000 [00:02<00:28, 330.86it/s]  7%|▋         | 687/10000 [00:02<00:28, 329.73it/s]  7%|▋         | 733/10000 [00:02<00:25, 363.27it/s]  8%|▊         | 772/10000 [00:02<00:25, 366.04it/s]  8%|▊         | 844/10000 [00:02<00:19, 461.85it/s]  9%|▉         | 907/10000 [00:02<00:17, 506.25it/s] 10%|▉         | 965/10000 [00:02<00:17, 516.56it/s] 10%|█         | 1024/10000 [00:02<00:16, 534.03it/s] 11%|█         | 1078/10000 [00:02<00:20, 432.48it/s] 11%|█▏        | 1125/10000 [00:03<00:20, 422.66it/s] 12%|█▏        | 1192/10000 [00:03<00:18, 483.86it/s] 13%|█▎        | 1265/10000 [00:03<00:15, 548.86it/s] 13%|█▎        | 1342/10000 [00:03<00:14, 598.48it/s] 14%|█▍        | 1404/10000 [00:03<00:14, 591.35it/s] 15%|█▍        | 1465/10000 [00:03<00:19, 428.70it/s] 15%|█▌        | 1515/10000 [00:03<00:23, 363.57it/s] 16%|█▌        | 1558/10000 [00:04<00:24, 340.19it/s] 16%|█▌        | 1597/10000 [00:04<00:24, 338.80it/s] 16%|█▋        | 1647/10000 [00:04<00:22, 368.29it/s] 17%|█▋        | 1729/10000 [00:04<00:17, 471.85it/s] 18%|█▊        | 1807/10000 [00:04<00:15, 541.67it/s] 19%|█▉        | 1947/10000 [00:04<00:10, 758.35it/s] 20%|██        | 2028/10000 [00:04<00:11, 700.12it/s] 21%|██        | 2103/10000 [00:04<00:11, 691.88it/s] 22%|██▏       | 2176/10000 [00:05<00:12, 608.96it/s] 22%|██▏       | 2241/10000 [00:05<00:13, 595.36it/s] 23%|██▎       | 2303/10000 [00:05<00:15, 508.55it/s] 24%|██▎       | 2358/10000 [00:05<00:18, 409.43it/s] 24%|██▍       | 2413/10000 [00:05<00:17, 430.96it/s] 25%|██▍       | 2491/10000 [00:05<00:14, 503.69it/s] 26%|██▌       | 2573/10000 [00:05<00:12, 573.04it/s] 26%|██▋       | 2635/10000 [00:06<00:14, 494.73it/s] 27%|██▋       | 2690/10000 [00:06<00:18, 395.51it/s] 27%|██▋       | 2736/10000 [00:06<00:21, 338.40it/s] 28%|██▊       | 2775/10000 [00:06<00:22, 325.35it/s] 28%|██▊       | 2817/10000 [00:06<00:21, 340.63it/s] 29%|██▉       | 2892/10000 [00:06<00:16, 428.01it/s] 30%|██▉       | 2959/10000 [00:06<00:14, 486.56it/s] 30%|███       | 3013/10000 [00:06<00:14, 485.58it/s] 31%|███       | 3068/10000 [00:07<00:14, 489.31it/s] 31%|███       | 3123/10000 [00:07<00:13, 505.48it/s] 32%|███▏      | 3176/10000 [00:07<00:15, 432.73it/s] 32%|███▏      | 3223/10000 [00:07<00:15, 433.12it/s] 33%|███▎      | 3304/10000 [00:07<00:12, 525.50it/s] 34%|███▍      | 3401/10000 [00:07<00:10, 639.61it/s] 35%|███▍      | 3490/10000 [00:07<00:09, 703.54it/s] 36%|███▌      | 3563/10000 [00:07<00:09, 650.03it/s] 36%|███▋      | 3631/10000 [00:08<00:10, 611.89it/s] 37%|███▋      | 3697/10000 [00:08<00:10, 624.23it/s] 38%|███▊      | 3762/10000 [00:08<00:09, 629.62it/s] 38%|███▊      | 3827/10000 [00:08<00:10, 606.87it/s] 39%|███▉      | 3900/10000 [00:08<00:09, 636.73it/s] 40%|███▉      | 3965/10000 [00:08<00:10, 571.78it/s] 40%|████      | 4034/10000 [00:08<00:09, 601.43it/s] 41%|████      | 4104/10000 [00:08<00:09, 624.01it/s] 42%|████▏     | 4183/10000 [00:08<00:08, 661.89it/s] 43%|████▎     | 4274/10000 [00:09<00:07, 723.30it/s] 44%|████▍     | 4379/10000 [00:09<00:06, 814.74it/s] 45%|████▍     | 4462/10000 [00:09<00:08, 616.45it/s] 45%|████▌     | 4532/10000 [00:09<00:08, 608.04it/s] 46%|████▌     | 4599/10000 [00:09<00:11, 478.61it/s] 47%|████▋     | 4655/10000 [00:09<00:11, 455.72it/s] 47%|████▋     | 4706/10000 [00:09<00:12, 427.04it/s] 48%|████▊     | 4753/10000 [00:10<00:12, 428.18it/s] 48%|████▊     | 4799/10000 [00:10<00:12, 421.59it/s] 48%|████▊     | 4843/10000 [00:10<00:12, 424.25it/s] 49%|████▉     | 4887/10000 [00:10<00:12, 415.43it/s] 49%|████▉     | 4930/10000 [00:10<00:14, 342.68it/s] 50%|████▉     | 4972/10000 [00:10<00:14, 358.44it/s] 50%|█████     | 5010/10000 [00:10<00:13, 359.59it/s] 51%|█████     | 5057/10000 [00:10<00:12, 383.82it/s] 51%|█████▏    | 5130/10000 [00:11<00:10, 470.91it/s] 52%|█████▏    | 5200/10000 [00:11<00:09, 532.26it/s] 53%|█████▎    | 5255/10000 [00:11<00:10, 450.20it/s] 53%|█████▎    | 5304/10000 [00:11<00:12, 366.79it/s] 53%|█████▎    | 5346/10000 [00:11<00:13, 342.44it/s] 54%|█████▍    | 5384/10000 [00:11<00:14, 329.33it/s] 54%|█████▍    | 5446/10000 [00:11<00:11, 390.14it/s] 55%|█████▌    | 5501/10000 [00:11<00:10, 426.08it/s] 56%|█████▌    | 5553/10000 [00:12<00:10, 444.22it/s] 56%|█████▋    | 5637/10000 [00:12<00:07, 548.89it/s] 57%|█████▋    | 5718/10000 [00:12<00:07, 607.61it/s] 58%|█████▊    | 5805/10000 [00:12<00:06, 667.25it/s] 59%|█████▊    | 5874/10000 [00:12<00:07, 548.27it/s] 59%|█████▉    | 5934/10000 [00:12<00:08, 452.74it/s] 60%|█████▉    | 5985/10000 [00:12<00:09, 442.99it/s] 60%|██████    | 6043/10000 [00:12<00:08, 471.90it/s] 61%|██████    | 6117/10000 [00:13<00:07, 537.04it/s] 62%|██████▏   | 6182/10000 [00:13<00:06, 565.01it/s] 62%|██████▏   | 6242/10000 [00:13<00:06, 538.07it/s] 63%|██████▎   | 6299/10000 [00:13<00:07, 480.50it/s] 64%|██████▎   | 6350/10000 [00:13<00:08, 444.81it/s] 64%|██████▍   | 6397/10000 [00:13<00:10, 353.88it/s] 65%|██████▍   | 6461/10000 [00:13<00:08, 407.97it/s] 65%|██████▌   | 6509/10000 [00:14<00:08, 407.49it/s] 66%|██████▌   | 6560/10000 [00:14<00:07, 431.64it/s] 66%|██████▌   | 6606/10000 [00:14<00:08, 392.70it/s] 67%|██████▋   | 6663/10000 [00:14<00:07, 424.39it/s] 67%|██████▋   | 6713/10000 [00:14<00:07, 439.99it/s] 68%|██████▊   | 6759/10000 [00:14<00:07, 439.36it/s] 68%|██████▊   | 6837/10000 [00:14<00:06, 518.49it/s] 69%|██████▉   | 6924/10000 [00:14<00:05, 615.11it/s] 70%|███████   | 7012/10000 [00:14<00:04, 687.56it/s] 71%|███████   | 7089/10000 [00:15<00:04, 691.17it/s] 72%|███████▏  | 7160/10000 [00:15<00:04, 638.91it/s] 72%|███████▏  | 7226/10000 [00:15<00:04, 611.68it/s] 73%|███████▎  | 7293/10000 [00:15<00:04, 615.61it/s] 74%|███████▍  | 7403/10000 [00:15<00:03, 746.65it/s] 75%|███████▍  | 7480/10000 [00:15<00:03, 659.83it/s] 76%|███████▌  | 7555/10000 [00:15<00:03, 676.28it/s] 76%|███████▋  | 7625/10000 [00:15<00:03, 602.45it/s] 77%|███████▋  | 7688/10000 [00:16<00:04, 558.12it/s] 77%|███████▋  | 7746/10000 [00:16<00:04, 524.48it/s] 78%|███████▊  | 7800/10000 [00:16<00:04, 525.00it/s] 79%|███████▉  | 7878/10000 [00:16<00:03, 591.05it/s] 80%|███████▉  | 7960/10000 [00:16<00:03, 653.10it/s] 80%|████████  | 8028/10000 [00:16<00:03, 649.23it/s] 81%|████████  | 8095/10000 [00:16<00:02, 641.80it/s] 82%|████████▏ | 8188/10000 [00:16<00:02, 722.71it/s] 83%|████████▎ | 8262/10000 [00:16<00:02, 622.21it/s] 83%|████████▎ | 8328/10000 [00:17<00:03, 523.11it/s] 84%|████████▍ | 8385/10000 [00:17<00:03, 500.05it/s] 84%|████████▍ | 8438/10000 [00:17<00:03, 493.41it/s] 85%|████████▍ | 8493/10000 [00:17<00:02, 507.10it/s] 86%|████████▌ | 8566/10000 [00:17<00:02, 549.36it/s] 87%|████████▋ | 8654/10000 [00:17<00:02, 637.63it/s] 87%|████████▋ | 8738/10000 [00:17<00:01, 691.27it/s] 88%|████████▊ | 8819/10000 [00:17<00:01, 717.62it/s] 89%|████████▉ | 8922/10000 [00:17<00:01, 802.26it/s] 90%|█████████ | 9004/10000 [00:18<00:01, 772.21it/s] 91%|█████████ | 9083/10000 [00:18<00:01, 757.56it/s] 92%|█████████▏| 9160/10000 [00:18<00:01, 731.99it/s] 92%|█████████▏| 9234/10000 [00:18<00:01, 607.87it/s] 93%|█████████▎| 9299/10000 [00:18<00:01, 488.12it/s] 94%|█████████▎| 9354/10000 [00:18<00:01, 458.89it/s] 94%|█████████▍| 9404/10000 [00:19<00:01, 410.91it/s] 94%|█████████▍| 9449/10000 [00:19<00:01, 415.75it/s] 95%|█████████▌| 9509/10000 [00:19<00:01, 459.14it/s] 96%|█████████▌| 9558/10000 [00:19<00:00, 446.53it/s] 96%|█████████▌| 9605/10000 [00:19<00:00, 423.13it/s] 96%|█████████▋| 9649/10000 [00:19<00:00, 421.89it/s] 97%|█████████▋| 9694/10000 [00:19<00:00, 429.22it/s] 97%|█████████▋| 9738/10000 [00:19<00:00, 429.12it/s] 98%|█████████▊| 9788/10000 [00:19<00:00, 447.54it/s] 99%|█████████▊| 9873/10000 [00:19<00:00, 552.85it/s] 99%|█████████▉| 9941/10000 [00:20<00:00, 576.37it/s]100%|██████████| 10000/10000 [00:20<00:00, 496.95it/s]
test_neglected_p50 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p50
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p50.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:35,  1.11it/s]evaluating model with Holmes:   8%|▊         | 3/40 [00:01<00:10,  3.58it/s]evaluating model with Holmes:  20%|██        | 8/40 [00:01<00:02, 10.78it/s]evaluating model with Holmes:  32%|███▎      | 13/40 [00:01<00:01, 17.58it/s]evaluating model with Holmes:  45%|████▌     | 18/40 [00:01<00:00, 23.82it/s]evaluating model with Holmes:  57%|█████▊    | 23/40 [00:01<00:00, 29.45it/s]evaluating model with Holmes:  70%|███████   | 28/40 [00:01<00:00, 33.81it/s]evaluating model with Holmes:  82%|████████▎ | 33/40 [00:01<00:00, 37.49it/s]evaluating model with Holmes:  95%|█████████▌| 38/40 [00:01<00:00, 40.30it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.56it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p50_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p50_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p50_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p50_Holmes_probs.npy
{'Accuracy': 0.0196, 'Precision': 0.0237, 'Recall': 0.0194, 'F1-score': 0.017}
starting gen taf script for test_neglected_p51
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 82/10000 [00:00<00:12, 777.81it/s]  2%|▏         | 160/10000 [00:00<00:20, 479.31it/s]  2%|▏         | 215/10000 [00:00<00:24, 393.20it/s]  3%|▎         | 259/10000 [00:00<00:29, 333.16it/s]  3%|▎         | 295/10000 [00:00<00:28, 336.66it/s]  3%|▎         | 332/10000 [00:00<00:28, 338.53it/s]  4%|▎         | 368/10000 [00:01<00:30, 311.60it/s]  4%|▍         | 408/10000 [00:01<00:28, 333.63it/s]  5%|▍         | 454/10000 [00:01<00:26, 365.30it/s]  5%|▌         | 501/10000 [00:01<00:24, 390.35it/s]  5%|▌         | 549/10000 [00:01<00:23, 403.20it/s]  6%|▌         | 604/10000 [00:01<00:21, 441.48it/s]  7%|▋         | 659/10000 [00:01<00:19, 468.07it/s]  7%|▋         | 707/10000 [00:01<00:20, 463.49it/s]  8%|▊         | 754/10000 [00:01<00:20, 446.34it/s]  8%|▊         | 800/10000 [00:01<00:20, 438.73it/s]  8%|▊         | 845/10000 [00:02<00:22, 403.75it/s]  9%|▉         | 901/10000 [00:02<00:20, 443.05it/s]  9%|▉         | 947/10000 [00:02<00:20, 436.94it/s] 10%|▉         | 992/10000 [00:02<00:20, 437.40it/s] 11%|█         | 1055/10000 [00:02<00:19, 466.24it/s] 11%|█         | 1106/10000 [00:02<00:18, 478.23it/s] 12%|█▏        | 1154/10000 [00:02<00:19, 451.64it/s] 12%|█▏        | 1200/10000 [00:02<00:19, 443.80it/s] 13%|█▎        | 1289/10000 [00:02<00:15, 562.56it/s] 14%|█▍        | 1393/10000 [00:03<00:12, 682.56it/s] 15%|█▍        | 1462/10000 [00:03<00:19, 447.53it/s] 15%|█▌        | 1518/10000 [00:03<00:22, 376.43it/s] 16%|█▌        | 1565/10000 [00:03<00:26, 323.64it/s] 16%|█▌        | 1605/10000 [00:03<00:24, 336.76it/s] 17%|█▋        | 1695/10000 [00:04<00:18, 451.12it/s] 18%|█▊        | 1761/10000 [00:04<00:16, 487.17it/s] 18%|█▊        | 1843/10000 [00:04<00:14, 561.98it/s] 20%|█▉        | 1975/10000 [00:04<00:10, 752.90it/s] 21%|██        | 2058/10000 [00:04<00:10, 752.59it/s] 21%|██▏       | 2139/10000 [00:04<00:12, 616.78it/s] 22%|██▏       | 2209/10000 [00:04<00:14, 551.86it/s] 23%|██▎       | 2271/10000 [00:04<00:14, 543.72it/s] 23%|██▎       | 2330/10000 [00:05<00:16, 454.06it/s] 24%|██▍       | 2381/10000 [00:05<00:17, 428.48it/s] 25%|██▍       | 2456/10000 [00:05<00:15, 498.65it/s] 25%|██▌       | 2525/10000 [00:05<00:13, 535.13it/s] 26%|██▌       | 2596/10000 [00:05<00:13, 568.11it/s] 27%|██▋       | 2656/10000 [00:05<00:17, 422.38it/s] 27%|██▋       | 2706/10000 [00:05<00:19, 364.94it/s] 27%|██▋       | 2749/10000 [00:06<00:22, 327.30it/s] 28%|██▊       | 2786/10000 [00:06<00:22, 318.98it/s] 28%|██▊       | 2821/10000 [00:06<00:22, 320.87it/s] 29%|██▉       | 2883/10000 [00:06<00:18, 385.24it/s] 29%|██▉       | 2945/10000 [00:06<00:16, 438.03it/s] 30%|███       | 3011/10000 [00:06<00:14, 489.52it/s] 31%|███       | 3063/10000 [00:06<00:14, 489.61it/s] 31%|███       | 3114/10000 [00:06<00:16, 425.80it/s] 32%|███▏      | 3176/10000 [00:07<00:14, 467.78it/s] 32%|███▏      | 3237/10000 [00:07<00:13, 502.90it/s] 33%|███▎      | 3310/10000 [00:07<00:11, 561.92it/s] 34%|███▍      | 3406/10000 [00:07<00:09, 668.50it/s] 35%|███▍      | 3475/10000 [00:07<00:10, 615.13it/s] 36%|███▌      | 3552/10000 [00:07<00:09, 650.51it/s] 36%|███▋      | 3631/10000 [00:07<00:09, 688.03it/s] 37%|███▋      | 3728/10000 [00:07<00:08, 765.78it/s] 38%|███▊      | 3807/10000 [00:07<00:08, 701.07it/s] 39%|███▉      | 3880/10000 [00:08<00:09, 679.99it/s] 40%|███▉      | 3950/10000 [00:08<00:09, 606.13it/s] 40%|████      | 4025/10000 [00:08<00:09, 642.49it/s] 41%|████      | 4092/10000 [00:08<00:09, 642.41it/s] 42%|████▏     | 4158/10000 [00:08<00:09, 643.53it/s] 42%|████▏     | 4248/10000 [00:08<00:08, 704.71it/s] 43%|████▎     | 4320/10000 [00:08<00:08, 689.66it/s] 44%|████▍     | 4390/10000 [00:08<00:08, 628.72it/s] 45%|████▍     | 4455/10000 [00:09<00:10, 525.31it/s] 45%|████▌     | 4511/10000 [00:09<00:10, 516.14it/s] 46%|████▌     | 4565/10000 [00:09<00:11, 484.18it/s] 46%|████▌     | 4616/10000 [00:09<00:13, 401.71it/s] 47%|████▋     | 4664/10000 [00:09<00:13, 400.48it/s] 47%|████▋     | 4710/10000 [00:09<00:13, 403.76it/s] 48%|████▊     | 4780/10000 [00:09<00:10, 476.63it/s] 48%|████▊     | 4831/10000 [00:10<00:13, 384.19it/s] 49%|████▉     | 4880/10000 [00:10<00:12, 407.24it/s] 49%|████▉     | 4925/10000 [00:10<00:14, 361.62it/s] 50%|████▉     | 4965/10000 [00:10<00:14, 341.06it/s] 50%|█████     | 5002/10000 [00:10<00:15, 322.68it/s] 51%|█████     | 5055/10000 [00:10<00:13, 371.62it/s] 51%|█████▏    | 5126/10000 [00:10<00:10, 454.55it/s] 52%|█████▏    | 5176/10000 [00:10<00:10, 466.35it/s] 52%|█████▏    | 5225/10000 [00:11<00:12, 392.11it/s] 53%|█████▎    | 5268/10000 [00:11<00:13, 341.78it/s] 53%|█████▎    | 5312/10000 [00:11<00:13, 354.73it/s] 54%|█████▎    | 5350/10000 [00:11<00:13, 338.79it/s] 54%|█████▍    | 5386/10000 [00:11<00:14, 312.53it/s] 54%|█████▍    | 5439/10000 [00:11<00:12, 364.87it/s] 55%|█████▍    | 5491/10000 [00:11<00:11, 399.93it/s] 55%|█████▌    | 5545/10000 [00:11<00:10, 433.61it/s] 56%|█████▌    | 5623/10000 [00:12<00:08, 518.68it/s] 57%|█████▋    | 5742/10000 [00:12<00:06, 704.45it/s] 58%|█████▊    | 5816/10000 [00:12<00:06, 613.44it/s] 59%|█████▉    | 5882/10000 [00:12<00:07, 571.99it/s] 59%|█████▉    | 5943/10000 [00:12<00:08, 462.55it/s] 60%|█████▉    | 5995/10000 [00:12<00:09, 402.66it/s] 61%|██████    | 6076/10000 [00:12<00:08, 489.08it/s] 62%|██████▏   | 6155/10000 [00:12<00:06, 559.06it/s] 62%|██████▏   | 6224/10000 [00:13<00:06, 589.54it/s] 63%|██████▎   | 6289/10000 [00:13<00:07, 501.40it/s] 63%|██████▎   | 6345/10000 [00:13<00:08, 433.96it/s] 64%|██████▍   | 6394/10000 [00:13<00:08, 411.87it/s] 64%|██████▍   | 6440/10000 [00:13<00:08, 421.64it/s] 65%|██████▍   | 6485/10000 [00:13<00:08, 394.97it/s] 65%|██████▌   | 6529/10000 [00:13<00:08, 397.13it/s] 66%|██████▌   | 6593/10000 [00:14<00:07, 452.14it/s] 66%|██████▋   | 6641/10000 [00:14<00:07, 459.19it/s] 67%|██████▋   | 6689/10000 [00:14<00:07, 436.55it/s] 68%|██████▊   | 6752/10000 [00:14<00:06, 475.25it/s] 68%|██████▊   | 6833/10000 [00:14<00:05, 564.36it/s] 69%|██████▉   | 6903/10000 [00:14<00:05, 602.10it/s] 70%|██████▉   | 6965/10000 [00:14<00:05, 568.29it/s] 70%|███████   | 7037/10000 [00:14<00:04, 608.06it/s] 71%|███████   | 7099/10000 [00:14<00:04, 597.83it/s] 72%|███████▏  | 7165/10000 [00:15<00:04, 610.52it/s] 72%|███████▏  | 7241/10000 [00:15<00:04, 642.31it/s] 73%|███████▎  | 7320/10000 [00:15<00:03, 676.59it/s] 74%|███████▍  | 7389/10000 [00:15<00:03, 680.37it/s] 75%|███████▍  | 7458/10000 [00:15<00:04, 619.09it/s] 75%|███████▌  | 7523/10000 [00:15<00:04, 598.31it/s] 76%|███████▌  | 7600/10000 [00:15<00:03, 644.67it/s] 77%|███████▋  | 7666/10000 [00:15<00:04, 555.56it/s] 77%|███████▋  | 7725/10000 [00:15<00:04, 539.75it/s] 78%|███████▊  | 7781/10000 [00:16<00:04, 473.95it/s] 79%|███████▊  | 7874/10000 [00:16<00:03, 571.13it/s] 80%|███████▉  | 7958/10000 [00:16<00:03, 631.92it/s] 80%|████████  | 8025/10000 [00:16<00:03, 631.41it/s] 81%|████████  | 8102/10000 [00:16<00:02, 661.96it/s] 82%|████████▏ | 8182/10000 [00:16<00:02, 700.05it/s] 83%|████████▎ | 8254/10000 [00:16<00:02, 613.64it/s] 83%|████████▎ | 8319/10000 [00:16<00:03, 525.93it/s] 84%|████████▍ | 8376/10000 [00:17<00:03, 490.78it/s] 84%|████████▍ | 8436/10000 [00:17<00:03, 509.11it/s] 85%|████████▍ | 8496/10000 [00:17<00:02, 526.91it/s] 86%|████████▌ | 8551/10000 [00:17<00:02, 530.31it/s] 86%|████████▌ | 8611/10000 [00:17<00:02, 544.23it/s] 87%|████████▋ | 8700/10000 [00:17<00:02, 633.13it/s] 88%|████████▊ | 8791/10000 [00:17<00:01, 701.66it/s] 89%|████████▊ | 8869/10000 [00:17<00:01, 720.48it/s] 90%|████████▉ | 8975/10000 [00:17<00:01, 807.41it/s] 91%|█████████ | 9064/10000 [00:18<00:01, 828.46it/s] 91%|█████████▏| 9148/10000 [00:18<00:01, 793.35it/s] 92%|█████████▏| 9228/10000 [00:18<00:01, 711.62it/s] 93%|█████████▎| 9301/10000 [00:18<00:01, 582.31it/s] 94%|█████████▎| 9364/10000 [00:18<00:01, 495.39it/s] 94%|█████████▍| 9422/10000 [00:18<00:01, 509.95it/s] 95%|█████████▍| 9477/10000 [00:18<00:01, 464.00it/s] 95%|█████████▌| 9528/10000 [00:19<00:01, 465.71it/s] 96%|█████████▌| 9585/10000 [00:19<00:00, 485.88it/s] 96%|█████████▋| 9640/10000 [00:19<00:00, 496.57it/s] 97%|█████████▋| 9692/10000 [00:19<00:00, 459.54it/s] 98%|█████████▊| 9762/10000 [00:19<00:00, 505.84it/s] 98%|█████████▊| 9835/10000 [00:19<00:00, 559.90it/s] 99%|█████████▉| 9899/10000 [00:19<00:00, 576.98it/s]100%|██████████| 10000/10000 [00:19<00:00, 505.17it/s]
test_neglected_p51 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p51
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p51.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.06s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.71it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.72it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.90it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.73it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.42it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.77it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.09it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.68it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p51_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p51_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p51_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p51_Holmes_probs.npy
{'Accuracy': 0.02, 'Precision': 0.0228, 'Recall': 0.0198, 'F1-score': 0.0176}
starting gen taf script for test_neglected_p52
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 69/10000 [00:00<00:15, 640.99it/s]  1%|▏         | 134/10000 [00:00<00:20, 485.77it/s]  2%|▏         | 185/10000 [00:00<00:24, 403.72it/s]  2%|▏         | 228/10000 [00:00<00:26, 367.88it/s]  3%|▎         | 266/10000 [00:00<00:34, 285.91it/s]  3%|▎         | 297/10000 [00:00<00:37, 255.85it/s]  3%|▎         | 330/10000 [00:01<00:35, 269.63it/s]  4%|▎         | 359/10000 [00:01<00:38, 250.14it/s]  4%|▍         | 385/10000 [00:01<00:38, 251.87it/s]  4%|▍         | 419/10000 [00:01<00:35, 272.12it/s]  5%|▍         | 472/10000 [00:01<00:28, 336.12it/s]  5%|▌         | 514/10000 [00:01<00:26, 358.30it/s]  6%|▌         | 551/10000 [00:01<00:26, 358.97it/s]  6%|▌         | 589/10000 [00:01<00:26, 356.17it/s]  6%|▋         | 626/10000 [00:01<00:31, 293.37it/s]  7%|▋         | 658/10000 [00:02<00:31, 292.01it/s]  7%|▋         | 698/10000 [00:02<00:29, 319.24it/s]  7%|▋         | 737/10000 [00:02<00:27, 338.11it/s]  8%|▊         | 781/10000 [00:02<00:25, 357.95it/s]  8%|▊         | 818/10000 [00:02<00:26, 347.05it/s]  9%|▊         | 864/10000 [00:02<00:24, 372.61it/s]  9%|▉         | 906/10000 [00:02<00:23, 384.20it/s] 10%|▉         | 963/10000 [00:02<00:21, 415.34it/s] 10%|█         | 1011/10000 [00:02<00:20, 430.89it/s] 11%|█         | 1055/10000 [00:03<00:22, 395.57it/s] 11%|█         | 1096/10000 [00:03<00:26, 339.40it/s] 12%|█▏        | 1157/10000 [00:03<00:21, 405.89it/s] 12%|█▏        | 1208/10000 [00:03<00:20, 428.55it/s] 13%|█▎        | 1298/10000 [00:03<00:15, 550.40it/s] 14%|█▎        | 1373/10000 [00:03<00:14, 604.75it/s] 14%|█▍        | 1436/10000 [00:03<00:18, 457.84it/s] 15%|█▍        | 1489/10000 [00:04<00:21, 396.61it/s] 15%|█▌        | 1535/10000 [00:04<00:24, 344.16it/s] 16%|█▌        | 1575/10000 [00:04<00:27, 309.95it/s] 16%|█▌        | 1610/10000 [00:04<00:26, 313.65it/s] 17%|█▋        | 1679/10000 [00:04<00:21, 395.03it/s] 18%|█▊        | 1750/10000 [00:04<00:17, 470.81it/s] 18%|█▊        | 1813/10000 [00:04<00:16, 509.04it/s] 19%|█▉        | 1920/10000 [00:04<00:12, 650.12it/s] 20%|██        | 2012/10000 [00:05<00:11, 699.75it/s] 21%|██        | 2092/10000 [00:05<00:11, 710.23it/s] 22%|██▏       | 2166/10000 [00:05<00:12, 620.78it/s] 22%|██▏       | 2232/10000 [00:05<00:13, 559.24it/s] 23%|██▎       | 2291/10000 [00:05<00:15, 513.76it/s] 23%|██▎       | 2345/10000 [00:05<00:17, 425.82it/s] 24%|██▍       | 2391/10000 [00:05<00:17, 433.15it/s] 24%|██▍       | 2448/10000 [00:05<00:16, 461.38it/s] 25%|██▌       | 2506/10000 [00:06<00:15, 489.31it/s] 26%|██▌       | 2570/10000 [00:06<00:14, 520.44it/s] 26%|██▌       | 2624/10000 [00:06<00:16, 452.48it/s] 27%|██▋       | 2672/10000 [00:06<00:20, 357.56it/s] 27%|██▋       | 2719/10000 [00:06<00:19, 374.21it/s] 28%|██▊       | 2761/10000 [00:06<00:22, 325.87it/s] 28%|██▊       | 2797/10000 [00:07<00:23, 306.32it/s] 29%|██▊       | 2853/10000 [00:07<00:19, 362.83it/s] 29%|██▉       | 2912/10000 [00:07<00:17, 416.66it/s] 30%|██▉       | 2959/10000 [00:07<00:16, 425.61it/s] 30%|███       | 3007/10000 [00:07<00:16, 436.49it/s] 31%|███       | 3065/10000 [00:07<00:14, 467.85it/s] 31%|███       | 3114/10000 [00:07<00:17, 387.64it/s] 32%|███▏      | 3156/10000 [00:07<00:17, 395.37it/s] 32%|███▏      | 3237/10000 [00:07<00:13, 501.52it/s] 33%|███▎      | 3316/10000 [00:08<00:11, 570.61it/s] 34%|███▍      | 3412/10000 [00:08<00:09, 667.94it/s] 35%|███▍      | 3482/10000 [00:08<00:10, 615.55it/s] 36%|███▌      | 3555/10000 [00:08<00:10, 631.65it/s] 36%|███▌      | 3623/10000 [00:08<00:10, 637.26it/s] 37%|███▋      | 3714/10000 [00:08<00:09, 688.02it/s] 38%|███▊      | 3784/10000 [00:08<00:09, 667.51it/s] 39%|███▊      | 3852/10000 [00:08<00:09, 654.60it/s] 39%|███▉      | 3918/10000 [00:08<00:10, 601.37it/s] 40%|███▉      | 3980/10000 [00:09<00:10, 582.98it/s] 41%|████      | 4066/10000 [00:09<00:09, 657.18it/s] 41%|████▏     | 4145/10000 [00:09<00:08, 680.52it/s] 42%|████▏     | 4228/10000 [00:09<00:08, 718.44it/s] 43%|████▎     | 4301/10000 [00:09<00:08, 667.30it/s] 44%|████▍     | 4376/10000 [00:09<00:08, 674.58it/s] 44%|████▍     | 4445/10000 [00:09<00:08, 664.46it/s] 45%|████▌     | 4513/10000 [00:09<00:10, 529.95it/s] 46%|████▌     | 4571/10000 [00:10<00:10, 510.86it/s] 46%|████▋     | 4626/10000 [00:10<00:10, 492.19it/s] 47%|████▋     | 4678/10000 [00:10<00:12, 431.77it/s] 47%|████▋     | 4724/10000 [00:10<00:12, 438.28it/s] 48%|████▊     | 4770/10000 [00:10<00:12, 408.45it/s] 48%|████▊     | 4825/10000 [00:10<00:11, 437.52it/s] 49%|████▊     | 4871/10000 [00:10<00:13, 368.04it/s] 49%|████▉     | 4912/10000 [00:10<00:13, 369.92it/s] 50%|████▉     | 4951/10000 [00:11<00:14, 337.33it/s] 50%|████▉     | 4990/10000 [00:11<00:14, 349.92it/s] 50%|█████     | 5027/10000 [00:11<00:14, 348.85it/s] 51%|█████     | 5104/10000 [00:11<00:10, 454.55it/s] 52%|█████▏    | 5171/10000 [00:11<00:09, 512.55it/s] 52%|█████▏    | 5225/10000 [00:11<00:10, 459.97it/s] 53%|█████▎    | 5274/10000 [00:11<00:12, 391.22it/s] 53%|█████▎    | 5317/10000 [00:12<00:14, 319.91it/s] 54%|█████▎    | 5363/10000 [00:12<00:13, 349.65it/s] 54%|█████▍    | 5408/10000 [00:12<00:12, 362.96it/s] 55%|█████▍    | 5467/10000 [00:12<00:10, 413.92it/s] 55%|█████▌    | 5534/10000 [00:12<00:09, 468.90it/s] 56%|█████▌    | 5584/10000 [00:12<00:09, 463.50it/s] 57%|█████▋    | 5655/10000 [00:12<00:08, 523.19it/s] 57%|█████▋    | 5728/10000 [00:12<00:07, 566.52it/s] 58%|█████▊    | 5800/10000 [00:12<00:07, 591.66it/s] 59%|█████▊    | 5861/10000 [00:12<00:07, 561.11it/s] 59%|█████▉    | 5918/10000 [00:13<00:08, 493.64it/s] 60%|█████▉    | 5970/10000 [00:13<00:08, 466.06it/s] 60%|██████    | 6018/10000 [00:13<00:09, 435.15it/s] 61%|██████    | 6075/10000 [00:13<00:08, 468.31it/s] 61%|██████▏   | 6141/10000 [00:13<00:07, 511.17it/s] 62%|██████▏   | 6207/10000 [00:13<00:07, 529.81it/s] 63%|██████▎   | 6261/10000 [00:13<00:07, 513.13it/s] 63%|██████▎   | 6313/10000 [00:13<00:08, 452.83it/s] 64%|██████▎   | 6360/10000 [00:14<00:08, 431.36it/s] 64%|██████▍   | 6405/10000 [00:14<00:09, 375.56it/s] 64%|██████▍   | 6445/10000 [00:14<00:09, 376.75it/s] 65%|██████▍   | 6485/10000 [00:14<00:09, 379.82it/s] 65%|██████▌   | 6524/10000 [00:14<00:09, 368.25it/s] 66%|██████▌   | 6581/10000 [00:14<00:08, 409.52it/s] 66%|██████▋   | 6626/10000 [00:14<00:08, 411.27it/s] 67%|██████▋   | 6675/10000 [00:14<00:07, 430.76it/s] 67%|██████▋   | 6726/10000 [00:15<00:07, 427.27it/s] 68%|██████▊   | 6778/10000 [00:15<00:07, 451.50it/s] 68%|██████▊   | 6850/10000 [00:15<00:06, 513.72it/s] 69%|██████▉   | 6928/10000 [00:15<00:05, 585.44it/s] 70%|██████▉   | 6988/10000 [00:15<00:05, 578.21it/s] 70%|███████   | 7047/10000 [00:15<00:05, 548.89it/s] 71%|███████   | 7114/10000 [00:15<00:05, 568.57it/s] 72%|███████▏  | 7175/10000 [00:15<00:04, 578.99it/s] 73%|███████▎  | 7263/10000 [00:15<00:04, 664.32it/s] 73%|███████▎  | 7335/10000 [00:16<00:03, 670.71it/s] 74%|███████▍  | 7420/10000 [00:16<00:03, 722.41it/s] 75%|███████▍  | 7495/10000 [00:16<00:03, 717.47it/s] 76%|███████▌  | 7568/10000 [00:16<00:03, 651.38it/s] 76%|███████▋  | 7635/10000 [00:16<00:03, 599.29it/s] 77%|███████▋  | 7697/10000 [00:16<00:04, 520.71it/s] 78%|███████▊  | 7752/10000 [00:16<00:04, 462.14it/s] 78%|███████▊  | 7801/10000 [00:16<00:04, 464.05it/s] 79%|███████▊  | 7872/10000 [00:17<00:04, 522.93it/s] 80%|███████▉  | 7953/10000 [00:17<00:03, 597.81it/s] 80%|████████  | 8031/10000 [00:17<00:03, 635.68it/s] 81%|████████  | 8106/10000 [00:17<00:02, 663.42it/s] 82%|████████▏ | 8175/10000 [00:17<00:02, 632.76it/s] 82%|████████▏ | 8240/10000 [00:17<00:03, 532.03it/s] 83%|████████▎ | 8297/10000 [00:17<00:03, 499.08it/s] 84%|████████▎ | 8350/10000 [00:17<00:03, 462.52it/s] 84%|████████▍ | 8399/10000 [00:18<00:03, 447.41it/s] 84%|████████▍ | 8448/10000 [00:18<00:03, 452.98it/s] 85%|████████▌ | 8506/10000 [00:18<00:03, 485.11it/s] 86%|████████▌ | 8575/10000 [00:18<00:02, 529.51it/s] 86%|████████▋ | 8644/10000 [00:18<00:02, 565.78it/s] 87%|████████▋ | 8741/10000 [00:18<00:01, 678.38it/s] 88%|████████▊ | 8816/10000 [00:18<00:01, 695.35it/s] 89%|████████▉ | 8913/10000 [00:18<00:01, 758.51it/s] 90%|█████████ | 9006/10000 [00:18<00:01, 806.13it/s] 91%|█████████ | 9088/10000 [00:18<00:01, 754.17it/s] 92%|█████████▏| 9184/10000 [00:19<00:01, 799.36it/s] 93%|█████████▎| 9265/10000 [00:19<00:01, 659.92it/s] 93%|█████████▎| 9336/10000 [00:19<00:01, 512.79it/s] 94%|█████████▍| 9395/10000 [00:19<00:01, 468.69it/s] 94%|█████████▍| 9448/10000 [00:19<00:01, 446.98it/s] 95%|█████████▍| 9497/10000 [00:19<00:01, 417.68it/s] 96%|█████████▌| 9563/10000 [00:20<00:00, 457.37it/s] 96%|█████████▌| 9612/10000 [00:20<00:00, 448.34it/s] 97%|█████████▋| 9659/10000 [00:20<00:00, 439.40it/s] 97%|█████████▋| 9713/10000 [00:20<00:00, 459.27it/s] 98%|█████████▊| 9770/10000 [00:20<00:00, 484.89it/s] 99%|█████████▊| 9860/10000 [00:20<00:00, 588.13it/s] 99%|█████████▉| 9921/10000 [00:20<00:00, 583.81it/s]100%|██████████| 10000/10000 [00:20<00:00, 482.50it/s]
test_neglected_p52 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p52
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p52.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.01s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.86it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.97it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.13it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.06it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.10it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.51it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.09it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.28it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p52_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p52_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p52_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p52_Holmes_probs.npy
{'Accuracy': 0.0197, 'Precision': 0.0218, 'Recall': 0.0195, 'F1-score': 0.0171}
starting gen taf script for test_neglected_p53
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 57/10000 [00:00<00:17, 562.88it/s]  1%|          | 114/10000 [00:00<00:27, 357.89it/s]  2%|▏         | 154/10000 [00:00<00:32, 305.64it/s]  2%|▏         | 187/10000 [00:00<00:33, 291.24it/s]  2%|▏         | 220/10000 [00:00<00:32, 298.87it/s]  3%|▎         | 251/10000 [00:00<00:32, 299.10it/s]  3%|▎         | 282/10000 [00:00<00:32, 301.10it/s]  3%|▎         | 313/10000 [00:01<00:32, 301.67it/s]  3%|▎         | 344/10000 [00:01<00:34, 283.50it/s]  4%|▍         | 379/10000 [00:01<00:32, 295.16it/s]  4%|▍         | 415/10000 [00:01<00:30, 310.98it/s]  4%|▍         | 447/10000 [00:01<00:30, 311.29it/s]  5%|▍         | 493/10000 [00:01<00:27, 345.76it/s]  5%|▌         | 530/10000 [00:01<00:27, 350.06it/s]  6%|▌         | 576/10000 [00:01<00:24, 381.65it/s]  6%|▌         | 615/10000 [00:01<00:24, 380.10it/s]  7%|▋         | 689/10000 [00:01<00:19, 484.96it/s]  8%|▊         | 753/10000 [00:02<00:17, 526.28it/s]  8%|▊         | 815/10000 [00:02<00:16, 553.60it/s]  9%|▉         | 879/10000 [00:02<00:15, 575.00it/s]  9%|▉         | 942/10000 [00:02<00:15, 571.25it/s] 10%|█         | 1006/10000 [00:02<00:15, 585.85it/s] 11%|█         | 1065/10000 [00:02<00:18, 476.45it/s] 11%|█         | 1116/10000 [00:02<00:19, 446.60it/s] 12%|█▏        | 1164/10000 [00:02<00:20, 439.50it/s] 12%|█▏        | 1218/10000 [00:03<00:18, 462.98it/s] 13%|█▎        | 1307/10000 [00:03<00:15, 572.11it/s] 14%|█▎        | 1367/10000 [00:03<00:15, 575.43it/s] 14%|█▍        | 1427/10000 [00:03<00:15, 543.47it/s] 15%|█▍        | 1483/10000 [00:03<00:20, 420.16it/s] 15%|█▌        | 1530/10000 [00:03<00:24, 347.22it/s] 16%|█▌        | 1570/10000 [00:03<00:26, 315.10it/s] 16%|█▌        | 1606/10000 [00:04<00:27, 304.84it/s] 17%|█▋        | 1664/10000 [00:04<00:22, 363.82it/s] 18%|█▊        | 1764/10000 [00:04<00:16, 514.00it/s] 18%|█▊        | 1829/10000 [00:04<00:14, 545.60it/s] 19%|█▉        | 1907/10000 [00:04<00:13, 601.06it/s] 20%|██        | 2002/10000 [00:04<00:11, 680.40it/s] 21%|██        | 2074/10000 [00:04<00:12, 630.57it/s] 21%|██▏       | 2140/10000 [00:04<00:12, 615.93it/s] 22%|██▏       | 2209/10000 [00:04<00:12, 631.78it/s] 23%|██▎       | 2274/10000 [00:05<00:16, 482.20it/s] 23%|██▎       | 2329/10000 [00:05<00:17, 432.47it/s] 24%|██▍       | 2377/10000 [00:05<00:18, 410.09it/s] 24%|██▍       | 2423/10000 [00:05<00:18, 418.46it/s] 25%|██▍       | 2492/10000 [00:05<00:15, 474.67it/s] 26%|██▌       | 2582/10000 [00:05<00:12, 578.93it/s] 26%|██▋       | 2644/10000 [00:05<00:17, 429.26it/s] 27%|██▋       | 2695/10000 [00:06<00:21, 343.62it/s] 27%|██▋       | 2737/10000 [00:06<00:22, 329.00it/s] 28%|██▊       | 2775/10000 [00:06<00:26, 275.48it/s] 28%|██▊       | 2840/10000 [00:06<00:20, 340.99it/s] 29%|██▉       | 2885/10000 [00:06<00:19, 363.79it/s] 30%|██▉       | 2952/10000 [00:06<00:16, 434.15it/s] 30%|███       | 3027/10000 [00:07<00:13, 498.63it/s] 31%|███       | 3082/10000 [00:07<00:15, 447.07it/s] 31%|███▏      | 3131/10000 [00:07<00:16, 404.52it/s] 32%|███▏      | 3178/10000 [00:07<00:16, 411.57it/s] 33%|███▎      | 3259/10000 [00:07<00:13, 506.28it/s] 33%|███▎      | 3348/10000 [00:07<00:11, 598.85it/s] 34%|███▍      | 3412/10000 [00:07<00:10, 600.45it/s] 35%|███▍      | 3475/10000 [00:07<00:11, 582.90it/s] 35%|███▌      | 3536/10000 [00:07<00:11, 558.47it/s] 36%|███▌      | 3608/10000 [00:08<00:10, 594.86it/s] 37%|███▋      | 3680/10000 [00:08<00:10, 621.62it/s] 38%|███▊      | 3755/10000 [00:08<00:09, 649.39it/s] 38%|███▊      | 3821/10000 [00:08<00:10, 567.53it/s] 39%|███▉      | 3880/10000 [00:08<00:12, 489.56it/s] 39%|███▉      | 3932/10000 [00:08<00:12, 482.19it/s] 40%|████      | 4004/10000 [00:08<00:11, 540.96it/s] 41%|████      | 4074/10000 [00:08<00:10, 577.04it/s] 41%|████▏     | 4137/10000 [00:09<00:09, 588.35it/s] 42%|████▏     | 4198/10000 [00:09<00:09, 592.98it/s] 43%|████▎     | 4262/10000 [00:09<00:09, 593.11it/s] 43%|████▎     | 4343/10000 [00:09<00:08, 647.63it/s] 44%|████▍     | 4420/10000 [00:09<00:08, 679.24it/s] 45%|████▍     | 4489/10000 [00:09<00:10, 530.19it/s] 45%|████▌     | 4548/10000 [00:09<00:10, 514.33it/s] 46%|████▌     | 4604/10000 [00:09<00:12, 440.67it/s] 47%|████▋     | 4653/10000 [00:10<00:12, 428.50it/s] 47%|████▋     | 4699/10000 [00:10<00:12, 430.39it/s] 47%|████▋     | 4744/10000 [00:10<00:13, 394.86it/s] 48%|████▊     | 4796/10000 [00:10<00:12, 414.93it/s] 48%|████▊     | 4839/10000 [00:10<00:15, 323.33it/s] 49%|████▉     | 4880/10000 [00:10<00:15, 337.75it/s] 49%|████▉     | 4922/10000 [00:10<00:14, 354.06it/s] 50%|████▉     | 4960/10000 [00:10<00:14, 336.46it/s] 50%|████▉     | 4996/10000 [00:11<00:16, 312.10it/s] 50%|█████     | 5048/10000 [00:11<00:13, 355.25it/s] 51%|█████     | 5120/10000 [00:11<00:11, 438.94it/s] 52%|█████▏    | 5180/10000 [00:11<00:10, 466.42it/s] 52%|█████▏    | 5229/10000 [00:11<00:12, 386.36it/s] 53%|█████▎    | 5272/10000 [00:11<00:12, 379.43it/s] 53%|█████▎    | 5313/10000 [00:11<00:12, 369.68it/s] 54%|█████▎    | 5352/10000 [00:12<00:13, 335.24it/s] 54%|█████▍    | 5387/10000 [00:12<00:15, 301.09it/s] 54%|█████▍    | 5441/10000 [00:12<00:13, 341.48it/s] 55%|█████▍    | 5499/10000 [00:12<00:11, 399.43it/s] 56%|█████▌    | 5562/10000 [00:12<00:09, 452.29it/s] 56%|█████▌    | 5610/10000 [00:12<00:09, 446.94it/s] 57%|█████▋    | 5679/10000 [00:12<00:08, 509.78it/s] 58%|█████▊    | 5768/10000 [00:12<00:06, 608.12it/s] 58%|█████▊    | 5831/10000 [00:12<00:07, 542.92it/s] 59%|█████▉    | 5888/10000 [00:13<00:08, 461.47it/s] 59%|█████▉    | 5938/10000 [00:13<00:09, 441.27it/s] 60%|█████▉    | 5985/10000 [00:13<00:10, 372.90it/s] 60%|██████    | 6049/10000 [00:13<00:09, 432.23it/s] 61%|██████    | 6118/10000 [00:13<00:07, 493.02it/s] 62%|██████▏   | 6199/10000 [00:13<00:06, 569.34it/s] 63%|██████▎   | 6260/10000 [00:13<00:07, 479.25it/s] 63%|██████▎   | 6313/10000 [00:14<00:08, 420.37it/s] 64%|██████▎   | 6360/10000 [00:14<00:09, 388.40it/s] 64%|██████▍   | 6405/10000 [00:14<00:08, 402.04it/s] 64%|██████▍   | 6448/10000 [00:14<00:09, 381.07it/s] 65%|██████▍   | 6488/10000 [00:14<00:09, 371.07it/s] 65%|██████▌   | 6527/10000 [00:14<00:09, 372.97it/s] 66%|██████▌   | 6566/10000 [00:14<00:09, 369.31it/s] 66%|██████▌   | 6605/10000 [00:14<00:09, 367.79it/s] 66%|██████▋   | 6650/10000 [00:15<00:08, 384.59it/s] 67%|██████▋   | 6699/10000 [00:15<00:07, 413.61it/s] 67%|██████▋   | 6747/10000 [00:15<00:07, 430.77it/s] 68%|██████▊   | 6806/10000 [00:15<00:06, 476.31it/s] 69%|██████▉   | 6906/10000 [00:15<00:04, 628.07it/s] 70%|██████▉   | 6970/10000 [00:15<00:05, 585.59it/s] 70%|███████   | 7030/10000 [00:15<00:05, 552.61it/s] 71%|███████▏  | 7126/10000 [00:15<00:04, 647.11it/s] 72%|███████▏  | 7192/10000 [00:15<00:04, 626.49it/s] 73%|███████▎  | 7272/10000 [00:15<00:04, 669.72it/s] 73%|███████▎  | 7340/10000 [00:16<00:04, 643.56it/s] 74%|███████▍  | 7411/10000 [00:16<00:04, 645.67it/s] 75%|███████▍  | 7477/10000 [00:16<00:04, 611.78it/s] 75%|███████▌  | 7544/10000 [00:16<00:03, 615.60it/s] 76%|███████▌  | 7606/10000 [00:16<00:04, 579.92it/s] 77%|███████▋  | 7665/10000 [00:16<00:04, 501.23it/s] 77%|███████▋  | 7718/10000 [00:16<00:05, 455.01it/s] 78%|███████▊  | 7766/10000 [00:16<00:04, 449.07it/s] 78%|███████▊  | 7840/10000 [00:17<00:04, 520.68it/s] 79%|███████▉  | 7915/10000 [00:17<00:03, 580.57it/s] 80%|███████▉  | 7977/10000 [00:17<00:03, 578.41it/s] 80%|████████  | 8037/10000 [00:17<00:03, 567.82it/s] 81%|████████  | 8106/10000 [00:17<00:03, 598.54it/s] 82%|████████▏ | 8167/10000 [00:17<00:03, 593.62it/s] 82%|████████▏ | 8228/10000 [00:17<00:03, 589.56it/s] 83%|████████▎ | 8288/10000 [00:17<00:03, 490.89it/s] 83%|████████▎ | 8341/10000 [00:18<00:03, 448.76it/s] 84%|████████▍ | 8389/10000 [00:18<00:04, 384.23it/s] 84%|████████▍ | 8441/10000 [00:18<00:03, 406.79it/s] 85%|████████▌ | 8509/10000 [00:18<00:03, 459.16it/s] 86%|████████▌ | 8558/10000 [00:18<00:03, 446.09it/s] 86%|████████▌ | 8615/10000 [00:18<00:02, 473.02it/s] 87%|████████▋ | 8716/10000 [00:18<00:02, 610.89it/s] 88%|████████▊ | 8793/10000 [00:18<00:01, 650.23it/s] 89%|████████▊ | 8866/10000 [00:18<00:01, 671.54it/s] 89%|████████▉ | 8935/10000 [00:19<00:01, 663.94it/s] 90%|█████████ | 9023/10000 [00:19<00:01, 720.53it/s] 91%|█████████ | 9112/10000 [00:19<00:01, 761.48it/s] 92%|█████████▏| 9189/10000 [00:19<00:01, 679.86it/s] 93%|█████████▎| 9260/10000 [00:19<00:01, 590.41it/s] 93%|█████████▎| 9323/10000 [00:19<00:01, 438.70it/s] 94%|█████████▍| 9375/10000 [00:19<00:01, 427.60it/s] 94%|█████████▍| 9423/10000 [00:20<00:01, 396.76it/s] 95%|█████████▍| 9474/10000 [00:20<00:01, 419.34it/s] 95%|█████████▌| 9520/10000 [00:20<00:01, 411.26it/s] 96%|█████████▌| 9564/10000 [00:20<00:01, 394.16it/s] 96%|█████████▌| 9622/10000 [00:20<00:00, 431.17it/s] 97%|█████████▋| 9681/10000 [00:20<00:00, 464.42it/s] 97%|█████████▋| 9730/10000 [00:20<00:00, 465.30it/s] 98%|█████████▊| 9801/10000 [00:20<00:00, 523.36it/s] 99%|█████████▉| 9909/10000 [00:20<00:00, 667.80it/s]100%|█████████▉| 9989/10000 [00:21<00:00, 704.39it/s]100%|██████████| 10000/10000 [00:21<00:00, 473.75it/s]
test_neglected_p53 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p53
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p53.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.07s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.55it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.48it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.55it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.44it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.57it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.97it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.52it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.62it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p53_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p53_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p53_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p53_Holmes_probs.npy
{'Accuracy': 0.0207, 'Precision': 0.0247, 'Recall': 0.0205, 'F1-score': 0.0182}
starting gen taf script for test_neglected_p54
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 96/10000 [00:00<00:11, 899.07it/s]  2%|▏         | 186/10000 [00:00<00:21, 459.90it/s]  2%|▏         | 243/10000 [00:00<00:23, 413.23it/s]  3%|▎         | 290/10000 [00:00<00:24, 391.90it/s]  3%|▎         | 332/10000 [00:00<00:24, 386.91it/s]  4%|▎         | 373/10000 [00:00<00:25, 375.91it/s]  4%|▍         | 412/10000 [00:01<00:26, 364.45it/s]  4%|▍         | 449/10000 [00:01<00:26, 365.86it/s]  5%|▍         | 495/10000 [00:01<00:24, 384.28it/s]  5%|▌         | 540/10000 [00:01<00:23, 395.28it/s]  6%|▌         | 580/10000 [00:01<00:24, 390.45it/s]  6%|▌         | 620/10000 [00:01<00:24, 379.78it/s]  7%|▋         | 668/10000 [00:01<00:22, 407.42it/s]  7%|▋         | 716/10000 [00:01<00:21, 427.57it/s]  8%|▊         | 760/10000 [00:01<00:21, 426.01it/s]  8%|▊         | 803/10000 [00:01<00:22, 410.38it/s]  8%|▊         | 845/10000 [00:02<00:25, 362.51it/s]  9%|▉         | 891/10000 [00:02<00:23, 387.71it/s]  9%|▉         | 934/10000 [00:02<00:22, 399.12it/s] 10%|█         | 1011/10000 [00:02<00:18, 483.61it/s] 11%|█         | 1060/10000 [00:02<00:21, 420.24it/s] 11%|█         | 1109/10000 [00:02<00:20, 429.34it/s] 12%|█▏        | 1154/10000 [00:02<00:20, 423.38it/s] 12%|█▏        | 1219/10000 [00:02<00:18, 480.67it/s] 13%|█▎        | 1269/10000 [00:03<00:18, 463.80it/s] 13%|█▎        | 1326/10000 [00:03<00:17, 489.59it/s] 14%|█▍        | 1391/10000 [00:03<00:16, 524.74it/s] 14%|█▍        | 1445/10000 [00:03<00:19, 448.31it/s] 15%|█▍        | 1493/10000 [00:03<00:23, 363.15it/s] 15%|█▌        | 1534/10000 [00:03<00:24, 345.52it/s] 16%|█▌        | 1572/10000 [00:03<00:27, 304.32it/s] 16%|█▌        | 1605/10000 [00:04<00:29, 284.82it/s] 17%|█▋        | 1664/10000 [00:04<00:23, 352.97it/s] 17%|█▋        | 1737/10000 [00:04<00:18, 442.76it/s] 18%|█▊        | 1797/10000 [00:04<00:16, 482.72it/s] 19%|█▉        | 1903/10000 [00:04<00:12, 637.34it/s] 20%|█▉        | 1982/10000 [00:04<00:11, 679.39it/s] 21%|██        | 2054/10000 [00:04<00:11, 686.95it/s] 21%|██▏       | 2126/10000 [00:04<00:13, 571.99it/s] 22%|██▏       | 2189/10000 [00:04<00:15, 504.77it/s] 22%|██▏       | 2244/10000 [00:05<00:16, 463.10it/s] 23%|██▎       | 2305/10000 [00:05<00:16, 471.00it/s] 24%|██▎       | 2355/10000 [00:05<00:17, 437.15it/s] 24%|██▍       | 2401/10000 [00:05<00:17, 432.79it/s] 25%|██▍       | 2464/10000 [00:05<00:15, 476.30it/s] 25%|██▌       | 2515/10000 [00:05<00:15, 483.49it/s] 26%|██▌       | 2579/10000 [00:05<00:14, 518.56it/s] 26%|██▋       | 2632/10000 [00:05<00:15, 488.93it/s] 27%|██▋       | 2682/10000 [00:06<00:18, 394.30it/s] 27%|██▋       | 2725/10000 [00:06<00:21, 333.14it/s] 28%|██▊       | 2762/10000 [00:06<00:23, 308.71it/s] 28%|██▊       | 2796/10000 [00:06<00:26, 267.44it/s] 28%|██▊       | 2847/10000 [00:06<00:22, 314.81it/s] 29%|██▉       | 2904/10000 [00:06<00:19, 372.87it/s] 29%|██▉       | 2946/10000 [00:06<00:19, 366.82it/s] 30%|███       | 3005/10000 [00:07<00:16, 419.57it/s] 31%|███       | 3054/10000 [00:07<00:16, 427.11it/s] 31%|███       | 3101/10000 [00:07<00:15, 438.58it/s] 31%|███▏      | 3147/10000 [00:07<00:15, 436.65it/s] 32%|███▏      | 3192/10000 [00:07<00:16, 411.40it/s] 33%|███▎      | 3271/10000 [00:07<00:13, 508.83it/s] 33%|███▎      | 3344/10000 [00:07<00:11, 561.78it/s] 34%|███▍      | 3422/10000 [00:07<00:10, 621.39it/s] 35%|███▍      | 3486/10000 [00:07<00:11, 563.65it/s] 35%|███▌      | 3545/10000 [00:08<00:12, 520.78it/s] 36%|███▌      | 3608/10000 [00:08<00:11, 538.80it/s] 37%|███▋      | 3675/10000 [00:08<00:11, 570.40it/s] 37%|███▋      | 3734/10000 [00:08<00:10, 571.92it/s] 38%|███▊      | 3805/10000 [00:08<00:10, 595.60it/s] 39%|███▊      | 3866/10000 [00:08<00:10, 596.22it/s] 39%|███▉      | 3931/10000 [00:08<00:10, 594.68it/s] 40%|███▉      | 3993/10000 [00:08<00:09, 601.43it/s] 41%|████      | 4077/10000 [00:08<00:09, 657.79it/s] 42%|████▏     | 4180/10000 [00:09<00:07, 755.68it/s] 43%|████▎     | 4257/10000 [00:09<00:07, 758.74it/s] 44%|████▎     | 4365/10000 [00:09<00:06, 843.50it/s] 44%|████▍     | 4450/10000 [00:09<00:08, 671.38it/s] 45%|████▌     | 4523/10000 [00:09<00:10, 537.65it/s] 46%|████▌     | 4585/10000 [00:09<00:12, 445.70it/s] 46%|████▋     | 4641/10000 [00:09<00:11, 458.93it/s] 47%|████▋     | 4693/10000 [00:10<00:12, 427.52it/s] 47%|████▋     | 4740/10000 [00:10<00:12, 432.03it/s] 48%|████▊     | 4786/10000 [00:10<00:12, 429.72it/s] 48%|████▊     | 4831/10000 [00:10<00:13, 373.82it/s] 49%|████▊     | 4871/10000 [00:10<00:13, 375.66it/s] 49%|████▉     | 4911/10000 [00:10<00:16, 316.04it/s] 49%|████▉     | 4946/10000 [00:10<00:15, 322.30it/s] 50%|████▉     | 4981/10000 [00:11<00:15, 314.47it/s] 50%|█████     | 5024/10000 [00:11<00:14, 336.95it/s] 51%|█████     | 5067/10000 [00:11<00:13, 355.17it/s] 51%|█████     | 5116/10000 [00:11<00:12, 385.52it/s] 52%|█████▏    | 5161/10000 [00:11<00:12, 399.20it/s] 52%|█████▏    | 5214/10000 [00:11<00:11, 421.55it/s] 53%|█████▎    | 5257/10000 [00:11<00:12, 373.50it/s] 53%|█████▎    | 5296/10000 [00:11<00:13, 348.17it/s] 53%|█████▎    | 5332/10000 [00:12<00:15, 301.74it/s] 54%|█████▎    | 5364/10000 [00:12<00:16, 288.39it/s] 54%|█████▍    | 5394/10000 [00:12<00:16, 280.09it/s] 54%|█████▍    | 5448/10000 [00:12<00:13, 337.69it/s] 55%|█████▌    | 5511/10000 [00:12<00:11, 403.75it/s] 56%|█████▌    | 5570/10000 [00:12<00:09, 452.97it/s] 56%|█████▌    | 5617/10000 [00:12<00:09, 450.20it/s] 57%|█████▋    | 5712/10000 [00:12<00:07, 584.32it/s] 58%|█████▊    | 5782/10000 [00:12<00:06, 613.83it/s] 58%|█████▊    | 5845/10000 [00:13<00:07, 563.82it/s] 59%|█████▉    | 5903/10000 [00:13<00:09, 437.07it/s] 60%|█████▉    | 5952/10000 [00:13<00:09, 439.28it/s] 60%|██████    | 6000/10000 [00:13<00:09, 403.25it/s] 61%|██████    | 6066/10000 [00:13<00:08, 457.63it/s] 61%|██████▏   | 6142/10000 [00:13<00:07, 528.42it/s] 62%|██████▏   | 6211/10000 [00:13<00:06, 563.41it/s] 63%|██████▎   | 6271/10000 [00:13<00:08, 458.35it/s] 63%|██████▎   | 6322/10000 [00:14<00:09, 394.16it/s] 64%|██████▎   | 6367/10000 [00:14<00:08, 406.28it/s] 64%|██████▍   | 6412/10000 [00:14<00:09, 371.57it/s] 65%|██████▍   | 6455/10000 [00:14<00:09, 383.11it/s] 65%|██████▍   | 6496/10000 [00:14<00:09, 355.45it/s] 65%|██████▌   | 6540/10000 [00:14<00:09, 374.24it/s] 66%|██████▌   | 6579/10000 [00:14<00:09, 353.19it/s] 66%|██████▋   | 6641/10000 [00:14<00:08, 411.85it/s] 67%|██████▋   | 6702/10000 [00:15<00:07, 434.16it/s] 68%|██████▊   | 6756/10000 [00:15<00:07, 455.20it/s] 68%|██████▊   | 6803/10000 [00:15<00:07, 413.65it/s] 69%|██████▉   | 6887/10000 [00:15<00:06, 518.55it/s] 70%|██████▉   | 6996/10000 [00:15<00:04, 656.67it/s] 71%|███████   | 7065/10000 [00:15<00:04, 648.62it/s] 71%|███████▏  | 7132/10000 [00:15<00:04, 606.04it/s] 72%|███████▏  | 7196/10000 [00:15<00:04, 609.91it/s] 73%|███████▎  | 7267/10000 [00:16<00:04, 630.42it/s] 74%|███████▎  | 7361/10000 [00:16<00:03, 707.72it/s] 74%|███████▍  | 7433/10000 [00:16<00:03, 664.55it/s] 75%|███████▌  | 7501/10000 [00:16<00:04, 616.69it/s] 76%|███████▌  | 7591/10000 [00:16<00:03, 688.94it/s] 77%|███████▋  | 7662/10000 [00:16<00:04, 542.94it/s] 77%|███████▋  | 7722/10000 [00:16<00:04, 466.99it/s] 78%|███████▊  | 7774/10000 [00:16<00:04, 458.82it/s] 78%|███████▊  | 7848/10000 [00:17<00:04, 510.83it/s] 79%|███████▉  | 7929/10000 [00:17<00:03, 568.43it/s] 80%|████████  | 8004/10000 [00:17<00:03, 598.98it/s] 81%|████████  | 8067/10000 [00:17<00:03, 592.53it/s] 81%|████████▏ | 8133/10000 [00:17<00:03, 602.38it/s] 82%|████████▏ | 8215/10000 [00:17<00:02, 635.59it/s] 83%|████████▎ | 8280/10000 [00:17<00:03, 562.74it/s] 83%|████████▎ | 8339/10000 [00:18<00:03, 457.29it/s] 84%|████████▍ | 8389/10000 [00:18<00:03, 446.73it/s] 84%|████████▍ | 8437/10000 [00:18<00:03, 449.18it/s] 85%|████████▍ | 8486/10000 [00:18<00:03, 459.25it/s] 85%|████████▌ | 8534/10000 [00:18<00:03, 455.21it/s] 86%|████████▌ | 8594/10000 [00:18<00:02, 486.21it/s] 87%|████████▋ | 8655/10000 [00:18<00:02, 518.92it/s] 87%|████████▋ | 8725/10000 [00:18<00:02, 566.75it/s] 88%|████████▊ | 8798/10000 [00:18<00:01, 610.06it/s] 89%|████████▉ | 8891/10000 [00:18<00:01, 694.52it/s] 90%|████████▉ | 8983/10000 [00:19<00:01, 752.55it/s] 91%|█████████ | 9075/10000 [00:19<00:01, 798.93it/s] 92%|█████████▏| 9156/10000 [00:19<00:01, 726.67it/s] 92%|█████████▏| 9231/10000 [00:19<00:01, 541.68it/s] 93%|█████████▎| 9293/10000 [00:19<00:01, 523.12it/s] 94%|█████████▎| 9351/10000 [00:19<00:01, 454.41it/s] 94%|█████████▍| 9402/10000 [00:19<00:01, 414.03it/s] 94%|█████████▍| 9447/10000 [00:20<00:01, 408.66it/s] 95%|█████████▍| 9491/10000 [00:20<00:01, 385.14it/s] 95%|█████████▌| 9545/10000 [00:20<00:01, 407.33it/s] 96%|█████████▌| 9588/10000 [00:20<00:01, 386.46it/s] 96%|█████████▋| 9641/10000 [00:20<00:00, 408.54it/s] 97%|█████████▋| 9702/10000 [00:20<00:00, 459.58it/s] 98%|█████████▊| 9755/10000 [00:20<00:00, 475.76it/s] 98%|█████████▊| 9804/10000 [00:20<00:00, 471.87it/s] 99%|█████████▉| 9879/10000 [00:21<00:00, 545.03it/s]100%|█████████▉| 9959/10000 [00:21<00:00, 616.22it/s]100%|██████████| 10000/10000 [00:21<00:00, 473.52it/s]
test_neglected_p54 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p54
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p54.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.03s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.80it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.90it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.13it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.03it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.05it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.39it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.93it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.21it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p54_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p54_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p54_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p54_Holmes_probs.npy
{'Accuracy': 0.0209, 'Precision': 0.0265, 'Recall': 0.0207, 'F1-score': 0.0185}
starting gen taf script for test_neglected_p55
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 70/10000 [00:00<00:15, 649.43it/s]  1%|▏         | 135/10000 [00:00<00:26, 377.03it/s]  2%|▏         | 179/10000 [00:00<00:26, 364.31it/s]  2%|▏         | 219/10000 [00:00<00:27, 351.27it/s]  3%|▎         | 256/10000 [00:00<00:30, 318.58it/s]  3%|▎         | 289/10000 [00:00<00:30, 317.73it/s]  3%|▎         | 322/10000 [00:00<00:30, 314.71it/s]  4%|▎         | 354/10000 [00:01<00:31, 305.91it/s]  4%|▍         | 385/10000 [00:01<00:31, 300.62it/s]  4%|▍         | 416/10000 [00:01<00:32, 291.02it/s]  4%|▍         | 446/10000 [00:01<00:35, 269.75it/s]  5%|▌         | 504/10000 [00:01<00:27, 351.67it/s]  6%|▌         | 554/10000 [00:01<00:24, 392.38it/s]  6%|▌         | 599/10000 [00:01<00:23, 404.44it/s]  6%|▋         | 648/10000 [00:01<00:21, 428.66it/s]  8%|▊         | 752/10000 [00:01<00:15, 605.25it/s]  8%|▊         | 821/10000 [00:02<00:15, 605.34it/s]  9%|▉         | 883/10000 [00:02<00:16, 566.26it/s]  9%|▉         | 941/10000 [00:02<00:16, 545.87it/s] 10%|█         | 1011/10000 [00:02<00:15, 583.78it/s] 11%|█         | 1071/10000 [00:02<00:19, 464.42it/s] 11%|█         | 1122/10000 [00:02<00:20, 435.68it/s] 12%|█▏        | 1181/10000 [00:02<00:18, 470.40it/s] 12%|█▏        | 1247/10000 [00:02<00:17, 511.51it/s] 13%|█▎        | 1307/10000 [00:03<00:16, 530.45it/s] 14%|█▍        | 1377/10000 [00:03<00:15, 569.78it/s] 14%|█▍        | 1436/10000 [00:03<00:16, 505.17it/s] 15%|█▍        | 1489/10000 [00:03<00:20, 425.18it/s] 15%|█▌        | 1535/10000 [00:03<00:26, 320.12it/s] 16%|█▌        | 1573/10000 [00:03<00:26, 321.43it/s] 16%|█▌        | 1610/10000 [00:03<00:26, 315.47it/s] 17%|█▋        | 1683/10000 [00:04<00:20, 408.80it/s] 18%|█▊        | 1750/10000 [00:04<00:17, 468.92it/s] 18%|█▊        | 1822/10000 [00:04<00:15, 529.82it/s] 19%|█▉        | 1935/10000 [00:04<00:11, 681.62it/s] 20%|██        | 2011/10000 [00:04<00:11, 702.90it/s] 21%|██        | 2085/10000 [00:04<00:11, 695.39it/s] 22%|██▏       | 2157/10000 [00:04<00:12, 615.73it/s] 22%|██▏       | 2222/10000 [00:04<00:13, 574.35it/s] 23%|██▎       | 2282/10000 [00:05<00:15, 505.00it/s] 23%|██▎       | 2336/10000 [00:05<00:17, 435.45it/s] 24%|██▍       | 2383/10000 [00:05<00:17, 431.75it/s] 24%|██▍       | 2434/10000 [00:05<00:16, 449.56it/s] 25%|██▍       | 2481/10000 [00:05<00:16, 450.46it/s] 25%|██▌       | 2540/10000 [00:05<00:15, 485.31it/s] 26%|██▌       | 2597/10000 [00:05<00:14, 498.63it/s] 26%|██▋       | 2648/10000 [00:05<00:16, 448.05it/s] 27%|██▋       | 2695/10000 [00:06<00:21, 345.61it/s] 27%|██▋       | 2734/10000 [00:06<00:23, 307.43it/s] 28%|██▊       | 2769/10000 [00:06<00:24, 297.42it/s] 28%|██▊       | 2801/10000 [00:06<00:23, 300.35it/s] 28%|██▊       | 2846/10000 [00:06<00:21, 336.17it/s] 29%|██▉       | 2886/10000 [00:06<00:20, 351.83it/s] 30%|██▉       | 2957/10000 [00:06<00:16, 429.35it/s] 30%|███       | 3015/10000 [00:06<00:15, 447.84it/s] 31%|███       | 3068/10000 [00:07<00:14, 468.29it/s] 31%|███       | 3116/10000 [00:07<00:15, 442.91it/s] 32%|███▏      | 3167/10000 [00:07<00:14, 455.80it/s] 32%|███▏      | 3220/10000 [00:07<00:14, 475.01it/s] 33%|███▎      | 3295/10000 [00:07<00:12, 542.50it/s] 34%|███▎      | 3360/10000 [00:07<00:11, 572.20it/s] 34%|███▍      | 3422/10000 [00:07<00:11, 574.85it/s] 35%|███▌      | 3514/10000 [00:07<00:09, 654.87it/s] 36%|███▌      | 3580/10000 [00:07<00:09, 652.60it/s] 37%|███▋      | 3655/10000 [00:07<00:09, 670.47it/s] 37%|███▋      | 3729/10000 [00:08<00:09, 684.06it/s] 38%|███▊      | 3810/10000 [00:08<00:08, 699.88it/s] 39%|███▉      | 3880/10000 [00:08<00:08, 688.07it/s] 39%|███▉      | 3949/10000 [00:08<00:09, 610.96it/s] 40%|████      | 4012/10000 [00:08<00:09, 603.91it/s] 41%|████      | 4099/10000 [00:08<00:08, 671.25it/s] 42%|████▏     | 4168/10000 [00:08<00:08, 658.61it/s] 43%|████▎     | 4256/10000 [00:08<00:08, 716.84it/s] 43%|████▎     | 4338/10000 [00:08<00:07, 732.34it/s] 44%|████▍     | 4412/10000 [00:09<00:08, 693.68it/s] 45%|████▍     | 4483/10000 [00:09<00:09, 595.56it/s] 45%|████▌     | 4546/10000 [00:09<00:11, 475.15it/s] 46%|████▌     | 4601/10000 [00:09<00:11, 481.03it/s] 47%|████▋     | 4653/10000 [00:09<00:12, 419.71it/s] 47%|████▋     | 4699/10000 [00:09<00:13, 391.17it/s] 47%|████▋     | 4741/10000 [00:09<00:13, 383.03it/s] 48%|████▊     | 4792/10000 [00:10<00:12, 408.43it/s] 48%|████▊     | 4835/10000 [00:10<00:13, 394.71it/s] 49%|████▉     | 4883/10000 [00:10<00:12, 415.51it/s] 49%|████▉     | 4926/10000 [00:10<00:14, 347.44it/s] 50%|████▉     | 4964/10000 [00:10<00:15, 330.58it/s] 50%|████▉     | 4999/10000 [00:10<00:15, 324.57it/s] 50%|█████     | 5033/10000 [00:10<00:15, 322.89it/s] 51%|█████     | 5101/10000 [00:10<00:11, 412.56it/s] 52%|█████▏    | 5151/10000 [00:11<00:11, 435.87it/s] 52%|█████▏    | 5207/10000 [00:11<00:10, 466.05it/s] 53%|█████▎    | 5255/10000 [00:11<00:12, 379.76it/s] 53%|█████▎    | 5297/10000 [00:11<00:12, 362.22it/s] 53%|█████▎    | 5336/10000 [00:11<00:14, 312.74it/s] 54%|█████▎    | 5370/10000 [00:11<00:15, 303.53it/s] 54%|█████▍    | 5402/10000 [00:11<00:15, 291.13it/s] 55%|█████▍    | 5450/10000 [00:11<00:13, 335.41it/s] 55%|█████▌    | 5518/10000 [00:12<00:10, 412.41it/s] 56%|█████▌    | 5570/10000 [00:12<00:10, 434.01it/s] 56%|█████▋    | 5645/10000 [00:12<00:08, 519.28it/s] 57%|█████▋    | 5711/10000 [00:12<00:07, 558.25it/s] 58%|█████▊    | 5791/10000 [00:12<00:06, 609.73it/s] 59%|█████▊    | 5854/10000 [00:12<00:07, 566.17it/s] 59%|█████▉    | 5912/10000 [00:12<00:08, 470.13it/s] 60%|█████▉    | 5963/10000 [00:12<00:08, 464.37it/s] 60%|██████    | 6012/10000 [00:13<00:09, 432.10it/s] 61%|██████    | 6075/10000 [00:13<00:08, 477.33it/s] 62%|██████▏   | 6151/10000 [00:13<00:07, 545.11it/s] 62%|██████▏   | 6217/10000 [00:13<00:06, 575.97it/s] 63%|██████▎   | 6277/10000 [00:13<00:07, 468.64it/s] 63%|██████▎   | 6329/10000 [00:13<00:08, 408.84it/s] 64%|██████▍   | 6377/10000 [00:13<00:08, 417.59it/s] 64%|██████▍   | 6422/10000 [00:13<00:08, 403.64it/s] 65%|██████▍   | 6467/10000 [00:14<00:08, 414.49it/s] 65%|██████▌   | 6511/10000 [00:14<00:08, 394.66it/s] 66%|██████▌   | 6552/10000 [00:14<00:09, 345.00it/s] 66%|██████▌   | 6598/10000 [00:14<00:09, 370.75it/s] 67%|██████▋   | 6659/10000 [00:14<00:07, 421.05it/s] 67%|██████▋   | 6703/10000 [00:14<00:08, 410.57it/s] 68%|██████▊   | 6752/10000 [00:14<00:07, 422.50it/s] 68%|██████▊   | 6824/10000 [00:14<00:06, 497.34it/s] 69%|██████▉   | 6897/10000 [00:14<00:05, 558.45it/s] 70%|██████▉   | 6995/10000 [00:15<00:04, 670.27it/s] 71%|███████   | 7064/10000 [00:15<00:04, 616.50it/s] 71%|███████▏  | 7128/10000 [00:15<00:05, 568.56it/s] 72%|███████▏  | 7187/10000 [00:15<00:04, 562.94it/s] 73%|███████▎  | 7271/10000 [00:15<00:04, 634.55it/s] 74%|███████▎  | 7360/10000 [00:15<00:03, 680.98it/s] 74%|███████▍  | 7430/10000 [00:15<00:03, 661.10it/s] 75%|███████▍  | 7497/10000 [00:15<00:03, 626.71it/s] 76%|███████▌  | 7564/10000 [00:16<00:03, 628.66it/s] 76%|███████▋  | 7628/10000 [00:16<00:03, 617.00it/s] 77%|███████▋  | 7691/10000 [00:16<00:04, 535.28it/s] 77%|███████▋  | 7747/10000 [00:16<00:04, 497.84it/s] 78%|███████▊  | 7799/10000 [00:16<00:04, 464.11it/s] 79%|███████▊  | 7871/10000 [00:16<00:04, 524.97it/s] 80%|███████▉  | 7955/10000 [00:16<00:03, 603.24it/s] 80%|████████  | 8021/10000 [00:16<00:03, 608.08it/s] 81%|████████  | 8084/10000 [00:16<00:03, 594.24it/s] 82%|████████▏ | 8171/10000 [00:17<00:02, 667.80it/s] 82%|████████▏ | 8240/10000 [00:17<00:02, 625.85it/s] 83%|████████▎ | 8304/10000 [00:17<00:03, 493.96it/s] 84%|████████▎ | 8359/10000 [00:17<00:03, 452.94it/s] 84%|████████▍ | 8408/10000 [00:17<00:03, 450.62it/s] 85%|████████▍ | 8456/10000 [00:17<00:03, 457.34it/s] 85%|████████▌ | 8518/10000 [00:17<00:02, 497.07it/s] 86%|████████▌ | 8577/10000 [00:17<00:02, 509.18it/s] 87%|████████▋ | 8669/10000 [00:18<00:02, 616.17it/s] 88%|████████▊ | 8760/10000 [00:18<00:01, 697.44it/s] 88%|████████▊ | 8840/10000 [00:18<00:01, 722.57it/s] 89%|████████▉ | 8946/10000 [00:18<00:01, 807.29it/s] 90%|█████████ | 9028/10000 [00:18<00:01, 747.66it/s] 91%|█████████ | 9105/10000 [00:18<00:01, 736.78it/s] 92%|█████████▏| 9180/10000 [00:18<00:01, 704.76it/s] 93%|█████████▎| 9252/10000 [00:18<00:01, 552.88it/s] 93%|█████████▎| 9313/10000 [00:19<00:01, 459.55it/s] 94%|█████████▎| 9365/10000 [00:19<00:01, 414.29it/s] 94%|█████████▍| 9411/10000 [00:19<00:01, 406.89it/s] 95%|█████████▍| 9459/10000 [00:19<00:01, 423.14it/s] 95%|█████████▌| 9504/10000 [00:19<00:01, 424.12it/s] 95%|█████████▌| 9549/10000 [00:19<00:01, 382.79it/s] 96%|█████████▌| 9589/10000 [00:19<00:01, 380.84it/s] 96%|█████████▋| 9641/10000 [00:20<00:00, 410.41it/s] 97%|█████████▋| 9715/10000 [00:20<00:00, 491.70it/s] 98%|█████████▊| 9766/10000 [00:20<00:00, 489.20it/s] 98%|█████████▊| 9841/10000 [00:20<00:00, 555.14it/s] 99%|█████████▉| 9899/10000 [00:20<00:00, 547.96it/s]100%|█████████▉| 9990/10000 [00:20<00:00, 649.61it/s]100%|██████████| 10000/10000 [00:20<00:00, 486.72it/s]
test_neglected_p55 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p55
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p55.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:35,  1.10it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.37it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 13.29it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.97it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 26.11it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 31.23it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 35.56it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 39.03it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 41.10it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 22.60it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p55_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p55_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p55_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p55_Holmes_probs.npy
{'Accuracy': 0.021, 'Precision': 0.0262, 'Recall': 0.0208, 'F1-score': 0.0186}
starting gen taf script for test_neglected_p56
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 91/10000 [00:00<00:11, 836.85it/s]  2%|▏         | 175/10000 [00:00<00:20, 474.94it/s]  2%|▏         | 231/10000 [00:00<00:23, 409.90it/s]  3%|▎         | 277/10000 [00:00<00:25, 378.97it/s]  3%|▎         | 317/10000 [00:00<00:26, 361.41it/s]  4%|▎         | 355/10000 [00:00<00:30, 318.88it/s]  4%|▍         | 388/10000 [00:01<00:30, 315.10it/s]  4%|▍         | 429/10000 [00:01<00:28, 333.00it/s]  5%|▍         | 471/10000 [00:01<00:26, 353.86it/s]  5%|▌         | 526/10000 [00:01<00:23, 404.31it/s]  6%|▌         | 568/10000 [00:01<00:24, 382.94it/s]  6%|▌         | 608/10000 [00:01<00:25, 371.87it/s]  7%|▋         | 651/10000 [00:01<00:24, 387.29it/s]  7%|▋         | 691/10000 [00:01<00:24, 383.47it/s]  7%|▋         | 732/10000 [00:01<00:23, 387.57it/s]  8%|▊         | 772/10000 [00:02<00:25, 359.81it/s]  8%|▊         | 817/10000 [00:02<00:24, 377.97it/s]  9%|▊         | 861/10000 [00:02<00:23, 390.44it/s]  9%|▉         | 910/10000 [00:02<00:21, 417.44it/s] 10%|▉         | 953/10000 [00:02<00:21, 419.21it/s] 10%|▉         | 998/10000 [00:02<00:21, 428.11it/s] 10%|█         | 1050/10000 [00:02<00:20, 445.51it/s] 11%|█         | 1095/10000 [00:02<00:20, 427.78it/s] 12%|█▏        | 1158/10000 [00:02<00:18, 474.62it/s] 12%|█▏        | 1206/10000 [00:03<00:20, 420.01it/s] 13%|█▎        | 1275/10000 [00:03<00:18, 480.44it/s] 13%|█▎        | 1341/10000 [00:03<00:16, 523.56it/s] 14%|█▍        | 1407/10000 [00:03<00:15, 546.54it/s] 15%|█▍        | 1463/10000 [00:03<00:23, 370.42it/s] 15%|█▌        | 1508/10000 [00:03<00:25, 332.97it/s] 15%|█▌        | 1548/10000 [00:03<00:27, 304.40it/s] 16%|█▌        | 1583/10000 [00:04<00:30, 274.59it/s] 17%|█▋        | 1656/10000 [00:04<00:22, 366.67it/s] 17%|█▋        | 1730/10000 [00:04<00:18, 448.37it/s] 18%|█▊        | 1819/10000 [00:04<00:14, 548.82it/s] 19%|█▉        | 1918/10000 [00:04<00:12, 656.51it/s] 20%|██        | 2011/10000 [00:04<00:11, 719.08it/s] 21%|██        | 2088/10000 [00:04<00:12, 658.25it/s] 22%|██▏       | 2159/10000 [00:04<00:12, 620.66it/s] 22%|██▏       | 2225/10000 [00:05<00:13, 585.95it/s] 23%|██▎       | 2286/10000 [00:05<00:16, 465.70it/s] 23%|██▎       | 2338/10000 [00:05<00:17, 428.54it/s] 24%|██▍       | 2385/10000 [00:05<00:18, 411.54it/s] 24%|██▍       | 2440/10000 [00:05<00:17, 437.57it/s] 25%|██▌       | 2512/10000 [00:05<00:15, 489.26it/s] 26%|██▌       | 2602/10000 [00:05<00:12, 570.98it/s] 27%|██▋       | 2662/10000 [00:06<00:18, 393.84it/s] 27%|██▋       | 2710/10000 [00:06<00:20, 359.88it/s] 28%|██▊       | 2752/10000 [00:06<00:23, 313.38it/s] 28%|██▊       | 2788/10000 [00:06<00:26, 275.64it/s] 28%|██▊       | 2844/10000 [00:06<00:21, 326.01it/s] 29%|██▉       | 2917/10000 [00:06<00:17, 409.55it/s] 30%|██▉       | 2974/10000 [00:07<00:15, 443.56it/s] 30%|███       | 3024/10000 [00:07<00:15, 438.25it/s] 31%|███       | 3072/10000 [00:07<00:16, 428.95it/s] 31%|███       | 3118/10000 [00:07<00:17, 395.92it/s] 32%|███▏      | 3162/10000 [00:07<00:16, 405.59it/s] 32%|███▏      | 3205/10000 [00:07<00:17, 388.51it/s] 33%|███▎      | 3275/10000 [00:07<00:14, 468.16it/s] 34%|███▎      | 3352/10000 [00:07<00:12, 544.34it/s] 34%|███▍      | 3424/10000 [00:07<00:11, 589.01it/s] 35%|███▍      | 3485/10000 [00:08<00:11, 574.65it/s] 35%|███▌      | 3544/10000 [00:08<00:11, 552.25it/s] 36%|███▋      | 3636/10000 [00:08<00:09, 653.28it/s] 37%|███▋      | 3703/10000 [00:08<00:09, 634.20it/s] 38%|███▊      | 3779/10000 [00:08<00:09, 665.54it/s] 38%|███▊      | 3847/10000 [00:08<00:10, 564.17it/s] 39%|███▉      | 3919/10000 [00:08<00:10, 599.06it/s] 40%|███▉      | 3982/10000 [00:08<00:10, 588.66it/s] 40%|████      | 4048/10000 [00:08<00:10, 593.88it/s] 41%|████      | 4124/10000 [00:09<00:09, 639.03it/s] 42%|████▏     | 4199/10000 [00:09<00:08, 656.43it/s] 43%|████▎     | 4267/10000 [00:09<00:08, 653.47it/s] 44%|████▎     | 4360/10000 [00:09<00:07, 727.50it/s] 44%|████▍     | 4434/10000 [00:09<00:08, 637.54it/s] 45%|████▌     | 4501/10000 [00:09<00:10, 544.27it/s] 46%|████▌     | 4560/10000 [00:09<00:12, 430.91it/s] 46%|████▌     | 4609/10000 [00:10<00:12, 423.07it/s] 47%|████▋     | 4656/10000 [00:10<00:12, 429.91it/s] 47%|████▋     | 4702/10000 [00:10<00:12, 412.86it/s] 48%|████▊     | 4760/10000 [00:10<00:11, 446.95it/s] 48%|████▊     | 4807/10000 [00:10<00:12, 426.65it/s] 49%|████▊     | 4851/10000 [00:10<00:13, 374.54it/s] 49%|████▉     | 4891/10000 [00:10<00:14, 344.75it/s] 49%|████▉     | 4927/10000 [00:10<00:16, 307.35it/s] 50%|████▉     | 4972/10000 [00:11<00:15, 333.25it/s] 50%|█████     | 5017/10000 [00:11<00:14, 350.40it/s] 51%|█████     | 5063/10000 [00:11<00:13, 369.19it/s] 52%|█████▏    | 5150/10000 [00:11<00:09, 486.80it/s] 52%|█████▏    | 5201/10000 [00:11<00:10, 471.79it/s] 52%|█████▎    | 5250/10000 [00:11<00:12, 371.33it/s] 53%|█████▎    | 5291/10000 [00:11<00:12, 372.70it/s] 53%|█████▎    | 5331/10000 [00:11<00:13, 345.67it/s] 54%|█████▎    | 5368/10000 [00:12<00:14, 310.41it/s] 54%|█████▍    | 5401/10000 [00:12<00:15, 292.91it/s] 55%|█████▍    | 5459/10000 [00:12<00:12, 358.49it/s] 55%|█████▌    | 5517/10000 [00:12<00:11, 399.46it/s] 56%|█████▌    | 5569/10000 [00:12<00:10, 423.86it/s] 56%|█████▋    | 5640/10000 [00:12<00:08, 492.93it/s] 57%|█████▋    | 5715/10000 [00:12<00:07, 562.90it/s] 58%|█████▊    | 5791/10000 [00:12<00:07, 597.94it/s] 59%|█████▊    | 5853/10000 [00:13<00:08, 501.25it/s] 59%|█████▉    | 5907/10000 [00:13<00:10, 399.05it/s] 60%|█████▉    | 5953/10000 [00:13<00:10, 394.54it/s] 60%|█████▉    | 5996/10000 [00:13<00:10, 392.97it/s] 61%|██████    | 6058/10000 [00:13<00:08, 443.45it/s] 61%|██████    | 6115/10000 [00:13<00:08, 474.86it/s] 62%|██████▏   | 6202/10000 [00:13<00:06, 566.21it/s] 63%|██████▎   | 6261/10000 [00:14<00:07, 482.44it/s] 63%|██████▎   | 6313/10000 [00:14<00:08, 410.80it/s] 64%|██████▎   | 6358/10000 [00:14<00:09, 380.46it/s] 64%|██████▍   | 6399/10000 [00:14<00:09, 361.93it/s] 64%|██████▍   | 6439/10000 [00:14<00:09, 368.83it/s] 65%|██████▍   | 6479/10000 [00:14<00:09, 372.57it/s] 65%|██████▌   | 6521/10000 [00:14<00:09, 370.78it/s] 66%|██████▌   | 6559/10000 [00:14<00:09, 345.72it/s] 66%|██████▌   | 6612/10000 [00:15<00:08, 391.98it/s] 67%|██████▋   | 6655/10000 [00:15<00:08, 399.84it/s] 67%|██████▋   | 6696/10000 [00:15<00:08, 401.97it/s] 68%|██████▊   | 6767/10000 [00:15<00:07, 459.24it/s] 68%|██████▊   | 6823/10000 [00:15<00:06, 486.71it/s] 69%|██████▉   | 6914/10000 [00:15<00:05, 604.86it/s] 70%|██████▉   | 6976/10000 [00:15<00:05, 564.23it/s] 71%|███████   | 7061/10000 [00:15<00:04, 632.58it/s] 71%|███████▏  | 7132/10000 [00:15<00:04, 638.62it/s] 72%|███████▏  | 7197/10000 [00:16<00:04, 608.46it/s] 73%|███████▎  | 7265/10000 [00:16<00:04, 626.44it/s] 73%|███████▎  | 7339/10000 [00:16<00:04, 656.46it/s] 74%|███████▍  | 7427/10000 [00:16<00:03, 708.23it/s] 75%|███████▍  | 7499/10000 [00:16<00:03, 638.91it/s] 76%|███████▌  | 7565/10000 [00:16<00:04, 603.24it/s] 76%|███████▋  | 7627/10000 [00:16<00:04, 563.68it/s] 77%|███████▋  | 7685/10000 [00:16<00:04, 495.97it/s] 77%|███████▋  | 7737/10000 [00:17<00:04, 468.59it/s] 78%|███████▊  | 7786/10000 [00:17<00:04, 468.80it/s] 79%|███████▊  | 7864/10000 [00:17<00:03, 546.84it/s] 79%|███████▉  | 7944/10000 [00:17<00:03, 606.38it/s] 80%|████████  | 8007/10000 [00:17<00:03, 609.12it/s] 81%|████████  | 8070/10000 [00:17<00:03, 576.75it/s] 81%|████████▏ | 8141/10000 [00:17<00:03, 602.67it/s] 82%|████████▏ | 8209/10000 [00:17<00:02, 618.88it/s] 83%|████████▎ | 8272/10000 [00:17<00:03, 541.40it/s] 83%|████████▎ | 8329/10000 [00:18<00:03, 491.88it/s] 84%|████████▍ | 8381/10000 [00:18<00:03, 456.39it/s] 84%|████████▍ | 8429/10000 [00:18<00:03, 406.88it/s] 85%|████████▍ | 8497/10000 [00:18<00:03, 456.34it/s] 86%|████████▌ | 8551/10000 [00:18<00:03, 476.51it/s] 86%|████████▌ | 8620/10000 [00:18<00:02, 526.61it/s] 87%|████████▋ | 8740/10000 [00:18<00:01, 707.35it/s] 88%|████████▊ | 8815/10000 [00:18<00:01, 711.90it/s] 89%|████████▉ | 8891/10000 [00:18<00:01, 721.09it/s] 90%|████████▉ | 8979/10000 [00:19<00:01, 749.04it/s] 91%|█████████ | 9056/10000 [00:19<00:01, 697.60it/s] 91%|█████████▏| 9129/10000 [00:19<00:01, 692.04it/s] 92%|█████████▏| 9200/10000 [00:19<00:01, 678.76it/s] 93%|█████████▎| 9269/10000 [00:19<00:01, 546.05it/s] 93%|█████████▎| 9328/10000 [00:19<00:01, 437.69it/s] 94%|█████████▍| 9378/10000 [00:19<00:01, 431.30it/s] 94%|█████████▍| 9426/10000 [00:20<00:01, 420.37it/s] 95%|█████████▍| 9471/10000 [00:20<00:01, 424.21it/s] 95%|█████████▌| 9516/10000 [00:20<00:01, 407.83it/s] 96%|█████████▌| 9559/10000 [00:20<00:01, 342.14it/s] 96%|█████████▌| 9601/10000 [00:20<00:01, 355.33it/s] 97%|█████████▋| 9661/10000 [00:20<00:00, 414.33it/s] 97%|█████████▋| 9706/10000 [00:20<00:00, 410.91it/s] 97%|█████████▋| 9749/10000 [00:20<00:00, 403.39it/s] 98%|█████████▊| 9817/10000 [00:21<00:00, 475.23it/s] 99%|█████████▉| 9883/10000 [00:21<00:00, 523.97it/s]100%|█████████▉| 9960/10000 [00:21<00:00, 591.23it/s]100%|██████████| 10000/10000 [00:21<00:00, 471.05it/s]
test_neglected_p56 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p56
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p56.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.01it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.00it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.16it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.40it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.24it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.33it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.69it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.94it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.50it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p56_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p56_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p56_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p56_Holmes_probs.npy
{'Accuracy': 0.0205, 'Precision': 0.025, 'Recall': 0.0203, 'F1-score': 0.018}
starting gen taf script for test_neglected_p57
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 70/10000 [00:00<00:15, 659.51it/s]  1%|▏         | 136/10000 [00:00<00:24, 398.45it/s]  2%|▏         | 182/10000 [00:00<00:24, 393.49it/s]  2%|▏         | 225/10000 [00:00<00:28, 346.22it/s]  3%|▎         | 262/10000 [00:00<00:29, 332.09it/s]  3%|▎         | 297/10000 [00:00<00:31, 305.65it/s]  3%|▎         | 329/10000 [00:00<00:31, 307.01it/s]  4%|▎         | 371/10000 [00:01<00:28, 333.27it/s]  4%|▍         | 406/10000 [00:01<00:31, 306.11it/s]  4%|▍         | 438/10000 [00:01<00:31, 298.86it/s]  5%|▍         | 475/10000 [00:01<00:30, 315.36it/s]  5%|▌         | 512/10000 [00:01<00:29, 324.99it/s]  5%|▌         | 545/10000 [00:01<00:34, 276.79it/s]  6%|▌         | 583/10000 [00:01<00:31, 302.68it/s]  6%|▌         | 615/10000 [00:01<00:31, 299.59it/s]  7%|▋         | 652/10000 [00:02<00:29, 314.66it/s]  7%|▋         | 694/10000 [00:02<00:27, 341.18it/s]  7%|▋         | 729/10000 [00:02<00:27, 337.19it/s]  8%|▊         | 771/10000 [00:02<00:26, 348.70it/s]  8%|▊         | 827/10000 [00:02<00:22, 407.96it/s]  9%|▉         | 886/10000 [00:02<00:20, 455.31it/s]  9%|▉         | 943/10000 [00:02<00:18, 486.85it/s] 10%|█         | 1014/10000 [00:02<00:17, 527.27it/s] 11%|█         | 1067/10000 [00:02<00:17, 500.45it/s] 11%|█         | 1118/10000 [00:03<00:21, 422.36it/s] 12%|█▏        | 1181/10000 [00:03<00:18, 470.45it/s] 12%|█▏        | 1231/10000 [00:03<00:20, 432.22it/s] 13%|█▎        | 1333/10000 [00:03<00:15, 571.38it/s] 14%|█▍        | 1397/10000 [00:03<00:14, 589.13it/s] 15%|█▍        | 1459/10000 [00:03<00:19, 436.44it/s] 15%|█▌        | 1510/10000 [00:03<00:24, 341.47it/s] 16%|█▌        | 1552/10000 [00:04<00:28, 296.84it/s] 16%|█▌        | 1588/10000 [00:04<00:30, 278.98it/s] 17%|█▋        | 1678/10000 [00:04<00:21, 394.52it/s] 17%|█▋        | 1743/10000 [00:04<00:18, 441.36it/s] 18%|█▊        | 1810/10000 [00:04<00:16, 491.39it/s] 19%|█▉        | 1908/10000 [00:04<00:13, 605.22it/s] 20%|█▉        | 1989/10000 [00:04<00:12, 643.58it/s] 21%|██        | 2059/10000 [00:04<00:12, 624.15it/s] 21%|██▏       | 2125/10000 [00:05<00:13, 586.75it/s] 22%|██▏       | 2187/10000 [00:05<00:14, 537.72it/s] 22%|██▏       | 2244/10000 [00:05<00:15, 488.57it/s] 23%|██▎       | 2295/10000 [00:05<00:16, 464.64it/s] 23%|██▎       | 2343/10000 [00:05<00:19, 392.17it/s] 24%|██▍       | 2397/10000 [00:05<00:18, 414.56it/s] 25%|██▍       | 2452/10000 [00:05<00:16, 446.98it/s] 25%|██▌       | 2502/10000 [00:06<00:16, 455.02it/s] 26%|██▌       | 2586/10000 [00:06<00:13, 550.41it/s] 26%|██▋       | 2644/10000 [00:06<00:17, 409.57it/s] 27%|██▋       | 2692/10000 [00:06<00:19, 366.34it/s] 27%|██▋       | 2734/10000 [00:06<00:22, 318.85it/s] 28%|██▊       | 2770/10000 [00:06<00:24, 290.27it/s] 28%|██▊       | 2804/10000 [00:06<00:24, 298.53it/s] 28%|██▊       | 2847/10000 [00:07<00:21, 326.63it/s] 29%|██▉       | 2906/10000 [00:07<00:18, 384.22it/s] 30%|██▉       | 2965/10000 [00:07<00:16, 429.91it/s] 30%|███       | 3029/10000 [00:07<00:15, 450.37it/s] 31%|███       | 3076/10000 [00:07<00:16, 429.44it/s] 31%|███       | 3121/10000 [00:07<00:16, 415.34it/s] 32%|███▏      | 3164/10000 [00:07<00:17, 396.93it/s] 32%|███▏      | 3205/10000 [00:07<00:17, 388.60it/s] 33%|███▎      | 3285/10000 [00:08<00:13, 487.94it/s] 34%|███▎      | 3358/10000 [00:08<00:12, 553.48it/s] 34%|███▍      | 3434/10000 [00:08<00:11, 557.27it/s] 35%|███▍      | 3492/10000 [00:08<00:11, 558.66it/s] 36%|███▌      | 3572/10000 [00:08<00:10, 609.58it/s] 36%|███▋      | 3637/10000 [00:08<00:10, 619.04it/s] 37%|███▋      | 3724/10000 [00:08<00:09, 678.69it/s] 38%|███▊      | 3797/10000 [00:08<00:09, 675.94it/s] 39%|███▊      | 3865/10000 [00:08<00:10, 562.28it/s] 39%|███▉      | 3941/10000 [00:09<00:10, 588.19it/s] 40%|████      | 4003/10000 [00:09<00:11, 538.39it/s] 41%|████      | 4059/10000 [00:09<00:10, 543.70it/s] 41%|████▏     | 4145/10000 [00:09<00:09, 617.58it/s] 42%|████▏     | 4218/10000 [00:09<00:08, 645.23it/s] 43%|████▎     | 4295/10000 [00:09<00:08, 673.89it/s] 44%|████▍     | 4378/10000 [00:09<00:07, 707.08it/s] 44%|████▍     | 4450/10000 [00:09<00:08, 620.30it/s] 45%|████▌     | 4515/10000 [00:10<00:11, 479.19it/s] 46%|████▌     | 4570/10000 [00:10<00:12, 441.97it/s] 46%|████▌     | 4619/10000 [00:10<00:12, 439.33it/s] 47%|████▋     | 4666/10000 [00:10<00:12, 432.83it/s] 47%|████▋     | 4712/10000 [00:10<00:12, 422.97it/s] 48%|████▊     | 4756/10000 [00:10<00:12, 406.92it/s] 48%|████▊     | 4801/10000 [00:10<00:12, 417.92it/s] 48%|████▊     | 4844/10000 [00:10<00:13, 396.56it/s] 49%|████▉     | 4885/10000 [00:11<00:16, 317.65it/s] 49%|████▉     | 4928/10000 [00:11<00:15, 337.54it/s] 50%|████▉     | 4968/10000 [00:11<00:14, 344.25it/s] 50%|█████     | 5005/10000 [00:11<00:14, 349.98it/s] 51%|█████     | 5071/10000 [00:11<00:11, 431.47it/s] 51%|█████     | 5119/10000 [00:11<00:11, 438.79it/s] 52%|█████▏    | 5180/10000 [00:11<00:10, 478.84it/s] 52%|█████▏    | 5229/10000 [00:11<00:10, 434.18it/s] 53%|█████▎    | 5274/10000 [00:12<00:13, 354.25it/s] 53%|█████▎    | 5313/10000 [00:12<00:14, 327.32it/s] 53%|█████▎    | 5348/10000 [00:12<00:15, 306.81it/s] 54%|█████▍    | 5381/10000 [00:12<00:16, 286.96it/s] 54%|█████▍    | 5421/10000 [00:12<00:14, 310.98it/s] 55%|█████▍    | 5474/10000 [00:12<00:12, 358.48it/s] 55%|█████▌    | 5524/10000 [00:12<00:11, 392.73it/s] 56%|█████▌    | 5570/10000 [00:12<00:11, 400.91it/s] 56%|█████▋    | 5631/10000 [00:13<00:09, 455.37it/s] 57%|█████▋    | 5687/10000 [00:13<00:08, 480.46it/s] 58%|█████▊    | 5780/10000 [00:13<00:07, 588.08it/s] 58%|█████▊    | 5840/10000 [00:13<00:07, 580.42it/s] 59%|█████▉    | 5899/10000 [00:13<00:08, 456.78it/s] 59%|█████▉    | 5949/10000 [00:13<00:10, 403.45it/s] 60%|█████▉    | 5995/10000 [00:13<00:09, 411.78it/s] 61%|██████    | 6053/10000 [00:13<00:08, 447.27it/s] 61%|██████    | 6103/10000 [00:14<00:08, 450.29it/s] 62%|██████▏   | 6177/10000 [00:14<00:07, 520.07it/s] 62%|██████▏   | 6231/10000 [00:14<00:07, 496.02it/s] 63%|██████▎   | 6283/10000 [00:14<00:09, 388.34it/s] 63%|██████▎   | 6327/10000 [00:14<00:10, 363.31it/s] 64%|██████▎   | 6367/10000 [00:14<00:10, 344.10it/s] 64%|██████▍   | 6414/10000 [00:14<00:09, 372.98it/s] 65%|██████▍   | 6454/10000 [00:14<00:10, 351.31it/s] 65%|██████▌   | 6509/10000 [00:15<00:09, 385.31it/s] 65%|██████▌   | 6549/10000 [00:15<00:09, 347.54it/s] 66%|██████▌   | 6588/10000 [00:15<00:09, 357.08it/s] 66%|██████▋   | 6641/10000 [00:15<00:08, 401.65it/s] 67%|██████▋   | 6685/10000 [00:15<00:08, 405.19it/s] 67%|██████▋   | 6727/10000 [00:15<00:08, 387.91it/s] 68%|██████▊   | 6777/10000 [00:15<00:07, 406.62it/s] 69%|██████▊   | 6863/10000 [00:15<00:06, 519.93it/s] 69%|██████▉   | 6929/10000 [00:15<00:05, 550.21it/s] 70%|██████▉   | 6992/10000 [00:16<00:05, 571.16it/s] 70%|███████   | 7050/10000 [00:16<00:05, 564.69it/s] 71%|███████   | 7107/10000 [00:16<00:05, 557.47it/s] 72%|███████▏  | 7175/10000 [00:16<00:04, 592.51it/s] 72%|███████▏  | 7246/10000 [00:16<00:04, 621.33it/s] 73%|███████▎  | 7309/10000 [00:16<00:04, 620.08it/s] 74%|███████▍  | 7387/10000 [00:16<00:03, 653.26it/s] 75%|███████▍  | 7455/10000 [00:16<00:04, 635.75it/s] 75%|███████▌  | 7519/10000 [00:16<00:03, 620.27it/s] 76%|███████▌  | 7585/10000 [00:17<00:03, 621.97it/s] 76%|███████▋  | 7648/10000 [00:17<00:04, 541.74it/s] 77%|███████▋  | 7704/10000 [00:17<00:04, 507.87it/s] 78%|███████▊  | 7757/10000 [00:17<00:05, 417.64it/s] 78%|███████▊  | 7820/10000 [00:17<00:04, 465.88it/s] 79%|███████▉  | 7887/10000 [00:17<00:04, 511.16it/s] 80%|███████▉  | 7968/10000 [00:17<00:03, 582.14it/s] 80%|████████  | 8033/10000 [00:17<00:03, 591.06it/s] 81%|████████  | 8095/10000 [00:18<00:03, 596.77it/s] 82%|████████▏ | 8157/10000 [00:18<00:03, 587.04it/s] 82%|████████▏ | 8217/10000 [00:18<00:03, 546.05it/s] 83%|████████▎ | 8273/10000 [00:18<00:03, 514.71it/s] 83%|████████▎ | 8326/10000 [00:18<00:03, 493.47it/s] 84%|████████▍ | 8377/10000 [00:18<00:03, 454.95it/s] 84%|████████▍ | 8424/10000 [00:18<00:03, 431.57it/s] 85%|████████▍ | 8482/10000 [00:18<00:03, 450.95it/s] 85%|████████▌ | 8545/10000 [00:19<00:03, 484.78it/s] 86%|████████▌ | 8602/10000 [00:19<00:02, 507.40it/s] 87%|████████▋ | 8665/10000 [00:19<00:02, 537.51it/s] 87%|████████▋ | 8739/10000 [00:19<00:02, 591.35it/s] 88%|████████▊ | 8814/10000 [00:19<00:01, 634.44it/s] 89%|████████▉ | 8889/10000 [00:19<00:01, 667.09it/s] 90%|████████▉ | 8979/10000 [00:19<00:01, 730.99it/s] 91%|█████████ | 9060/10000 [00:19<00:01, 753.85it/s] 91%|█████████▏| 9136/10000 [00:19<00:01, 731.03it/s] 92%|█████████▏| 9211/10000 [00:19<00:01, 685.41it/s] 93%|█████████▎| 9281/10000 [00:20<00:01, 502.30it/s] 93%|█████████▎| 9339/10000 [00:20<00:01, 430.59it/s] 94%|█████████▍| 9389/10000 [00:20<00:01, 375.21it/s] 94%|█████████▍| 9432/10000 [00:20<00:01, 371.83it/s] 95%|█████████▍| 9473/10000 [00:20<00:01, 354.38it/s] 95%|█████████▌| 9529/10000 [00:20<00:01, 388.53it/s] 96%|█████████▌| 9574/10000 [00:21<00:01, 397.97it/s] 96%|█████████▌| 9622/10000 [00:21<00:00, 416.67it/s] 97%|█████████▋| 9667/10000 [00:21<00:00, 419.38it/s] 97%|█████████▋| 9711/10000 [00:21<00:00, 390.28it/s] 98%|█████████▊| 9752/10000 [00:21<00:00, 390.05it/s] 98%|█████████▊| 9816/10000 [00:21<00:00, 453.97it/s] 99%|█████████▊| 9873/10000 [00:21<00:00, 477.92it/s] 99%|█████████▉| 9937/10000 [00:21<00:00, 517.86it/s]100%|██████████| 10000/10000 [00:21<00:00, 457.52it/s]
test_neglected_p57 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p57
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p57.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.11s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.34it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.22it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.26it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.12it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.32it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.81it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.44it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.30it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p57_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p57_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p57_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p57_Holmes_probs.npy
{'Accuracy': 0.0204, 'Precision': 0.0232, 'Recall': 0.0202, 'F1-score': 0.0178}
starting gen taf script for test_neglected_p58
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 76/10000 [00:00<00:13, 729.18it/s]  1%|▏         | 149/10000 [00:00<00:27, 360.98it/s]  2%|▏         | 195/10000 [00:00<00:29, 335.23it/s]  2%|▏         | 234/10000 [00:00<00:34, 285.36it/s]  3%|▎         | 266/10000 [00:00<00:35, 274.31it/s]  3%|▎         | 295/10000 [00:00<00:36, 264.97it/s]  3%|▎         | 323/10000 [00:01<00:37, 260.54it/s]  4%|▎         | 350/10000 [00:01<00:37, 258.23it/s]  4%|▍         | 377/10000 [00:01<00:36, 260.31it/s]  4%|▍         | 404/10000 [00:01<00:38, 250.76it/s]  4%|▍         | 446/10000 [00:01<00:32, 291.60it/s]  5%|▍         | 490/10000 [00:01<00:28, 330.22it/s]  5%|▌         | 532/10000 [00:01<00:27, 350.42it/s]  6%|▌         | 568/10000 [00:01<00:33, 284.71it/s]  6%|▌         | 608/10000 [00:02<00:30, 312.88it/s]  6%|▋         | 642/10000 [00:02<00:30, 303.84it/s]  7%|▋         | 674/10000 [00:02<00:33, 278.54it/s]  7%|▋         | 722/10000 [00:02<00:28, 325.46it/s]  8%|▊         | 776/10000 [00:02<00:24, 376.90it/s]  8%|▊         | 839/10000 [00:02<00:21, 432.81it/s]  9%|▉         | 885/10000 [00:02<00:20, 438.41it/s]  9%|▉         | 930/10000 [00:02<00:20, 436.28it/s] 10%|█         | 1004/10000 [00:02<00:17, 521.95it/s] 11%|█         | 1058/10000 [00:03<00:21, 424.59it/s] 11%|█         | 1105/10000 [00:03<00:20, 427.82it/s] 12%|█▏        | 1151/10000 [00:03<00:23, 372.09it/s] 12%|█▏        | 1192/10000 [00:03<00:23, 380.13it/s] 13%|█▎        | 1251/10000 [00:03<00:20, 431.31it/s] 13%|█▎        | 1322/10000 [00:03<00:17, 499.67it/s] 14%|█▍        | 1406/10000 [00:03<00:14, 574.83it/s] 15%|█▍        | 1466/10000 [00:04<00:20, 425.03it/s] 15%|█▌        | 1516/10000 [00:04<00:23, 358.88it/s] 16%|█▌        | 1558/10000 [00:04<00:27, 306.96it/s] 16%|█▌        | 1594/10000 [00:04<00:29, 288.18it/s] 16%|█▋        | 1635/10000 [00:04<00:26, 310.01it/s] 17%|█▋        | 1692/10000 [00:04<00:22, 367.77it/s] 18%|█▊        | 1751/10000 [00:04<00:19, 418.58it/s] 19%|█▊        | 1854/10000 [00:04<00:14, 568.79it/s] 20%|█▉        | 1956/10000 [00:05<00:11, 688.15it/s] 20%|██        | 2030/10000 [00:05<00:12, 649.04it/s] 21%|██        | 2104/10000 [00:05<00:12, 657.04it/s] 22%|██▏       | 2173/10000 [00:05<00:12, 625.95it/s] 22%|██▏       | 2238/10000 [00:05<00:13, 562.68it/s] 23%|██▎       | 2297/10000 [00:05<00:15, 492.00it/s] 23%|██▎       | 2349/10000 [00:05<00:17, 426.11it/s] 24%|██▍       | 2395/10000 [00:06<00:18, 414.40it/s] 25%|██▍       | 2464/10000 [00:06<00:15, 472.15it/s] 25%|██▌       | 2514/10000 [00:06<00:15, 477.43it/s] 26%|██▌       | 2564/10000 [00:06<00:15, 471.01it/s] 26%|██▌       | 2613/10000 [00:06<00:15, 469.12it/s] 27%|██▋       | 2661/10000 [00:06<00:21, 347.71it/s] 27%|██▋       | 2701/10000 [00:06<00:22, 321.76it/s] 27%|██▋       | 2737/10000 [00:06<00:23, 306.68it/s] 28%|██▊       | 2770/10000 [00:07<00:26, 277.68it/s] 28%|██▊       | 2800/10000 [00:07<00:25, 279.15it/s] 28%|██▊       | 2837/10000 [00:07<00:23, 300.87it/s] 29%|██▉       | 2925/10000 [00:07<00:16, 428.25it/s] 30%|██▉       | 2976/10000 [00:07<00:15, 448.12it/s] 30%|███       | 3023/10000 [00:07<00:16, 423.54it/s] 31%|███       | 3067/10000 [00:07<00:16, 411.95it/s] 31%|███       | 3109/10000 [00:07<00:18, 367.56it/s] 31%|███▏      | 3147/10000 [00:08<00:18, 369.41it/s] 32%|███▏      | 3189/10000 [00:08<00:17, 381.18it/s] 33%|███▎      | 3257/10000 [00:08<00:14, 457.62it/s] 33%|███▎      | 3322/10000 [00:08<00:13, 507.34it/s] 34%|███▍      | 3392/10000 [00:08<00:11, 553.11it/s] 35%|███▍      | 3452/10000 [00:08<00:11, 565.12it/s] 35%|███▌      | 3510/10000 [00:08<00:11, 551.44it/s] 36%|███▌      | 3579/10000 [00:08<00:10, 586.77it/s] 37%|███▋      | 3663/10000 [00:08<00:09, 652.83it/s] 37%|███▋      | 3733/10000 [00:08<00:09, 665.98it/s] 38%|███▊      | 3800/10000 [00:09<00:09, 630.37it/s] 39%|███▊      | 3864/10000 [00:09<00:10, 604.05it/s] 39%|███▉      | 3930/10000 [00:09<00:10, 601.91it/s] 40%|███▉      | 3991/10000 [00:09<00:10, 567.84it/s] 41%|████      | 4056/10000 [00:09<00:10, 580.04it/s] 41%|████▏     | 4136/10000 [00:09<00:09, 636.17it/s] 42%|████▏     | 4224/10000 [00:09<00:08, 698.57it/s] 43%|████▎     | 4295/10000 [00:09<00:08, 673.45it/s] 44%|████▎     | 4371/10000 [00:09<00:08, 687.14it/s] 44%|████▍     | 4441/10000 [00:10<00:09, 583.94it/s] 45%|████▌     | 4503/10000 [00:10<00:10, 527.10it/s] 46%|████▌     | 4559/10000 [00:10<00:11, 460.92it/s] 46%|████▌     | 4608/10000 [00:10<00:12, 427.47it/s] 47%|████▋     | 4653/10000 [00:10<00:12, 426.02it/s] 47%|████▋     | 4698/10000 [00:10<00:12, 419.75it/s] 47%|████▋     | 4741/10000 [00:10<00:13, 401.05it/s] 48%|████▊     | 4795/10000 [00:11<00:12, 428.36it/s] 48%|████▊     | 4839/10000 [00:11<00:13, 389.08it/s] 49%|████▉     | 4879/10000 [00:11<00:14, 355.20it/s] 49%|████▉     | 4916/10000 [00:11<00:14, 347.27it/s] 50%|████▉     | 4952/10000 [00:11<00:17, 293.55it/s] 50%|████▉     | 4983/10000 [00:11<00:18, 265.70it/s] 50%|█████     | 5038/10000 [00:11<00:15, 326.75it/s] 51%|█████     | 5103/10000 [00:11<00:12, 402.53it/s] 52%|█████▏    | 5158/10000 [00:12<00:11, 424.77it/s] 52%|█████▏    | 5203/10000 [00:12<00:12, 394.01it/s] 52%|█████▏    | 5245/10000 [00:12<00:13, 362.68it/s] 53%|█████▎    | 5284/10000 [00:12<00:12, 369.41it/s] 53%|█████▎    | 5323/10000 [00:12<00:13, 336.29it/s] 54%|█████▎    | 5358/10000 [00:12<00:15, 300.87it/s] 54%|█████▍    | 5390/10000 [00:12<00:17, 269.65it/s] 54%|█████▍    | 5444/10000 [00:13<00:14, 315.87it/s] 55%|█████▌    | 5520/10000 [00:13<00:10, 416.09it/s] 56%|█████▌    | 5571/10000 [00:13<00:10, 421.81it/s] 56%|█████▋    | 5637/10000 [00:13<00:09, 475.14it/s] 57%|█████▋    | 5714/10000 [00:13<00:07, 553.31it/s] 58%|█████▊    | 5775/10000 [00:13<00:07, 562.09it/s] 58%|█████▊    | 5833/10000 [00:13<00:07, 544.71it/s] 59%|█████▉    | 5889/10000 [00:13<00:08, 479.58it/s] 59%|█████▉    | 5940/10000 [00:14<00:09, 421.66it/s] 60%|█████▉    | 5985/10000 [00:14<00:10, 379.63it/s] 60%|██████    | 6048/10000 [00:14<00:09, 435.98it/s] 61%|██████    | 6112/10000 [00:14<00:08, 482.66it/s] 62%|██████▏   | 6176/10000 [00:14<00:07, 513.05it/s] 62%|██████▏   | 6235/10000 [00:14<00:07, 480.16it/s] 63%|██████▎   | 6285/10000 [00:14<00:07, 478.23it/s] 63%|██████▎   | 6335/10000 [00:14<00:09, 399.35it/s] 64%|██████▍   | 6378/10000 [00:15<00:10, 345.94it/s] 64%|██████▍   | 6416/10000 [00:15<00:10, 329.60it/s] 65%|██████▍   | 6451/10000 [00:15<00:10, 333.63it/s] 65%|██████▍   | 6491/10000 [00:15<00:10, 349.24it/s] 66%|██████▌   | 6551/10000 [00:15<00:08, 403.78it/s] 66%|██████▌   | 6593/10000 [00:15<00:09, 364.29it/s] 66%|██████▋   | 6650/10000 [00:15<00:08, 409.56it/s] 67%|██████▋   | 6693/10000 [00:15<00:08, 409.76it/s] 67%|██████▋   | 6737/10000 [00:16<00:08, 398.04it/s] 68%|██████▊   | 6788/10000 [00:16<00:07, 422.37it/s] 68%|██████▊   | 6845/10000 [00:16<00:06, 460.71it/s] 69%|██████▉   | 6923/10000 [00:16<00:05, 547.06it/s] 70%|██████▉   | 6996/10000 [00:16<00:05, 584.00it/s] 71%|███████   | 7056/10000 [00:16<00:05, 580.97it/s] 71%|███████   | 7115/10000 [00:16<00:05, 568.40it/s] 72%|███████▏  | 7176/10000 [00:16<00:04, 575.40it/s] 73%|███████▎  | 7252/10000 [00:16<00:04, 624.82it/s] 73%|███████▎  | 7315/10000 [00:16<00:04, 593.44it/s] 74%|███████▍  | 7375/10000 [00:17<00:04, 586.16it/s] 74%|███████▍  | 7434/10000 [00:17<00:04, 546.10it/s] 75%|███████▌  | 7502/10000 [00:17<00:04, 581.65it/s] 76%|███████▌  | 7578/10000 [00:17<00:03, 626.10it/s] 76%|███████▋  | 7642/10000 [00:17<00:04, 501.43it/s] 77%|███████▋  | 7697/10000 [00:17<00:05, 451.13it/s] 77%|███████▋  | 7746/10000 [00:17<00:05, 449.07it/s] 78%|███████▊  | 7794/10000 [00:17<00:05, 421.38it/s] 79%|███████▉  | 7879/10000 [00:18<00:04, 522.99it/s] 79%|███████▉  | 7947/10000 [00:18<00:03, 556.35it/s] 80%|████████  | 8013/10000 [00:18<00:03, 577.60it/s] 81%|████████  | 8075/10000 [00:18<00:03, 580.50it/s] 82%|████████▏ | 8154/10000 [00:18<00:02, 625.67it/s] 82%|████████▏ | 8218/10000 [00:18<00:03, 587.27it/s] 83%|████████▎ | 8278/10000 [00:18<00:03, 505.89it/s] 83%|████████▎ | 8332/10000 [00:18<00:03, 462.94it/s] 84%|████████▍ | 8381/10000 [00:19<00:03, 406.74it/s] 84%|████████▍ | 8424/10000 [00:19<00:03, 402.66it/s] 85%|████████▍ | 8490/10000 [00:19<00:03, 458.51it/s] 85%|████████▌ | 8538/10000 [00:19<00:03, 455.06it/s] 86%|████████▌ | 8602/10000 [00:19<00:02, 499.13it/s] 87%|████████▋ | 8664/10000 [00:19<00:02, 529.68it/s] 87%|████████▋ | 8747/10000 [00:19<00:02, 613.40it/s] 88%|████████▊ | 8832/10000 [00:19<00:01, 670.11it/s] 89%|████████▉ | 8917/10000 [00:19<00:01, 695.16it/s] 90%|████████▉ | 8990/10000 [00:20<00:01, 704.62it/s] 91%|█████████ | 9062/10000 [00:20<00:01, 683.40it/s] 91%|█████████▏| 9131/10000 [00:20<00:01, 667.28it/s] 92%|█████████▏| 9199/10000 [00:20<00:01, 641.32it/s] 93%|█████████▎| 9264/10000 [00:20<00:01, 554.20it/s] 93%|█████████▎| 9322/10000 [00:20<00:01, 427.50it/s] 94%|█████████▎| 9371/10000 [00:20<00:01, 413.33it/s] 94%|█████████▍| 9416/10000 [00:21<00:01, 355.70it/s] 95%|█████████▍| 9460/10000 [00:21<00:01, 368.33it/s] 95%|█████████▌| 9522/10000 [00:21<00:01, 402.58it/s] 96%|█████████▌| 9565/10000 [00:21<00:01, 407.33it/s] 96%|█████████▌| 9608/10000 [00:21<00:00, 412.06it/s] 97%|█████████▋| 9661/10000 [00:21<00:00, 434.96it/s] 97%|█████████▋| 9715/10000 [00:21<00:00, 460.74it/s] 98%|█████████▊| 9763/10000 [00:21<00:00, 417.56it/s] 98%|█████████▊| 9827/10000 [00:21<00:00, 474.90it/s] 99%|█████████▉| 9916/10000 [00:22<00:00, 587.85it/s]100%|██████████| 10000/10000 [00:22<00:00, 450.92it/s]
test_neglected_p58 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p58
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p58.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.05s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.73it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.82it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.05it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.92it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.69it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.07it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.56it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.88it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p58_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p58_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p58_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p58_Holmes_probs.npy
{'Accuracy': 0.0208, 'Precision': 0.0226, 'Recall': 0.0206, 'F1-score': 0.0179}
starting gen taf script for test_neglected_p59
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 109/10000 [00:00<00:10, 986.10it/s]  2%|▏         | 208/10000 [00:00<00:21, 453.75it/s]  3%|▎         | 268/10000 [00:00<00:25, 386.30it/s]  3%|▎         | 314/10000 [00:00<00:27, 349.52it/s]  4%|▎         | 353/10000 [00:00<00:32, 297.34it/s]  4%|▍         | 386/10000 [00:01<00:32, 299.61it/s]  4%|▍         | 426/10000 [00:01<00:29, 321.85it/s]  5%|▍         | 467/10000 [00:01<00:27, 343.41it/s]  5%|▌         | 514/10000 [00:01<00:25, 371.84it/s]  6%|▌         | 554/10000 [00:01<00:25, 374.72it/s]  6%|▌         | 596/10000 [00:01<00:24, 383.12it/s]  6%|▋         | 646/10000 [00:01<00:22, 411.45it/s]  7%|▋         | 737/10000 [00:01<00:16, 546.00it/s]  8%|▊         | 802/10000 [00:01<00:16, 563.70it/s]  9%|▊         | 860/10000 [00:02<00:17, 529.67it/s]  9%|▉         | 914/10000 [00:02<00:17, 516.41it/s] 10%|▉         | 982/10000 [00:02<00:16, 543.40it/s] 10%|█         | 1037/10000 [00:02<00:17, 501.18it/s] 11%|█         | 1088/10000 [00:02<00:19, 467.51it/s] 11%|█▏        | 1136/10000 [00:02<00:20, 422.46it/s] 12%|█▏        | 1188/10000 [00:02<00:19, 444.50it/s] 12%|█▏        | 1234/10000 [00:02<00:20, 435.52it/s] 13%|█▎        | 1312/10000 [00:02<00:16, 526.75it/s] 14%|█▍        | 1377/10000 [00:03<00:15, 558.69it/s] 14%|█▍        | 1435/10000 [00:03<00:17, 483.25it/s] 15%|█▍        | 1486/10000 [00:03<00:21, 393.66it/s] 15%|█▌        | 1530/10000 [00:03<00:28, 298.51it/s] 16%|█▌        | 1566/10000 [00:03<00:29, 287.56it/s] 16%|█▌        | 1599/10000 [00:03<00:29, 280.99it/s] 17%|█▋        | 1667/10000 [00:04<00:23, 360.90it/s] 17%|█▋        | 1729/10000 [00:04<00:19, 421.14it/s] 18%|█▊        | 1810/10000 [00:04<00:15, 517.51it/s] 19%|█▉        | 1925/10000 [00:04<00:11, 676.48it/s] 20%|█▉        | 1999/10000 [00:04<00:12, 657.29it/s] 21%|██        | 2069/10000 [00:04<00:11, 665.58it/s] 21%|██▏       | 2139/10000 [00:04<00:12, 609.16it/s] 22%|██▏       | 2203/10000 [00:04<00:12, 612.52it/s] 23%|██▎       | 2267/10000 [00:05<00:16, 479.52it/s] 23%|██▎       | 2321/10000 [00:05<00:17, 438.36it/s] 24%|██▎       | 2369/10000 [00:05<00:18, 408.14it/s] 24%|██▍       | 2413/10000 [00:05<00:18, 411.77it/s] 25%|██▍       | 2492/10000 [00:05<00:15, 495.27it/s] 26%|██▌       | 2551/10000 [00:05<00:14, 511.62it/s] 26%|██▌       | 2605/10000 [00:05<00:14, 506.76it/s] 27%|██▋       | 2658/10000 [00:06<00:19, 375.04it/s] 27%|██▋       | 2702/10000 [00:06<00:22, 323.79it/s] 27%|██▋       | 2740/10000 [00:06<00:25, 287.84it/s] 28%|██▊       | 2773/10000 [00:06<00:26, 273.08it/s] 28%|██▊       | 2803/10000 [00:06<00:26, 273.50it/s] 28%|██▊       | 2845/10000 [00:06<00:23, 306.83it/s] 29%|██▉       | 2909/10000 [00:06<00:18, 387.77it/s] 30%|██▉       | 2952/10000 [00:06<00:17, 392.47it/s] 30%|██▉       | 2999/10000 [00:07<00:16, 412.13it/s] 30%|███       | 3047/10000 [00:07<00:16, 430.65it/s] 31%|███       | 3092/10000 [00:07<00:17, 384.23it/s] 32%|███▏      | 3150/10000 [00:07<00:16, 423.07it/s] 32%|███▏      | 3194/10000 [00:07<00:16, 401.62it/s] 33%|███▎      | 3273/10000 [00:07<00:13, 503.45it/s] 34%|███▍      | 3375/10000 [00:07<00:10, 634.57it/s] 34%|███▍      | 3442/10000 [00:07<00:10, 626.35it/s] 35%|███▌      | 3507/10000 [00:07<00:11, 576.12it/s] 36%|███▌      | 3567/10000 [00:08<00:12, 522.44it/s] 36%|███▋      | 3649/10000 [00:08<00:10, 591.46it/s] 38%|███▊      | 3751/10000 [00:08<00:08, 699.49it/s] 38%|███▊      | 3835/10000 [00:08<00:08, 701.66it/s] 39%|███▉      | 3908/10000 [00:08<00:10, 604.67it/s] 40%|███▉      | 3972/10000 [00:08<00:09, 606.49it/s] 40%|████      | 4036/10000 [00:08<00:09, 609.54it/s] 41%|████      | 4112/10000 [00:08<00:09, 641.94it/s] 42%|████▏     | 4185/10000 [00:09<00:08, 666.05it/s] 43%|████▎     | 4254/10000 [00:09<00:08, 666.20it/s] 43%|████▎     | 4328/10000 [00:09<00:08, 674.98it/s] 44%|████▍     | 4397/10000 [00:09<00:08, 651.99it/s] 45%|████▍     | 4463/10000 [00:09<00:10, 517.43it/s] 45%|████▌     | 4520/10000 [00:09<00:11, 483.66it/s] 46%|████▌     | 4572/10000 [00:09<00:12, 427.20it/s] 46%|████▌     | 4618/10000 [00:09<00:12, 420.23it/s] 47%|████▋     | 4662/10000 [00:10<00:14, 377.79it/s] 47%|████▋     | 4702/10000 [00:10<00:13, 379.45it/s] 48%|████▊     | 4764/10000 [00:10<00:12, 432.50it/s] 48%|████▊     | 4809/10000 [00:10<00:13, 388.94it/s] 48%|████▊     | 4850/10000 [00:10<00:15, 333.78it/s] 49%|████▉     | 4894/10000 [00:10<00:14, 351.81it/s] 49%|████▉     | 4932/10000 [00:10<00:14, 342.75it/s] 50%|████▉     | 4968/10000 [00:11<00:15, 316.30it/s] 50%|█████     | 5005/10000 [00:11<00:15, 325.19it/s] 50%|█████     | 5048/10000 [00:11<00:14, 345.53it/s] 51%|█████     | 5096/10000 [00:11<00:12, 381.13it/s] 51%|█████▏    | 5149/10000 [00:11<00:11, 413.78it/s] 52%|█████▏    | 5202/10000 [00:11<00:10, 444.68it/s] 52%|█████▏    | 5248/10000 [00:11<00:12, 380.38it/s] 53%|█████▎    | 5289/10000 [00:11<00:13, 352.75it/s] 53%|█████▎    | 5326/10000 [00:11<00:14, 313.25it/s] 54%|█████▎    | 5359/10000 [00:12<00:14, 315.37it/s] 54%|█████▍    | 5392/10000 [00:12<00:16, 280.35it/s] 54%|█████▍    | 5437/10000 [00:12<00:14, 321.07it/s] 55%|█████▍    | 5495/10000 [00:12<00:11, 380.82it/s] 55%|█████▌    | 5546/10000 [00:12<00:10, 414.19it/s] 56%|█████▌    | 5617/10000 [00:12<00:09, 482.85it/s] 57%|█████▋    | 5681/10000 [00:12<00:08, 517.27it/s] 58%|█████▊    | 5772/10000 [00:12<00:06, 620.14it/s] 58%|█████▊    | 5836/10000 [00:13<00:08, 505.15it/s] 59%|█████▉    | 5891/10000 [00:13<00:09, 453.29it/s] 59%|█████▉    | 5940/10000 [00:13<00:09, 409.06it/s] 60%|█████▉    | 5984/10000 [00:13<00:09, 412.30it/s] 60%|██████    | 6035/10000 [00:13<00:09, 435.33it/s] 61%|██████    | 6116/10000 [00:13<00:07, 527.98it/s] 62%|██████▏   | 6190/10000 [00:13<00:06, 581.43it/s] 63%|██████▎   | 6251/10000 [00:13<00:07, 507.11it/s] 63%|██████▎   | 6305/10000 [00:14<00:08, 415.47it/s] 64%|██████▎   | 6352/10000 [00:14<00:08, 422.77it/s] 64%|██████▍   | 6398/10000 [00:14<00:09, 372.65it/s] 64%|██████▍   | 6445/10000 [00:14<00:09, 394.19it/s] 65%|██████▍   | 6488/10000 [00:14<00:08, 401.68it/s] 65%|██████▌   | 6531/10000 [00:14<00:09, 368.50it/s] 66%|██████▌   | 6582/10000 [00:14<00:08, 403.87it/s] 66%|██████▋   | 6625/10000 [00:14<00:08, 401.89it/s] 67%|██████▋   | 6667/10000 [00:15<00:08, 390.20it/s] 67%|██████▋   | 6707/10000 [00:15<00:08, 385.83it/s] 68%|██████▊   | 6755/10000 [00:15<00:07, 408.07it/s] 68%|██████▊   | 6821/10000 [00:15<00:06, 475.52it/s] 69%|██████▉   | 6885/10000 [00:15<00:06, 518.79it/s] 70%|██████▉   | 6970/10000 [00:15<00:05, 600.74it/s] 70%|███████   | 7032/10000 [00:15<00:04, 606.00it/s] 71%|███████   | 7093/10000 [00:15<00:05, 576.12it/s] 72%|███████▏  | 7152/10000 [00:15<00:05, 536.96it/s] 72%|███████▏  | 7233/10000 [00:16<00:04, 610.72it/s] 73%|███████▎  | 7306/10000 [00:16<00:04, 638.46it/s] 74%|███████▎  | 7371/10000 [00:16<00:04, 624.15it/s] 74%|███████▍  | 7440/10000 [00:16<00:03, 641.90it/s] 75%|███████▌  | 7510/10000 [00:16<00:03, 656.70it/s] 76%|███████▌  | 7577/10000 [00:16<00:03, 620.72it/s] 76%|███████▋  | 7640/10000 [00:16<00:04, 565.96it/s] 77%|███████▋  | 7698/10000 [00:16<00:05, 454.60it/s] 77%|███████▋  | 7748/10000 [00:17<00:05, 425.08it/s] 78%|███████▊  | 7794/10000 [00:17<00:05, 420.06it/s] 79%|███████▊  | 7859/10000 [00:17<00:04, 475.97it/s] 79%|███████▉  | 7910/10000 [00:17<00:04, 469.23it/s] 80%|███████▉  | 7985/10000 [00:17<00:03, 541.72it/s] 81%|████████  | 8055/10000 [00:17<00:03, 582.50it/s] 81%|████████  | 8116/10000 [00:17<00:03, 581.75it/s] 82%|████████▏ | 8201/10000 [00:17<00:02, 626.25it/s] 83%|████████▎ | 8265/10000 [00:17<00:03, 501.87it/s] 83%|████████▎ | 8320/10000 [00:18<00:03, 464.20it/s] 84%|████████▎ | 8370/10000 [00:18<00:03, 426.18it/s] 84%|████████▍ | 8415/10000 [00:18<00:04, 380.83it/s] 85%|████████▍ | 8491/10000 [00:18<00:03, 465.18it/s] 85%|████████▌ | 8549/10000 [00:18<00:03, 481.13it/s] 86%|████████▌ | 8622/10000 [00:18<00:02, 534.97it/s] 87%|████████▋ | 8710/10000 [00:18<00:02, 620.92it/s] 88%|████████▊ | 8797/10000 [00:18<00:01, 677.15it/s] 89%|████████▊ | 8874/10000 [00:19<00:01, 702.65it/s] 89%|████████▉ | 8947/10000 [00:19<00:01, 701.30it/s] 90%|█████████ | 9031/10000 [00:19<00:01, 729.69it/s] 91%|█████████ | 9114/10000 [00:19<00:01, 754.07it/s] 92%|█████████▏| 9191/10000 [00:19<00:01, 736.96it/s] 93%|█████████▎| 9266/10000 [00:19<00:01, 544.28it/s] 93%|█████████▎| 9328/10000 [00:19<00:01, 442.52it/s] 94%|█████████▍| 9380/10000 [00:20<00:01, 413.53it/s] 94%|█████████▍| 9427/10000 [00:20<00:01, 411.40it/s] 95%|█████████▍| 9472/10000 [00:20<00:01, 419.86it/s] 95%|█████████▌| 9517/10000 [00:20<00:01, 403.68it/s] 96%|█████████▌| 9560/10000 [00:20<00:01, 383.76it/s] 96%|█████████▌| 9621/10000 [00:20<00:00, 435.27it/s] 97%|█████████▋| 9667/10000 [00:20<00:00, 419.50it/s] 97%|█████████▋| 9723/10000 [00:20<00:00, 448.23it/s] 98%|█████████▊| 9776/10000 [00:20<00:00, 467.54it/s] 98%|█████████▊| 9824/10000 [00:21<00:00, 448.88it/s] 99%|█████████▉| 9886/10000 [00:21<00:00, 489.13it/s]100%|█████████▉| 9960/10000 [00:21<00:00, 552.03it/s]100%|██████████| 10000/10000 [00:21<00:00, 468.47it/s]
test_neglected_p59 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p59
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p59.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.12s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.31it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.19it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.26it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.10it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.11it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.54it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.22it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.21it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p59_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p59_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p59_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p59_Holmes_probs.npy
{'Accuracy': 0.0209, 'Precision': 0.0218, 'Recall': 0.0207, 'F1-score': 0.0178}
starting gen taf script for test_neglected_p60
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 64/10000 [00:00<00:15, 639.28it/s]  1%|▏         | 128/10000 [00:00<00:31, 317.83it/s]  2%|▏         | 169/10000 [00:00<00:33, 291.81it/s]  2%|▏         | 203/10000 [00:00<00:33, 293.86it/s]  2%|▏         | 236/10000 [00:00<00:34, 284.87it/s]  3%|▎         | 267/10000 [00:00<00:38, 255.79it/s]  3%|▎         | 294/10000 [00:01<00:41, 236.60it/s]  3%|▎         | 319/10000 [00:01<00:44, 217.41it/s]  3%|▎         | 347/10000 [00:01<00:41, 231.12it/s]  4%|▍         | 375/10000 [00:01<00:40, 240.37it/s]  4%|▍         | 404/10000 [00:01<00:38, 251.40it/s]  4%|▍         | 445/10000 [00:01<00:32, 294.46it/s]  5%|▍         | 492/10000 [00:01<00:27, 342.72it/s]  5%|▌         | 540/10000 [00:01<00:25, 376.09it/s]  6%|▌         | 579/10000 [00:01<00:25, 374.82it/s]  6%|▌         | 620/10000 [00:02<00:24, 383.73it/s]  7%|▋         | 659/10000 [00:02<00:25, 366.97it/s]  7%|▋         | 713/10000 [00:02<00:22, 412.23it/s]  8%|▊         | 766/10000 [00:02<00:21, 432.84it/s]  8%|▊         | 824/10000 [00:02<00:20, 455.60it/s]  9%|▉         | 888/10000 [00:02<00:17, 506.90it/s] 10%|▉         | 954/10000 [00:02<00:16, 548.77it/s] 10%|█         | 1010/10000 [00:02<00:18, 496.00it/s] 11%|█         | 1061/10000 [00:02<00:19, 458.94it/s] 11%|█         | 1109/10000 [00:03<00:20, 431.04it/s] 12%|█▏        | 1154/10000 [00:03<00:22, 394.95it/s] 12%|█▏        | 1195/10000 [00:03<00:22, 397.81it/s] 13%|█▎        | 1253/10000 [00:03<00:19, 439.33it/s] 14%|█▎        | 1352/10000 [00:03<00:14, 584.55it/s] 14%|█▍        | 1414/10000 [00:03<00:14, 587.66it/s] 15%|█▍        | 1475/10000 [00:03<00:21, 398.81it/s] 15%|█▌        | 1524/10000 [00:04<00:24, 352.31it/s] 16%|█▌        | 1566/10000 [00:04<00:28, 295.49it/s] 16%|█▌        | 1607/10000 [00:04<00:26, 311.41it/s] 17%|█▋        | 1696/10000 [00:04<00:19, 433.10it/s] 18%|█▊        | 1752/10000 [00:04<00:18, 455.88it/s] 18%|█▊        | 1808/10000 [00:04<00:17, 476.88it/s] 19%|█▉        | 1903/10000 [00:04<00:13, 595.82it/s] 20%|█▉        | 1983/10000 [00:04<00:12, 643.03it/s] 21%|██        | 2052/10000 [00:05<00:12, 655.41it/s] 21%|██        | 2121/10000 [00:05<00:13, 567.21it/s] 22%|██▏       | 2184/10000 [00:05<00:13, 569.33it/s] 22%|██▏       | 2244/10000 [00:05<00:14, 527.82it/s] 23%|██▎       | 2300/10000 [00:05<00:19, 402.58it/s] 24%|██▎       | 2355/10000 [00:05<00:17, 426.26it/s] 24%|██▍       | 2403/10000 [00:05<00:19, 395.65it/s] 25%|██▍       | 2459/10000 [00:06<00:17, 433.39it/s] 25%|██▌       | 2518/10000 [00:06<00:16, 463.92it/s] 26%|██▌       | 2571/10000 [00:06<00:15, 475.37it/s] 26%|██▌       | 2621/10000 [00:06<00:16, 452.64it/s] 27%|██▋       | 2668/10000 [00:06<00:20, 353.09it/s] 27%|██▋       | 2708/10000 [00:06<00:22, 326.29it/s] 27%|██▋       | 2744/10000 [00:06<00:25, 286.04it/s] 28%|██▊       | 2776/10000 [00:07<00:26, 271.02it/s] 28%|██▊       | 2805/10000 [00:07<00:26, 267.21it/s] 29%|██▊       | 2863/10000 [00:07<00:21, 334.96it/s] 29%|██▉       | 2926/10000 [00:07<00:17, 406.49it/s] 30%|██▉       | 2984/10000 [00:07<00:15, 448.61it/s] 30%|███       | 3032/10000 [00:07<00:15, 448.21it/s] 31%|███       | 3079/10000 [00:07<00:17, 398.36it/s] 31%|███▏      | 3130/10000 [00:07<00:16, 422.69it/s] 32%|███▏      | 3175/10000 [00:07<00:17, 380.28it/s] 32%|███▏      | 3239/10000 [00:08<00:15, 438.25it/s] 33%|███▎      | 3301/10000 [00:08<00:13, 481.82it/s] 34%|███▍      | 3392/10000 [00:08<00:11, 594.02it/s] 35%|███▍      | 3462/10000 [00:08<00:10, 616.38it/s] 35%|███▌      | 3526/10000 [00:08<00:11, 577.43it/s] 36%|███▌      | 3600/10000 [00:08<00:10, 614.71it/s] 37%|███▋      | 3684/10000 [00:08<00:09, 675.57it/s] 38%|███▊      | 3754/10000 [00:08<00:09, 635.42it/s] 38%|███▊      | 3819/10000 [00:08<00:10, 617.74it/s] 39%|███▉      | 3883/10000 [00:09<00:09, 622.91it/s] 39%|███▉      | 3947/10000 [00:09<00:10, 573.91it/s] 40%|████      | 4010/10000 [00:09<00:10, 583.11it/s] 41%|████      | 4095/10000 [00:09<00:09, 652.88it/s] 42%|████▏     | 4167/10000 [00:09<00:08, 670.01it/s] 42%|████▏     | 4235/10000 [00:09<00:08, 665.00it/s] 43%|████▎     | 4303/10000 [00:09<00:08, 645.22it/s] 44%|████▍     | 4387/10000 [00:09<00:08, 680.93it/s] 45%|████▍     | 4456/10000 [00:10<00:10, 546.96it/s] 45%|████▌     | 4515/10000 [00:10<00:11, 492.89it/s] 46%|████▌     | 4568/10000 [00:10<00:11, 479.47it/s] 46%|████▌     | 4619/10000 [00:10<00:13, 387.62it/s] 47%|████▋     | 4662/10000 [00:10<00:13, 396.35it/s] 47%|████▋     | 4705/10000 [00:10<00:13, 388.83it/s] 47%|████▋     | 4746/10000 [00:10<00:14, 370.87it/s] 48%|████▊     | 4789/10000 [00:10<00:13, 373.56it/s] 48%|████▊     | 4828/10000 [00:11<00:16, 322.54it/s] 49%|████▊     | 4862/10000 [00:11<00:15, 322.38it/s] 49%|████▉     | 4896/10000 [00:11<00:15, 321.60it/s] 49%|████▉     | 4929/10000 [00:11<00:15, 320.96it/s] 50%|████▉     | 4962/10000 [00:11<00:19, 263.56it/s] 50%|████▉     | 4995/10000 [00:11<00:18, 276.68it/s] 50%|█████     | 5050/10000 [00:11<00:14, 344.44it/s] 51%|█████     | 5118/10000 [00:11<00:11, 414.47it/s] 52%|█████▏    | 5162/10000 [00:12<00:11, 413.49it/s] 52%|█████▏    | 5208/10000 [00:12<00:11, 416.90it/s] 53%|█████▎    | 5251/10000 [00:12<00:15, 301.32it/s] 53%|█████▎    | 5287/10000 [00:12<00:15, 309.69it/s] 53%|█████▎    | 5322/10000 [00:12<00:16, 285.94it/s] 54%|█████▎    | 5354/10000 [00:12<00:17, 266.67it/s] 54%|█████▍    | 5383/10000 [00:12<00:17, 271.22it/s] 54%|█████▍    | 5429/10000 [00:13<00:14, 317.54it/s] 55%|█████▍    | 5474/10000 [00:13<00:13, 346.82it/s] 55%|█████▌    | 5535/10000 [00:13<00:10, 409.41it/s] 56%|█████▌    | 5602/10000 [00:13<00:09, 478.91it/s] 57%|█████▋    | 5678/10000 [00:13<00:07, 553.27it/s] 57%|█████▋    | 5735/10000 [00:13<00:08, 532.88it/s] 58%|█████▊    | 5790/10000 [00:13<00:08, 497.65it/s] 58%|█████▊    | 5847/10000 [00:13<00:08, 513.43it/s] 59%|█████▉    | 5900/10000 [00:13<00:09, 444.02it/s] 59%|█████▉    | 5947/10000 [00:14<00:10, 368.86it/s] 60%|█████▉    | 5988/10000 [00:14<00:11, 358.64it/s] 61%|██████    | 6065/10000 [00:14<00:08, 454.16it/s] 61%|██████    | 6115/10000 [00:14<00:08, 460.36it/s] 62%|██████▏   | 6202/10000 [00:14<00:07, 542.41it/s] 63%|██████▎   | 6259/10000 [00:14<00:08, 438.16it/s] 63%|██████▎   | 6308/10000 [00:14<00:09, 391.06it/s] 64%|██████▎   | 6351/10000 [00:15<00:09, 391.25it/s] 64%|██████▍   | 6393/10000 [00:15<00:09, 362.21it/s] 64%|██████▍   | 6431/10000 [00:15<00:10, 342.24it/s] 65%|██████▍   | 6467/10000 [00:15<00:10, 323.24it/s] 65%|██████▌   | 6512/10000 [00:15<00:09, 351.31it/s] 65%|██████▌   | 6549/10000 [00:15<00:10, 343.34it/s] 66%|██████▌   | 6585/10000 [00:15<00:09, 342.96it/s] 66%|██████▌   | 6620/10000 [00:15<00:09, 341.07it/s] 67%|██████▋   | 6655/10000 [00:15<00:09, 336.24it/s] 67%|██████▋   | 6689/10000 [00:16<00:09, 333.88it/s] 67%|██████▋   | 6727/10000 [00:16<00:09, 340.16it/s] 68%|██████▊   | 6763/10000 [00:16<00:09, 343.68it/s] 68%|██████▊   | 6843/10000 [00:16<00:06, 464.13it/s] 69%|██████▉   | 6919/10000 [00:16<00:05, 544.41it/s] 70%|██████▉   | 6978/10000 [00:16<00:05, 556.56it/s] 70%|███████   | 7034/10000 [00:16<00:05, 546.44it/s] 71%|███████   | 7089/10000 [00:16<00:05, 542.42it/s] 71%|███████▏  | 7147/10000 [00:16<00:05, 550.99it/s] 72%|███████▏  | 7224/10000 [00:17<00:04, 612.62it/s] 73%|███████▎  | 7304/10000 [00:17<00:04, 652.14it/s] 74%|███████▎  | 7370/10000 [00:17<00:04, 652.72it/s] 74%|███████▍  | 7436/10000 [00:17<00:04, 588.67it/s] 75%|███████▍  | 7496/10000 [00:17<00:04, 544.61it/s] 76%|███████▌  | 7566/10000 [00:17<00:04, 582.57it/s] 76%|███████▋  | 7626/10000 [00:17<00:04, 547.38it/s] 77%|███████▋  | 7682/10000 [00:17<00:04, 467.51it/s] 77%|███████▋  | 7732/10000 [00:18<00:05, 452.96it/s] 78%|███████▊  | 7779/10000 [00:18<00:05, 406.27it/s] 79%|███████▊  | 7854/10000 [00:18<00:04, 484.58it/s] 79%|███████▉  | 7912/10000 [00:18<00:04, 508.11it/s] 80%|███████▉  | 7985/10000 [00:18<00:03, 551.37it/s] 81%|████████  | 8053/10000 [00:18<00:03, 583.00it/s] 81%|████████▏ | 8131/10000 [00:18<00:02, 636.57it/s] 82%|████████▏ | 8197/10000 [00:18<00:03, 565.92it/s] 83%|████████▎ | 8256/10000 [00:18<00:03, 488.12it/s] 83%|████████▎ | 8308/10000 [00:19<00:03, 462.31it/s] 84%|████████▎ | 8357/10000 [00:19<00:03, 417.10it/s] 84%|████████▍ | 8401/10000 [00:19<00:04, 376.51it/s] 85%|████████▍ | 8464/10000 [00:19<00:03, 435.03it/s] 85%|████████▌ | 8529/10000 [00:19<00:03, 479.84it/s] 86%|████████▌ | 8585/10000 [00:19<00:03, 466.73it/s] 87%|████████▋ | 8662/10000 [00:19<00:02, 540.56it/s] 88%|████████▊ | 8756/10000 [00:19<00:01, 642.63it/s] 88%|████████▊ | 8838/10000 [00:20<00:01, 679.04it/s] 89%|████████▉ | 8946/10000 [00:20<00:01, 789.96it/s] 90%|█████████ | 9028/10000 [00:20<00:01, 725.65it/s] 91%|█████████ | 9104/10000 [00:20<00:01, 730.22it/s] 92%|█████████▏| 9179/10000 [00:20<00:01, 702.47it/s] 93%|█████████▎| 9251/10000 [00:20<00:01, 614.33it/s] 93%|█████████▎| 9316/10000 [00:20<00:01, 451.16it/s] 94%|█████████▎| 9369/10000 [00:21<00:01, 401.42it/s] 94%|█████████▍| 9415/10000 [00:21<00:01, 371.71it/s] 95%|█████████▍| 9469/10000 [00:21<00:01, 394.03it/s] 95%|█████████▌| 9512/10000 [00:21<00:01, 375.39it/s] 96%|█████████▌| 9552/10000 [00:21<00:01, 376.47it/s] 96%|█████████▌| 9601/10000 [00:21<00:01, 385.02it/s] 97%|█████████▋| 9657/10000 [00:21<00:00, 424.29it/s] 97%|█████████▋| 9714/10000 [00:21<00:00, 455.20it/s] 98%|█████████▊| 9761/10000 [00:22<00:00, 410.40it/s] 98%|█████████▊| 9829/10000 [00:22<00:00, 475.46it/s] 99%|█████████▉| 9896/10000 [00:22<00:00, 516.49it/s]100%|█████████▉| 9950/10000 [00:22<00:00, 519.76it/s]100%|██████████| 10000/10000 [00:22<00:00, 445.81it/s]
test_neglected_p60 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p60
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p60.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.02s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.75it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.17it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.64it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.74it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.92it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.05it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.71it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.53it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.05it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p60_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p60_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p60_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p60_Holmes_probs.npy
{'Accuracy': 0.0205, 'Precision': 0.0212, 'Recall': 0.0203, 'F1-score': 0.0174}
starting gen taf script for test_neglected_p61
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 77/10000 [00:00<00:12, 767.99it/s]  2%|▏         | 154/10000 [00:00<00:28, 345.44it/s]  2%|▏         | 201/10000 [00:00<00:30, 323.61it/s]  2%|▏         | 240/10000 [00:00<00:31, 309.88it/s]  3%|▎         | 275/10000 [00:00<00:32, 301.32it/s]  3%|▎         | 308/10000 [00:00<00:34, 284.53it/s]  3%|▎         | 344/10000 [00:01<00:32, 299.93it/s]  4%|▍         | 379/10000 [00:01<00:30, 311.56it/s]  4%|▍         | 417/10000 [00:01<00:29, 324.49it/s]  5%|▍         | 464/10000 [00:01<00:26, 360.82it/s]  5%|▌         | 509/10000 [00:01<00:24, 381.44it/s]  6%|▌         | 554/10000 [00:01<00:23, 400.73it/s]  6%|▌         | 610/10000 [00:01<00:21, 445.16it/s]  7%|▋         | 656/10000 [00:01<00:22, 412.93it/s]  7%|▋         | 715/10000 [00:01<00:20, 461.64it/s]  8%|▊         | 766/10000 [00:02<00:19, 469.75it/s]  8%|▊         | 827/10000 [00:02<00:18, 509.60it/s]  9%|▉         | 882/10000 [00:02<00:17, 513.36it/s] 10%|▉         | 953/10000 [00:02<00:16, 546.66it/s] 10%|█         | 1008/10000 [00:02<00:18, 477.76it/s] 11%|█         | 1058/10000 [00:02<00:20, 436.70it/s] 11%|█         | 1104/10000 [00:02<00:20, 437.86it/s] 11%|█▏        | 1149/10000 [00:02<00:20, 421.92it/s] 12%|█▏        | 1192/10000 [00:02<00:20, 422.39it/s] 13%|█▎        | 1265/10000 [00:03<00:17, 500.14it/s] 14%|█▎        | 1355/10000 [00:03<00:14, 599.91it/s] 14%|█▍        | 1416/10000 [00:03<00:15, 552.49it/s] 15%|█▍        | 1473/10000 [00:03<00:22, 384.05it/s] 15%|█▌        | 1519/10000 [00:03<00:25, 331.75it/s] 16%|█▌        | 1559/10000 [00:03<00:27, 306.46it/s] 16%|█▌        | 1594/10000 [00:04<00:29, 285.14it/s] 17%|█▋        | 1662/10000 [00:04<00:22, 363.11it/s] 17%|█▋        | 1727/10000 [00:04<00:19, 426.99it/s] 18%|█▊        | 1800/10000 [00:04<00:16, 495.25it/s] 19%|█▉        | 1886/10000 [00:04<00:13, 584.74it/s] 20%|█▉        | 1977/10000 [00:04<00:11, 671.33it/s] 20%|██        | 2049/10000 [00:04<00:12, 654.72it/s] 21%|██        | 2118/10000 [00:04<00:13, 576.11it/s] 22%|██▏       | 2180/10000 [00:04<00:13, 561.41it/s] 22%|██▏       | 2239/10000 [00:05<00:19, 401.88it/s] 23%|██▎       | 2287/10000 [00:05<00:20, 385.39it/s] 23%|██▎       | 2331/10000 [00:05<00:19, 391.84it/s] 24%|██▍       | 2377/10000 [00:05<00:18, 407.30it/s] 24%|██▍       | 2421/10000 [00:05<00:20, 378.94it/s] 25%|██▍       | 2468/10000 [00:05<00:19, 392.07it/s] 25%|██▌       | 2549/10000 [00:05<00:15, 488.08it/s] 26%|██▌       | 2601/10000 [00:06<00:16, 445.91it/s] 26%|██▋       | 2648/10000 [00:06<00:19, 371.98it/s] 27%|██▋       | 2689/10000 [00:06<00:23, 314.25it/s] 27%|██▋       | 2724/10000 [00:06<00:26, 271.14it/s] 28%|██▊       | 2754/10000 [00:06<00:28, 258.72it/s] 28%|██▊       | 2782/10000 [00:06<00:31, 229.97it/s] 28%|██▊       | 2833/10000 [00:07<00:24, 288.69it/s] 29%|██▉       | 2878/10000 [00:07<00:22, 316.95it/s] 29%|██▉       | 2937/10000 [00:07<00:18, 376.42it/s] 30%|██▉       | 2992/10000 [00:07<00:17, 406.18it/s] 30%|███       | 3037/10000 [00:07<00:17, 403.47it/s] 31%|███       | 3079/10000 [00:07<00:17, 398.36it/s] 31%|███       | 3121/10000 [00:07<00:18, 381.75it/s] 32%|███▏      | 3160/10000 [00:07<00:17, 381.14it/s] 32%|███▏      | 3199/10000 [00:07<00:20, 338.67it/s] 33%|███▎      | 3271/10000 [00:08<00:15, 435.05it/s] 33%|███▎      | 3343/10000 [00:08<00:13, 501.45it/s] 34%|███▍      | 3397/10000 [00:08<00:12, 511.96it/s] 34%|███▍      | 3450/10000 [00:08<00:12, 508.08it/s] 35%|███▌      | 3511/10000 [00:08<00:12, 536.80it/s] 36%|███▌      | 3566/10000 [00:08<00:12, 518.53it/s] 36%|███▋      | 3635/10000 [00:08<00:11, 562.19it/s] 37%|███▋      | 3707/10000 [00:08<00:10, 603.80it/s] 38%|███▊      | 3781/10000 [00:08<00:09, 636.57it/s] 38%|███▊      | 3846/10000 [00:09<00:10, 576.10it/s] 39%|███▉      | 3905/10000 [00:09<00:11, 526.55it/s] 40%|███▉      | 3960/10000 [00:09<00:11, 514.41it/s] 40%|████      | 4014/10000 [00:09<00:11, 508.41it/s] 41%|████      | 4076/10000 [00:09<00:11, 533.45it/s] 41%|████▏     | 4131/10000 [00:09<00:11, 532.88it/s] 42%|████▏     | 4185/10000 [00:09<00:11, 523.47it/s] 42%|████▏     | 4248/10000 [00:09<00:10, 549.61it/s] 43%|████▎     | 4340/10000 [00:09<00:08, 646.42it/s] 44%|████▍     | 4406/10000 [00:10<00:08, 625.37it/s] 45%|████▍     | 4469/10000 [00:10<00:10, 522.20it/s] 45%|████▌     | 4525/10000 [00:10<00:12, 440.30it/s] 46%|████▌     | 4573/10000 [00:10<00:15, 349.22it/s] 46%|████▋     | 4627/10000 [00:10<00:13, 384.25it/s] 47%|████▋     | 4671/10000 [00:10<00:14, 380.50it/s] 47%|████▋     | 4713/10000 [00:10<00:14, 370.98it/s] 48%|████▊     | 4753/10000 [00:11<00:14, 370.51it/s] 48%|████▊     | 4792/10000 [00:11<00:14, 369.32it/s] 48%|████▊     | 4831/10000 [00:11<00:14, 354.12it/s] 49%|████▊     | 4868/10000 [00:11<00:14, 351.02it/s] 49%|████▉     | 4904/10000 [00:11<00:16, 311.47it/s] 49%|████▉     | 4937/10000 [00:11<00:16, 298.78it/s] 50%|████▉     | 4968/10000 [00:11<00:17, 282.57it/s] 50%|████▉     | 4997/10000 [00:11<00:18, 271.42it/s] 51%|█████     | 5059/10000 [00:12<00:13, 356.88it/s] 51%|█████     | 5104/10000 [00:12<00:12, 377.52it/s] 52%|█████▏    | 5159/10000 [00:12<00:11, 423.24it/s] 52%|█████▏    | 5203/10000 [00:12<00:13, 362.86it/s] 52%|█████▏    | 5242/10000 [00:12<00:13, 351.74it/s] 53%|█████▎    | 5279/10000 [00:12<00:15, 313.80it/s] 53%|█████▎    | 5312/10000 [00:12<00:14, 315.18it/s] 53%|█████▎    | 5345/10000 [00:12<00:17, 270.77it/s] 54%|█████▎    | 5374/10000 [00:13<00:17, 265.96it/s] 54%|█████▍    | 5410/10000 [00:13<00:15, 287.58it/s] 55%|█████▍    | 5466/10000 [00:13<00:13, 347.98it/s] 55%|█████▌    | 5503/10000 [00:13<00:13, 342.58it/s] 55%|█████▌    | 5544/10000 [00:13<00:12, 354.93it/s] 56%|█████▌    | 5615/10000 [00:13<00:09, 451.99it/s] 57%|█████▋    | 5712/10000 [00:13<00:07, 594.40it/s] 58%|█████▊    | 5774/10000 [00:13<00:07, 574.52it/s] 58%|█████▊    | 5833/10000 [00:13<00:08, 520.85it/s] 59%|█████▉    | 5887/10000 [00:14<00:09, 451.75it/s] 59%|█████▉    | 5935/10000 [00:14<00:10, 397.97it/s] 60%|█████▉    | 5978/10000 [00:14<00:10, 365.82it/s] 60%|██████    | 6035/10000 [00:14<00:09, 406.58it/s] 61%|██████    | 6095/10000 [00:14<00:08, 451.67it/s] 62%|██████▏   | 6171/10000 [00:14<00:07, 516.80it/s] 62%|██████▏   | 6226/10000 [00:14<00:07, 513.18it/s] 63%|██████▎   | 6279/10000 [00:15<00:08, 440.59it/s] 63%|██████▎   | 6326/10000 [00:15<00:09, 381.06it/s] 64%|██████▎   | 6367/10000 [00:15<00:09, 363.79it/s] 64%|██████▍   | 6406/10000 [00:15<00:11, 314.19it/s] 64%|██████▍   | 6441/10000 [00:15<00:11, 312.25it/s] 65%|██████▍   | 6481/10000 [00:15<00:10, 332.65it/s] 65%|██████▌   | 6529/10000 [00:15<00:09, 367.88it/s] 66%|██████▌   | 6568/10000 [00:15<00:10, 330.97it/s] 66%|██████▋   | 6626/10000 [00:16<00:09, 368.92it/s] 67%|██████▋   | 6665/10000 [00:16<00:09, 355.44it/s] 67%|██████▋   | 6709/10000 [00:16<00:08, 375.53it/s] 68%|██████▊   | 6767/10000 [00:16<00:07, 419.27it/s] 68%|██████▊   | 6827/10000 [00:16<00:06, 466.43it/s] 69%|██████▉   | 6901/10000 [00:16<00:05, 531.93it/s] 70%|██████▉   | 6995/10000 [00:16<00:04, 627.18it/s] 71%|███████   | 7059/10000 [00:16<00:05, 552.34it/s] 71%|███████   | 7117/10000 [00:17<00:05, 540.42it/s] 72%|███████▏  | 7176/10000 [00:17<00:05, 550.85it/s] 73%|███████▎  | 7252/10000 [00:17<00:04, 595.10it/s] 73%|███████▎  | 7316/10000 [00:17<00:04, 605.03it/s] 74%|███████▍  | 7396/10000 [00:17<00:04, 641.75it/s] 75%|███████▍  | 7461/10000 [00:17<00:04, 626.99it/s] 75%|███████▌  | 7525/10000 [00:17<00:04, 612.97it/s] 76%|███████▌  | 7587/10000 [00:17<00:04, 598.06it/s] 76%|███████▋  | 7647/10000 [00:17<00:04, 544.13it/s] 77%|███████▋  | 7703/10000 [00:18<00:04, 461.36it/s] 78%|███████▊  | 7752/10000 [00:18<00:05, 446.71it/s] 78%|███████▊  | 7799/10000 [00:18<00:05, 399.98it/s] 79%|███████▊  | 7874/10000 [00:18<00:04, 478.02it/s] 80%|███████▉  | 7951/10000 [00:18<00:03, 541.27it/s] 80%|████████  | 8010/10000 [00:18<00:03, 552.12it/s] 81%|████████  | 8070/10000 [00:18<00:03, 561.86it/s] 81%|████████▏ | 8128/10000 [00:18<00:03, 536.96it/s] 82%|████████▏ | 8183/10000 [00:19<00:03, 511.85it/s] 82%|████████▏ | 8236/10000 [00:19<00:03, 469.48it/s] 83%|████████▎ | 8285/10000 [00:19<00:03, 474.03it/s] 83%|████████▎ | 8334/10000 [00:19<00:03, 419.70it/s] 84%|████████▍ | 8378/10000 [00:19<00:04, 365.72it/s] 84%|████████▍ | 8426/10000 [00:19<00:04, 374.76it/s] 85%|████████▍ | 8483/10000 [00:19<00:03, 421.96it/s] 86%|████████▌ | 8554/10000 [00:19<00:02, 491.58it/s] 86%|████████▋ | 8628/10000 [00:19<00:02, 554.84it/s] 87%|████████▋ | 8719/10000 [00:20<00:01, 642.62it/s] 88%|████████▊ | 8789/10000 [00:20<00:01, 653.49it/s] 89%|████████▉ | 8885/10000 [00:20<00:01, 733.82it/s] 90%|████████▉ | 8960/10000 [00:20<00:01, 658.74it/s] 90%|█████████ | 9030/10000 [00:20<00:01, 667.48it/s] 91%|█████████ | 9102/10000 [00:20<00:01, 681.30it/s] 92%|█████████▏| 9172/10000 [00:20<00:01, 638.89it/s] 92%|█████████▏| 9238/10000 [00:20<00:01, 526.47it/s] 93%|█████████▎| 9295/10000 [00:21<00:01, 445.43it/s] 93%|█████████▎| 9344/10000 [00:21<00:01, 439.69it/s] 94%|█████████▍| 9391/10000 [00:21<00:01, 375.45it/s] 94%|█████████▍| 9434/10000 [00:21<00:01, 385.37it/s] 95%|█████████▍| 9475/10000 [00:21<00:01, 362.68it/s] 95%|█████████▌| 9513/10000 [00:21<00:01, 366.40it/s] 96%|█████████▌| 9551/10000 [00:21<00:01, 321.60it/s] 96%|█████████▌| 9598/10000 [00:22<00:01, 350.63it/s] 96%|█████████▋| 9638/10000 [00:22<00:01, 359.07it/s] 97%|█████████▋| 9693/10000 [00:22<00:00, 399.30it/s] 98%|█████████▊| 9768/10000 [00:22<00:00, 469.02it/s] 98%|█████████▊| 9823/10000 [00:22<00:00, 485.15it/s] 99%|█████████▉| 9886/10000 [00:22<00:00, 521.61it/s]100%|█████████▉| 9954/10000 [00:22<00:00, 561.72it/s]100%|██████████| 10000/10000 [00:22<00:00, 440.20it/s]
test_neglected_p61 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p61
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p61.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.03it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.13it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.48it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.71it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.68it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.78it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 35.14it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.58it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.82it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p61_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p61_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p61_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p61_Holmes_probs.npy
{'Accuracy': 0.0204, 'Precision': 0.0225, 'Recall': 0.0202, 'F1-score': 0.0177}
starting gen taf script for test_neglected_p62
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 86/10000 [00:00<00:11, 846.64it/s]  2%|▏         | 171/10000 [00:00<00:22, 427.60it/s]  2%|▏         | 225/10000 [00:00<00:27, 358.71it/s]  3%|▎         | 267/10000 [00:00<00:27, 352.74it/s]  3%|▎         | 306/10000 [00:00<00:29, 324.86it/s]  3%|▎         | 341/10000 [00:00<00:31, 303.25it/s]  4%|▎         | 373/10000 [00:01<00:35, 271.27it/s]  4%|▍         | 401/10000 [00:01<00:36, 260.79it/s]  4%|▍         | 432/10000 [00:01<00:35, 269.30it/s]  5%|▍         | 491/10000 [00:01<00:27, 350.53it/s]  5%|▌         | 545/10000 [00:01<00:23, 394.77it/s]  6%|▋         | 632/10000 [00:01<00:18, 514.49it/s]  7%|▋         | 706/10000 [00:01<00:16, 567.30it/s]  8%|▊         | 772/10000 [00:01<00:15, 587.40it/s]  8%|▊         | 835/10000 [00:01<00:15, 593.32it/s]  9%|▉         | 896/10000 [00:02<00:17, 530.69it/s] 10%|▉         | 960/10000 [00:02<00:16, 551.71it/s] 10%|█         | 1017/10000 [00:02<00:17, 524.71it/s] 11%|█         | 1071/10000 [00:02<00:20, 443.30it/s] 11%|█         | 1118/10000 [00:02<00:20, 424.18it/s] 12%|█▏        | 1163/10000 [00:02<00:21, 420.09it/s] 12%|█▏        | 1211/10000 [00:02<00:20, 434.16it/s] 13%|█▎        | 1274/10000 [00:02<00:17, 486.30it/s] 14%|█▎        | 1360/10000 [00:03<00:14, 583.90it/s] 14%|█▍        | 1421/10000 [00:03<00:15, 568.42it/s] 15%|█▍        | 1479/10000 [00:03<00:21, 392.50it/s] 15%|█▌        | 1527/10000 [00:03<00:24, 341.51it/s] 16%|█▌        | 1568/10000 [00:03<00:30, 274.17it/s] 16%|█▌        | 1602/10000 [00:03<00:29, 282.74it/s] 17%|█▋        | 1664/10000 [00:04<00:23, 347.67it/s] 17%|█▋        | 1730/10000 [00:04<00:19, 413.81it/s] 18%|█▊        | 1805/10000 [00:04<00:16, 490.54it/s] 19%|█▉        | 1883/10000 [00:04<00:14, 562.69it/s] 20%|█▉        | 1978/10000 [00:04<00:12, 657.32it/s] 20%|██        | 2049/10000 [00:04<00:12, 625.20it/s] 21%|██        | 2115/10000 [00:04<00:12, 611.29it/s] 22%|██▏       | 2179/10000 [00:04<00:14, 557.34it/s] 22%|██▏       | 2238/10000 [00:05<00:16, 483.20it/s] 23%|██▎       | 2290/10000 [00:05<00:17, 430.23it/s] 23%|██▎       | 2336/10000 [00:05<00:19, 393.63it/s] 24%|██▍       | 2378/10000 [00:05<00:21, 356.12it/s] 24%|██▍       | 2428/10000 [00:05<00:19, 382.44it/s] 25%|██▌       | 2510/10000 [00:05<00:15, 477.29it/s] 26%|██▌       | 2561/10000 [00:05<00:15, 485.06it/s] 26%|██▌       | 2612/10000 [00:05<00:16, 440.65it/s] 27%|██▋       | 2659/10000 [00:06<00:18, 388.99it/s] 27%|██▋       | 2701/10000 [00:06<00:24, 301.50it/s] 27%|██▋       | 2736/10000 [00:06<00:24, 290.75it/s] 28%|██▊       | 2768/10000 [00:06<00:30, 237.07it/s] 28%|██▊       | 2800/10000 [00:06<00:28, 253.17it/s] 28%|██▊       | 2846/10000 [00:06<00:24, 296.89it/s] 29%|██▉       | 2901/10000 [00:07<00:20, 353.20it/s] 30%|██▉       | 2950/10000 [00:07<00:18, 386.31it/s] 30%|███       | 3002/10000 [00:07<00:16, 416.42it/s] 30%|███       | 3049/10000 [00:07<00:16, 419.71it/s] 31%|███       | 3093/10000 [00:07<00:19, 347.11it/s] 31%|███▏      | 3131/10000 [00:07<00:20, 335.86it/s] 32%|███▏      | 3179/10000 [00:07<00:19, 355.25it/s] 32%|███▏      | 3242/10000 [00:07<00:15, 423.90it/s] 33%|███▎      | 3307/10000 [00:07<00:13, 478.66it/s] 34%|███▍      | 3394/10000 [00:08<00:11, 572.13it/s] 35%|███▍      | 3454/10000 [00:08<00:11, 575.98it/s] 35%|███▌      | 3513/10000 [00:08<00:11, 575.64it/s] 36%|███▌      | 3576/10000 [00:08<00:10, 586.76it/s] 36%|███▋      | 3636/10000 [00:08<00:11, 554.19it/s] 37%|███▋      | 3718/10000 [00:08<00:10, 627.96it/s] 38%|███▊      | 3782/10000 [00:08<00:10, 609.50it/s] 39%|███▊      | 3856/10000 [00:08<00:09, 628.98it/s] 39%|███▉      | 3920/10000 [00:09<00:11, 538.85it/s] 40%|███▉      | 3983/10000 [00:09<00:10, 561.40it/s] 40%|████      | 4042/10000 [00:09<00:10, 563.94it/s] 42%|████▏     | 4157/10000 [00:09<00:08, 722.18it/s] 42%|████▏     | 4232/10000 [00:09<00:08, 700.68it/s] 43%|████▎     | 4323/10000 [00:09<00:07, 747.12it/s] 44%|████▍     | 4406/10000 [00:09<00:07, 755.37it/s] 45%|████▍     | 4483/10000 [00:09<00:09, 576.64it/s] 45%|████▌     | 4548/10000 [00:10<00:11, 457.68it/s] 46%|████▌     | 4602/10000 [00:10<00:12, 429.77it/s] 47%|████▋     | 4654/10000 [00:10<00:12, 414.94it/s] 47%|████▋     | 4708/10000 [00:10<00:12, 431.64it/s] 48%|████▊     | 4755/10000 [00:10<00:12, 416.45it/s] 48%|████▊     | 4799/10000 [00:10<00:12, 403.30it/s] 48%|████▊     | 4841/10000 [00:10<00:14, 358.40it/s] 49%|████▉     | 4879/10000 [00:11<00:15, 325.79it/s] 49%|████▉     | 4913/10000 [00:11<00:15, 320.86it/s] 50%|████▉     | 4954/10000 [00:11<00:14, 338.45it/s] 50%|████▉     | 4989/10000 [00:11<00:15, 317.19it/s] 50%|█████     | 5034/10000 [00:11<00:14, 347.50it/s] 51%|█████     | 5086/10000 [00:11<00:12, 393.02it/s] 51%|█████▏    | 5146/10000 [00:11<00:10, 444.63it/s] 52%|█████▏    | 5210/10000 [00:11<00:09, 492.07it/s] 53%|█████▎    | 5261/10000 [00:12<00:13, 358.04it/s] 53%|█████▎    | 5303/10000 [00:12<00:14, 317.69it/s] 53%|█████▎    | 5340/10000 [00:12<00:14, 317.98it/s] 54%|█████▍    | 5375/10000 [00:12<00:15, 307.32it/s] 54%|█████▍    | 5408/10000 [00:12<00:15, 304.21it/s] 54%|█████▍    | 5442/10000 [00:12<00:14, 307.02it/s] 55%|█████▍    | 5493/10000 [00:12<00:12, 354.84it/s] 55%|█████▌    | 5534/10000 [00:12<00:12, 367.98it/s] 56%|█████▌    | 5572/10000 [00:12<00:11, 370.82it/s] 56%|█████▋    | 5639/10000 [00:13<00:09, 448.18it/s] 57%|█████▋    | 5724/10000 [00:13<00:07, 561.51it/s] 58%|█████▊    | 5788/10000 [00:13<00:07, 574.00it/s] 58%|█████▊    | 5847/10000 [00:13<00:07, 548.16it/s] 59%|█████▉    | 5903/10000 [00:13<00:09, 443.17it/s] 60%|█████▉    | 5951/10000 [00:13<00:09, 436.86it/s] 60%|█████▉    | 5998/10000 [00:13<00:10, 390.62it/s] 61%|██████    | 6062/10000 [00:13<00:08, 443.80it/s] 61%|██████▏   | 6143/10000 [00:14<00:07, 536.17it/s] 62%|██████▏   | 6201/10000 [00:14<00:07, 522.31it/s] 63%|██████▎   | 6256/10000 [00:14<00:09, 410.17it/s] 63%|██████▎   | 6308/10000 [00:14<00:08, 434.39it/s] 64%|██████▎   | 6356/10000 [00:14<00:10, 362.38it/s] 64%|██████▍   | 6397/10000 [00:14<00:09, 363.47it/s] 64%|██████▍   | 6437/10000 [00:14<00:10, 347.79it/s] 65%|██████▍   | 6484/10000 [00:15<00:09, 369.97it/s] 65%|██████▌   | 6523/10000 [00:15<00:10, 338.09it/s] 66%|██████▌   | 6568/10000 [00:15<00:09, 363.86it/s] 66%|██████▌   | 6608/10000 [00:15<00:09, 369.18it/s] 66%|██████▋   | 6647/10000 [00:15<00:09, 370.86it/s] 67%|██████▋   | 6707/10000 [00:15<00:07, 429.39it/s] 68%|██████▊   | 6751/10000 [00:15<00:08, 400.87it/s] 68%|██████▊   | 6800/10000 [00:15<00:07, 418.58it/s] 69%|██████▊   | 6860/10000 [00:15<00:06, 465.67it/s] 69%|██████▉   | 6946/10000 [00:16<00:05, 574.80it/s] 70%|███████   | 7005/10000 [00:16<00:05, 566.83it/s] 71%|███████   | 7064/10000 [00:16<00:05, 572.97it/s] 71%|███████   | 7122/10000 [00:16<00:05, 565.55it/s] 72%|███████▏  | 7180/10000 [00:16<00:05, 562.44it/s] 73%|███████▎  | 7253/10000 [00:16<00:04, 605.70it/s] 73%|███████▎  | 7320/10000 [00:16<00:04, 624.31it/s] 74%|███████▍  | 7383/10000 [00:16<00:04, 543.19it/s] 75%|███████▍  | 7460/10000 [00:16<00:04, 588.58it/s] 75%|███████▌  | 7521/10000 [00:17<00:04, 552.04it/s] 76%|███████▌  | 7578/10000 [00:17<00:04, 504.74it/s] 76%|███████▋  | 7637/10000 [00:17<00:04, 512.80it/s] 77%|███████▋  | 7690/10000 [00:17<00:04, 474.22it/s] 77%|███████▋  | 7739/10000 [00:17<00:04, 453.06it/s] 78%|███████▊  | 7785/10000 [00:17<00:05, 437.25it/s] 79%|███████▊  | 7859/10000 [00:17<00:04, 514.53it/s] 79%|███████▉  | 7948/10000 [00:17<00:03, 611.65it/s] 80%|████████  | 8011/10000 [00:17<00:03, 603.35it/s] 81%|████████  | 8085/10000 [00:18<00:03, 637.11it/s] 82%|████████▏ | 8150/10000 [00:18<00:02, 619.97it/s] 82%|████████▏ | 8213/10000 [00:18<00:02, 603.58it/s] 83%|████████▎ | 8274/10000 [00:18<00:03, 531.14it/s] 83%|████████▎ | 8329/10000 [00:18<00:04, 416.09it/s] 84%|████████▍ | 8376/10000 [00:18<00:03, 423.92it/s] 84%|████████▍ | 8422/10000 [00:18<00:03, 423.66it/s] 85%|████████▍ | 8483/10000 [00:18<00:03, 468.05it/s] 85%|████████▌ | 8538/10000 [00:19<00:03, 482.47it/s] 86%|████████▌ | 8598/10000 [00:19<00:02, 510.81it/s] 87%|████████▋ | 8690/10000 [00:19<00:02, 613.97it/s] 88%|████████▊ | 8753/10000 [00:19<00:02, 617.11it/s] 88%|████████▊ | 8826/10000 [00:19<00:01, 645.99it/s] 89%|████████▉ | 8905/10000 [00:19<00:01, 667.80it/s] 90%|████████▉ | 8981/10000 [00:19<00:01, 686.27it/s] 91%|█████████ | 9051/10000 [00:19<00:01, 652.00it/s] 91%|█████████ | 9121/10000 [00:19<00:01, 659.35it/s] 92%|█████████▏| 9188/10000 [00:20<00:01, 596.57it/s] 92%|█████████▏| 9249/10000 [00:20<00:01, 503.39it/s] 93%|█████████▎| 9303/10000 [00:20<00:01, 441.77it/s] 94%|█████████▎| 9351/10000 [00:20<00:01, 412.17it/s] 94%|█████████▍| 9395/10000 [00:20<00:01, 377.28it/s] 94%|█████████▍| 9435/10000 [00:20<00:01, 348.63it/s] 95%|█████████▍| 9471/10000 [00:20<00:01, 332.07it/s] 95%|█████████▌| 9521/10000 [00:21<00:01, 366.75it/s] 96%|█████████▌| 9561/10000 [00:21<00:01, 373.27it/s] 96%|█████████▌| 9600/10000 [00:21<00:01, 372.79it/s] 97%|█████████▋| 9654/10000 [00:21<00:00, 415.73it/s] 97%|█████████▋| 9697/10000 [00:21<00:00, 393.58it/s] 98%|█████████▊| 9756/10000 [00:21<00:00, 437.00it/s] 98%|█████████▊| 9805/10000 [00:21<00:00, 448.15it/s] 99%|█████████▊| 9868/10000 [00:21<00:00, 490.71it/s]100%|█████████▉| 9962/10000 [00:21<00:00, 615.57it/s]100%|██████████| 10000/10000 [00:21<00:00, 455.75it/s]
test_neglected_p62 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p62
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p62.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.11s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.34it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.41it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 17.54it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 23.51it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 28.54it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.12it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 36.79it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.19it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.02it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p62_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p62_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p62_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p62_Holmes_probs.npy
{'Accuracy': 0.0198, 'Precision': 0.0224, 'Recall': 0.0196, 'F1-score': 0.0172}
starting gen taf script for test_neglected_p63
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 65/10000 [00:00<00:17, 577.23it/s]  1%|          | 123/10000 [00:00<00:30, 325.47it/s]  2%|▏         | 162/10000 [00:00<00:29, 333.65it/s]  2%|▏         | 199/10000 [00:00<00:28, 343.14it/s]  2%|▏         | 236/10000 [00:00<00:29, 335.84it/s]  3%|▎         | 271/10000 [00:00<00:30, 314.72it/s]  3%|▎         | 304/10000 [00:00<00:31, 306.07it/s]  3%|▎         | 336/10000 [00:01<00:32, 297.80it/s]  4%|▎         | 370/10000 [00:01<00:31, 306.61it/s]  4%|▍         | 402/10000 [00:01<00:32, 293.89it/s]  4%|▍         | 442/10000 [00:01<00:29, 322.30it/s]  5%|▍         | 482/10000 [00:01<00:28, 338.97it/s]  5%|▌         | 517/10000 [00:01<00:28, 327.68it/s]  6%|▌         | 554/10000 [00:01<00:28, 332.97it/s]  6%|▌         | 588/10000 [00:01<00:30, 310.63it/s]  6%|▌         | 622/10000 [00:01<00:29, 317.52it/s]  7%|▋         | 659/10000 [00:02<00:28, 328.89it/s]  7%|▋         | 693/10000 [00:02<00:28, 329.76it/s]  7%|▋         | 728/10000 [00:02<00:28, 330.91it/s]  8%|▊         | 785/10000 [00:02<00:23, 397.95it/s]  8%|▊         | 834/10000 [00:02<00:21, 422.84it/s]  9%|▉         | 887/10000 [00:02<00:20, 449.11it/s]  9%|▉         | 933/10000 [00:02<00:20, 437.24it/s] 10%|▉         | 981/10000 [00:02<00:20, 441.62it/s] 10%|█         | 1027/10000 [00:02<00:20, 430.16it/s] 11%|█         | 1071/10000 [00:03<00:23, 382.62it/s] 11%|█         | 1111/10000 [00:03<00:25, 348.55it/s] 12%|█▏        | 1161/10000 [00:03<00:23, 379.21it/s] 12%|█▏        | 1217/10000 [00:03<00:20, 422.43it/s] 13%|█▎        | 1287/10000 [00:03<00:17, 494.24it/s] 14%|█▍        | 1390/10000 [00:03<00:13, 642.24it/s] 15%|█▍        | 1457/10000 [00:03<00:18, 459.51it/s] 15%|█▌        | 1512/10000 [00:04<00:23, 368.68it/s] 16%|█▌        | 1558/10000 [00:04<00:26, 314.80it/s] 16%|█▌        | 1597/10000 [00:04<00:27, 300.87it/s] 17%|█▋        | 1656/10000 [00:04<00:23, 355.71it/s] 17%|█▋        | 1737/10000 [00:04<00:18, 452.70it/s] 18%|█▊        | 1829/10000 [00:04<00:14, 557.19it/s] 19%|█▉        | 1922/10000 [00:04<00:12, 643.81it/s] 20%|█▉        | 1994/10000 [00:04<00:12, 647.05it/s] 21%|██        | 2064/10000 [00:05<00:13, 574.80it/s] 21%|██▏       | 2127/10000 [00:05<00:13, 573.33it/s] 22%|██▏       | 2188/10000 [00:05<00:15, 512.81it/s] 22%|██▏       | 2247/10000 [00:05<00:14, 529.51it/s] 23%|██▎       | 2303/10000 [00:05<00:17, 438.94it/s] 24%|██▎       | 2351/10000 [00:05<00:21, 353.43it/s] 24%|██▍       | 2398/10000 [00:05<00:20, 375.02it/s] 24%|██▍       | 2444/10000 [00:06<00:19, 388.07it/s] 25%|██▌       | 2512/10000 [00:06<00:16, 452.70it/s] 26%|██▌       | 2568/10000 [00:06<00:15, 469.20it/s] 26%|██▌       | 2618/10000 [00:06<00:17, 430.74it/s] 27%|██▋       | 2664/10000 [00:06<00:21, 338.71it/s] 27%|██▋       | 2703/10000 [00:06<00:22, 331.62it/s] 27%|██▋       | 2740/10000 [00:06<00:22, 322.31it/s] 28%|██▊       | 2775/10000 [00:07<00:26, 277.59it/s] 28%|██▊       | 2805/10000 [00:07<00:26, 270.25it/s] 29%|██▊       | 2866/10000 [00:07<00:20, 343.56it/s] 29%|██▉       | 2909/10000 [00:07<00:19, 358.47it/s] 30%|██▉       | 2964/10000 [00:07<00:17, 400.47it/s] 30%|███       | 3007/10000 [00:07<00:17, 403.20it/s] 31%|███       | 3053/10000 [00:07<00:16, 412.76it/s] 31%|███       | 3096/10000 [00:07<00:17, 384.51it/s] 32%|███▏      | 3152/10000 [00:07<00:16, 425.75it/s] 32%|███▏      | 3196/10000 [00:08<00:18, 368.71it/s] 33%|███▎      | 3280/10000 [00:08<00:14, 479.25it/s] 34%|███▍      | 3377/10000 [00:08<00:10, 606.03it/s] 34%|███▍      | 3442/10000 [00:08<00:11, 592.15it/s] 35%|███▌      | 3504/10000 [00:08<00:11, 570.64it/s] 36%|███▌      | 3563/10000 [00:08<00:12, 523.06it/s] 36%|███▋      | 3632/10000 [00:08<00:11, 563.86it/s] 37%|███▋      | 3719/10000 [00:08<00:09, 645.68it/s] 38%|███▊      | 3786/10000 [00:09<00:09, 622.51it/s] 38%|███▊      | 3850/10000 [00:09<00:10, 562.24it/s] 39%|███▉      | 3909/10000 [00:09<00:11, 533.40it/s] 40%|███▉      | 3964/10000 [00:09<00:13, 463.31it/s] 40%|████      | 4022/10000 [00:09<00:12, 485.00it/s] 41%|████      | 4074/10000 [00:09<00:12, 484.58it/s] 42%|████▏     | 4177/10000 [00:09<00:09, 613.81it/s] 42%|████▏     | 4244/10000 [00:09<00:09, 618.64it/s] 43%|████▎     | 4321/10000 [00:09<00:08, 644.67it/s] 44%|████▍     | 4387/10000 [00:10<00:09, 613.34it/s] 44%|████▍     | 4450/10000 [00:10<00:10, 547.49it/s] 45%|████▌     | 4507/10000 [00:10<00:11, 464.55it/s] 46%|████▌     | 4557/10000 [00:10<00:13, 411.85it/s] 46%|████▌     | 4601/10000 [00:10<00:13, 413.41it/s] 46%|████▋     | 4645/10000 [00:10<00:13, 388.28it/s] 47%|████▋     | 4690/10000 [00:10<00:13, 396.51it/s] 47%|████▋     | 4736/10000 [00:11<00:12, 409.20it/s] 48%|████▊     | 4785/10000 [00:11<00:12, 401.18it/s] 48%|████▊     | 4826/10000 [00:11<00:14, 354.40it/s] 49%|████▊     | 4869/10000 [00:11<00:14, 353.16it/s] 49%|████▉     | 4906/10000 [00:11<00:17, 294.05it/s] 49%|████▉     | 4938/10000 [00:11<00:18, 281.06it/s] 50%|████▉     | 4970/10000 [00:11<00:18, 273.25it/s] 50%|█████     | 5015/10000 [00:11<00:16, 309.56it/s] 51%|█████     | 5077/10000 [00:12<00:12, 386.66it/s] 51%|█████▏    | 5147/10000 [00:12<00:10, 469.03it/s] 52%|█████▏    | 5197/10000 [00:12<00:11, 402.47it/s] 52%|█████▏    | 5241/10000 [00:12<00:13, 351.41it/s] 53%|█████▎    | 5280/10000 [00:12<00:13, 349.36it/s] 53%|█████▎    | 5318/10000 [00:12<00:15, 307.56it/s] 54%|█████▎    | 5351/10000 [00:12<00:16, 286.84it/s] 54%|█████▍    | 5382/10000 [00:13<00:15, 289.81it/s] 54%|█████▍    | 5433/10000 [00:13<00:13, 326.86it/s] 55%|█████▍    | 5467/10000 [00:13<00:13, 324.79it/s] 55%|█████▌    | 5536/10000 [00:13<00:10, 419.78it/s] 56%|█████▌    | 5581/10000 [00:13<00:10, 427.16it/s] 57%|█████▋    | 5654/10000 [00:13<00:08, 502.29it/s] 57%|█████▋    | 5742/10000 [00:13<00:07, 601.21it/s] 58%|█████▊    | 5804/10000 [00:13<00:07, 599.29it/s] 59%|█████▊    | 5865/10000 [00:13<00:08, 485.78it/s] 59%|█████▉    | 5918/10000 [00:14<00:09, 414.81it/s] 60%|█████▉    | 5964/10000 [00:14<00:10, 389.45it/s] 60%|██████    | 6006/10000 [00:14<00:10, 380.12it/s] 61%|██████    | 6068/10000 [00:14<00:08, 437.53it/s] 62%|██████▏   | 6151/10000 [00:14<00:07, 530.77it/s] 62%|██████▏   | 6216/10000 [00:14<00:06, 549.86it/s] 63%|██████▎   | 6274/10000 [00:14<00:09, 404.80it/s] 63%|██████▎   | 6322/10000 [00:15<00:09, 377.99it/s] 64%|██████▎   | 6365/10000 [00:15<00:09, 366.44it/s] 64%|██████▍   | 6405/10000 [00:15<00:09, 368.58it/s] 64%|██████▍   | 6449/10000 [00:15<00:09, 363.66it/s] 65%|██████▍   | 6487/10000 [00:15<00:09, 361.05it/s] 65%|██████▌   | 6525/10000 [00:15<00:10, 330.67it/s] 66%|██████▌   | 6576/10000 [00:15<00:09, 370.89it/s] 66%|██████▌   | 6615/10000 [00:15<00:09, 363.63it/s] 67%|██████▋   | 6660/10000 [00:16<00:09, 354.77it/s] 67%|██████▋   | 6707/10000 [00:16<00:09, 364.80it/s] 67%|██████▋   | 6746/10000 [00:16<00:08, 365.13it/s] 68%|██████▊   | 6819/10000 [00:16<00:06, 460.20it/s] 69%|██████▉   | 6906/10000 [00:16<00:05, 567.17it/s] 70%|██████▉   | 6973/10000 [00:16<00:05, 584.92it/s] 70%|███████   | 7033/10000 [00:16<00:05, 583.86it/s] 71%|███████   | 7093/10000 [00:16<00:05, 566.35it/s] 72%|███████▏  | 7151/10000 [00:16<00:05, 561.23it/s] 72%|███████▏  | 7210/10000 [00:17<00:04, 569.25it/s] 73%|███████▎  | 7270/10000 [00:17<00:04, 566.66it/s] 74%|███████▎  | 7371/10000 [00:17<00:03, 681.76it/s] 74%|███████▍  | 7440/10000 [00:17<00:04, 626.10it/s] 75%|███████▌  | 7510/10000 [00:17<00:03, 632.18it/s] 76%|███████▌  | 7574/10000 [00:17<00:03, 610.96it/s] 76%|███████▋  | 7636/10000 [00:17<00:04, 556.83it/s] 77%|███████▋  | 7693/10000 [00:17<00:04, 519.59it/s] 77%|███████▋  | 7746/10000 [00:18<00:04, 493.23it/s] 78%|███████▊  | 7796/10000 [00:18<00:05, 437.38it/s] 79%|███████▊  | 7863/10000 [00:18<00:04, 477.61it/s] 80%|███████▉  | 7967/10000 [00:18<00:03, 617.08it/s] 80%|████████  | 8039/10000 [00:18<00:03, 635.94it/s] 81%|████████  | 8106/10000 [00:18<00:02, 633.95it/s] 82%|████████▏ | 8193/10000 [00:18<00:02, 656.98it/s] 83%|████████▎ | 8260/10000 [00:18<00:03, 533.48it/s] 83%|████████▎ | 8318/10000 [00:19<00:03, 444.05it/s] 84%|████████▎ | 8368/10000 [00:19<00:03, 411.72it/s] 84%|████████▍ | 8428/10000 [00:19<00:03, 448.13it/s] 85%|████████▍ | 8492/10000 [00:19<00:03, 491.91it/s] 85%|████████▌ | 8545/10000 [00:19<00:03, 467.81it/s] 86%|████████▌ | 8607/10000 [00:19<00:02, 499.93it/s] 87%|████████▋ | 8692/10000 [00:19<00:02, 585.67it/s] 88%|████████▊ | 8768/10000 [00:19<00:01, 631.42it/s] 88%|████████▊ | 8834/10000 [00:19<00:01, 638.54it/s] 89%|████████▉ | 8923/10000 [00:20<00:01, 708.62it/s] 90%|█████████ | 9003/10000 [00:20<00:01, 719.59it/s] 91%|█████████ | 9077/10000 [00:20<00:01, 681.85it/s] 91%|█████████▏| 9147/10000 [00:20<00:01, 669.84it/s] 92%|█████████▏| 9215/10000 [00:20<00:01, 623.23it/s] 93%|█████████▎| 9279/10000 [00:20<00:01, 489.65it/s] 93%|█████████▎| 9333/10000 [00:20<00:01, 428.26it/s] 94%|█████████▍| 9380/10000 [00:21<00:01, 396.52it/s] 94%|█████████▍| 9423/10000 [00:21<00:01, 388.18it/s] 95%|█████████▍| 9464/10000 [00:21<00:01, 365.25it/s] 95%|█████████▌| 9502/10000 [00:21<00:01, 362.26it/s] 96%|█████████▌| 9551/10000 [00:21<00:01, 390.77it/s] 96%|█████████▌| 9592/10000 [00:21<00:01, 349.20it/s] 96%|█████████▋| 9646/10000 [00:21<00:00, 387.64it/s] 97%|█████████▋| 9713/10000 [00:21<00:00, 458.52it/s] 98%|█████████▊| 9767/10000 [00:22<00:00, 477.84it/s] 98%|█████████▊| 9817/10000 [00:22<00:00, 470.73it/s] 99%|█████████▉| 9877/10000 [00:22<00:00, 504.51it/s]100%|█████████▉| 9959/10000 [00:22<00:00, 592.22it/s]100%|██████████| 10000/10000 [00:22<00:00, 447.17it/s]
test_neglected_p63 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p63
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p63.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:36,  1.07it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.22it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.99it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.28it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.45it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.61it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.89it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 38.39it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.52it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 22.07it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p63_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p63_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p63_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p63_Holmes_probs.npy
{'Accuracy': 0.0196, 'Precision': 0.0216, 'Recall': 0.0193, 'F1-score': 0.0168}
starting gen taf script for test_neglected_p64
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 85/10000 [00:00<00:12, 807.07it/s]  2%|▏         | 166/10000 [00:00<00:24, 409.38it/s]  2%|▏         | 217/10000 [00:00<00:30, 322.62it/s]  3%|▎         | 256/10000 [00:00<00:36, 266.26it/s]  3%|▎         | 287/10000 [00:00<00:39, 248.49it/s]  3%|▎         | 314/10000 [00:01<00:39, 243.45it/s]  3%|▎         | 340/10000 [00:01<00:39, 244.69it/s]  4%|▎         | 366/10000 [00:01<00:43, 222.65it/s]  4%|▍         | 389/10000 [00:01<00:44, 217.39it/s]  4%|▍         | 419/10000 [00:01<00:40, 237.72it/s]  5%|▍         | 462/10000 [00:01<00:33, 286.46it/s]  5%|▌         | 504/10000 [00:01<00:29, 317.19it/s]  6%|▌         | 551/10000 [00:01<00:26, 358.10it/s]  6%|▋         | 626/10000 [00:01<00:20, 457.48it/s]  7%|▋         | 690/10000 [00:02<00:18, 503.89it/s]  7%|▋         | 746/10000 [00:02<00:17, 518.31it/s]  8%|▊         | 799/10000 [00:02<00:18, 492.11it/s]  9%|▉         | 880/10000 [00:02<00:15, 580.63it/s]  9%|▉         | 940/10000 [00:02<00:16, 551.01it/s] 10%|▉         | 997/10000 [00:02<00:18, 500.14it/s] 10%|█         | 1049/10000 [00:02<00:19, 468.58it/s] 11%|█         | 1101/10000 [00:02<00:19, 464.28it/s] 11%|█▏        | 1149/10000 [00:03<00:18, 465.99it/s] 12%|█▏        | 1197/10000 [00:03<00:20, 423.86it/s] 12%|█▎        | 1250/10000 [00:03<00:19, 449.68it/s] 13%|█▎        | 1331/10000 [00:03<00:15, 545.91it/s] 14%|█▍        | 1411/10000 [00:03<00:13, 614.85it/s] 15%|█▍        | 1475/10000 [00:03<00:20, 411.74it/s] 15%|█▌        | 1527/10000 [00:04<00:27, 313.77it/s] 16%|█▌        | 1569/10000 [00:04<00:29, 284.65it/s] 16%|█▌        | 1612/10000 [00:04<00:27, 310.43it/s] 17%|█▋        | 1686/10000 [00:04<00:20, 397.55it/s] 17%|█▋        | 1743/10000 [00:04<00:19, 432.19it/s] 18%|█▊        | 1814/10000 [00:04<00:16, 493.71it/s] 19%|█▉        | 1926/10000 [00:04<00:12, 650.26it/s] 20%|██        | 2013/10000 [00:04<00:11, 686.70it/s] 21%|██        | 2087/10000 [00:04<00:12, 619.96it/s] 22%|██▏       | 2154/10000 [00:05<00:12, 609.36it/s] 22%|██▏       | 2218/10000 [00:05<00:15, 515.94it/s] 23%|██▎       | 2274/10000 [00:05<00:16, 476.42it/s] 23%|██▎       | 2325/10000 [00:05<00:18, 419.76it/s] 24%|██▎       | 2370/10000 [00:05<00:19, 388.62it/s] 24%|██▍       | 2415/10000 [00:05<00:19, 393.53it/s] 25%|██▍       | 2466/10000 [00:05<00:18, 416.40it/s] 25%|██▌       | 2532/10000 [00:06<00:15, 474.87it/s] 26%|██▌       | 2582/10000 [00:06<00:16, 445.51it/s] 26%|██▋       | 2629/10000 [00:06<00:18, 406.53it/s] 27%|██▋       | 2672/10000 [00:06<00:20, 354.45it/s] 27%|██▋       | 2710/10000 [00:06<00:24, 298.06it/s] 27%|██▋       | 2743/10000 [00:06<00:26, 272.64it/s] 28%|██▊       | 2772/10000 [00:06<00:27, 264.02it/s] 28%|██▊       | 2800/10000 [00:07<00:27, 262.11it/s] 28%|██▊       | 2845/10000 [00:07<00:23, 306.75it/s] 29%|██▉       | 2897/10000 [00:07<00:19, 361.32it/s] 29%|██▉       | 2940/10000 [00:07<00:18, 375.88it/s] 30%|██▉       | 2987/10000 [00:07<00:17, 391.11it/s] 30%|███       | 3031/10000 [00:07<00:17, 404.58it/s] 31%|███       | 3073/10000 [00:07<00:17, 393.99it/s] 31%|███       | 3114/10000 [00:07<00:17, 389.99it/s] 32%|███▏      | 3154/10000 [00:07<00:18, 378.26it/s] 32%|███▏      | 3193/10000 [00:08<00:18, 369.60it/s] 33%|███▎      | 3264/10000 [00:08<00:14, 456.19it/s] 33%|███▎      | 3327/10000 [00:08<00:13, 504.83it/s] 34%|███▍      | 3397/10000 [00:08<00:11, 554.34it/s] 35%|███▍      | 3458/10000 [00:08<00:11, 562.43it/s] 35%|███▌      | 3515/10000 [00:08<00:11, 553.55it/s] 36%|███▌      | 3571/10000 [00:08<00:12, 528.33it/s] 36%|███▋      | 3636/10000 [00:08<00:11, 549.01it/s] 37%|███▋      | 3704/10000 [00:08<00:10, 574.00it/s] 38%|███▊      | 3770/10000 [00:08<00:10, 593.14it/s] 38%|███▊      | 3832/10000 [00:09<00:10, 600.22it/s] 39%|███▉      | 3893/10000 [00:09<00:10, 559.11it/s] 40%|███▉      | 3950/10000 [00:09<00:12, 484.89it/s] 40%|████      | 4001/10000 [00:09<00:12, 472.89it/s] 41%|████      | 4090/10000 [00:09<00:10, 575.39it/s] 42%|████▏     | 4150/10000 [00:09<00:10, 580.05it/s] 42%|████▏     | 4241/10000 [00:09<00:08, 653.26it/s] 43%|████▎     | 4308/10000 [00:09<00:09, 624.45it/s] 44%|████▎     | 4372/10000 [00:10<00:09, 620.90it/s] 44%|████▍     | 4435/10000 [00:10<00:10, 545.71it/s] 45%|████▍     | 4492/10000 [00:10<00:11, 473.78it/s] 45%|████▌     | 4542/10000 [00:10<00:12, 454.80it/s] 46%|████▌     | 4590/10000 [00:10<00:13, 401.54it/s] 46%|████▋     | 4632/10000 [00:10<00:14, 372.40it/s] 47%|████▋     | 4680/10000 [00:10<00:14, 377.65it/s] 47%|████▋     | 4719/10000 [00:10<00:14, 376.90it/s] 48%|████▊     | 4758/10000 [00:11<00:14, 355.85it/s] 48%|████▊     | 4805/10000 [00:11<00:13, 380.01it/s] 48%|████▊     | 4844/10000 [00:11<00:16, 315.60it/s] 49%|████▉     | 4881/10000 [00:11<00:15, 322.23it/s] 49%|████▉     | 4915/10000 [00:11<00:16, 313.21it/s] 49%|████▉     | 4948/10000 [00:11<00:18, 280.13it/s] 50%|████▉     | 4978/10000 [00:11<00:19, 261.64it/s] 50%|█████     | 5027/10000 [00:12<00:16, 301.81it/s] 51%|█████     | 5090/10000 [00:12<00:13, 376.48it/s] 52%|█████▏    | 5152/10000 [00:12<00:11, 434.92it/s] 52%|█████▏    | 5205/10000 [00:12<00:10, 450.72it/s] 53%|█████▎    | 5252/10000 [00:12<00:13, 353.95it/s] 53%|█████▎    | 5292/10000 [00:12<00:14, 327.73it/s] 53%|█████▎    | 5328/10000 [00:12<00:16, 287.34it/s] 54%|█████▎    | 5367/10000 [00:12<00:14, 309.31it/s] 54%|█████▍    | 5401/10000 [00:13<00:15, 294.24it/s] 54%|█████▍    | 5433/10000 [00:13<00:15, 288.46it/s] 55%|█████▌    | 5500/10000 [00:13<00:12, 365.73it/s] 56%|█████▌    | 5568/10000 [00:13<00:10, 437.96it/s] 56%|█████▌    | 5622/10000 [00:13<00:09, 464.14it/s] 57%|█████▋    | 5690/10000 [00:13<00:08, 517.47it/s] 58%|█████▊    | 5778/10000 [00:13<00:06, 614.72it/s] 58%|█████▊    | 5842/10000 [00:13<00:08, 484.59it/s] 59%|█████▉    | 5896/10000 [00:14<00:08, 473.42it/s] 59%|█████▉    | 5948/10000 [00:14<00:09, 425.89it/s] 60%|█████▉    | 5994/10000 [00:14<00:10, 377.19it/s] 60%|██████    | 6041/10000 [00:14<00:10, 393.91it/s] 61%|██████    | 6104/10000 [00:14<00:08, 450.92it/s] 62%|██████▏   | 6163/10000 [00:14<00:08, 478.32it/s] 62%|██████▏   | 6226/10000 [00:14<00:07, 497.22it/s] 63%|██████▎   | 6278/10000 [00:14<00:08, 443.46it/s] 63%|██████▎   | 6325/10000 [00:15<00:09, 404.92it/s] 64%|██████▎   | 6368/10000 [00:15<00:10, 350.97it/s] 64%|██████▍   | 6406/10000 [00:15<00:12, 297.61it/s] 65%|██████▍   | 6459/10000 [00:15<00:10, 346.39it/s] 65%|██████▍   | 6498/10000 [00:15<00:10, 349.16it/s] 65%|██████▌   | 6536/10000 [00:15<00:10, 339.26it/s] 66%|██████▌   | 6572/10000 [00:15<00:10, 335.51it/s] 66%|██████▌   | 6619/10000 [00:16<00:09, 369.97it/s] 67%|██████▋   | 6658/10000 [00:16<00:09, 357.12it/s] 67%|██████▋   | 6700/10000 [00:16<00:08, 367.48it/s] 67%|██████▋   | 6738/10000 [00:16<00:09, 345.42it/s] 68%|██████▊   | 6774/10000 [00:16<00:09, 340.90it/s] 69%|██████▊   | 6853/10000 [00:16<00:06, 461.16it/s] 69%|██████▉   | 6926/10000 [00:16<00:05, 535.90it/s] 70%|███████   | 7021/10000 [00:16<00:04, 623.89it/s] 71%|███████   | 7085/10000 [00:16<00:05, 546.41it/s] 71%|███████▏  | 7145/10000 [00:17<00:05, 557.03it/s] 72%|███████▏  | 7223/10000 [00:17<00:04, 602.62it/s] 73%|███████▎  | 7294/10000 [00:17<00:04, 622.95it/s] 74%|███████▎  | 7361/10000 [00:17<00:04, 634.04it/s] 74%|███████▍  | 7426/10000 [00:17<00:04, 618.44it/s] 75%|███████▍  | 7489/10000 [00:17<00:04, 620.83it/s] 76%|███████▌  | 7561/10000 [00:17<00:03, 626.16it/s] 76%|███████▌  | 7624/10000 [00:17<00:04, 571.73it/s] 77%|███████▋  | 7683/10000 [00:17<00:04, 522.58it/s] 77%|███████▋  | 7737/10000 [00:18<00:04, 490.78it/s] 78%|███████▊  | 7788/10000 [00:18<00:05, 427.60it/s] 79%|███████▊  | 7852/10000 [00:18<00:04, 478.32it/s] 79%|███████▉  | 7934/10000 [00:18<00:03, 565.35it/s] 80%|████████  | 8018/10000 [00:18<00:03, 629.97it/s] 81%|████████  | 8084/10000 [00:18<00:03, 613.38it/s] 82%|████████▏ | 8165/10000 [00:18<00:02, 658.09it/s] 82%|████████▏ | 8233/10000 [00:18<00:02, 637.02it/s] 83%|████████▎ | 8298/10000 [00:19<00:03, 517.04it/s] 84%|████████▎ | 8354/10000 [00:19<00:03, 476.06it/s] 84%|████████▍ | 8405/10000 [00:19<00:03, 435.38it/s] 85%|████████▍ | 8451/10000 [00:19<00:03, 417.05it/s] 85%|████████▌ | 8523/10000 [00:19<00:03, 489.59it/s] 86%|████████▌ | 8575/10000 [00:19<00:02, 480.83it/s] 86%|████████▋ | 8649/10000 [00:19<00:02, 547.47it/s] 87%|████████▋ | 8709/10000 [00:19<00:02, 553.73it/s] 88%|████████▊ | 8805/10000 [00:20<00:01, 659.15it/s] 89%|████████▉ | 8892/10000 [00:20<00:01, 710.01it/s] 90%|████████▉ | 8974/10000 [00:20<00:01, 740.88it/s] 90%|█████████ | 9050/10000 [00:20<00:01, 674.71it/s] 91%|█████████ | 9120/10000 [00:20<00:01, 643.13it/s] 92%|█████████▏| 9186/10000 [00:20<00:01, 640.85it/s] 93%|█████████▎| 9252/10000 [00:20<00:01, 537.04it/s] 93%|█████████▎| 9309/10000 [00:20<00:01, 437.64it/s] 94%|█████████▎| 9358/10000 [00:21<00:01, 431.99it/s] 94%|█████████▍| 9405/10000 [00:21<00:01, 374.19it/s] 94%|█████████▍| 9446/10000 [00:21<00:01, 377.34it/s] 95%|█████████▍| 9486/10000 [00:21<00:01, 372.77it/s] 95%|█████████▌| 9525/10000 [00:21<00:01, 351.47it/s] 96%|█████████▌| 9562/10000 [00:21<00:01, 327.00it/s] 96%|█████████▌| 9616/10000 [00:21<00:01, 371.85it/s] 97%|█████████▋| 9664/10000 [00:21<00:00, 393.72it/s] 97%|█████████▋| 9715/10000 [00:22<00:00, 404.68it/s] 98%|█████████▊| 9768/10000 [00:22<00:00, 430.89it/s] 98%|█████████▊| 9828/10000 [00:22<00:00, 471.70it/s] 99%|█████████▉| 9917/10000 [00:22<00:00, 587.45it/s]100%|██████████| 10000/10000 [00:22<00:00, 445.08it/s]
test_neglected_p64 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p64
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p64.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.08s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.50it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.53it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.69it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.47it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.73it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.28it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.93it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.68it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p64_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p64_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p64_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p64_Holmes_probs.npy
{'Accuracy': 0.0197, 'Precision': 0.0229, 'Recall': 0.0194, 'F1-score': 0.0171}
starting gen taf script for test_neglected_p65
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 69/10000 [00:00<00:16, 602.15it/s]  1%|▏         | 130/10000 [00:00<00:27, 354.50it/s]  2%|▏         | 171/10000 [00:00<00:32, 301.37it/s]  2%|▏         | 213/10000 [00:00<00:29, 329.99it/s]  2%|▏         | 249/10000 [00:00<00:32, 302.90it/s]  3%|▎         | 282/10000 [00:00<00:32, 299.42it/s]  3%|▎         | 314/10000 [00:01<00:34, 282.34it/s]  3%|▎         | 343/10000 [00:01<00:36, 261.80it/s]  4%|▎         | 370/10000 [00:01<00:37, 254.74it/s]  4%|▍         | 396/10000 [00:01<00:37, 255.22it/s]  4%|▍         | 427/10000 [00:01<00:36, 260.50it/s]  5%|▍         | 454/10000 [00:01<00:38, 246.95it/s]  5%|▍         | 479/10000 [00:01<00:40, 233.49it/s]  5%|▌         | 503/10000 [00:01<00:45, 209.49it/s]  6%|▌         | 551/10000 [00:01<00:34, 275.66it/s]  6%|▌         | 584/10000 [00:02<00:33, 279.80it/s]  6%|▌         | 616/10000 [00:02<00:32, 289.48it/s]  6%|▋         | 649/10000 [00:02<00:31, 300.61it/s]  7%|▋         | 717/10000 [00:02<00:23, 401.80it/s]  8%|▊         | 776/10000 [00:02<00:20, 452.39it/s]  8%|▊         | 833/10000 [00:02<00:18, 484.45it/s]  9%|▉         | 904/10000 [00:02<00:16, 547.92it/s] 10%|▉         | 960/10000 [00:02<00:19, 452.72it/s] 10%|█         | 1009/10000 [00:02<00:20, 433.32it/s] 11%|█         | 1056/10000 [00:03<00:20, 437.14it/s] 11%|█         | 1103/10000 [00:03<00:20, 431.93it/s] 11%|█▏        | 1149/10000 [00:03<00:20, 438.80it/s] 12%|█▏        | 1194/10000 [00:03<00:21, 415.25it/s] 13%|█▎        | 1258/10000 [00:03<00:18, 464.27it/s] 13%|█▎        | 1345/10000 [00:03<00:15, 571.76it/s] 14%|█▍        | 1412/10000 [00:03<00:14, 578.31it/s] 15%|█▍        | 1471/10000 [00:04<00:20, 412.68it/s] 15%|█▌        | 1520/10000 [00:04<00:23, 354.34it/s] 16%|█▌        | 1562/10000 [00:04<00:27, 309.69it/s] 16%|█▌        | 1598/10000 [00:04<00:28, 296.60it/s] 16%|█▋        | 1648/10000 [00:04<00:24, 334.32it/s] 17%|█▋        | 1714/10000 [00:04<00:20, 403.98it/s] 18%|█▊        | 1794/10000 [00:04<00:16, 492.41it/s] 19%|█▉        | 1875/10000 [00:04<00:14, 573.21it/s] 20%|█▉        | 1957/10000 [00:05<00:12, 635.17it/s] 20%|██        | 2028/10000 [00:05<00:12, 629.18it/s] 21%|██        | 2094/10000 [00:05<00:14, 553.03it/s] 22%|██▏       | 2153/10000 [00:05<00:14, 534.22it/s] 22%|██▏       | 2210/10000 [00:05<00:14, 521.64it/s] 23%|██▎       | 2264/10000 [00:05<00:16, 456.84it/s] 23%|██▎       | 2312/10000 [00:05<00:20, 366.13it/s] 24%|██▎       | 2353/10000 [00:06<00:20, 364.30it/s] 24%|██▍       | 2393/10000 [00:06<00:20, 365.35it/s] 24%|██▍       | 2433/10000 [00:06<00:20, 365.40it/s] 25%|██▍       | 2475/10000 [00:06<00:20, 373.03it/s] 25%|██▌       | 2522/10000 [00:06<00:19, 391.82it/s] 26%|██▌       | 2602/10000 [00:06<00:15, 492.13it/s] 27%|██▋       | 2653/10000 [00:06<00:22, 323.58it/s] 27%|██▋       | 2694/10000 [00:07<00:26, 280.39it/s] 27%|██▋       | 2729/10000 [00:07<00:26, 271.21it/s] 28%|██▊       | 2761/10000 [00:07<00:26, 276.14it/s] 28%|██▊       | 2792/10000 [00:07<00:31, 228.27it/s] 28%|██▊       | 2825/10000 [00:07<00:29, 247.32it/s] 29%|██▊       | 2871/10000 [00:07<00:24, 293.04it/s] 29%|██▉       | 2939/10000 [00:07<00:18, 377.78it/s] 30%|██▉       | 2981/10000 [00:07<00:19, 366.56it/s] 30%|███       | 3034/10000 [00:08<00:17, 393.57it/s] 31%|███       | 3076/10000 [00:08<00:19, 346.62it/s] 31%|███       | 3113/10000 [00:08<00:20, 335.79it/s] 31%|███▏      | 3149/10000 [00:08<00:20, 341.00it/s] 32%|███▏      | 3192/10000 [00:08<00:18, 361.06it/s] 33%|███▎      | 3271/10000 [00:08<00:14, 475.08it/s] 33%|███▎      | 3349/10000 [00:08<00:12, 553.49it/s] 34%|███▍      | 3417/10000 [00:08<00:11, 575.89it/s] 35%|███▍      | 3476/10000 [00:09<00:11, 550.61it/s] 35%|███▌      | 3533/10000 [00:09<00:12, 532.10it/s] 36%|███▌      | 3587/10000 [00:09<00:12, 516.51it/s] 37%|███▋      | 3668/10000 [00:09<00:10, 582.44it/s] 37%|███▋      | 3730/10000 [00:09<00:10, 584.32it/s] 38%|███▊      | 3789/10000 [00:09<00:11, 533.19it/s] 38%|███▊      | 3844/10000 [00:09<00:11, 527.60it/s] 39%|███▉      | 3898/10000 [00:09<00:11, 528.71it/s] 40%|███▉      | 3953/10000 [00:09<00:11, 533.71it/s] 40%|████      | 4023/10000 [00:10<00:10, 573.20it/s] 41%|████      | 4111/10000 [00:10<00:08, 658.79it/s] 42%|████▏     | 4178/10000 [00:10<00:08, 659.91it/s] 42%|████▏     | 4245/10000 [00:10<00:09, 624.05it/s] 43%|████▎     | 4309/10000 [00:10<00:09, 621.54it/s] 44%|████▎     | 4372/10000 [00:10<00:09, 615.16it/s] 44%|████▍     | 4434/10000 [00:10<00:11, 490.09it/s] 45%|████▍     | 4488/10000 [00:10<00:11, 499.44it/s] 45%|████▌     | 4541/10000 [00:11<00:14, 372.42it/s] 46%|████▌     | 4585/10000 [00:11<00:14, 365.48it/s] 46%|████▋     | 4626/10000 [00:11<00:14, 370.30it/s] 47%|████▋     | 4667/10000 [00:11<00:16, 326.68it/s] 47%|████▋     | 4703/10000 [00:11<00:16, 326.54it/s] 47%|████▋     | 4738/10000 [00:11<00:16, 320.15it/s] 48%|████▊     | 4785/10000 [00:11<00:15, 342.41it/s] 48%|████▊     | 4821/10000 [00:11<00:17, 295.10it/s] 49%|████▊     | 4853/10000 [00:12<00:17, 297.47it/s] 49%|████▉     | 4894/10000 [00:12<00:16, 318.23it/s] 49%|████▉     | 4927/10000 [00:12<00:16, 308.85it/s] 50%|████▉     | 4959/10000 [00:12<00:16, 299.02it/s] 50%|████▉     | 4990/10000 [00:12<00:18, 269.48it/s] 50%|█████     | 5034/10000 [00:12<00:15, 312.20it/s] 51%|█████     | 5083/10000 [00:12<00:13, 352.66it/s] 52%|█████▏    | 5150/10000 [00:12<00:11, 428.15it/s] 52%|█████▏    | 5200/10000 [00:12<00:10, 447.69it/s] 52%|█████▏    | 5246/10000 [00:13<00:14, 337.50it/s] 53%|█████▎    | 5285/10000 [00:13<00:16, 286.59it/s] 53%|█████▎    | 5318/10000 [00:13<00:17, 267.19it/s] 54%|█████▎    | 5353/10000 [00:13<00:16, 280.84it/s] 54%|█████▍    | 5384/10000 [00:13<00:17, 266.51it/s] 54%|█████▍    | 5426/10000 [00:13<00:15, 299.89it/s] 55%|█████▍    | 5470/10000 [00:14<00:13, 332.33it/s] 55%|█████▌    | 5531/10000 [00:14<00:11, 401.21it/s] 56%|█████▌    | 5576/10000 [00:14<00:11, 399.89it/s] 56%|█████▋    | 5640/10000 [00:14<00:09, 458.49it/s] 57%|█████▋    | 5688/10000 [00:14<00:09, 460.75it/s] 58%|█████▊    | 5752/10000 [00:14<00:08, 510.95it/s] 58%|█████▊    | 5819/10000 [00:14<00:07, 536.94it/s] 59%|█████▊    | 5874/10000 [00:14<00:08, 459.47it/s] 59%|█████▉    | 5923/10000 [00:14<00:10, 383.92it/s] 60%|█████▉    | 5965/10000 [00:15<00:11, 362.41it/s] 60%|██████    | 6004/10000 [00:15<00:11, 358.68it/s] 61%|██████    | 6071/10000 [00:15<00:09, 434.76it/s] 61%|██████▏   | 6143/10000 [00:15<00:07, 501.34it/s] 62%|██████▏   | 6196/10000 [00:15<00:08, 448.13it/s] 62%|██████▏   | 6246/10000 [00:15<00:08, 454.72it/s] 63%|██████▎   | 6294/10000 [00:15<00:09, 385.54it/s] 63%|██████▎   | 6336/10000 [00:16<00:10, 359.08it/s] 64%|██████▎   | 6374/10000 [00:16<00:10, 334.67it/s] 64%|██████▍   | 6409/10000 [00:16<00:11, 310.03it/s] 64%|██████▍   | 6443/10000 [00:16<00:11, 316.44it/s] 65%|██████▍   | 6489/10000 [00:16<00:10, 348.95it/s] 65%|██████▌   | 6525/10000 [00:16<00:10, 335.64it/s] 66%|██████▌   | 6563/10000 [00:16<00:09, 344.77it/s] 66%|██████▌   | 6610/10000 [00:16<00:09, 361.07it/s] 67%|██████▋   | 6653/10000 [00:16<00:09, 351.35it/s] 67%|██████▋   | 6689/10000 [00:17<00:10, 330.93it/s] 68%|██████▊   | 6751/10000 [00:17<00:08, 405.59it/s] 68%|██████▊   | 6803/10000 [00:17<00:07, 427.47it/s] 69%|██████▊   | 6868/10000 [00:17<00:06, 488.47it/s] 69%|██████▉   | 6942/10000 [00:17<00:05, 540.80it/s] 70%|██████▉   | 6997/10000 [00:17<00:05, 519.88it/s] 70%|███████   | 7050/10000 [00:17<00:05, 519.48it/s] 71%|███████   | 7103/10000 [00:17<00:05, 489.41it/s] 72%|███████▏  | 7179/10000 [00:17<00:05, 544.83it/s] 72%|███████▏  | 7243/10000 [00:18<00:04, 563.26it/s] 73%|███████▎  | 7306/10000 [00:18<00:04, 569.71it/s] 74%|███████▍  | 7378/10000 [00:18<00:04, 601.59it/s] 74%|███████▍  | 7439/10000 [00:18<00:04, 548.03it/s] 75%|███████▍  | 7498/10000 [00:18<00:04, 556.21it/s] 76%|███████▌  | 7555/10000 [00:18<00:04, 542.46it/s] 76%|███████▌  | 7610/10000 [00:18<00:05, 470.72it/s] 77%|███████▋  | 7659/10000 [00:18<00:05, 443.18it/s] 77%|███████▋  | 7718/10000 [00:19<00:04, 469.84it/s] 78%|███████▊  | 7767/10000 [00:19<00:05, 419.83it/s] 78%|███████▊  | 7843/10000 [00:19<00:04, 503.68it/s] 79%|███████▉  | 7901/10000 [00:19<00:04, 513.53it/s] 80%|███████▉  | 7974/10000 [00:19<00:03, 571.23it/s] 81%|████████  | 8056/10000 [00:19<00:03, 616.35it/s] 81%|████████  | 8120/10000 [00:19<00:03, 575.18it/s] 82%|████████▏ | 8179/10000 [00:19<00:03, 567.41it/s] 82%|████████▏ | 8237/10000 [00:20<00:03, 455.35it/s] 83%|████████▎ | 8287/10000 [00:20<00:03, 453.47it/s] 83%|████████▎ | 8335/10000 [00:20<00:04, 407.09it/s] 84%|████████▍ | 8379/10000 [00:20<00:04, 383.63it/s] 84%|████████▍ | 8427/10000 [00:20<00:03, 405.93it/s] 85%|████████▍ | 8476/10000 [00:20<00:03, 418.53it/s] 85%|████████▌ | 8520/10000 [00:20<00:03, 405.67it/s] 86%|████████▌ | 8579/10000 [00:20<00:03, 446.22it/s] 86%|████████▋ | 8640/10000 [00:20<00:02, 490.42it/s] 87%|████████▋ | 8694/10000 [00:21<00:02, 503.05it/s] 88%|████████▊ | 8767/10000 [00:21<00:02, 559.00it/s] 89%|████████▊ | 8859/10000 [00:21<00:01, 652.02it/s] 89%|████████▉ | 8927/10000 [00:21<00:01, 655.53it/s] 90%|████████▉ | 8993/10000 [00:21<00:01, 629.49it/s] 91%|█████████ | 9065/10000 [00:21<00:01, 650.60it/s] 91%|█████████▏| 9140/10000 [00:21<00:01, 667.93it/s] 92%|█████████▏| 9208/10000 [00:21<00:01, 662.49it/s] 93%|█████████▎| 9275/10000 [00:22<00:01, 441.28it/s] 93%|█████████▎| 9329/10000 [00:22<00:01, 381.87it/s] 94%|█████████▍| 9375/10000 [00:22<00:01, 386.92it/s] 94%|█████████▍| 9420/10000 [00:22<00:01, 367.99it/s] 95%|█████████▍| 9461/10000 [00:22<00:01, 339.92it/s] 95%|█████████▍| 9498/10000 [00:22<00:01, 340.77it/s] 95%|█████████▌| 9547/10000 [00:22<00:01, 374.64it/s] 96%|█████████▌| 9587/10000 [00:23<00:01, 354.98it/s] 96%|█████████▋| 9625/10000 [00:23<00:01, 360.09it/s] 97%|█████████▋| 9670/10000 [00:23<00:00, 383.84it/s] 97%|█████████▋| 9717/10000 [00:23<00:00, 400.60it/s] 98%|█████████▊| 9763/10000 [00:23<00:00, 413.94it/s] 98%|█████████▊| 9839/10000 [00:23<00:00, 511.75it/s] 99%|█████████▉| 9920/10000 [00:23<00:00, 586.01it/s]100%|██████████| 10000/10000 [00:23<00:00, 421.80it/s]
test_neglected_p65 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p65
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p65.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.03it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.01it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.71it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.26it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.23it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.42it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.82it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 38.25it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.39it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.76it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p65_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p65_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p65_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p65_Holmes_probs.npy
{'Accuracy': 0.0188, 'Precision': 0.0206, 'Recall': 0.0185, 'F1-score': 0.0162}
starting gen taf script for test_neglected_p66
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 71/10000 [00:00<00:14, 690.24it/s]  1%|▏         | 141/10000 [00:00<00:25, 381.35it/s]  2%|▏         | 187/10000 [00:00<00:28, 339.92it/s]  2%|▏         | 225/10000 [00:00<00:31, 313.59it/s]  3%|▎         | 259/10000 [00:00<00:33, 287.57it/s]  3%|▎         | 289/10000 [00:00<00:36, 265.19it/s]  3%|▎         | 318/10000 [00:01<00:36, 265.93it/s]  3%|▎         | 345/10000 [00:01<00:37, 256.67it/s]  4%|▎         | 371/10000 [00:01<00:39, 244.18it/s]  4%|▍         | 396/10000 [00:01<00:40, 235.78it/s]  4%|▍         | 431/10000 [00:01<00:36, 258.78it/s]  5%|▍         | 468/10000 [00:01<00:33, 286.35it/s]  5%|▌         | 505/10000 [00:01<00:30, 307.70it/s]  5%|▌         | 548/10000 [00:01<00:27, 339.20it/s]  6%|▌         | 587/10000 [00:01<00:26, 353.25it/s]  6%|▋         | 631/10000 [00:02<00:25, 372.18it/s]  7%|▋         | 669/10000 [00:02<00:26, 354.80it/s]  7%|▋         | 722/10000 [00:02<00:23, 396.33it/s]  8%|▊         | 791/10000 [00:02<00:19, 479.30it/s]  8%|▊         | 846/10000 [00:02<00:18, 495.32it/s]  9%|▉         | 897/10000 [00:02<00:18, 483.35it/s]  9%|▉         | 946/10000 [00:02<00:19, 475.78it/s] 10%|▉         | 994/10000 [00:02<00:20, 444.10it/s] 10%|█         | 1039/10000 [00:02<00:23, 382.39it/s] 11%|█         | 1081/10000 [00:03<00:23, 377.48it/s] 11%|█         | 1120/10000 [00:03<00:23, 380.06it/s] 12%|█▏        | 1163/10000 [00:03<00:22, 392.37it/s] 12%|█▏        | 1203/10000 [00:03<00:24, 357.89it/s] 13%|█▎        | 1258/10000 [00:03<00:21, 408.15it/s] 14%|█▎        | 1350/10000 [00:03<00:15, 543.36it/s] 14%|█▍        | 1413/10000 [00:03<00:15, 561.88it/s] 15%|█▍        | 1471/10000 [00:03<00:21, 389.57it/s] 15%|█▌        | 1518/10000 [00:04<00:26, 316.12it/s] 16%|█▌        | 1557/10000 [00:04<00:29, 287.01it/s] 16%|█▌        | 1591/10000 [00:04<00:30, 273.47it/s] 16%|█▋        | 1635/10000 [00:04<00:27, 305.99it/s] 17%|█▋        | 1710/10000 [00:04<00:20, 404.39it/s] 18%|█▊        | 1774/10000 [00:04<00:18, 455.85it/s] 19%|█▊        | 1863/10000 [00:04<00:14, 563.22it/s] 20%|█▉        | 1969/10000 [00:05<00:11, 694.92it/s] 20%|██        | 2044/10000 [00:05<00:11, 705.81it/s] 21%|██        | 2119/10000 [00:05<00:13, 582.25it/s] 22%|██▏       | 2184/10000 [00:05<00:14, 543.17it/s] 22%|██▏       | 2243/10000 [00:05<00:16, 478.17it/s] 23%|██▎       | 2295/10000 [00:05<00:16, 473.55it/s] 23%|██▎       | 2346/10000 [00:05<00:18, 406.91it/s] 24%|██▍       | 2391/10000 [00:06<00:18, 416.53it/s] 24%|██▍       | 2443/10000 [00:06<00:17, 437.86it/s] 25%|██▍       | 2489/10000 [00:06<00:17, 435.42it/s] 26%|██▌       | 2554/10000 [00:06<00:15, 491.99it/s] 26%|██▌       | 2605/10000 [00:06<00:16, 437.45it/s] 27%|██▋       | 2651/10000 [00:06<00:18, 399.93it/s] 27%|██▋       | 2693/10000 [00:06<00:22, 319.59it/s] 27%|██▋       | 2729/10000 [00:06<00:24, 299.55it/s] 28%|██▊       | 2762/10000 [00:07<00:29, 246.41it/s] 28%|██▊       | 2792/10000 [00:07<00:28, 254.22it/s] 28%|██▊       | 2841/10000 [00:07<00:23, 306.36it/s] 29%|██▉       | 2905/10000 [00:07<00:18, 386.79it/s] 30%|██▉       | 2951/10000 [00:07<00:17, 404.30it/s] 30%|███       | 3003/10000 [00:07<00:16, 426.34it/s] 31%|███       | 3053/10000 [00:07<00:16, 423.11it/s] 31%|███       | 3098/10000 [00:07<00:17, 391.71it/s] 31%|███▏      | 3139/10000 [00:08<00:18, 365.94it/s] 32%|███▏      | 3177/10000 [00:08<00:18, 359.38it/s] 33%|███▎      | 3256/10000 [00:08<00:14, 471.07it/s] 33%|███▎      | 3319/10000 [00:08<00:13, 502.77it/s] 34%|███▍      | 3390/10000 [00:08<00:12, 549.79it/s] 35%|███▍      | 3459/10000 [00:08<00:11, 588.64it/s] 35%|███▌      | 3520/10000 [00:08<00:11, 547.31it/s] 36%|███▌      | 3577/10000 [00:08<00:11, 550.06it/s] 36%|███▋      | 3633/10000 [00:08<00:11, 531.05it/s] 37%|███▋      | 3697/10000 [00:09<00:11, 548.11it/s] 38%|███▊      | 3778/10000 [00:09<00:10, 613.33it/s] 38%|███▊      | 3841/10000 [00:09<00:10, 571.92it/s] 39%|███▉      | 3900/10000 [00:09<00:11, 542.95it/s] 40%|███▉      | 3956/10000 [00:09<00:12, 501.97it/s] 40%|████      | 4011/10000 [00:09<00:11, 508.53it/s] 41%|████      | 4087/10000 [00:09<00:10, 569.69it/s] 42%|████▏     | 4167/10000 [00:09<00:09, 630.53it/s] 43%|████▎     | 4251/10000 [00:09<00:08, 682.07it/s] 43%|████▎     | 4321/10000 [00:10<00:08, 652.79it/s] 44%|████▍     | 4411/10000 [00:10<00:07, 719.75it/s] 45%|████▍     | 4485/10000 [00:10<00:11, 482.68it/s] 45%|████▌     | 4545/10000 [00:10<00:12, 433.71it/s] 46%|████▌     | 4597/10000 [00:10<00:13, 396.06it/s] 46%|████▋     | 4643/10000 [00:10<00:14, 370.52it/s] 47%|████▋     | 4684/10000 [00:11<00:14, 362.15it/s] 47%|████▋     | 4723/10000 [00:11<00:14, 357.07it/s] 48%|████▊     | 4781/10000 [00:11<00:12, 404.00it/s] 48%|████▊     | 4824/10000 [00:11<00:14, 360.00it/s] 49%|████▊     | 4863/10000 [00:11<00:15, 323.16it/s] 49%|████▉     | 4898/10000 [00:11<00:19, 266.98it/s] 49%|████▉     | 4939/10000 [00:11<00:17, 291.08it/s] 50%|████▉     | 4971/10000 [00:12<00:18, 267.03it/s] 50%|█████     | 5002/10000 [00:12<00:18, 276.62it/s] 51%|█████     | 5071/10000 [00:12<00:13, 377.38it/s] 51%|█████     | 5122/10000 [00:12<00:11, 406.94it/s] 52%|█████▏    | 5174/10000 [00:12<00:11, 430.58it/s] 52%|█████▏    | 5220/10000 [00:12<00:12, 396.62it/s] 53%|█████▎    | 5262/10000 [00:12<00:13, 348.64it/s] 53%|█████▎    | 5299/10000 [00:12<00:13, 336.57it/s] 53%|█████▎    | 5335/10000 [00:13<00:17, 270.29it/s] 54%|█████▎    | 5365/10000 [00:13<00:17, 261.34it/s] 54%|█████▍    | 5397/10000 [00:13<00:17, 261.70it/s] 54%|█████▍    | 5434/10000 [00:13<00:15, 287.00it/s] 55%|█████▍    | 5487/10000 [00:13<00:13, 340.03it/s] 55%|█████▌    | 5538/10000 [00:13<00:11, 377.48it/s] 56%|█████▌    | 5584/10000 [00:13<00:11, 393.41it/s] 56%|█████▋    | 5650/10000 [00:13<00:09, 463.39it/s] 57%|█████▋    | 5709/10000 [00:14<00:08, 498.32it/s] 58%|█████▊    | 5770/10000 [00:14<00:08, 524.95it/s] 58%|█████▊    | 5824/10000 [00:14<00:08, 504.68it/s] 59%|█████▉    | 5876/10000 [00:14<00:09, 440.96it/s] 59%|█████▉    | 5922/10000 [00:14<00:09, 422.35it/s] 60%|█████▉    | 5966/10000 [00:14<00:11, 351.06it/s] 60%|██████    | 6004/10000 [00:14<00:11, 352.59it/s] 61%|██████    | 6070/10000 [00:14<00:09, 419.53it/s] 61%|██████    | 6120/10000 [00:14<00:08, 439.49it/s] 62%|██████▏   | 6182/10000 [00:15<00:08, 476.98it/s] 62%|██████▏   | 6232/10000 [00:15<00:08, 455.25it/s] 63%|██████▎   | 6279/10000 [00:15<00:09, 391.76it/s] 63%|██████▎   | 6321/10000 [00:15<00:10, 352.48it/s] 64%|██████▎   | 6359/10000 [00:15<00:10, 339.86it/s] 64%|██████▍   | 6395/10000 [00:15<00:10, 331.28it/s] 64%|██████▍   | 6430/10000 [00:15<00:10, 332.62it/s] 65%|██████▍   | 6464/10000 [00:16<00:11, 317.13it/s] 65%|██████▌   | 6500/10000 [00:16<00:10, 321.55it/s] 65%|██████▌   | 6534/10000 [00:16<00:10, 326.31it/s] 66%|██████▌   | 6567/10000 [00:16<00:10, 313.35it/s] 66%|██████▌   | 6612/10000 [00:16<00:09, 341.44it/s] 66%|██████▋   | 6650/10000 [00:16<00:09, 347.15it/s] 67%|██████▋   | 6700/10000 [00:16<00:08, 381.59it/s] 67%|██████▋   | 6739/10000 [00:16<00:08, 369.56it/s] 68%|██████▊   | 6777/10000 [00:16<00:08, 367.97it/s] 68%|██████▊   | 6844/10000 [00:16<00:06, 451.28it/s] 69%|██████▉   | 6932/10000 [00:17<00:05, 564.79it/s] 70%|███████   | 7010/10000 [00:17<00:04, 618.61it/s] 71%|███████   | 7073/10000 [00:17<00:05, 534.35it/s] 71%|███████▏  | 7130/10000 [00:17<00:05, 525.30it/s] 72%|███████▏  | 7185/10000 [00:17<00:05, 522.00it/s] 73%|███████▎  | 7266/10000 [00:17<00:04, 600.04it/s] 73%|███████▎  | 7328/10000 [00:17<00:04, 592.52it/s] 74%|███████▍  | 7406/10000 [00:17<00:04, 623.10it/s] 75%|███████▍  | 7470/10000 [00:18<00:04, 558.61it/s] 75%|███████▌  | 7543/10000 [00:18<00:04, 590.91it/s] 76%|███████▌  | 7604/10000 [00:18<00:04, 516.41it/s] 77%|███████▋  | 7658/10000 [00:18<00:04, 475.23it/s] 77%|███████▋  | 7708/10000 [00:18<00:05, 435.89it/s] 78%|███████▊  | 7754/10000 [00:18<00:05, 430.78it/s] 78%|███████▊  | 7799/10000 [00:18<00:05, 386.62it/s] 79%|███████▊  | 7859/10000 [00:18<00:04, 433.99it/s] 79%|███████▉  | 7938/10000 [00:19<00:03, 523.26it/s] 80%|███████▉  | 7997/10000 [00:19<00:03, 539.64it/s] 81%|████████  | 8071/10000 [00:19<00:03, 588.81it/s] 81%|████████▏ | 8132/10000 [00:19<00:03, 580.28it/s] 82%|████████▏ | 8192/10000 [00:19<00:03, 559.27it/s] 82%|████████▏ | 8249/10000 [00:19<00:03, 526.83it/s] 83%|████████▎ | 8303/10000 [00:19<00:04, 419.29it/s] 83%|████████▎ | 8349/10000 [00:19<00:04, 399.12it/s] 84%|████████▍ | 8397/10000 [00:20<00:03, 417.43it/s] 84%|████████▍ | 8441/10000 [00:20<00:04, 373.46it/s] 85%|████████▍ | 8494/10000 [00:20<00:03, 403.99it/s] 85%|████████▌ | 8537/10000 [00:20<00:03, 400.20it/s] 86%|████████▌ | 8593/10000 [00:20<00:03, 441.14it/s] 87%|████████▋ | 8657/10000 [00:20<00:02, 492.05it/s] 87%|████████▋ | 8749/10000 [00:20<00:02, 605.68it/s] 88%|████████▊ | 8825/10000 [00:20<00:01, 645.64it/s] 89%|████████▉ | 8905/10000 [00:20<00:01, 687.66it/s] 90%|████████▉ | 8986/10000 [00:21<00:01, 715.06it/s] 91%|█████████ | 9059/10000 [00:21<00:01, 681.69it/s] 91%|█████████▏| 9133/10000 [00:21<00:01, 691.64it/s] 92%|█████████▏| 9205/10000 [00:21<00:01, 698.62it/s] 93%|█████████▎| 9276/10000 [00:21<00:01, 473.09it/s] 93%|█████████▎| 9334/10000 [00:21<00:01, 445.49it/s] 94%|█████████▍| 9386/10000 [00:21<00:01, 379.69it/s] 94%|█████████▍| 9430/10000 [00:22<00:01, 377.63it/s] 95%|█████████▍| 9472/10000 [00:22<00:01, 361.12it/s] 95%|█████████▌| 9512/10000 [00:22<00:01, 357.50it/s] 96%|█████████▌| 9550/10000 [00:22<00:01, 349.06it/s] 96%|█████████▌| 9590/10000 [00:22<00:01, 357.22it/s] 96%|█████████▋| 9643/10000 [00:22<00:00, 399.70it/s] 97%|█████████▋| 9690/10000 [00:22<00:00, 393.06it/s] 97%|█████████▋| 9743/10000 [00:22<00:00, 427.09it/s] 98%|█████████▊| 9787/10000 [00:22<00:00, 427.29it/s] 98%|█████████▊| 9833/10000 [00:23<00:00, 436.26it/s] 99%|█████████▉| 9888/10000 [00:23<00:00, 460.02it/s]100%|█████████▉| 9967/10000 [00:23<00:00, 544.27it/s]100%|██████████| 10000/10000 [00:23<00:00, 429.12it/s]
test_neglected_p66 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p66
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p66.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:36,  1.06it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.37it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.80it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 20.22it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 26.20it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 31.20it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 35.45it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.84it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 22.11it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p66_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p66_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p66_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p66_Holmes_probs.npy
{'Accuracy': 0.0201, 'Precision': 0.0218, 'Recall': 0.0199, 'F1-score': 0.0173}
starting gen taf script for test_neglected_p67
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 77/10000 [00:00<00:14, 700.81it/s]  1%|▏         | 148/10000 [00:00<00:25, 383.28it/s]  2%|▏         | 194/10000 [00:00<00:30, 324.20it/s]  2%|▏         | 231/10000 [00:00<00:30, 324.63it/s]  3%|▎         | 266/10000 [00:00<00:33, 291.97it/s]  3%|▎         | 297/10000 [00:00<00:35, 277.20it/s]  3%|▎         | 326/10000 [00:01<00:34, 276.95it/s]  4%|▎         | 355/10000 [00:01<00:34, 278.26it/s]  4%|▍         | 387/10000 [00:01<00:33, 284.45it/s]  4%|▍         | 432/10000 [00:01<00:29, 325.14it/s]  5%|▍         | 467/10000 [00:01<00:29, 326.40it/s]  5%|▌         | 501/10000 [00:01<00:34, 273.32it/s]  5%|▌         | 530/10000 [00:01<00:35, 270.22it/s]  6%|▌         | 571/10000 [00:01<00:31, 300.48it/s]  6%|▌         | 612/10000 [00:01<00:29, 319.58it/s]  6%|▋         | 646/10000 [00:02<00:28, 323.66it/s]  7%|▋         | 686/10000 [00:02<00:27, 342.39it/s]  7%|▋         | 735/10000 [00:02<00:24, 381.63it/s]  8%|▊         | 778/10000 [00:02<00:24, 383.54it/s]  8%|▊         | 817/10000 [00:02<00:23, 384.31it/s]  9%|▊         | 856/10000 [00:02<00:24, 379.41it/s]  9%|▉         | 913/10000 [00:02<00:20, 434.06it/s] 10%|▉         | 969/10000 [00:02<00:19, 468.85it/s] 10%|█         | 1017/10000 [00:02<00:22, 405.60it/s] 11%|█         | 1060/10000 [00:03<00:24, 367.41it/s] 11%|█         | 1106/10000 [00:03<00:23, 384.72it/s] 11%|█▏        | 1146/10000 [00:03<00:23, 383.17it/s] 12%|█▏        | 1186/10000 [00:03<00:24, 364.99it/s] 12%|█▏        | 1235/10000 [00:03<00:22, 389.16it/s] 13%|█▎        | 1314/10000 [00:03<00:17, 483.29it/s] 14%|█▍        | 1383/10000 [00:03<00:15, 539.67it/s] 14%|█▍        | 1439/10000 [00:03<00:19, 438.56it/s] 15%|█▍        | 1487/10000 [00:04<00:24, 351.98it/s] 15%|█▌        | 1528/10000 [00:04<00:27, 306.12it/s] 16%|█▌        | 1563/10000 [00:04<00:32, 260.33it/s] 16%|█▌        | 1593/10000 [00:04<00:34, 246.36it/s] 16%|█▋        | 1649/10000 [00:04<00:27, 307.19it/s] 17%|█▋        | 1733/10000 [00:04<00:19, 426.28it/s] 18%|█▊        | 1807/10000 [00:04<00:16, 501.12it/s] 19%|█▉        | 1889/10000 [00:05<00:14, 575.88it/s] 20%|█▉        | 1981/10000 [00:05<00:12, 649.19it/s] 21%|██        | 2051/10000 [00:05<00:12, 655.55it/s] 21%|██        | 2120/10000 [00:05<00:13, 571.98it/s] 22%|██▏       | 2200/10000 [00:05<00:12, 605.37it/s] 23%|██▎       | 2264/10000 [00:05<00:16, 462.69it/s] 23%|██▎       | 2317/10000 [00:05<00:18, 424.84it/s] 24%|██▎       | 2365/10000 [00:06<00:17, 430.51it/s] 24%|██▍       | 2412/10000 [00:06<00:20, 378.90it/s] 25%|██▍       | 2459/10000 [00:06<00:19, 392.29it/s] 25%|██▌       | 2513/10000 [00:06<00:17, 424.77it/s] 26%|██▌       | 2569/10000 [00:06<00:16, 453.80it/s] 26%|██▌       | 2617/10000 [00:06<00:17, 414.33it/s] 27%|██▋       | 2661/10000 [00:06<00:23, 313.05it/s] 27%|██▋       | 2697/10000 [00:07<00:25, 285.09it/s] 27%|██▋       | 2729/10000 [00:07<00:25, 287.20it/s] 28%|██▊       | 2761/10000 [00:07<00:26, 273.85it/s] 28%|██▊       | 2790/10000 [00:07<00:27, 258.53it/s] 28%|██▊       | 2821/10000 [00:07<00:26, 266.65it/s] 29%|██▉       | 2876/10000 [00:07<00:21, 333.58it/s] 29%|██▉       | 2941/10000 [00:07<00:17, 411.02it/s] 30%|██▉       | 2986/10000 [00:07<00:16, 416.30it/s] 30%|███       | 3030/10000 [00:08<00:17, 390.40it/s] 31%|███       | 3071/10000 [00:08<00:19, 357.13it/s] 31%|███       | 3108/10000 [00:08<00:19, 358.90it/s] 31%|███▏      | 3146/10000 [00:08<00:18, 364.15it/s] 32%|███▏      | 3189/10000 [00:08<00:18, 366.87it/s] 33%|███▎      | 3256/10000 [00:08<00:15, 449.29it/s] 33%|███▎      | 3348/10000 [00:08<00:11, 570.51it/s] 34%|███▍      | 3429/10000 [00:08<00:10, 636.81it/s] 35%|███▍      | 3494/10000 [00:08<00:11, 550.46it/s] 36%|███▌      | 3552/10000 [00:09<00:11, 546.56it/s] 36%|███▌      | 3609/10000 [00:09<00:11, 537.44it/s] 37%|███▋      | 3696/10000 [00:09<00:10, 626.87it/s] 38%|███▊      | 3772/10000 [00:09<00:09, 663.91it/s] 38%|███▊      | 3840/10000 [00:09<00:10, 606.76it/s] 39%|███▉      | 3903/10000 [00:09<00:10, 564.08it/s] 40%|███▉      | 3962/10000 [00:09<00:12, 472.10it/s] 40%|████      | 4019/10000 [00:09<00:12, 490.13it/s] 41%|████      | 4082/10000 [00:10<00:11, 515.24it/s] 42%|████▏     | 4172/10000 [00:10<00:09, 602.20it/s] 42%|████▏     | 4241/10000 [00:10<00:09, 621.80it/s] 43%|████▎     | 4324/10000 [00:10<00:08, 672.02it/s] 44%|████▍     | 4393/10000 [00:10<00:09, 573.23it/s] 45%|████▍     | 4454/10000 [00:10<00:11, 467.79it/s] 45%|████▌     | 4506/10000 [00:10<00:13, 398.80it/s] 46%|████▌     | 4559/10000 [00:10<00:12, 425.14it/s] 46%|████▌     | 4606/10000 [00:11<00:13, 395.36it/s] 46%|████▋     | 4649/10000 [00:11<00:13, 388.13it/s] 47%|████▋     | 4690/10000 [00:11<00:13, 392.68it/s] 47%|████▋     | 4731/10000 [00:11<00:15, 341.25it/s] 48%|████▊     | 4782/10000 [00:11<00:13, 375.02it/s] 48%|████▊     | 4822/10000 [00:11<00:13, 371.25it/s] 49%|████▊     | 4861/10000 [00:11<00:14, 347.00it/s] 49%|████▉     | 4897/10000 [00:12<00:16, 309.89it/s] 49%|████▉     | 4930/10000 [00:12<00:16, 300.64it/s] 50%|████▉     | 4961/10000 [00:12<00:18, 272.78it/s] 50%|████▉     | 4993/10000 [00:12<00:17, 281.49it/s] 50%|█████     | 5039/10000 [00:12<00:15, 320.16it/s] 51%|█████     | 5084/10000 [00:12<00:14, 346.64it/s] 51%|█████▏    | 5141/10000 [00:12<00:11, 405.49it/s] 52%|█████▏    | 5186/10000 [00:12<00:11, 414.70it/s] 52%|█████▏    | 5229/10000 [00:12<00:13, 345.95it/s] 53%|█████▎    | 5267/10000 [00:13<00:14, 334.54it/s] 53%|█████▎    | 5303/10000 [00:13<00:18, 259.32it/s] 53%|█████▎    | 5333/10000 [00:13<00:19, 243.70it/s] 54%|█████▎    | 5360/10000 [00:13<00:20, 228.02it/s] 54%|█████▍    | 5417/10000 [00:13<00:15, 295.28it/s] 55%|█████▍    | 5472/10000 [00:13<00:13, 346.04it/s] 55%|█████▌    | 5514/10000 [00:13<00:12, 363.50it/s] 56%|█████▌    | 5566/10000 [00:14<00:11, 394.53it/s] 56%|█████▌    | 5613/10000 [00:14<00:10, 410.60it/s] 57%|█████▋    | 5674/10000 [00:14<00:09, 461.35it/s] 57%|█████▋    | 5747/10000 [00:14<00:07, 536.10it/s] 58%|█████▊    | 5809/10000 [00:14<00:07, 549.02it/s] 59%|█████▊    | 5865/10000 [00:14<00:08, 461.47it/s] 59%|█████▉    | 5915/10000 [00:14<00:09, 444.00it/s] 60%|█████▉    | 5962/10000 [00:14<00:10, 395.55it/s] 60%|██████    | 6004/10000 [00:15<00:10, 387.75it/s] 61%|██████    | 6061/10000 [00:15<00:09, 432.44it/s] 61%|██████    | 6124/10000 [00:15<00:08, 480.42it/s] 62%|██████▏   | 6180/10000 [00:15<00:07, 495.53it/s] 62%|██████▏   | 6231/10000 [00:15<00:07, 498.49it/s] 63%|██████▎   | 6282/10000 [00:15<00:09, 393.97it/s] 63%|██████▎   | 6326/10000 [00:15<00:11, 329.42it/s] 64%|██████▎   | 6366/10000 [00:15<00:10, 338.28it/s] 64%|██████▍   | 6407/10000 [00:16<00:10, 338.39it/s] 64%|██████▍   | 6444/10000 [00:16<00:10, 330.22it/s] 65%|██████▍   | 6483/10000 [00:16<00:10, 340.54it/s] 65%|██████▌   | 6527/10000 [00:16<00:09, 356.12it/s] 66%|██████▌   | 6564/10000 [00:16<00:10, 322.42it/s] 66%|██████▌   | 6598/10000 [00:16<00:10, 322.25it/s] 66%|██████▋   | 6646/10000 [00:16<00:09, 351.12it/s] 67%|██████▋   | 6686/10000 [00:16<00:09, 361.83it/s] 67%|██████▋   | 6725/10000 [00:16<00:08, 366.60it/s] 68%|██████▊   | 6763/10000 [00:17<00:08, 360.91it/s] 68%|██████▊   | 6800/10000 [00:17<00:09, 330.75it/s] 69%|██████▊   | 6874/10000 [00:17<00:07, 438.79it/s] 69%|██████▉   | 6926/10000 [00:17<00:06, 461.07it/s] 70%|██████▉   | 6982/10000 [00:17<00:06, 486.59it/s] 70%|███████   | 7032/10000 [00:17<00:06, 483.64it/s] 71%|███████   | 7088/10000 [00:17<00:05, 497.09it/s] 71%|███████▏  | 7139/10000 [00:17<00:06, 456.69it/s] 72%|███████▏  | 7199/10000 [00:17<00:05, 487.43it/s] 73%|███████▎  | 7270/10000 [00:18<00:05, 545.70it/s] 73%|███████▎  | 7330/10000 [00:18<00:04, 551.34it/s] 74%|███████▍  | 7418/10000 [00:18<00:04, 632.28it/s] 75%|███████▍  | 7482/10000 [00:18<00:04, 541.67it/s] 75%|███████▌  | 7539/10000 [00:18<00:04, 547.63it/s] 76%|███████▌  | 7599/10000 [00:18<00:04, 546.01it/s] 77%|███████▋  | 7655/10000 [00:18<00:05, 458.41it/s] 77%|███████▋  | 7704/10000 [00:18<00:04, 460.98it/s] 78%|███████▊  | 7753/10000 [00:19<00:05, 426.05it/s] 78%|███████▊  | 7801/10000 [00:19<00:05, 430.77it/s] 79%|███████▊  | 7854/10000 [00:19<00:04, 454.84it/s] 79%|███████▉  | 7918/10000 [00:19<00:04, 504.70it/s] 80%|███████▉  | 7989/10000 [00:19<00:03, 561.71it/s] 81%|████████  | 8070/10000 [00:19<00:03, 619.73it/s] 81%|████████▏ | 8135/10000 [00:19<00:02, 628.17it/s] 82%|████████▏ | 8199/10000 [00:19<00:03, 597.93it/s] 83%|████████▎ | 8260/10000 [00:19<00:03, 481.09it/s] 83%|████████▎ | 8313/10000 [00:20<00:03, 431.83it/s] 84%|████████▎ | 8360/10000 [00:20<00:04, 383.73it/s] 84%|████████▍ | 8402/10000 [00:20<00:04, 386.69it/s] 84%|████████▍ | 8443/10000 [00:20<00:04, 377.66it/s] 85%|████████▍ | 8490/10000 [00:20<00:03, 393.58it/s] 85%|████████▌ | 8546/10000 [00:20<00:03, 431.21it/s] 86%|████████▌ | 8610/10000 [00:20<00:02, 477.16it/s] 87%|████████▋ | 8713/10000 [00:20<00:02, 617.19it/s] 88%|████████▊ | 8777/10000 [00:21<00:02, 598.18it/s] 89%|████████▊ | 8872/10000 [00:21<00:01, 687.50it/s] 89%|████████▉ | 8943/10000 [00:21<00:01, 664.72it/s] 90%|█████████ | 9011/10000 [00:21<00:01, 666.21it/s] 91%|█████████ | 9079/10000 [00:21<00:01, 640.77it/s] 92%|█████████▏| 9155/10000 [00:21<00:01, 663.06it/s] 92%|█████████▏| 9222/10000 [00:21<00:01, 574.99it/s] 93%|█████████▎| 9282/10000 [00:21<00:01, 533.97it/s] 93%|█████████▎| 9338/10000 [00:22<00:01, 433.51it/s] 94%|█████████▍| 9386/10000 [00:22<00:01, 369.50it/s] 94%|█████████▍| 9434/10000 [00:22<00:01, 388.83it/s] 95%|█████████▍| 9477/10000 [00:22<00:01, 385.11it/s] 95%|█████████▌| 9518/10000 [00:22<00:01, 377.03it/s] 96%|█████████▌| 9558/10000 [00:22<00:01, 362.82it/s] 96%|█████████▌| 9599/10000 [00:22<00:01, 365.26it/s] 96%|█████████▋| 9647/10000 [00:22<00:00, 368.54it/s] 97%|█████████▋| 9695/10000 [00:23<00:00, 395.05it/s] 97%|█████████▋| 9743/10000 [00:23<00:00, 409.64it/s] 98%|█████████▊| 9785/10000 [00:23<00:00, 396.25it/s] 98%|█████████▊| 9832/10000 [00:23<00:00, 411.96it/s] 99%|█████████▉| 9910/10000 [00:23<00:00, 501.59it/s]100%|█████████▉| 9978/10000 [00:23<00:00, 543.42it/s]100%|██████████| 10000/10000 [00:23<00:00, 422.72it/s]
test_neglected_p67 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p67
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p67.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.04it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.19it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.58it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.82it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.73it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.81it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 35.11it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.54it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.89it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p67_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p67_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p67_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p67_Holmes_probs.npy
{'Accuracy': 0.02, 'Precision': 0.0237, 'Recall': 0.0197, 'F1-score': 0.0174}
starting gen taf script for test_neglected_p68
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 93/10000 [00:00<00:11, 878.43it/s]  2%|▏         | 181/10000 [00:00<00:30, 320.95it/s]  2%|▏         | 231/10000 [00:00<00:30, 315.71it/s]  3%|▎         | 272/10000 [00:00<00:32, 299.11it/s]  3%|▎         | 307/10000 [00:00<00:34, 279.17it/s]  3%|▎         | 340/10000 [00:01<00:33, 289.81it/s]  4%|▍         | 375/10000 [00:01<00:31, 302.14it/s]  4%|▍         | 408/10000 [00:01<00:32, 295.39it/s]  4%|▍         | 443/10000 [00:01<00:31, 306.72it/s]  5%|▍         | 476/10000 [00:01<00:30, 308.99it/s]  5%|▌         | 509/10000 [00:01<00:30, 314.54it/s]  5%|▌         | 548/10000 [00:01<00:28, 329.96it/s]  6%|▌         | 590/10000 [00:01<00:26, 351.08it/s]  6%|▋         | 626/10000 [00:01<00:26, 350.65it/s]  7%|▋         | 662/10000 [00:02<00:27, 335.40it/s]  7%|▋         | 718/10000 [00:02<00:23, 397.59it/s]  8%|▊         | 788/10000 [00:02<00:19, 483.42it/s]  8%|▊         | 838/10000 [00:02<00:19, 481.52it/s]  9%|▉         | 895/10000 [00:02<00:17, 507.05it/s]  9%|▉         | 947/10000 [00:02<00:17, 508.16it/s] 10%|▉         | 999/10000 [00:02<00:20, 441.14it/s] 10%|█         | 1045/10000 [00:02<00:21, 421.29it/s] 11%|█         | 1101/10000 [00:02<00:19, 453.34it/s] 11%|█▏        | 1148/10000 [00:03<00:23, 378.07it/s] 12%|█▏        | 1202/10000 [00:03<00:21, 414.26it/s] 13%|█▎        | 1260/10000 [00:03<00:19, 456.56it/s] 13%|█▎        | 1315/10000 [00:03<00:18, 474.36it/s] 14%|█▍        | 1380/10000 [00:03<00:16, 515.59it/s] 14%|█▍        | 1434/10000 [00:03<00:20, 412.04it/s] 15%|█▍        | 1480/10000 [00:03<00:24, 343.32it/s] 15%|█▌        | 1519/10000 [00:04<00:26, 317.78it/s] 16%|█▌        | 1554/10000 [00:04<00:31, 269.45it/s] 16%|█▌        | 1584/10000 [00:04<00:31, 271.02it/s] 16%|█▌        | 1614/10000 [00:04<00:32, 261.54it/s] 17%|█▋        | 1698/10000 [00:04<00:21, 388.75it/s] 18%|█▊        | 1763/10000 [00:04<00:18, 441.30it/s] 18%|█▊        | 1838/10000 [00:04<00:15, 512.95it/s] 19%|█▉        | 1925/10000 [00:04<00:13, 603.52it/s] 20%|█▉        | 1989/10000 [00:05<00:13, 613.20it/s] 21%|██        | 2053/10000 [00:05<00:14, 566.94it/s] 21%|██        | 2112/10000 [00:05<00:15, 522.09it/s] 22%|██▏       | 2167/10000 [00:05<00:15, 496.28it/s] 22%|██▏       | 2219/10000 [00:05<00:17, 433.99it/s] 23%|██▎       | 2265/10000 [00:05<00:20, 381.47it/s] 23%|██▎       | 2306/10000 [00:05<00:21, 355.93it/s] 23%|██▎       | 2343/10000 [00:06<00:24, 316.60it/s] 24%|██▍       | 2382/10000 [00:06<00:22, 332.45it/s] 24%|██▍       | 2444/10000 [00:06<00:19, 395.66it/s] 25%|██▌       | 2508/10000 [00:06<00:16, 452.59it/s] 26%|██▌       | 2566/10000 [00:06<00:15, 483.51it/s] 26%|██▌       | 2617/10000 [00:06<00:15, 477.71it/s] 27%|██▋       | 2667/10000 [00:06<00:22, 329.61it/s] 27%|██▋       | 2707/10000 [00:07<00:24, 296.85it/s] 27%|██▋       | 2742/10000 [00:07<00:28, 250.29it/s] 28%|██▊       | 2772/10000 [00:07<00:30, 238.99it/s] 28%|██▊       | 2822/10000 [00:07<00:24, 290.41it/s] 29%|██▊       | 2860/10000 [00:07<00:23, 309.82it/s] 29%|██▉       | 2921/10000 [00:07<00:18, 379.78it/s] 30%|██▉       | 2970/10000 [00:07<00:17, 402.74it/s] 30%|███       | 3014/10000 [00:07<00:17, 410.52it/s] 31%|███       | 3058/10000 [00:07<00:16, 414.59it/s] 31%|███       | 3102/10000 [00:08<00:19, 354.81it/s] 31%|███▏      | 3143/10000 [00:08<00:19, 359.06it/s] 32%|███▏      | 3181/10000 [00:08<00:20, 333.08it/s] 32%|███▏      | 3232/10000 [00:08<00:18, 364.86it/s] 33%|███▎      | 3307/10000 [00:08<00:14, 462.47it/s] 34%|███▎      | 3370/10000 [00:08<00:13, 503.39it/s] 34%|███▍      | 3433/10000 [00:08<00:12, 535.15it/s] 35%|███▌      | 3505/10000 [00:08<00:11, 572.41it/s] 36%|███▌      | 3564/10000 [00:09<00:12, 519.18it/s] 36%|███▌      | 3618/10000 [00:09<00:12, 516.24it/s] 37%|███▋      | 3682/10000 [00:09<00:11, 549.51it/s] 37%|███▋      | 3749/10000 [00:09<00:10, 575.63it/s] 38%|███▊      | 3828/10000 [00:09<00:09, 624.94it/s] 39%|███▉      | 3892/10000 [00:09<00:10, 574.79it/s] 40%|███▉      | 3951/10000 [00:09<00:11, 523.34it/s] 40%|████      | 4015/10000 [00:09<00:11, 543.58it/s] 41%|████      | 4076/10000 [00:09<00:10, 557.90it/s] 41%|████▏     | 4137/10000 [00:10<00:10, 571.50it/s] 42%|████▏     | 4212/10000 [00:10<00:09, 620.52it/s] 43%|████▎     | 4281/10000 [00:10<00:09, 629.72it/s] 44%|████▎     | 4352/10000 [00:10<00:08, 650.62it/s] 44%|████▍     | 4418/10000 [00:10<00:09, 558.69it/s] 45%|████▍     | 4477/10000 [00:10<00:10, 523.41it/s] 45%|████▌     | 4532/10000 [00:10<00:12, 436.06it/s] 46%|████▌     | 4579/10000 [00:11<00:14, 380.14it/s] 46%|████▌     | 4621/10000 [00:11<00:14, 367.97it/s] 47%|████▋     | 4660/10000 [00:11<00:15, 351.25it/s] 47%|████▋     | 4704/10000 [00:11<00:14, 364.80it/s] 47%|████▋     | 4742/10000 [00:11<00:15, 340.47it/s] 48%|████▊     | 4791/10000 [00:11<00:13, 375.24it/s] 48%|████▊     | 4830/10000 [00:11<00:16, 305.55it/s] 49%|████▊     | 4868/10000 [00:11<00:16, 311.42it/s] 49%|████▉     | 4902/10000 [00:12<00:17, 298.08it/s] 49%|████▉     | 4934/10000 [00:12<00:18, 276.44it/s] 50%|████▉     | 4965/10000 [00:12<00:18, 273.50it/s] 50%|████▉     | 4994/10000 [00:12<00:18, 275.10it/s] 50%|█████     | 5037/10000 [00:12<00:15, 315.07it/s] 51%|█████     | 5109/10000 [00:12<00:11, 420.34it/s] 52%|█████▏    | 5161/10000 [00:12<00:11, 436.46it/s] 52%|█████▏    | 5207/10000 [00:12<00:10, 442.86it/s] 53%|█████▎    | 5253/10000 [00:12<00:12, 384.37it/s] 53%|█████▎    | 5294/10000 [00:13<00:14, 321.33it/s] 53%|█████▎    | 5329/10000 [00:13<00:16, 291.40it/s] 54%|█████▎    | 5361/10000 [00:13<00:15, 295.89it/s] 54%|█████▍    | 5393/10000 [00:13<00:16, 273.86it/s] 54%|█████▍    | 5435/10000 [00:13<00:14, 307.13it/s] 55%|█████▍    | 5479/10000 [00:13<00:13, 340.24it/s] 55%|█████▌    | 5547/10000 [00:13<00:10, 419.72it/s] 56%|█████▌    | 5595/10000 [00:13<00:10, 432.86it/s] 57%|█████▋    | 5651/10000 [00:14<00:09, 463.54it/s] 57%|█████▋    | 5712/10000 [00:14<00:08, 504.79it/s] 58%|█████▊    | 5777/10000 [00:14<00:07, 538.78it/s] 58%|█████▊    | 5832/10000 [00:14<00:09, 434.31it/s] 59%|█████▉    | 5880/10000 [00:14<00:10, 411.17it/s] 59%|█████▉    | 5924/10000 [00:14<00:10, 404.95it/s] 60%|█████▉    | 5967/10000 [00:14<00:09, 407.40it/s] 60%|██████    | 6010/10000 [00:14<00:10, 390.35it/s] 61%|██████    | 6077/10000 [00:15<00:08, 461.51it/s] 61%|██████▏   | 6127/10000 [00:15<00:08, 470.25it/s] 62%|██████▏   | 6181/10000 [00:15<00:07, 489.18it/s] 62%|██████▏   | 6231/10000 [00:15<00:08, 454.10it/s] 63%|██████▎   | 6278/10000 [00:15<00:09, 374.77it/s] 63%|██████▎   | 6319/10000 [00:15<00:10, 365.32it/s] 64%|██████▎   | 6358/10000 [00:15<00:10, 352.13it/s] 64%|██████▍   | 6403/10000 [00:15<00:09, 365.28it/s] 64%|██████▍   | 6441/10000 [00:16<00:09, 362.70it/s] 65%|██████▍   | 6478/10000 [00:16<00:10, 344.29it/s] 65%|██████▌   | 6513/10000 [00:16<00:10, 329.61it/s] 66%|██████▌   | 6553/10000 [00:16<00:10, 343.51it/s] 66%|██████▌   | 6601/10000 [00:16<00:08, 380.30it/s] 66%|██████▋   | 6640/10000 [00:16<00:09, 347.73it/s] 67%|██████▋   | 6688/10000 [00:16<00:08, 382.68it/s] 67%|██████▋   | 6728/10000 [00:16<00:08, 374.20it/s] 68%|██████▊   | 6768/10000 [00:16<00:08, 366.12it/s] 68%|██████▊   | 6821/10000 [00:17<00:07, 406.19it/s] 69%|██████▉   | 6896/10000 [00:17<00:06, 488.90it/s] 70%|██████▉   | 6980/10000 [00:17<00:05, 582.16it/s] 70%|███████   | 7040/10000 [00:17<00:05, 515.26it/s] 71%|███████   | 7094/10000 [00:17<00:05, 505.48it/s] 72%|███████▏  | 7150/10000 [00:17<00:05, 506.49it/s] 72%|███████▏  | 7204/10000 [00:17<00:05, 506.21it/s] 73%|███████▎  | 7274/10000 [00:17<00:04, 552.77it/s] 73%|███████▎  | 7338/10000 [00:17<00:04, 572.62it/s] 74%|███████▍  | 7412/10000 [00:18<00:04, 607.57it/s] 75%|███████▍  | 7474/10000 [00:18<00:04, 546.47it/s] 75%|███████▌  | 7530/10000 [00:18<00:04, 512.06it/s] 76%|███████▌  | 7589/10000 [00:18<00:04, 528.18it/s] 76%|███████▋  | 7643/10000 [00:18<00:04, 517.11it/s] 77%|███████▋  | 7696/10000 [00:18<00:05, 427.10it/s] 77%|███████▋  | 7742/10000 [00:18<00:05, 407.40it/s] 78%|███████▊  | 7785/10000 [00:18<00:05, 405.09it/s] 79%|███████▊  | 7872/10000 [00:19<00:04, 521.42it/s] 79%|███████▉  | 7947/10000 [00:19<00:03, 577.54it/s] 80%|████████  | 8032/10000 [00:19<00:03, 649.28it/s] 81%|████████  | 8100/10000 [00:19<00:03, 580.66it/s] 82%|████████▏ | 8162/10000 [00:19<00:03, 588.61it/s] 82%|████████▏ | 8223/10000 [00:19<00:03, 531.05it/s] 83%|████████▎ | 8279/10000 [00:19<00:03, 472.90it/s] 83%|████████▎ | 8329/10000 [00:19<00:03, 451.00it/s] 84%|████████▍ | 8376/10000 [00:20<00:04, 396.69it/s] 84%|████████▍ | 8418/10000 [00:20<00:04, 373.91it/s] 85%|████████▍ | 8463/10000 [00:20<00:04, 379.45it/s] 85%|████████▌ | 8522/10000 [00:20<00:03, 408.10it/s] 86%|████████▌ | 8580/10000 [00:20<00:03, 447.81it/s] 86%|████████▋ | 8638/10000 [00:20<00:02, 479.53it/s] 87%|████████▋ | 8715/10000 [00:20<00:02, 546.22it/s] 88%|████████▊ | 8793/10000 [00:20<00:01, 610.21it/s] 89%|████████▉ | 8888/10000 [00:20<00:01, 704.85it/s] 90%|████████▉ | 8988/10000 [00:21<00:01, 773.87it/s] 91%|█████████ | 9067/10000 [00:21<00:01, 698.34it/s] 92%|█████████▏| 9156/10000 [00:21<00:01, 742.91it/s] 92%|█████████▏| 9233/10000 [00:21<00:01, 580.20it/s] 93%|█████████▎| 9298/10000 [00:21<00:01, 488.53it/s] 94%|█████████▎| 9354/10000 [00:21<00:01, 467.44it/s] 94%|█████████▍| 9405/10000 [00:22<00:01, 366.33it/s] 94%|█████████▍| 9448/10000 [00:22<00:01, 361.23it/s] 95%|█████████▌| 9503/10000 [00:22<00:01, 382.76it/s] 95%|█████████▌| 9545/10000 [00:22<00:01, 353.87it/s] 96%|█████████▌| 9586/10000 [00:22<00:01, 357.13it/s] 96%|█████████▋| 9635/10000 [00:22<00:00, 380.05it/s] 97%|█████████▋| 9676/10000 [00:22<00:00, 383.02it/s] 97%|█████████▋| 9716/10000 [00:22<00:00, 357.59it/s] 98%|█████████▊| 9774/10000 [00:23<00:00, 402.28it/s] 98%|█████████▊| 9836/10000 [00:23<00:00, 453.10it/s] 99%|█████████▉| 9923/10000 [00:23<00:00, 559.10it/s]100%|██████████| 10000/10000 [00:23<00:00, 428.09it/s]
test_neglected_p68 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p68
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p68.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:34,  1.12it/s]evaluating model with Holmes:   5%|▌         | 2/40 [00:01<00:16,  2.29it/s]evaluating model with Holmes:  18%|█▊        | 7/40 [00:01<00:03,  9.86it/s]evaluating model with Holmes:  30%|███       | 12/40 [00:01<00:01, 17.05it/s]evaluating model with Holmes:  42%|████▎     | 17/40 [00:01<00:00, 23.48it/s]evaluating model with Holmes:  55%|█████▌    | 22/40 [00:01<00:00, 29.25it/s]evaluating model with Holmes:  68%|██████▊   | 27/40 [00:01<00:00, 33.71it/s]evaluating model with Holmes:  80%|████████  | 32/40 [00:01<00:00, 37.31it/s]evaluating model with Holmes:  92%|█████████▎| 37/40 [00:01<00:00, 40.10it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.65it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p68_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p68_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p68_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p68_Holmes_probs.npy
{'Accuracy': 0.02, 'Precision': 0.0236, 'Recall': 0.0197, 'F1-score': 0.0175}
starting gen taf script for test_neglected_p69
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 89/10000 [00:00<00:11, 826.69it/s]  2%|▏         | 172/10000 [00:00<00:24, 404.39it/s]  2%|▏         | 224/10000 [00:00<00:30, 318.05it/s]  3%|▎         | 263/10000 [00:00<00:32, 296.09it/s]  3%|▎         | 296/10000 [00:00<00:33, 289.26it/s]  3%|▎         | 327/10000 [00:01<00:33, 292.96it/s]  4%|▎         | 358/10000 [00:01<00:35, 275.41it/s]  4%|▍         | 396/10000 [00:01<00:31, 300.54it/s]  4%|▍         | 434/10000 [00:01<00:30, 318.07it/s]  5%|▍         | 479/10000 [00:01<00:27, 350.25it/s]  5%|▌         | 516/10000 [00:01<00:27, 349.90it/s]  6%|▌         | 552/10000 [00:01<00:26, 351.15it/s]  6%|▌         | 588/10000 [00:01<00:26, 350.71it/s]  6%|▋         | 629/10000 [00:01<00:25, 363.24it/s]  7%|▋         | 666/10000 [00:01<00:27, 344.35it/s]  7%|▋         | 701/10000 [00:02<00:27, 340.47it/s]  7%|▋         | 736/10000 [00:02<00:28, 320.82it/s]  8%|▊         | 781/10000 [00:02<00:26, 347.21it/s]  8%|▊         | 837/10000 [00:02<00:22, 405.39it/s]  9%|▉         | 888/10000 [00:02<00:20, 434.66it/s]  9%|▉         | 933/10000 [00:02<00:21, 428.87it/s] 10%|▉         | 977/10000 [00:02<00:20, 431.83it/s] 10%|█         | 1021/10000 [00:02<00:20, 428.20it/s] 11%|█         | 1065/10000 [00:03<00:24, 360.74it/s] 11%|█         | 1104/10000 [00:03<00:26, 331.69it/s] 11%|█▏        | 1139/10000 [00:03<00:28, 314.81it/s] 12%|█▏        | 1175/10000 [00:03<00:27, 315.74it/s] 12%|█▏        | 1220/10000 [00:03<00:25, 349.98it/s] 13%|█▎        | 1306/10000 [00:03<00:18, 475.63it/s] 14%|█▍        | 1376/10000 [00:03<00:16, 534.92it/s] 14%|█▍        | 1432/10000 [00:03<00:18, 467.22it/s] 15%|█▍        | 1482/10000 [00:04<00:24, 347.69it/s] 15%|█▌        | 1523/10000 [00:04<00:28, 301.14it/s] 16%|█▌        | 1558/10000 [00:04<00:31, 263.86it/s] 16%|█▌        | 1590/10000 [00:04<00:30, 273.98it/s] 16%|█▋        | 1638/10000 [00:04<00:26, 314.01it/s] 17%|█▋        | 1687/10000 [00:04<00:23, 352.40it/s] 18%|█▊        | 1771/10000 [00:04<00:18, 453.76it/s] 19%|█▉        | 1884/10000 [00:05<00:12, 625.72it/s] 20%|█▉        | 1979/10000 [00:05<00:11, 700.59it/s] 21%|██        | 2054/10000 [00:05<00:12, 644.25it/s] 21%|██        | 2123/10000 [00:05<00:13, 574.44it/s] 22%|██▏       | 2185/10000 [00:05<00:14, 526.02it/s] 22%|██▏       | 2241/10000 [00:05<00:16, 477.00it/s] 23%|██▎       | 2292/10000 [00:05<00:19, 404.88it/s] 23%|██▎       | 2336/10000 [00:06<00:20, 369.92it/s] 24%|██▍       | 2375/10000 [00:06<00:21, 347.50it/s] 24%|██▍       | 2411/10000 [00:06<00:22, 340.70it/s] 25%|██▍       | 2471/10000 [00:06<00:19, 396.18it/s] 25%|██▌       | 2534/10000 [00:06<00:16, 444.20it/s] 26%|██▌       | 2583/10000 [00:06<00:16, 451.40it/s] 26%|██▋       | 2630/10000 [00:06<00:17, 420.09it/s] 27%|██▋       | 2674/10000 [00:06<00:23, 311.55it/s] 27%|██▋       | 2710/10000 [00:07<00:24, 294.20it/s] 27%|██▋       | 2743/10000 [00:07<00:27, 260.16it/s] 28%|██▊       | 2772/10000 [00:07<00:29, 246.04it/s] 28%|██▊       | 2799/10000 [00:07<00:32, 221.59it/s] 29%|██▊       | 2866/10000 [00:07<00:22, 315.31it/s] 29%|██▉       | 2925/10000 [00:07<00:18, 375.33it/s] 30%|██▉       | 2974/10000 [00:07<00:17, 395.65it/s] 30%|███       | 3022/10000 [00:08<00:16, 417.25it/s] 31%|███       | 3067/10000 [00:08<00:19, 363.45it/s] 31%|███       | 3107/10000 [00:08<00:20, 328.54it/s] 31%|███▏      | 3143/10000 [00:08<00:22, 304.61it/s] 32%|███▏      | 3187/10000 [00:08<00:21, 320.96it/s] 33%|███▎      | 3253/10000 [00:08<00:16, 402.57it/s] 33%|███▎      | 3328/10000 [00:08<00:13, 491.49it/s] 34%|███▍      | 3400/10000 [00:08<00:12, 538.53it/s] 35%|███▍      | 3457/10000 [00:09<00:12, 531.53it/s] 35%|███▌      | 3518/10000 [00:09<00:11, 542.48it/s] 36%|███▌      | 3574/10000 [00:09<00:12, 502.59it/s] 36%|███▋      | 3642/10000 [00:09<00:11, 541.61it/s] 37%|███▋      | 3712/10000 [00:09<00:11, 562.74it/s] 38%|███▊      | 3784/10000 [00:09<00:10, 594.70it/s] 38%|███▊      | 3846/10000 [00:09<00:10, 589.94it/s] 39%|███▉      | 3906/10000 [00:09<00:10, 584.86it/s] 40%|███▉      | 3965/10000 [00:09<00:12, 470.62it/s] 41%|████      | 4060/10000 [00:10<00:10, 587.52it/s] 41%|████      | 4124/10000 [00:10<00:10, 569.01it/s] 42%|████▏     | 4190/10000 [00:10<00:09, 590.01it/s] 43%|████▎     | 4252/10000 [00:10<00:10, 562.93it/s] 43%|████▎     | 4314/10000 [00:10<00:10, 568.18it/s] 44%|████▍     | 4382/10000 [00:10<00:09, 590.61it/s] 44%|████▍     | 4443/10000 [00:10<00:10, 534.34it/s] 45%|████▍     | 4499/10000 [00:10<00:11, 464.69it/s] 45%|████▌     | 4548/10000 [00:11<00:13, 399.66it/s] 46%|████▌     | 4591/10000 [00:11<00:13, 398.37it/s] 46%|████▋     | 4633/10000 [00:11<00:13, 398.18it/s] 47%|████▋     | 4675/10000 [00:11<00:13, 390.48it/s] 47%|████▋     | 4715/10000 [00:11<00:14, 372.93it/s] 48%|████▊     | 4753/10000 [00:11<00:15, 334.51it/s] 48%|████▊     | 4805/10000 [00:11<00:14, 370.27it/s] 48%|████▊     | 4844/10000 [00:11<00:16, 321.85it/s] 49%|████▉     | 4878/10000 [00:12<00:15, 322.12it/s] 49%|████▉     | 4912/10000 [00:12<00:15, 321.35it/s] 49%|████▉     | 4945/10000 [00:12<00:16, 297.94it/s] 50%|████▉     | 4976/10000 [00:12<00:18, 267.73it/s] 50%|█████     | 5013/10000 [00:12<00:17, 285.18it/s] 51%|█████     | 5059/10000 [00:12<00:15, 323.14it/s] 51%|█████     | 5093/10000 [00:12<00:15, 320.93it/s] 51%|█████▏    | 5145/10000 [00:12<00:13, 366.97it/s] 52%|█████▏    | 5194/10000 [00:13<00:12, 377.31it/s] 52%|█████▏    | 5233/10000 [00:13<00:13, 343.86it/s] 53%|█████▎    | 5269/10000 [00:13<00:17, 277.16it/s] 53%|█████▎    | 5306/10000 [00:13<00:15, 294.88it/s] 53%|█████▎    | 5338/10000 [00:13<00:16, 277.06it/s] 54%|█████▎    | 5368/10000 [00:13<00:19, 238.15it/s] 54%|█████▍    | 5405/10000 [00:13<00:17, 263.13it/s] 54%|█████▍    | 5445/10000 [00:14<00:15, 291.17it/s] 55%|█████▌    | 5504/10000 [00:14<00:12, 357.21it/s] 55%|█████▌    | 5544/10000 [00:14<00:12, 359.35it/s] 56%|█████▌    | 5585/10000 [00:14<00:12, 367.77it/s] 57%|█████▋    | 5660/10000 [00:14<00:09, 460.75it/s] 57%|█████▋    | 5719/10000 [00:14<00:08, 483.94it/s] 58%|█████▊    | 5781/10000 [00:14<00:08, 516.98it/s] 58%|█████▊    | 5834/10000 [00:14<00:08, 472.43it/s] 59%|█████▉    | 5883/10000 [00:14<00:09, 448.10it/s] 59%|█████▉    | 5929/10000 [00:15<00:11, 364.64it/s] 60%|█████▉    | 5969/10000 [00:15<00:11, 358.42it/s] 60%|██████    | 6007/10000 [00:15<00:11, 343.20it/s] 61%|██████    | 6069/10000 [00:15<00:09, 408.76it/s] 62%|██████▏   | 6157/10000 [00:15<00:07, 519.24it/s] 62%|██████▏   | 6212/10000 [00:15<00:07, 476.57it/s] 63%|██████▎   | 6262/10000 [00:15<00:08, 425.40it/s] 63%|██████▎   | 6307/10000 [00:16<00:09, 385.39it/s] 63%|██████▎   | 6348/10000 [00:16<00:10, 359.65it/s] 64%|██████▍   | 6386/10000 [00:16<00:11, 301.66it/s] 64%|██████▍   | 6427/10000 [00:16<00:11, 318.29it/s] 65%|██████▍   | 6461/10000 [00:16<00:11, 316.89it/s] 65%|██████▍   | 6494/10000 [00:16<00:11, 299.23it/s] 65%|██████▌   | 6530/10000 [00:16<00:11, 310.45it/s] 66%|██████▌   | 6562/10000 [00:16<00:11, 312.25it/s] 66%|██████▌   | 6599/10000 [00:17<00:10, 316.27it/s] 66%|██████▋   | 6643/10000 [00:17<00:09, 348.48it/s] 67%|██████▋   | 6679/10000 [00:17<00:10, 329.65it/s] 67%|██████▋   | 6728/10000 [00:17<00:08, 370.99it/s] 68%|██████▊   | 6767/10000 [00:17<00:08, 376.19it/s] 68%|██████▊   | 6806/10000 [00:17<00:08, 372.96it/s] 69%|██████▉   | 6883/10000 [00:17<00:06, 474.05it/s] 69%|██████▉   | 6931/10000 [00:17<00:06, 474.77it/s] 70%|██████▉   | 6993/10000 [00:17<00:05, 507.09it/s] 70%|███████   | 7050/10000 [00:17<00:05, 515.35it/s] 71%|███████   | 7105/10000 [00:18<00:05, 510.21it/s] 72%|███████▏  | 7167/10000 [00:18<00:05, 537.08it/s] 72%|███████▏  | 7229/10000 [00:18<00:04, 558.17it/s] 73%|███████▎  | 7285/10000 [00:18<00:04, 549.89it/s] 73%|███████▎  | 7347/10000 [00:18<00:04, 545.78it/s] 74%|███████▍  | 7411/10000 [00:18<00:04, 561.75it/s] 75%|███████▍  | 7469/10000 [00:18<00:04, 559.47it/s] 75%|███████▌  | 7526/10000 [00:18<00:04, 515.25it/s] 76%|███████▌  | 7579/10000 [00:18<00:04, 511.57it/s] 76%|███████▋  | 7631/10000 [00:19<00:04, 489.57it/s] 77%|███████▋  | 7681/10000 [00:19<00:05, 421.50it/s] 77%|███████▋  | 7729/10000 [00:19<00:05, 410.17it/s] 78%|███████▊  | 7772/10000 [00:19<00:05, 411.41it/s] 78%|███████▊  | 7814/10000 [00:19<00:05, 395.51it/s] 79%|███████▊  | 7865/10000 [00:19<00:05, 425.39it/s] 79%|███████▉  | 7916/10000 [00:19<00:04, 446.04it/s] 80%|███████▉  | 7987/10000 [00:19<00:03, 519.11it/s] 80%|████████  | 8048/10000 [00:19<00:03, 543.88it/s] 81%|████████  | 8122/10000 [00:20<00:03, 600.52it/s] 82%|████████▏ | 8183/10000 [00:20<00:03, 498.98it/s] 82%|████████▏ | 8237/10000 [00:20<00:03, 506.61it/s] 83%|████████▎ | 8291/10000 [00:20<00:04, 423.15it/s] 83%|████████▎ | 8338/10000 [00:20<00:04, 401.70it/s] 84%|████████▍ | 8381/10000 [00:20<00:04, 375.09it/s] 84%|████████▍ | 8432/10000 [00:20<00:03, 407.28it/s] 85%|████████▍ | 8486/10000 [00:21<00:03, 419.23it/s] 85%|████████▌ | 8532/10000 [00:21<00:03, 418.12it/s] 86%|████████▌ | 8591/10000 [00:21<00:03, 453.09it/s] 86%|████████▋ | 8650/10000 [00:21<00:02, 489.89it/s] 87%|████████▋ | 8725/10000 [00:21<00:02, 560.12it/s] 88%|████████▊ | 8816/10000 [00:21<00:01, 647.81it/s] 89%|████████▉ | 8888/10000 [00:21<00:01, 659.06it/s] 90%|████████▉ | 8955/10000 [00:21<00:01, 661.65it/s] 90%|█████████ | 9027/10000 [00:21<00:01, 671.93it/s] 91%|█████████ | 9095/10000 [00:21<00:01, 672.72it/s] 92%|█████████▏| 9163/10000 [00:22<00:01, 643.17it/s] 92%|█████████▏| 9228/10000 [00:22<00:01, 534.74it/s] 93%|█████████▎| 9285/10000 [00:22<00:01, 486.06it/s] 93%|█████████▎| 9337/10000 [00:22<00:01, 409.14it/s] 94%|█████████▍| 9382/10000 [00:22<00:01, 378.62it/s] 94%|█████████▍| 9423/10000 [00:22<00:01, 350.45it/s] 95%|█████████▍| 9465/10000 [00:22<00:01, 360.01it/s] 95%|█████████▌| 9503/10000 [00:23<00:01, 358.97it/s] 95%|█████████▌| 9544/10000 [00:23<00:01, 369.98it/s] 96%|█████████▌| 9582/10000 [00:23<00:01, 369.12it/s] 96%|█████████▋| 9625/10000 [00:23<00:01, 373.88it/s] 97%|█████████▋| 9679/10000 [00:23<00:00, 406.24it/s] 97%|█████████▋| 9733/10000 [00:23<00:00, 439.93it/s] 98%|█████████▊| 9778/10000 [00:23<00:00, 430.92it/s] 98%|█████████▊| 9838/10000 [00:23<00:00, 466.83it/s] 99%|█████████▉| 9913/10000 [00:23<00:00, 539.00it/s]100%|█████████▉| 9974/10000 [00:24<00:00, 559.11it/s]100%|██████████| 10000/10000 [00:24<00:00, 415.76it/s]
test_neglected_p69 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p69
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p69.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.04it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.17it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.50it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.75it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.72it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.73it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 35.08it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.54it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.93it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p69_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p69_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p69_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p69_Holmes_probs.npy
{'Accuracy': 0.0202, 'Precision': 0.0238, 'Recall': 0.0199, 'F1-score': 0.0176}
starting gen taf script for test_neglected_p70
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 55/10000 [00:00<00:19, 504.67it/s]  1%|          | 106/10000 [00:00<00:22, 446.93it/s]  2%|▏         | 151/10000 [00:00<00:34, 288.91it/s]  2%|▏         | 185/10000 [00:00<00:36, 265.39it/s]  2%|▏         | 216/10000 [00:00<00:35, 274.13it/s]  2%|▏         | 246/10000 [00:00<00:41, 237.11it/s]  3%|▎         | 272/10000 [00:01<00:44, 219.56it/s]  3%|▎         | 296/10000 [00:01<00:43, 223.56it/s]  3%|▎         | 320/10000 [00:01<00:43, 221.52it/s]  3%|▎         | 343/10000 [00:01<00:43, 222.34it/s]  4%|▎         | 366/10000 [00:01<00:48, 197.54it/s]  4%|▍         | 390/10000 [00:01<00:47, 204.34it/s]  4%|▍         | 411/10000 [00:01<00:46, 204.85it/s]  4%|▍         | 448/10000 [00:01<00:38, 249.02it/s]  5%|▍         | 482/10000 [00:01<00:35, 270.67it/s]  5%|▌         | 517/10000 [00:02<00:33, 286.59it/s]  6%|▌         | 554/10000 [00:02<00:30, 310.04it/s]  6%|▌         | 602/10000 [00:02<00:26, 355.85it/s]  6%|▋         | 649/10000 [00:02<00:24, 387.86it/s]  7%|▋         | 693/10000 [00:02<00:23, 397.66it/s]  8%|▊         | 767/10000 [00:02<00:18, 490.07it/s]  8%|▊         | 835/10000 [00:02<00:17, 531.58it/s]  9%|▉         | 889/10000 [00:02<00:18, 498.82it/s]  9%|▉         | 940/10000 [00:02<00:20, 433.09it/s] 10%|▉         | 985/10000 [00:03<00:21, 428.72it/s] 10%|█         | 1029/10000 [00:03<00:21, 416.19it/s] 11%|█         | 1072/10000 [00:03<00:24, 363.18it/s] 11%|█         | 1114/10000 [00:03<00:23, 371.34it/s] 12%|█▏        | 1153/10000 [00:03<00:24, 363.71it/s] 12%|█▏        | 1194/10000 [00:03<00:23, 370.54it/s] 13%|█▎        | 1261/10000 [00:03<00:19, 445.49it/s] 13%|█▎        | 1317/10000 [00:03<00:18, 475.13it/s] 14%|█▎        | 1366/10000 [00:03<00:18, 469.07it/s] 14%|█▍        | 1414/10000 [00:04<00:20, 410.74it/s] 15%|█▍        | 1457/10000 [00:04<00:22, 376.11it/s] 15%|█▍        | 1497/10000 [00:04<00:26, 316.94it/s] 15%|█▌        | 1531/10000 [00:04<00:29, 282.77it/s] 16%|█▌        | 1562/10000 [00:04<00:32, 256.18it/s] 16%|█▌        | 1589/10000 [00:04<00:32, 257.29it/s] 16%|█▋        | 1626/10000 [00:04<00:29, 284.06it/s] 17%|█▋        | 1681/10000 [00:05<00:23, 351.44it/s] 17%|█▋        | 1739/10000 [00:05<00:20, 409.23it/s] 18%|█▊        | 1821/10000 [00:05<00:15, 514.98it/s] 19%|█▉        | 1905/10000 [00:05<00:13, 605.03it/s] 20%|█▉        | 1992/10000 [00:05<00:11, 680.40it/s] 21%|██        | 2062/10000 [00:05<00:12, 648.52it/s] 21%|██▏       | 2129/10000 [00:05<00:14, 542.54it/s] 22%|██▏       | 2188/10000 [00:05<00:14, 546.90it/s] 22%|██▏       | 2246/10000 [00:06<00:16, 462.31it/s] 23%|██▎       | 2297/10000 [00:06<00:18, 413.19it/s] 23%|██▎       | 2342/10000 [00:06<00:20, 376.10it/s] 24%|██▍       | 2382/10000 [00:06<00:22, 345.07it/s] 24%|██▍       | 2419/10000 [00:06<00:22, 337.11it/s] 25%|██▍       | 2486/10000 [00:06<00:18, 410.62it/s] 25%|██▌       | 2546/10000 [00:06<00:16, 453.60it/s] 26%|██▌       | 2597/10000 [00:06<00:17, 429.12it/s] 26%|██▋       | 2642/10000 [00:07<00:20, 364.40it/s] 27%|██▋       | 2682/10000 [00:07<00:25, 282.85it/s] 27%|██▋       | 2715/10000 [00:07<00:25, 283.28it/s] 27%|██▋       | 2747/10000 [00:07<00:29, 245.81it/s] 28%|██▊       | 2775/10000 [00:07<00:30, 233.96it/s] 28%|██▊       | 2800/10000 [00:07<00:31, 228.31it/s] 29%|██▊       | 2852/10000 [00:08<00:24, 291.84it/s] 29%|██▉       | 2893/10000 [00:08<00:22, 316.85it/s] 30%|██▉       | 2957/10000 [00:08<00:17, 398.95it/s] 30%|███       | 3008/10000 [00:08<00:17, 410.14it/s] 31%|███       | 3051/10000 [00:08<00:16, 413.21it/s] 31%|███       | 3094/10000 [00:08<00:19, 358.61it/s] 31%|███▏      | 3132/10000 [00:08<00:19, 358.94it/s] 32%|███▏      | 3170/10000 [00:08<00:18, 360.87it/s] 32%|███▏      | 3208/10000 [00:08<00:19, 344.78it/s] 33%|███▎      | 3262/10000 [00:09<00:16, 396.88it/s] 33%|███▎      | 3335/10000 [00:09<00:13, 488.56it/s] 34%|███▍      | 3397/10000 [00:09<00:12, 522.13it/s] 35%|███▍      | 3454/10000 [00:09<00:12, 534.26it/s] 35%|███▌      | 3522/10000 [00:09<00:11, 574.78it/s] 36%|███▌      | 3581/10000 [00:09<00:11, 554.15it/s] 37%|███▋      | 3652/10000 [00:09<00:10, 583.84it/s] 37%|███▋      | 3716/10000 [00:09<00:10, 583.48it/s] 38%|███▊      | 3786/10000 [00:09<00:10, 601.75it/s] 38%|███▊      | 3849/10000 [00:09<00:10, 606.94it/s] 39%|███▉      | 3910/10000 [00:10<00:12, 492.74it/s] 40%|███▉      | 3963/10000 [00:10<00:13, 454.55it/s] 40%|████      | 4018/10000 [00:10<00:12, 470.60it/s] 41%|████      | 4098/10000 [00:10<00:10, 542.68it/s] 42%|████▏     | 4174/10000 [00:10<00:09, 586.59it/s] 42%|████▏     | 4241/10000 [00:10<00:09, 596.30it/s] 43%|████▎     | 4303/10000 [00:10<00:09, 589.79it/s] 44%|████▎     | 4368/10000 [00:10<00:09, 604.11it/s] 44%|████▍     | 4430/10000 [00:11<00:09, 596.52it/s] 45%|████▍     | 4491/10000 [00:11<00:12, 451.83it/s] 45%|████▌     | 4542/10000 [00:11<00:13, 404.90it/s] 46%|████▌     | 4587/10000 [00:11<00:14, 361.00it/s] 46%|████▋     | 4633/10000 [00:11<00:14, 374.45it/s] 47%|████▋     | 4674/10000 [00:11<00:16, 327.94it/s] 47%|████▋     | 4721/10000 [00:12<00:15, 346.84it/s] 48%|████▊     | 4758/10000 [00:12<00:16, 326.90it/s] 48%|████▊     | 4809/10000 [00:12<00:14, 361.45it/s] 48%|████▊     | 4847/10000 [00:12<00:17, 300.00it/s] 49%|████▉     | 4882/10000 [00:12<00:16, 309.40it/s] 49%|████▉     | 4915/10000 [00:12<00:18, 276.28it/s] 50%|████▉     | 4950/10000 [00:12<00:17, 292.68it/s] 50%|████▉     | 4981/10000 [00:12<00:18, 274.13it/s] 50%|█████     | 5010/10000 [00:13<00:19, 262.38it/s] 50%|█████     | 5046/10000 [00:13<00:17, 286.31it/s] 51%|█████     | 5097/10000 [00:13<00:14, 338.54it/s] 51%|█████▏    | 5149/10000 [00:13<00:12, 381.28it/s] 52%|█████▏    | 5202/10000 [00:13<00:11, 412.18it/s] 52%|█████▏    | 5245/10000 [00:13<00:13, 341.57it/s] 53%|█████▎    | 5282/10000 [00:13<00:14, 322.49it/s] 53%|█████▎    | 5316/10000 [00:13<00:17, 266.77it/s] 54%|█████▎    | 5352/10000 [00:14<00:16, 286.19it/s] 54%|█████▍    | 5383/10000 [00:14<00:16, 274.44it/s] 54%|█████▍    | 5418/10000 [00:14<00:15, 291.91it/s] 55%|█████▍    | 5459/10000 [00:14<00:14, 317.61it/s] 55%|█████▌    | 5516/10000 [00:14<00:11, 384.64it/s] 56%|█████▌    | 5557/10000 [00:14<00:12, 367.10it/s] 56%|█████▋    | 5639/10000 [00:14<00:08, 488.41it/s] 57%|█████▋    | 5694/10000 [00:14<00:08, 493.65it/s] 57%|█████▋    | 5745/10000 [00:14<00:09, 470.47it/s] 58%|█████▊    | 5794/10000 [00:15<00:08, 469.99it/s] 58%|█████▊    | 5842/10000 [00:15<00:09, 420.51it/s] 59%|█████▉    | 5887/10000 [00:15<00:09, 426.82it/s] 59%|█████▉    | 5931/10000 [00:15<00:11, 366.87it/s] 60%|█████▉    | 5970/10000 [00:15<00:11, 338.46it/s] 60%|██████    | 6017/10000 [00:15<00:11, 360.45it/s] 61%|██████    | 6079/10000 [00:15<00:09, 416.13it/s] 61%|██████▏   | 6148/10000 [00:15<00:07, 487.50it/s] 62%|██████▏   | 6203/10000 [00:16<00:07, 500.41it/s] 63%|██████▎   | 6255/10000 [00:16<00:08, 436.22it/s] 63%|██████▎   | 6302/10000 [00:16<00:10, 363.87it/s] 63%|██████▎   | 6342/10000 [00:16<00:10, 346.59it/s] 64%|██████▍   | 6379/10000 [00:16<00:11, 315.05it/s] 64%|██████▍   | 6413/10000 [00:16<00:11, 308.88it/s] 64%|██████▍   | 6446/10000 [00:16<00:12, 281.98it/s] 65%|██████▍   | 6484/10000 [00:17<00:11, 303.92it/s] 65%|██████▌   | 6516/10000 [00:17<00:11, 304.78it/s] 66%|██████▌   | 6558/10000 [00:17<00:10, 332.78it/s] 66%|██████▌   | 6594/10000 [00:17<00:10, 327.08it/s] 66%|██████▋   | 6628/10000 [00:17<00:10, 311.16it/s] 67%|██████▋   | 6662/10000 [00:17<00:10, 317.47it/s] 67%|██████▋   | 6712/10000 [00:17<00:09, 357.63it/s] 67%|██████▋   | 6749/10000 [00:17<00:09, 353.04it/s] 68%|██████▊   | 6816/10000 [00:17<00:07, 430.44it/s] 69%|██████▉   | 6889/10000 [00:18<00:06, 511.61it/s] 69%|██████▉   | 6948/10000 [00:18<00:05, 533.66it/s] 70%|███████   | 7004/10000 [00:18<00:05, 532.31it/s] 71%|███████   | 7058/10000 [00:18<00:05, 520.69it/s] 71%|███████▏  | 7126/10000 [00:18<00:05, 549.99it/s] 72%|███████▏  | 7182/10000 [00:18<00:05, 533.35it/s] 72%|███████▏  | 7237/10000 [00:18<00:05, 531.87it/s] 73%|███████▎  | 7312/10000 [00:18<00:04, 580.73it/s] 74%|███████▍  | 7375/10000 [00:18<00:04, 583.04it/s] 74%|███████▍  | 7434/10000 [00:19<00:04, 551.67it/s] 75%|███████▌  | 7500/10000 [00:19<00:04, 577.43it/s] 76%|███████▌  | 7579/10000 [00:19<00:03, 635.10it/s] 76%|███████▋  | 7644/10000 [00:19<00:04, 476.61it/s] 77%|███████▋  | 7698/10000 [00:19<00:05, 459.17it/s] 77%|███████▋  | 7749/10000 [00:19<00:05, 414.86it/s] 78%|███████▊  | 7794/10000 [00:19<00:05, 416.66it/s] 79%|███████▊  | 7851/10000 [00:19<00:04, 451.12it/s] 79%|███████▉  | 7933/10000 [00:20<00:03, 530.04it/s] 80%|████████  | 8011/10000 [00:20<00:03, 590.36it/s] 81%|████████  | 8095/10000 [00:20<00:02, 657.53it/s] 82%|████████▏ | 8163/10000 [00:20<00:02, 617.17it/s] 82%|████████▏ | 8227/10000 [00:20<00:03, 526.04it/s] 83%|████████▎ | 8283/10000 [00:20<00:04, 426.43it/s] 83%|████████▎ | 8333/10000 [00:20<00:03, 442.50it/s] 84%|████████▍ | 8382/10000 [00:20<00:04, 404.37it/s] 84%|████████▍ | 8431/10000 [00:21<00:03, 415.28it/s] 85%|████████▍ | 8475/10000 [00:21<00:03, 413.52it/s] 85%|████████▌ | 8541/10000 [00:21<00:03, 470.56it/s] 86%|████████▌ | 8590/10000 [00:21<00:03, 449.85it/s] 86%|████████▋ | 8642/10000 [00:21<00:02, 462.45it/s] 87%|████████▋ | 8714/10000 [00:21<00:02, 527.74it/s] 88%|████████▊ | 8790/10000 [00:21<00:02, 581.63it/s] 89%|████████▉ | 8879/10000 [00:21<00:01, 662.11it/s] 90%|████████▉ | 8951/10000 [00:21<00:01, 673.58it/s] 90%|█████████ | 9038/10000 [00:22<00:01, 726.90it/s] 91%|█████████ | 9112/10000 [00:22<00:01, 663.80it/s] 92%|█████████▏| 9180/10000 [00:22<00:01, 626.70it/s] 92%|█████████▏| 9244/10000 [00:22<00:01, 495.48it/s] 93%|█████████▎| 9299/10000 [00:22<00:01, 418.30it/s] 93%|█████████▎| 9346/10000 [00:22<00:01, 385.04it/s] 94%|█████████▍| 9388/10000 [00:23<00:01, 341.93it/s] 94%|█████████▍| 9428/10000 [00:23<00:01, 352.89it/s] 95%|█████████▍| 9477/10000 [00:23<00:01, 383.75it/s] 95%|█████████▌| 9518/10000 [00:23<00:01, 351.31it/s] 96%|█████████▌| 9556/10000 [00:23<00:01, 318.93it/s] 96%|█████████▌| 9613/10000 [00:23<00:01, 370.85it/s] 97%|█████████▋| 9664/10000 [00:23<00:00, 405.32it/s] 97%|█████████▋| 9707/10000 [00:23<00:00, 381.70it/s] 98%|█████████▊| 9776/10000 [00:23<00:00, 460.95it/s] 98%|█████████▊| 9825/10000 [00:24<00:00, 467.31it/s] 99%|█████████▉| 9880/10000 [00:24<00:00, 487.60it/s]100%|█████████▉| 9954/10000 [00:24<00:00, 555.17it/s]100%|██████████| 10000/10000 [00:24<00:00, 410.96it/s]
test_neglected_p70 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p70
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p70.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.09s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.49it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.34it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.43it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.25it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.49it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.95it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.53it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.31it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p70_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p70_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p70_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p70_Holmes_probs.npy
{'Accuracy': 0.0205, 'Precision': 0.023, 'Recall': 0.0202, 'F1-score': 0.0177}
starting gen taf script for test_neglected_p71
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 115/10000 [00:00<00:09, 1051.72it/s]  2%|▏         | 221/10000 [00:00<00:19, 504.22it/s]   3%|▎         | 286/10000 [00:00<00:24, 390.20it/s]  3%|▎         | 334/10000 [00:00<00:27, 351.43it/s]  4%|▎         | 374/10000 [00:00<00:29, 322.34it/s]  4%|▍         | 409/10000 [00:01<00:29, 321.05it/s]  4%|▍         | 446/10000 [00:01<00:29, 328.68it/s]  5%|▍         | 487/10000 [00:01<00:27, 346.58it/s]  5%|▌         | 523/10000 [00:01<00:27, 341.84it/s]  6%|▌         | 560/10000 [00:01<00:27, 343.31it/s]  6%|▌         | 612/10000 [00:01<00:24, 391.04it/s]  7%|▋         | 653/10000 [00:01<00:24, 389.10it/s]  7%|▋         | 696/10000 [00:01<00:23, 398.57it/s]  7%|▋         | 737/10000 [00:01<00:24, 379.40it/s]  8%|▊         | 807/10000 [00:02<00:20, 447.61it/s]  9%|▊         | 863/10000 [00:02<00:19, 478.38it/s]  9%|▉         | 912/10000 [00:02<00:20, 437.47it/s] 10%|▉         | 957/10000 [00:02<00:21, 411.76it/s] 10%|█         | 1011/10000 [00:02<00:20, 432.87it/s] 11%|█         | 1055/10000 [00:02<00:21, 407.29it/s] 11%|█         | 1097/10000 [00:02<00:23, 378.33it/s] 11%|█▏        | 1136/10000 [00:02<00:25, 346.76it/s] 12%|█▏        | 1173/10000 [00:03<00:25, 346.05it/s] 12%|█▏        | 1222/10000 [00:03<00:23, 374.05it/s] 13%|█▎        | 1283/10000 [00:03<00:20, 431.93it/s] 14%|█▎        | 1363/10000 [00:03<00:16, 531.41it/s] 14%|█▍        | 1418/10000 [00:03<00:19, 435.99it/s] 15%|█▍        | 1466/10000 [00:03<00:21, 396.44it/s] 15%|█▌        | 1509/10000 [00:03<00:25, 330.53it/s] 15%|█▌        | 1546/10000 [00:04<00:29, 283.94it/s] 16%|█▌        | 1578/10000 [00:04<00:32, 258.09it/s] 16%|█▌        | 1619/10000 [00:04<00:29, 284.27it/s] 17%|█▋        | 1692/10000 [00:04<00:21, 384.08it/s] 18%|█▊        | 1774/10000 [00:04<00:16, 489.06it/s] 18%|█▊        | 1829/10000 [00:04<00:16, 498.73it/s] 19%|█▉        | 1931/10000 [00:04<00:12, 628.06it/s] 20%|██        | 2009/10000 [00:04<00:12, 665.30it/s] 21%|██        | 2079/10000 [00:05<00:13, 581.19it/s] 21%|██▏       | 2142/10000 [00:05<00:14, 544.55it/s] 22%|██▏       | 2200/10000 [00:05<00:14, 537.11it/s] 23%|██▎       | 2256/10000 [00:05<00:19, 406.84it/s] 23%|██▎       | 2303/10000 [00:05<00:20, 372.93it/s] 23%|██▎       | 2345/10000 [00:05<00:21, 350.66it/s] 24%|██▍       | 2383/10000 [00:05<00:22, 334.72it/s] 24%|██▍       | 2436/10000 [00:06<00:20, 374.63it/s] 25%|██▌       | 2503/10000 [00:06<00:16, 443.68it/s] 26%|██▌       | 2555/10000 [00:06<00:16, 462.74it/s] 26%|██▌       | 2604/10000 [00:06<00:19, 385.65it/s] 26%|██▋       | 2647/10000 [00:06<00:21, 336.39it/s] 27%|██▋       | 2684/10000 [00:06<00:22, 318.40it/s] 27%|██▋       | 2719/10000 [00:06<00:27, 263.19it/s] 28%|██▊       | 2750/10000 [00:07<00:28, 252.90it/s] 28%|██▊       | 2778/10000 [00:07<00:28, 253.11it/s] 28%|██▊       | 2812/10000 [00:07<00:26, 268.44it/s] 29%|██▊       | 2860/10000 [00:07<00:22, 314.19it/s] 29%|██▉       | 2931/10000 [00:07<00:17, 402.58it/s] 30%|██▉       | 2973/10000 [00:07<00:18, 385.72it/s] 30%|███       | 3026/10000 [00:07<00:16, 419.27it/s] 31%|███       | 3070/10000 [00:07<00:20, 330.94it/s] 31%|███       | 3121/10000 [00:08<00:19, 357.85it/s] 32%|███▏      | 3160/10000 [00:08<00:19, 345.95it/s] 32%|███▏      | 3197/10000 [00:08<00:19, 344.98it/s] 33%|███▎      | 3283/10000 [00:08<00:14, 474.03it/s] 33%|███▎      | 3340/10000 [00:08<00:13, 498.55it/s] 34%|███▍      | 3422/10000 [00:08<00:11, 573.43it/s] 35%|███▍      | 3482/10000 [00:08<00:12, 533.33it/s] 35%|███▌      | 3538/10000 [00:08<00:12, 497.41it/s] 36%|███▌      | 3611/10000 [00:08<00:11, 553.37it/s] 37%|███▋      | 3669/10000 [00:09<00:12, 504.83it/s] 37%|███▋      | 3736/10000 [00:09<00:11, 539.52it/s] 38%|███▊      | 3823/10000 [00:09<00:10, 606.76it/s] 39%|███▉      | 3886/10000 [00:09<00:11, 535.09it/s] 39%|███▉      | 3942/10000 [00:09<00:12, 481.98it/s] 40%|███▉      | 3998/10000 [00:09<00:11, 500.79it/s] 40%|████      | 4050/10000 [00:09<00:11, 505.01it/s] 41%|████      | 4117/10000 [00:09<00:10, 546.73it/s] 42%|████▏     | 4183/10000 [00:10<00:10, 577.52it/s] 43%|████▎     | 4264/10000 [00:10<00:09, 629.75it/s] 43%|████▎     | 4332/10000 [00:10<00:08, 636.43it/s] 44%|████▍     | 4397/10000 [00:10<00:09, 605.00it/s] 45%|████▍     | 4459/10000 [00:10<00:10, 548.13it/s] 45%|████▌     | 4516/10000 [00:10<00:15, 357.78it/s] 46%|████▌     | 4561/10000 [00:10<00:15, 348.75it/s] 46%|████▌     | 4604/10000 [00:11<00:14, 363.08it/s] 47%|████▋     | 4657/10000 [00:11<00:13, 383.36it/s] 47%|████▋     | 4700/10000 [00:11<00:14, 359.41it/s] 47%|████▋     | 4739/10000 [00:11<00:14, 363.11it/s] 48%|████▊     | 4778/10000 [00:11<00:15, 334.58it/s] 48%|████▊     | 4816/10000 [00:11<00:16, 323.19it/s] 48%|████▊     | 4850/10000 [00:11<00:16, 308.94it/s] 49%|████▉     | 4882/10000 [00:11<00:17, 286.44it/s] 49%|████▉     | 4912/10000 [00:12<00:18, 278.97it/s] 49%|████▉     | 4941/10000 [00:12<00:19, 253.96it/s] 50%|████▉     | 4967/10000 [00:12<00:20, 251.59it/s] 50%|████▉     | 4993/10000 [00:12<00:20, 238.43it/s] 50%|█████     | 5033/10000 [00:12<00:17, 277.85it/s] 51%|█████     | 5079/10000 [00:12<00:15, 325.47it/s] 51%|█████▏    | 5143/10000 [00:12<00:11, 410.23it/s] 52%|█████▏    | 5205/10000 [00:12<00:10, 443.77it/s] 53%|█████▎    | 5251/10000 [00:13<00:12, 381.02it/s] 53%|█████▎    | 5292/10000 [00:13<00:14, 314.30it/s] 53%|█████▎    | 5327/10000 [00:13<00:18, 259.43it/s] 54%|█████▎    | 5357/10000 [00:13<00:17, 262.79it/s] 54%|█████▍    | 5386/10000 [00:13<00:17, 264.00it/s] 54%|█████▍    | 5444/10000 [00:13<00:13, 338.59it/s] 55%|█████▍    | 5485/10000 [00:13<00:13, 343.48it/s] 56%|█████▌    | 5551/10000 [00:13<00:10, 423.24it/s] 56%|█████▌    | 5610/10000 [00:14<00:09, 459.27it/s] 57%|█████▋    | 5665/10000 [00:14<00:09, 475.43it/s] 57%|█████▋    | 5741/10000 [00:14<00:07, 548.36it/s] 58%|█████▊    | 5799/10000 [00:14<00:07, 554.26it/s] 59%|█████▊    | 5856/10000 [00:14<00:09, 435.71it/s] 59%|█████▉    | 5905/10000 [00:14<00:10, 377.57it/s] 60%|█████▉    | 5954/10000 [00:14<00:10, 400.09it/s] 60%|█████▉    | 5998/10000 [00:15<00:10, 366.67it/s] 60%|██████    | 6045/10000 [00:15<00:10, 380.44it/s] 61%|██████    | 6110/10000 [00:15<00:08, 440.43it/s] 62%|██████▏   | 6157/10000 [00:15<00:08, 435.88it/s] 62%|██████▏   | 6203/10000 [00:15<00:08, 435.08it/s] 62%|██████▏   | 6248/10000 [00:15<00:09, 392.61it/s] 63%|██████▎   | 6289/10000 [00:15<00:10, 349.91it/s] 63%|██████▎   | 6326/10000 [00:15<00:10, 346.32it/s] 64%|██████▎   | 6362/10000 [00:15<00:11, 313.26it/s] 64%|██████▍   | 6395/10000 [00:16<00:11, 314.63it/s] 64%|██████▍   | 6428/10000 [00:16<00:11, 298.34it/s] 65%|██████▍   | 6463/10000 [00:16<00:11, 304.98it/s] 65%|██████▍   | 6497/10000 [00:16<00:11, 313.41it/s] 65%|██████▌   | 6529/10000 [00:16<00:12, 288.33it/s] 66%|██████▌   | 6559/10000 [00:16<00:12, 281.11it/s] 66%|██████▌   | 6598/10000 [00:16<00:11, 302.86it/s] 66%|██████▋   | 6645/10000 [00:16<00:09, 337.46it/s] 67%|██████▋   | 6680/10000 [00:17<00:11, 294.46it/s] 67%|██████▋   | 6711/10000 [00:17<00:11, 291.70it/s] 68%|██████▊   | 6759/10000 [00:17<00:09, 336.79it/s] 68%|██████▊   | 6820/10000 [00:17<00:07, 406.69it/s] 69%|██████▊   | 6872/10000 [00:17<00:07, 434.56it/s] 69%|██████▉   | 6935/10000 [00:17<00:06, 475.92it/s] 70%|███████   | 7013/10000 [00:17<00:05, 539.14it/s] 71%|███████   | 7085/10000 [00:17<00:05, 555.51it/s] 71%|███████▏  | 7141/10000 [00:17<00:05, 549.05it/s] 72%|███████▏  | 7196/10000 [00:18<00:06, 456.90it/s] 72%|███████▏  | 7245/10000 [00:18<00:06, 452.68it/s] 73%|███████▎  | 7299/10000 [00:18<00:05, 470.67it/s] 74%|███████▎  | 7357/10000 [00:18<00:05, 499.09it/s] 74%|███████▍  | 7411/10000 [00:18<00:05, 503.53it/s] 75%|███████▍  | 7474/10000 [00:18<00:04, 531.94it/s] 75%|███████▌  | 7539/10000 [00:18<00:04, 564.59it/s] 76%|███████▌  | 7597/10000 [00:18<00:05, 479.93it/s] 76%|███████▋  | 7648/10000 [00:19<00:04, 481.91it/s] 77%|███████▋  | 7699/10000 [00:19<00:05, 424.67it/s] 78%|███████▊  | 7751/10000 [00:19<00:05, 432.92it/s] 78%|███████▊  | 7796/10000 [00:19<00:05, 418.87it/s] 79%|███████▊  | 7863/10000 [00:19<00:04, 472.73it/s] 79%|███████▉  | 7934/10000 [00:19<00:03, 529.00it/s] 80%|████████  | 8011/10000 [00:19<00:03, 590.96it/s] 81%|████████  | 8072/10000 [00:19<00:03, 576.34it/s] 81%|████████▏ | 8144/10000 [00:19<00:03, 601.49it/s] 82%|████████▏ | 8205/10000 [00:20<00:03, 554.13it/s] 83%|████████▎ | 8262/10000 [00:20<00:03, 471.24it/s] 83%|████████▎ | 8312/10000 [00:20<00:03, 424.18it/s] 84%|████████▎ | 8357/10000 [00:20<00:04, 370.76it/s] 84%|████████▍ | 8397/10000 [00:20<00:04, 353.23it/s] 84%|████████▍ | 8445/10000 [00:20<00:04, 371.71it/s] 85%|████████▍ | 8495/10000 [00:20<00:03, 387.87it/s] 85%|████████▌ | 8539/10000 [00:21<00:03, 397.56it/s] 86%|████████▌ | 8596/10000 [00:21<00:03, 441.14it/s] 87%|████████▋ | 8659/10000 [00:21<00:02, 484.49it/s] 87%|████████▋ | 8713/10000 [00:21<00:02, 493.86it/s] 88%|████████▊ | 8783/10000 [00:21<00:02, 548.89it/s] 89%|████████▊ | 8862/10000 [00:21<00:01, 604.87it/s] 89%|████████▉ | 8937/10000 [00:21<00:01, 646.19it/s] 90%|█████████ | 9003/10000 [00:21<00:01, 635.72it/s] 91%|█████████ | 9068/10000 [00:21<00:01, 626.63it/s] 91%|█████████▏| 9146/10000 [00:21<00:01, 656.58it/s] 92%|█████████▏| 9212/10000 [00:22<00:01, 609.34it/s] 93%|█████████▎| 9274/10000 [00:22<00:01, 501.62it/s] 93%|█████████▎| 9328/10000 [00:22<00:01, 417.07it/s] 94%|█████████▎| 9374/10000 [00:22<00:01, 366.15it/s] 94%|█████████▍| 9414/10000 [00:22<00:01, 335.70it/s] 95%|█████████▍| 9455/10000 [00:22<00:01, 341.78it/s] 95%|█████████▍| 9491/10000 [00:23<00:01, 323.97it/s] 95%|█████████▌| 9530/10000 [00:23<00:01, 334.49it/s] 96%|█████████▌| 9576/10000 [00:23<00:01, 362.92it/s] 96%|█████████▌| 9614/10000 [00:23<00:01, 349.33it/s] 97%|█████████▋| 9659/10000 [00:23<00:00, 364.90it/s] 97%|█████████▋| 9703/10000 [00:23<00:00, 379.67it/s] 98%|█████████▊| 9751/10000 [00:23<00:00, 395.55it/s] 98%|█████████▊| 9795/10000 [00:23<00:00, 407.73it/s] 98%|█████████▊| 9841/10000 [00:23<00:00, 421.54it/s] 99%|█████████▉| 9893/10000 [00:23<00:00, 447.71it/s] 99%|█████████▉| 9941/10000 [00:24<00:00, 456.78it/s]100%|██████████| 10000/10000 [00:24<00:00, 414.39it/s]
test_neglected_p71 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p71
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p71.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.05s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.63it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.61it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.79it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.66it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.80it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.22it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.83it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.54it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p71_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p71_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p71_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p71_Holmes_probs.npy
{'Accuracy': 0.0204, 'Precision': 0.0236, 'Recall': 0.0201, 'F1-score': 0.0177}
starting gen taf script for test_neglected_p72
  0%|          | 0/10000 [00:00<?, ?it/s]  0%|          | 49/10000 [00:00<00:20, 482.34it/s]  1%|          | 98/10000 [00:00<00:34, 282.92it/s]  1%|▏         | 131/10000 [00:00<00:40, 245.27it/s]  2%|▏         | 158/10000 [00:00<00:41, 239.53it/s]  2%|▏         | 195/10000 [00:00<00:35, 274.63it/s]  2%|▏         | 228/10000 [00:00<00:33, 289.07it/s]  3%|▎         | 276/10000 [00:00<00:29, 331.91it/s]  3%|▎         | 311/10000 [00:01<00:28, 335.78it/s]  4%|▎         | 351/10000 [00:01<00:27, 348.91it/s]  4%|▍         | 418/10000 [00:01<00:22, 425.32it/s]  5%|▍         | 489/10000 [00:01<00:18, 505.91it/s]  6%|▌         | 563/10000 [00:01<00:16, 570.40it/s]  6%|▋         | 641/10000 [00:01<00:15, 619.94it/s]  7%|▋         | 715/10000 [00:01<00:14, 654.34it/s]  8%|▊         | 782/10000 [00:01<00:14, 657.05it/s]  8%|▊         | 849/10000 [00:01<00:15, 604.48it/s]  9%|▉         | 911/10000 [00:02<00:16, 544.39it/s] 10%|▉         | 968/10000 [00:02<00:17, 511.37it/s] 10%|█         | 1021/10000 [00:02<00:19, 470.64it/s] 11%|█         | 1070/10000 [00:02<00:21, 416.86it/s] 11%|█         | 1115/10000 [00:02<00:21, 417.50it/s] 12%|█▏        | 1158/10000 [00:02<00:21, 413.08it/s] 12%|█▏        | 1201/10000 [00:02<00:22, 395.19it/s] 13%|█▎        | 1253/10000 [00:02<00:20, 427.30it/s] 13%|█▎        | 1328/10000 [00:02<00:17, 503.70it/s] 14%|█▍        | 1404/10000 [00:03<00:15, 551.38it/s] 15%|█▍        | 1460/10000 [00:03<00:20, 408.38it/s] 15%|█▌        | 1507/10000 [00:03<00:24, 340.13it/s] 15%|█▌        | 1547/10000 [00:03<00:30, 281.01it/s] 16%|█▌        | 1580/10000 [00:03<00:32, 262.97it/s] 16%|█▌        | 1616/10000 [00:04<00:30, 277.44it/s] 17%|█▋        | 1694/10000 [00:04<00:22, 374.10it/s] 18%|█▊        | 1759/10000 [00:04<00:18, 436.64it/s] 18%|█▊        | 1829/10000 [00:04<00:16, 496.14it/s] 19%|█▉        | 1943/10000 [00:04<00:12, 656.02it/s] 20%|██        | 2014/10000 [00:04<00:12, 647.61it/s] 21%|██        | 2083/10000 [00:04<00:13, 597.12it/s] 21%|██▏       | 2146/10000 [00:04<00:14, 535.07it/s] 22%|██▏       | 2203/10000 [00:05<00:15, 487.58it/s] 23%|██▎       | 2255/10000 [00:05<00:18, 428.95it/s] 23%|██▎       | 2301/10000 [00:05<00:17, 427.89it/s] 23%|██▎       | 2346/10000 [00:05<00:18, 409.21it/s] 24%|██▍       | 2388/10000 [00:05<00:21, 347.48it/s] 24%|██▍       | 2445/10000 [00:05<00:19, 391.75it/s] 25%|██▍       | 2491/10000 [00:05<00:18, 407.67it/s] 25%|██▌       | 2545/10000 [00:05<00:17, 436.43it/s] 26%|██▌       | 2607/10000 [00:06<00:15, 464.95it/s] 27%|██▋       | 2655/10000 [00:06<00:22, 327.16it/s] 27%|██▋       | 2694/10000 [00:06<00:25, 291.41it/s] 27%|██▋       | 2728/10000 [00:06<00:27, 262.64it/s] 28%|██▊       | 2758/10000 [00:06<00:27, 264.03it/s] 28%|██▊       | 2787/10000 [00:06<00:29, 243.55it/s] 28%|██▊       | 2822/10000 [00:06<00:27, 264.85it/s] 29%|██▊       | 2868/10000 [00:07<00:23, 301.99it/s] 29%|██▉       | 2932/10000 [00:07<00:18, 386.01it/s] 30%|███       | 3007/10000 [00:07<00:14, 469.40it/s] 31%|███       | 3057/10000 [00:07<00:19, 354.98it/s] 31%|███       | 3105/10000 [00:07<00:18, 382.60it/s] 31%|███▏      | 3149/10000 [00:07<00:19, 350.59it/s] 32%|███▏      | 3188/10000 [00:07<00:19, 344.51it/s] 32%|███▏      | 3243/10000 [00:08<00:17, 390.98it/s] 33%|███▎      | 3298/10000 [00:08<00:15, 427.50it/s] 34%|███▎      | 3374/10000 [00:08<00:12, 511.33it/s] 34%|███▍      | 3428/10000 [00:08<00:13, 487.78it/s] 35%|███▍      | 3479/10000 [00:08<00:13, 480.66it/s] 35%|███▌      | 3529/10000 [00:08<00:14, 443.22it/s] 36%|███▌      | 3585/10000 [00:08<00:13, 464.91it/s] 37%|███▋      | 3658/10000 [00:08<00:12, 527.95it/s] 37%|███▋      | 3713/10000 [00:08<00:11, 527.31it/s] 38%|███▊      | 3785/10000 [00:09<00:10, 579.56it/s] 38%|███▊      | 3844/10000 [00:09<00:11, 536.21it/s] 39%|███▉      | 3899/10000 [00:09<00:12, 504.33it/s] 40%|███▉      | 3951/10000 [00:09<00:12, 488.59it/s] 40%|████      | 4001/10000 [00:09<00:13, 452.66it/s] 41%|████      | 4054/10000 [00:09<00:12, 463.81it/s] 41%|████▏     | 4129/10000 [00:09<00:11, 521.78it/s] 42%|████▏     | 4202/10000 [00:09<00:10, 576.65it/s] 43%|████▎     | 4261/10000 [00:09<00:10, 554.50it/s] 43%|████▎     | 4318/10000 [00:10<00:10, 549.85it/s] 44%|████▍     | 4404/10000 [00:10<00:08, 633.30it/s] 45%|████▍     | 4469/10000 [00:10<00:12, 457.41it/s] 45%|████▌     | 4523/10000 [00:10<00:14, 382.55it/s] 46%|████▌     | 4568/10000 [00:10<00:16, 336.44it/s] 46%|████▌     | 4607/10000 [00:10<00:15, 338.52it/s] 46%|████▋     | 4649/10000 [00:11<00:15, 350.36it/s] 47%|████▋     | 4687/10000 [00:11<00:16, 328.43it/s] 47%|████▋     | 4726/10000 [00:11<00:15, 341.71it/s] 48%|████▊     | 4762/10000 [00:11<00:15, 332.17it/s] 48%|████▊     | 4809/10000 [00:11<00:14, 357.52it/s] 48%|████▊     | 4846/10000 [00:11<00:15, 328.07it/s] 49%|████▉     | 4880/10000 [00:11<00:17, 294.95it/s] 49%|████▉     | 4911/10000 [00:11<00:17, 289.55it/s] 49%|████▉     | 4941/10000 [00:12<00:18, 268.92it/s] 50%|████▉     | 4975/10000 [00:12<00:17, 286.45it/s] 50%|█████     | 5005/10000 [00:12<00:18, 265.74it/s] 50%|█████     | 5040/10000 [00:12<00:17, 287.22it/s] 51%|█████     | 5083/10000 [00:12<00:15, 318.14it/s] 51%|█████▏    | 5131/10000 [00:12<00:13, 358.28it/s] 52%|█████▏    | 5178/10000 [00:12<00:12, 379.58it/s] 52%|█████▏    | 5217/10000 [00:12<00:12, 376.01it/s] 53%|█████▎    | 5256/10000 [00:12<00:14, 332.03it/s] 53%|█████▎    | 5291/10000 [00:13<00:16, 283.73it/s] 53%|█████▎    | 5322/10000 [00:13<00:18, 249.27it/s] 54%|█████▎    | 5361/10000 [00:13<00:16, 274.31it/s] 54%|█████▍    | 5391/10000 [00:13<00:16, 276.50it/s] 54%|█████▍    | 5432/10000 [00:13<00:15, 298.76it/s] 55%|█████▍    | 5474/10000 [00:13<00:13, 327.35it/s] 55%|█████▌    | 5530/10000 [00:13<00:11, 377.80it/s] 56%|█████▌    | 5584/10000 [00:13<00:10, 421.40it/s] 56%|█████▋    | 5646/10000 [00:14<00:09, 472.46it/s] 57%|█████▋    | 5696/10000 [00:14<00:09, 477.39it/s] 58%|█████▊    | 5757/10000 [00:14<00:08, 514.76it/s] 58%|█████▊    | 5810/10000 [00:14<00:09, 428.06it/s] 59%|█████▊    | 5856/10000 [00:14<00:10, 383.21it/s] 59%|█████▉    | 5904/10000 [00:14<00:10, 390.08it/s] 59%|█████▉    | 5946/10000 [00:14<00:10, 392.79it/s] 60%|█████▉    | 5987/10000 [00:14<00:11, 351.64it/s] 60%|██████    | 6043/10000 [00:15<00:09, 396.86it/s] 61%|██████    | 6097/10000 [00:15<00:09, 427.61it/s] 62%|██████▏   | 6154/10000 [00:15<00:08, 456.83it/s] 62%|██████▏   | 6201/10000 [00:15<00:09, 410.72it/s] 63%|██████▎   | 6251/10000 [00:15<00:08, 431.06it/s] 63%|██████▎   | 6296/10000 [00:15<00:10, 356.06it/s] 63%|██████▎   | 6335/10000 [00:15<00:11, 312.74it/s] 64%|██████▎   | 6369/10000 [00:15<00:12, 285.98it/s] 64%|██████▍   | 6406/10000 [00:16<00:11, 302.10it/s] 64%|██████▍   | 6438/10000 [00:16<00:12, 283.13it/s] 65%|██████▍   | 6478/10000 [00:16<00:11, 311.22it/s] 65%|██████▌   | 6511/10000 [00:16<00:12, 272.86it/s] 66%|██████▌   | 6562/10000 [00:16<00:10, 324.04it/s] 66%|██████▌   | 6597/10000 [00:16<00:11, 288.31it/s] 67%|██████▋   | 6659/10000 [00:16<00:09, 360.29it/s] 67%|██████▋   | 6698/10000 [00:17<00:10, 325.09it/s] 67%|██████▋   | 6745/10000 [00:17<00:09, 356.98it/s] 68%|██████▊   | 6783/10000 [00:17<00:09, 342.47it/s] 68%|██████▊   | 6829/10000 [00:17<00:08, 368.86it/s] 69%|██████▉   | 6903/10000 [00:17<00:06, 462.33it/s] 70%|██████▉   | 6954/10000 [00:17<00:06, 474.18it/s] 70%|███████   | 7008/10000 [00:17<00:06, 481.66it/s] 71%|███████   | 7084/10000 [00:17<00:05, 552.62it/s] 71%|███████▏  | 7141/10000 [00:17<00:05, 532.77it/s] 72%|███████▏  | 7196/10000 [00:17<00:05, 532.20it/s] 72%|███████▎  | 7250/10000 [00:18<00:05, 532.84it/s] 73%|███████▎  | 7325/10000 [00:18<00:04, 580.70it/s] 74%|███████▍  | 7384/10000 [00:18<00:04, 575.33it/s] 74%|███████▍  | 7442/10000 [00:18<00:05, 509.35it/s] 75%|███████▌  | 7504/10000 [00:18<00:04, 534.84it/s] 76%|███████▌  | 7559/10000 [00:18<00:04, 530.85it/s] 76%|███████▌  | 7616/10000 [00:18<00:04, 532.31it/s] 77%|███████▋  | 7670/10000 [00:18<00:05, 430.46it/s] 77%|███████▋  | 7717/10000 [00:19<00:06, 360.19it/s] 78%|███████▊  | 7757/10000 [00:19<00:06, 362.30it/s] 78%|███████▊  | 7798/10000 [00:19<00:05, 367.51it/s] 79%|███████▉  | 7876/10000 [00:19<00:04, 460.59it/s] 80%|███████▉  | 7957/10000 [00:19<00:03, 545.29it/s] 80%|████████  | 8016/10000 [00:19<00:03, 541.93it/s] 81%|████████  | 8081/10000 [00:19<00:03, 571.12it/s] 81%|████████▏ | 8140/10000 [00:19<00:03, 544.32it/s] 82%|████████▏ | 8196/10000 [00:20<00:03, 524.09it/s] 82%|████████▎ | 8250/10000 [00:20<00:03, 485.94it/s] 83%|████████▎ | 8300/10000 [00:20<00:04, 377.60it/s] 83%|████████▎ | 8342/10000 [00:20<00:04, 364.75it/s] 84%|████████▍ | 8382/10000 [00:20<00:04, 359.21it/s] 84%|████████▍ | 8424/10000 [00:20<00:04, 366.70it/s] 85%|████████▍ | 8466/10000 [00:20<00:04, 378.29it/s] 85%|████████▌ | 8505/10000 [00:20<00:04, 366.04it/s] 86%|████████▌ | 8575/10000 [00:21<00:03, 444.46it/s] 86%|████████▌ | 8623/10000 [00:21<00:03, 451.66it/s] 87%|████████▋ | 8697/10000 [00:21<00:02, 520.60it/s] 88%|████████▊ | 8776/10000 [00:21<00:02, 583.92it/s] 89%|████████▊ | 8873/10000 [00:21<00:01, 686.87it/s] 89%|████████▉ | 8943/10000 [00:21<00:01, 682.05it/s] 90%|█████████ | 9012/10000 [00:21<00:01, 667.39it/s] 91%|█████████ | 9080/10000 [00:21<00:01, 647.58it/s] 92%|█████████▏| 9152/10000 [00:21<00:01, 666.13it/s] 92%|█████████▏| 9219/10000 [00:22<00:01, 611.13it/s] 93%|█████████▎| 9282/10000 [00:22<00:01, 423.73it/s] 93%|█████████▎| 9333/10000 [00:22<00:01, 379.05it/s] 94%|█████████▍| 9377/10000 [00:22<00:01, 351.53it/s] 94%|█████████▍| 9418/10000 [00:22<00:01, 363.68it/s] 95%|█████████▍| 9458/10000 [00:22<00:01, 355.96it/s] 95%|█████████▍| 9499/10000 [00:22<00:01, 366.07it/s] 95%|█████████▌| 9538/10000 [00:23<00:01, 337.72it/s] 96%|█████████▌| 9582/10000 [00:23<00:01, 347.20it/s] 96%|█████████▌| 9618/10000 [00:23<00:01, 325.95it/s] 97%|█████████▋| 9671/10000 [00:23<00:00, 354.76it/s] 97%|█████████▋| 9709/10000 [00:23<00:00, 356.89it/s] 97%|█████████▋| 9746/10000 [00:23<00:00, 348.33it/s] 98%|█████████▊| 9800/10000 [00:23<00:00, 398.06it/s] 99%|█████████▉| 9875/10000 [00:23<00:00, 490.80it/s] 99%|█████████▉| 9926/10000 [00:23<00:00, 493.89it/s]100%|██████████| 10000/10000 [00:24<00:00, 415.68it/s]
test_neglected_p72 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p72
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p72.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.07s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.51it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.73it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.01it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.00it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.32it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.79it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.37it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.95it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.30it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p72_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p72_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p72_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p72_Holmes_probs.npy
{'Accuracy': 0.0201, 'Precision': 0.0223, 'Recall': 0.0198, 'F1-score': 0.0174}
starting gen taf script for test_neglected_p73
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 60/10000 [00:00<00:19, 511.25it/s]  1%|          | 112/10000 [00:00<00:32, 308.39it/s]  1%|▏         | 147/10000 [00:00<00:38, 258.86it/s]  2%|▏         | 183/10000 [00:00<00:34, 283.00it/s]  2%|▏         | 214/10000 [00:00<00:34, 281.90it/s]  2%|▏         | 244/10000 [00:00<00:34, 283.74it/s]  3%|▎         | 274/10000 [00:00<00:35, 272.78it/s]  3%|▎         | 302/10000 [00:01<00:37, 261.13it/s]  3%|▎         | 329/10000 [00:01<00:36, 263.39it/s]  4%|▎         | 369/10000 [00:01<00:31, 301.56it/s]  4%|▍         | 404/10000 [00:01<00:30, 312.83it/s]  5%|▍         | 464/10000 [00:01<00:24, 393.72it/s]  5%|▌         | 537/10000 [00:01<00:19, 482.57it/s]  6%|▌         | 605/10000 [00:01<00:17, 537.80it/s]  7%|▋         | 685/10000 [00:01<00:15, 612.98it/s]  8%|▊         | 751/10000 [00:01<00:14, 626.41it/s]  8%|▊         | 815/10000 [00:01<00:14, 621.69it/s]  9%|▉         | 878/10000 [00:02<00:17, 509.33it/s]  9%|▉         | 934/10000 [00:02<00:17, 522.16it/s] 10%|▉         | 989/10000 [00:02<00:19, 469.77it/s] 10%|█         | 1039/10000 [00:02<00:19, 464.14it/s] 11%|█         | 1088/10000 [00:02<00:20, 438.30it/s] 11%|█▏        | 1134/10000 [00:02<00:22, 396.13it/s] 12%|█▏        | 1176/10000 [00:02<00:22, 385.86it/s] 12%|█▏        | 1248/10000 [00:03<00:18, 467.00it/s] 13%|█▎        | 1325/10000 [00:03<00:15, 546.66it/s] 14%|█▍        | 1399/10000 [00:03<00:14, 585.57it/s] 15%|█▍        | 1460/10000 [00:03<00:21, 399.22it/s] 15%|█▌        | 1509/10000 [00:03<00:25, 335.78it/s] 16%|█▌        | 1551/10000 [00:03<00:30, 276.16it/s] 16%|█▌        | 1585/10000 [00:04<00:31, 271.27it/s] 16%|█▋        | 1628/10000 [00:04<00:28, 296.45it/s] 17%|█▋        | 1690/10000 [00:04<00:22, 365.48it/s] 18%|█▊        | 1759/10000 [00:04<00:18, 436.94it/s] 18%|█▊        | 1823/10000 [00:04<00:16, 484.40it/s] 19%|█▉        | 1914/10000 [00:04<00:13, 587.35it/s] 20%|█▉        | 1989/10000 [00:04<00:12, 622.36it/s] 21%|██        | 2055/10000 [00:04<00:12, 611.50it/s] 21%|██        | 2119/10000 [00:04<00:13, 578.04it/s] 22%|██▏       | 2179/10000 [00:05<00:14, 553.21it/s] 22%|██▏       | 2236/10000 [00:05<00:18, 417.45it/s] 23%|██▎       | 2284/10000 [00:05<00:19, 404.26it/s] 23%|██▎       | 2329/10000 [00:05<00:20, 379.70it/s] 24%|██▎       | 2370/10000 [00:05<00:20, 369.61it/s] 24%|██▍       | 2409/10000 [00:05<00:21, 351.15it/s] 25%|██▍       | 2460/10000 [00:05<00:20, 374.16it/s] 25%|██▌       | 2501/10000 [00:06<00:19, 375.83it/s] 26%|██▌       | 2557/10000 [00:06<00:17, 421.63it/s] 26%|██▌       | 2603/10000 [00:06<00:17, 425.15it/s] 26%|██▋       | 2647/10000 [00:06<00:24, 302.41it/s] 27%|██▋       | 2683/10000 [00:06<00:26, 279.69it/s] 27%|██▋       | 2715/10000 [00:06<00:31, 232.49it/s] 27%|██▋       | 2742/10000 [00:07<00:33, 215.19it/s] 28%|██▊       | 2768/10000 [00:07<00:32, 222.95it/s] 28%|██▊       | 2793/10000 [00:07<00:31, 227.22it/s] 28%|██▊       | 2828/10000 [00:07<00:28, 255.88it/s] 29%|██▉       | 2898/10000 [00:07<00:19, 367.21it/s] 29%|██▉       | 2938/10000 [00:07<00:19, 359.59it/s] 30%|██▉       | 2986/10000 [00:07<00:18, 371.58it/s] 30%|███       | 3037/10000 [00:07<00:17, 398.37it/s] 31%|███       | 3078/10000 [00:07<00:19, 363.48it/s] 31%|███       | 3116/10000 [00:08<00:20, 338.04it/s] 32%|███▏      | 3151/10000 [00:08<00:20, 328.20it/s] 32%|███▏      | 3189/10000 [00:08<00:20, 338.65it/s] 33%|███▎      | 3253/10000 [00:08<00:16, 410.93it/s] 33%|███▎      | 3319/10000 [00:08<00:13, 478.05it/s] 34%|███▍      | 3380/10000 [00:08<00:13, 507.75it/s] 35%|███▍      | 3457/10000 [00:08<00:11, 575.76it/s] 35%|███▌      | 3516/10000 [00:08<00:13, 472.10it/s] 36%|███▌      | 3567/10000 [00:08<00:13, 479.34it/s] 36%|███▋      | 3634/10000 [00:09<00:12, 518.02it/s] 37%|███▋      | 3688/10000 [00:09<00:12, 510.07it/s] 38%|███▊      | 3752/10000 [00:09<00:11, 540.97it/s] 38%|███▊      | 3813/10000 [00:09<00:11, 554.82it/s] 39%|███▊      | 3871/10000 [00:09<00:10, 560.56it/s] 39%|███▉      | 3928/10000 [00:09<00:12, 480.80it/s] 40%|███▉      | 3979/10000 [00:09<00:14, 425.59it/s] 41%|████      | 4054/10000 [00:09<00:11, 500.97it/s] 41%|████▏     | 4128/10000 [00:10<00:10, 549.52it/s] 42%|████▏     | 4191/10000 [00:10<00:10, 564.18it/s] 43%|████▎     | 4271/10000 [00:10<00:09, 615.72it/s] 43%|████▎     | 4340/10000 [00:10<00:08, 631.11it/s] 44%|████▍     | 4406/10000 [00:10<00:08, 639.17it/s] 45%|████▍     | 4471/10000 [00:10<00:11, 478.61it/s] 45%|████▌     | 4526/10000 [00:10<00:14, 371.56it/s] 46%|████▌     | 4571/10000 [00:11<00:14, 383.40it/s] 46%|████▌     | 4616/10000 [00:11<00:15, 353.55it/s] 47%|████▋     | 4656/10000 [00:11<00:17, 306.81it/s] 47%|████▋     | 4720/10000 [00:11<00:14, 370.88it/s] 48%|████▊     | 4762/10000 [00:11<00:14, 361.88it/s] 48%|████▊     | 4802/10000 [00:11<00:15, 339.15it/s] 48%|████▊     | 4839/10000 [00:11<00:16, 322.09it/s] 49%|████▊     | 4873/10000 [00:12<00:17, 290.22it/s] 49%|████▉     | 4906/10000 [00:12<00:17, 290.97it/s] 49%|████▉     | 4937/10000 [00:12<00:17, 290.82it/s] 50%|████▉     | 4967/10000 [00:12<00:19, 259.63it/s] 50%|████▉     | 4994/10000 [00:12<00:21, 234.16it/s] 51%|█████     | 5057/10000 [00:12<00:15, 313.03it/s] 51%|█████     | 5096/10000 [00:12<00:14, 331.37it/s] 51%|█████▏    | 5142/10000 [00:12<00:13, 364.61it/s] 52%|█████▏    | 5208/10000 [00:12<00:11, 424.45it/s] 53%|█████▎    | 5252/10000 [00:13<00:14, 333.96it/s] 53%|█████▎    | 5289/10000 [00:13<00:16, 286.24it/s] 53%|█████▎    | 5321/10000 [00:13<00:17, 271.27it/s] 54%|█████▎    | 5351/10000 [00:13<00:17, 263.82it/s] 54%|█████▍    | 5379/10000 [00:13<00:17, 257.36it/s] 54%|█████▍    | 5406/10000 [00:13<00:18, 251.83it/s] 55%|█████▍    | 5460/10000 [00:13<00:14, 321.89it/s] 55%|█████▍    | 5497/10000 [00:14<00:13, 324.27it/s] 56%|█████▌    | 5553/10000 [00:14<00:11, 380.87it/s] 56%|█████▌    | 5593/10000 [00:14<00:11, 369.82it/s] 57%|█████▋    | 5656/10000 [00:14<00:09, 435.59it/s] 57%|█████▋    | 5719/10000 [00:14<00:08, 483.83it/s] 58%|█████▊    | 5778/10000 [00:14<00:08, 509.22it/s] 58%|█████▊    | 5830/10000 [00:14<00:08, 490.57it/s] 59%|█████▉    | 5880/10000 [00:14<00:09, 429.79it/s] 59%|█████▉    | 5925/10000 [00:15<00:10, 401.18it/s] 60%|█████▉    | 5967/10000 [00:15<00:11, 362.59it/s] 60%|██████    | 6005/10000 [00:15<00:11, 362.28it/s] 60%|██████    | 6043/10000 [00:15<00:10, 365.92it/s] 61%|██████    | 6099/10000 [00:15<00:09, 414.13it/s] 62%|██████▏   | 6154/10000 [00:15<00:08, 451.38it/s] 62%|██████▏   | 6201/10000 [00:15<00:08, 425.77it/s] 62%|██████▏   | 6245/10000 [00:15<00:09, 410.79it/s] 63%|██████▎   | 6287/10000 [00:15<00:10, 337.56it/s] 63%|██████▎   | 6327/10000 [00:16<00:10, 348.44it/s] 64%|██████▎   | 6364/10000 [00:16<00:12, 283.13it/s] 64%|██████▍   | 6411/10000 [00:16<00:11, 322.64it/s] 64%|██████▍   | 6447/10000 [00:16<00:11, 309.41it/s] 65%|██████▍   | 6481/10000 [00:16<00:11, 316.09it/s] 65%|██████▌   | 6515/10000 [00:16<00:12, 289.31it/s] 66%|██████▌   | 6551/10000 [00:16<00:11, 296.20it/s] 66%|██████▌   | 6582/10000 [00:17<00:11, 293.08it/s] 66%|██████▌   | 6623/10000 [00:17<00:10, 312.23it/s] 67%|██████▋   | 6660/10000 [00:17<00:10, 315.23it/s] 67%|██████▋   | 6705/10000 [00:17<00:09, 347.44it/s] 67%|██████▋   | 6743/10000 [00:17<00:09, 336.18it/s] 68%|██████▊   | 6778/10000 [00:17<00:09, 335.27it/s] 68%|██████▊   | 6835/10000 [00:17<00:07, 399.04it/s] 69%|██████▉   | 6927/10000 [00:17<00:05, 544.67it/s] 70%|██████▉   | 6988/10000 [00:17<00:05, 558.31it/s] 70%|███████   | 7045/10000 [00:17<00:05, 523.25it/s] 71%|███████   | 7106/10000 [00:18<00:05, 545.83it/s] 72%|███████▏  | 7179/10000 [00:18<00:04, 598.00it/s] 72%|███████▏  | 7240/10000 [00:18<00:05, 531.56it/s] 73%|███████▎  | 7296/10000 [00:18<00:05, 511.66it/s] 74%|███████▎  | 7366/10000 [00:18<00:04, 558.42it/s] 74%|███████▍  | 7424/10000 [00:18<00:04, 550.88it/s] 75%|███████▍  | 7481/10000 [00:18<00:04, 550.50it/s] 75%|███████▌  | 7537/10000 [00:18<00:04, 547.94it/s] 76%|███████▌  | 7606/10000 [00:18<00:04, 571.45it/s] 77%|███████▋  | 7664/10000 [00:19<00:05, 445.05it/s] 77%|███████▋  | 7713/10000 [00:19<00:05, 441.76it/s] 78%|███████▊  | 7761/10000 [00:19<00:05, 405.33it/s] 78%|███████▊  | 7817/10000 [00:19<00:05, 436.38it/s] 79%|███████▊  | 7866/10000 [00:19<00:04, 448.00it/s] 79%|███████▉  | 7913/10000 [00:19<00:04, 453.65it/s] 80%|███████▉  | 7981/10000 [00:19<00:04, 497.14it/s] 80%|████████  | 8036/10000 [00:19<00:03, 511.23it/s] 81%|████████  | 8094/10000 [00:20<00:03, 524.91it/s] 82%|████████▏ | 8153/10000 [00:20<00:03, 537.87it/s] 82%|████████▏ | 8208/10000 [00:20<00:03, 530.15it/s] 83%|████████▎ | 8262/10000 [00:20<00:03, 455.75it/s] 83%|████████▎ | 8310/10000 [00:20<00:04, 394.16it/s] 84%|████████▎ | 8352/10000 [00:20<00:04, 345.33it/s] 84%|████████▍ | 8400/10000 [00:20<00:04, 371.21it/s] 84%|████████▍ | 8440/10000 [00:21<00:04, 362.72it/s] 85%|████████▌ | 8508/10000 [00:21<00:03, 436.27it/s] 86%|████████▌ | 8554/10000 [00:21<00:03, 428.80it/s] 86%|████████▌ | 8599/10000 [00:21<00:03, 418.45it/s] 87%|████████▋ | 8664/10000 [00:21<00:02, 479.44it/s] 87%|████████▋ | 8718/10000 [00:21<00:02, 490.44it/s] 88%|████████▊ | 8790/10000 [00:21<00:02, 549.52it/s] 89%|████████▊ | 8853/10000 [00:21<00:02, 572.10it/s] 89%|████████▉ | 8924/10000 [00:21<00:01, 604.53it/s] 90%|█████████ | 9010/10000 [00:21<00:01, 678.14it/s] 91%|█████████ | 9079/10000 [00:22<00:01, 611.27it/s] 91%|█████████▏| 9142/10000 [00:22<00:01, 597.33it/s] 92%|█████████▏| 9203/10000 [00:22<00:01, 543.72it/s] 93%|█████████▎| 9259/10000 [00:22<00:01, 439.88it/s] 93%|█████████▎| 9307/10000 [00:22<00:01, 375.25it/s] 93%|█████████▎| 9349/10000 [00:22<00:01, 383.53it/s] 94%|█████████▍| 9391/10000 [00:22<00:01, 336.84it/s] 94%|█████████▍| 9428/10000 [00:23<00:01, 341.85it/s] 95%|█████████▍| 9469/10000 [00:23<00:01, 346.53it/s] 95%|█████████▌| 9515/10000 [00:23<00:01, 372.67it/s] 96%|█████████▌| 9554/10000 [00:23<00:01, 349.38it/s] 96%|█████████▌| 9591/10000 [00:23<00:01, 332.70it/s] 96%|█████████▋| 9646/10000 [00:23<00:00, 383.64it/s] 97%|█████████▋| 9692/10000 [00:23<00:00, 391.89it/s] 97%|█████████▋| 9733/10000 [00:23<00:00, 377.41it/s] 98%|█████████▊| 9790/10000 [00:24<00:00, 418.70it/s] 99%|█████████▊| 9859/10000 [00:24<00:00, 477.93it/s] 99%|█████████▉| 9931/10000 [00:24<00:00, 537.46it/s]100%|██████████| 10000/10000 [00:24<00:00, 411.50it/s]
test_neglected_p73 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p73
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p73.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:50,  1.30s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:06,  5.54it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 10.84it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 16.42it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 22.07it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 27.23it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 31.76it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:02<00:00, 35.53it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 18.11it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p73_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p73_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p73_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p73_Holmes_probs.npy
{'Accuracy': 0.02, 'Precision': 0.0225, 'Recall': 0.0197, 'F1-score': 0.0172}
starting gen taf script for test_neglected_p74
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 58/10000 [00:00<00:18, 542.07it/s]  1%|          | 113/10000 [00:00<00:30, 327.29it/s]  2%|▏         | 151/10000 [00:00<00:35, 274.49it/s]  2%|▏         | 181/10000 [00:00<00:35, 273.04it/s]  2%|▏         | 210/10000 [00:00<00:41, 236.19it/s]  2%|▏         | 242/10000 [00:00<00:37, 257.05it/s]  3%|▎         | 270/10000 [00:00<00:38, 251.97it/s]  3%|▎         | 297/10000 [00:01<00:38, 251.92it/s]  3%|▎         | 323/10000 [00:01<00:39, 242.06it/s]  3%|▎         | 348/10000 [00:01<00:40, 240.92it/s]  4%|▎         | 373/10000 [00:01<00:39, 242.35it/s]  4%|▍         | 398/10000 [00:01<00:39, 242.04it/s]  4%|▍         | 427/10000 [00:01<00:37, 254.43it/s]  5%|▍         | 455/10000 [00:01<00:37, 257.78it/s]  5%|▍         | 482/10000 [00:01<00:37, 253.66it/s]  5%|▌         | 514/10000 [00:01<00:35, 269.46it/s]  5%|▌         | 547/10000 [00:02<00:33, 285.07it/s]  6%|▌         | 583/10000 [00:02<00:31, 300.42it/s]  6%|▌         | 614/10000 [00:02<00:31, 295.82it/s]  6%|▋         | 648/10000 [00:02<00:32, 287.15it/s]  7%|▋         | 698/10000 [00:02<00:27, 337.99it/s]  7%|▋         | 745/10000 [00:02<00:24, 372.81it/s]  8%|▊         | 800/10000 [00:02<00:23, 393.24it/s]  9%|▊         | 862/10000 [00:02<00:20, 448.57it/s]  9%|▉         | 908/10000 [00:03<00:25, 363.26it/s] 10%|▉         | 950/10000 [00:03<00:24, 367.51it/s] 10%|▉         | 993/10000 [00:03<00:23, 375.65it/s] 10%|█         | 1036/10000 [00:03<00:23, 389.45it/s] 11%|█         | 1077/10000 [00:03<00:24, 367.71it/s] 11%|█         | 1115/10000 [00:03<00:25, 347.22it/s] 12%|█▏        | 1153/10000 [00:03<00:24, 355.67it/s] 12%|█▏        | 1190/10000 [00:03<00:24, 358.27it/s] 12%|█▏        | 1240/10000 [00:03<00:22, 388.15it/s] 13%|█▎        | 1283/10000 [00:04<00:21, 399.84it/s] 13%|█▎        | 1328/10000 [00:04<00:21, 410.28it/s] 14%|█▍        | 1385/10000 [00:04<00:19, 447.06it/s] 14%|█▍        | 1430/10000 [00:04<00:20, 412.78it/s] 15%|█▍        | 1472/10000 [00:04<00:25, 337.01it/s] 15%|█▌        | 1509/10000 [00:04<00:30, 274.27it/s] 15%|█▌        | 1540/10000 [00:04<00:34, 248.54it/s] 16%|█▌        | 1568/10000 [00:05<00:33, 250.66it/s] 16%|█▌        | 1595/10000 [00:05<00:36, 233.36it/s] 16%|█▋        | 1643/10000 [00:05<00:28, 288.43it/s] 17%|█▋        | 1697/10000 [00:05<00:23, 348.52it/s] 18%|█▊        | 1753/10000 [00:05<00:20, 402.04it/s] 18%|█▊        | 1828/10000 [00:05<00:16, 491.59it/s] 19%|█▉        | 1915/10000 [00:05<00:13, 588.76it/s] 20%|██        | 2008/10000 [00:05<00:11, 670.53it/s] 21%|██        | 2077/10000 [00:05<00:13, 573.89it/s] 21%|██▏       | 2138/10000 [00:06<00:16, 489.99it/s] 22%|██▏       | 2204/10000 [00:06<00:15, 497.30it/s] 23%|██▎       | 2257/10000 [00:06<00:17, 453.03it/s] 23%|██▎       | 2305/10000 [00:06<00:19, 404.56it/s] 23%|██▎       | 2348/10000 [00:06<00:20, 379.71it/s] 24%|██▍       | 2388/10000 [00:06<00:22, 339.38it/s] 24%|██▍       | 2437/10000 [00:06<00:20, 373.29it/s] 25%|██▍       | 2480/10000 [00:07<00:19, 384.02it/s] 25%|██▌       | 2521/10000 [00:07<00:19, 390.31it/s] 26%|██▌       | 2572/10000 [00:07<00:18, 408.33it/s] 26%|██▌       | 2615/10000 [00:07<00:18, 398.24it/s] 27%|██▋       | 2656/10000 [00:07<00:23, 318.65it/s] 27%|██▋       | 2691/10000 [00:07<00:27, 270.63it/s] 27%|██▋       | 2721/10000 [00:07<00:28, 254.56it/s] 27%|██▋       | 2749/10000 [00:08<00:34, 212.36it/s] 28%|██▊       | 2776/10000 [00:08<00:33, 215.64it/s] 28%|██▊       | 2806/10000 [00:08<00:31, 226.90it/s] 29%|██▊       | 2856/10000 [00:08<00:25, 284.77it/s] 29%|██▉       | 2896/10000 [00:08<00:22, 312.95it/s] 29%|██▉       | 2940/10000 [00:08<00:20, 344.97it/s] 30%|██▉       | 2977/10000 [00:08<00:21, 333.93it/s] 30%|███       | 3012/10000 [00:08<00:22, 317.08it/s] 31%|███       | 3059/10000 [00:08<00:19, 353.77it/s] 31%|███       | 3096/10000 [00:09<00:22, 304.85it/s] 31%|███▏      | 3134/10000 [00:09<00:21, 317.45it/s] 32%|███▏      | 3176/10000 [00:09<00:20, 340.51it/s] 32%|███▏      | 3219/10000 [00:09<00:18, 360.47it/s] 33%|███▎      | 3287/10000 [00:09<00:14, 447.95it/s] 34%|███▎      | 3350/10000 [00:09<00:13, 490.67it/s] 34%|███▍      | 3428/10000 [00:09<00:11, 553.40it/s] 35%|███▍      | 3485/10000 [00:09<00:13, 476.52it/s] 35%|███▌      | 3538/10000 [00:10<00:13, 489.84it/s] 36%|███▌      | 3589/10000 [00:10<00:13, 489.09it/s] 37%|███▋      | 3684/10000 [00:10<00:10, 597.41it/s] 37%|███▋      | 3746/10000 [00:10<00:10, 592.44it/s] 38%|███▊      | 3807/10000 [00:10<00:10, 595.58it/s] 39%|███▊      | 3868/10000 [00:10<00:11, 522.99it/s] 39%|███▉      | 3929/10000 [00:10<00:11, 516.79it/s] 40%|███▉      | 3982/10000 [00:10<00:13, 451.40it/s] 41%|████      | 4057/10000 [00:11<00:11, 518.05it/s] 41%|████      | 4121/10000 [00:11<00:10, 549.32it/s] 42%|████▏     | 4183/10000 [00:11<00:10, 563.64it/s] 42%|████▏     | 4242/10000 [00:11<00:10, 534.01it/s] 43%|████▎     | 4326/10000 [00:11<00:09, 613.59it/s] 44%|████▍     | 4390/10000 [00:11<00:09, 579.91it/s] 44%|████▍     | 4450/10000 [00:11<00:11, 467.00it/s] 45%|████▌     | 4501/10000 [00:11<00:15, 365.74it/s] 45%|████▌     | 4544/10000 [00:12<00:15, 360.78it/s] 46%|████▌     | 4584/10000 [00:12<00:15, 347.57it/s] 46%|████▋     | 4630/10000 [00:12<00:14, 363.92it/s] 47%|████▋     | 4669/10000 [00:12<00:15, 342.85it/s] 47%|████▋     | 4705/10000 [00:12<00:16, 317.35it/s] 47%|████▋     | 4747/10000 [00:12<00:16, 326.14it/s] 48%|████▊     | 4786/10000 [00:12<00:15, 335.92it/s] 48%|████▊     | 4821/10000 [00:12<00:16, 320.12it/s] 49%|████▊     | 4854/10000 [00:13<00:17, 298.05it/s] 49%|████▉     | 4885/10000 [00:13<00:19, 257.99it/s] 49%|████▉     | 4915/10000 [00:13<00:19, 255.88it/s] 49%|████▉     | 4946/10000 [00:13<00:19, 262.08it/s] 50%|████▉     | 4973/10000 [00:13<00:19, 253.02it/s] 50%|████▉     | 4999/10000 [00:13<00:20, 247.21it/s] 51%|█████     | 5062/10000 [00:13<00:14, 347.88it/s] 51%|█████     | 5109/10000 [00:13<00:13, 356.60it/s] 51%|█████▏    | 5148/10000 [00:14<00:13, 361.42it/s] 52%|█████▏    | 5185/10000 [00:14<00:13, 360.85it/s] 52%|█████▏    | 5222/10000 [00:14<00:14, 340.28it/s] 53%|█████▎    | 5257/10000 [00:14<00:16, 293.03it/s] 53%|█████▎    | 5288/10000 [00:14<00:16, 285.53it/s] 53%|█████▎    | 5318/10000 [00:14<00:17, 271.00it/s] 53%|█████▎    | 5346/10000 [00:14<00:18, 251.59it/s] 54%|█████▍    | 5382/10000 [00:14<00:18, 253.29it/s] 54%|█████▍    | 5426/10000 [00:15<00:15, 295.92it/s] 55%|█████▍    | 5464/10000 [00:15<00:14, 309.04it/s] 55%|█████▌    | 5527/10000 [00:15<00:11, 393.59it/s] 56%|█████▌    | 5569/10000 [00:15<00:11, 380.71it/s] 56%|█████▌    | 5617/10000 [00:15<00:10, 398.83it/s] 57%|█████▋    | 5683/10000 [00:15<00:09, 466.82it/s] 57%|█████▋    | 5746/10000 [00:15<00:08, 506.92it/s] 58%|█████▊    | 5798/10000 [00:15<00:09, 461.74it/s] 58%|█████▊    | 5846/10000 [00:15<00:09, 426.46it/s] 59%|█████▉    | 5890/10000 [00:16<00:10, 390.42it/s] 59%|█████▉    | 5931/10000 [00:16<00:12, 328.76it/s] 60%|█████▉    | 5966/10000 [00:16<00:12, 330.47it/s] 60%|██████    | 6012/10000 [00:16<00:11, 358.98it/s] 60%|██████    | 6050/10000 [00:16<00:11, 349.14it/s] 61%|██████    | 6098/10000 [00:16<00:10, 377.61it/s] 62%|██████▏   | 6150/10000 [00:16<00:09, 414.67it/s] 62%|██████▏   | 6197/10000 [00:16<00:08, 424.57it/s] 62%|██████▏   | 6241/10000 [00:17<00:09, 414.93it/s] 63%|██████▎   | 6284/10000 [00:17<00:10, 359.98it/s] 63%|██████▎   | 6322/10000 [00:17<00:10, 345.16it/s] 64%|██████▎   | 6358/10000 [00:17<00:12, 296.03it/s] 64%|██████▍   | 6390/10000 [00:17<00:12, 294.18it/s] 64%|██████▍   | 6421/10000 [00:17<00:12, 283.30it/s] 65%|██████▍   | 6457/10000 [00:17<00:11, 300.94it/s] 65%|██████▍   | 6495/10000 [00:17<00:11, 303.38it/s] 65%|██████▌   | 6534/10000 [00:18<00:10, 318.15it/s] 66%|██████▌   | 6567/10000 [00:18<00:10, 321.09it/s] 66%|██████▌   | 6600/10000 [00:18<00:10, 317.80it/s] 66%|██████▋   | 6633/10000 [00:18<00:12, 280.33it/s] 67%|██████▋   | 6675/10000 [00:18<00:10, 313.35it/s] 67%|██████▋   | 6715/10000 [00:18<00:10, 323.31it/s] 68%|██████▊   | 6750/10000 [00:18<00:10, 305.75it/s] 68%|██████▊   | 6795/10000 [00:18<00:09, 342.33it/s] 68%|██████▊   | 6845/10000 [00:18<00:08, 381.79it/s] 69%|██████▉   | 6908/10000 [00:19<00:06, 446.21it/s] 70%|██████▉   | 6964/10000 [00:19<00:06, 469.52it/s] 70%|███████   | 7018/10000 [00:19<00:06, 485.21it/s] 71%|███████   | 7068/10000 [00:19<00:06, 477.61it/s] 71%|███████   | 7117/10000 [00:19<00:06, 474.97it/s] 72%|███████▏  | 7165/10000 [00:19<00:06, 431.18it/s] 72%|███████▏  | 7223/10000 [00:19<00:05, 468.94it/s] 73%|███████▎  | 7308/10000 [00:19<00:04, 573.87it/s] 74%|███████▍  | 7376/10000 [00:19<00:04, 597.93it/s] 74%|███████▍  | 7437/10000 [00:20<00:04, 585.96it/s] 75%|███████▍  | 7497/10000 [00:20<00:04, 571.31it/s] 76%|███████▌  | 7555/10000 [00:20<00:04, 550.32it/s] 76%|███████▌  | 7611/10000 [00:20<00:04, 510.67it/s] 77%|███████▋  | 7663/10000 [00:20<00:05, 430.11it/s] 77%|███████▋  | 7709/10000 [00:20<00:05, 417.35it/s] 78%|███████▊  | 7753/10000 [00:20<00:06, 373.36it/s] 78%|███████▊  | 7792/10000 [00:20<00:06, 366.03it/s] 79%|███████▊  | 7853/10000 [00:21<00:05, 425.93it/s] 79%|███████▉  | 7913/10000 [00:21<00:04, 460.72it/s] 80%|███████▉  | 7975/10000 [00:21<00:04, 497.27it/s] 80%|████████  | 8038/10000 [00:21<00:03, 532.06it/s] 81%|████████  | 8117/10000 [00:21<00:03, 592.85it/s] 82%|████████▏ | 8181/10000 [00:21<00:03, 587.07it/s] 82%|████████▏ | 8241/10000 [00:21<00:03, 451.02it/s] 83%|████████▎ | 8292/10000 [00:21<00:03, 447.46it/s] 83%|████████▎ | 8341/10000 [00:22<00:04, 346.25it/s] 84%|████████▍ | 8384/10000 [00:22<00:04, 361.33it/s] 84%|████████▍ | 8425/10000 [00:22<00:04, 347.73it/s] 85%|████████▍ | 8473/10000 [00:22<00:04, 372.03it/s] 85%|████████▌ | 8520/10000 [00:22<00:03, 391.65it/s] 86%|████████▌ | 8562/10000 [00:22<00:03, 377.51it/s] 86%|████████▌ | 8614/10000 [00:22<00:03, 405.54it/s] 87%|████████▋ | 8684/10000 [00:22<00:02, 482.08it/s] 87%|████████▋ | 8748/10000 [00:23<00:02, 521.84it/s] 88%|████████▊ | 8802/10000 [00:23<00:02, 513.06it/s] 89%|████████▊ | 8862/10000 [00:23<00:02, 530.83it/s] 89%|████████▉ | 8917/10000 [00:23<00:02, 531.09it/s] 90%|████████▉ | 8981/10000 [00:23<00:01, 561.97it/s] 90%|█████████ | 9045/10000 [00:23<00:01, 584.53it/s] 91%|█████████ | 9104/10000 [00:23<00:01, 583.46it/s] 92%|█████████▏| 9163/10000 [00:23<00:01, 581.01it/s] 92%|█████████▏| 9222/10000 [00:23<00:01, 549.84it/s] 93%|█████████▎| 9278/10000 [00:24<00:01, 411.59it/s] 93%|█████████▎| 9325/10000 [00:24<00:01, 395.27it/s] 94%|█████████▎| 9369/10000 [00:24<00:01, 326.96it/s] 94%|█████████▍| 9406/10000 [00:24<00:01, 315.06it/s] 95%|█████████▍| 9453/10000 [00:24<00:01, 346.60it/s] 95%|█████████▍| 9491/10000 [00:24<00:01, 349.55it/s] 95%|█████████▌| 9532/10000 [00:24<00:01, 338.21it/s] 96%|█████████▌| 9568/10000 [00:25<00:01, 336.57it/s] 96%|█████████▌| 9603/10000 [00:25<00:01, 337.55it/s] 96%|█████████▋| 9643/10000 [00:25<00:01, 345.07it/s] 97%|█████████▋| 9692/10000 [00:25<00:00, 383.56it/s] 97%|█████████▋| 9732/10000 [00:25<00:00, 361.80it/s] 98%|█████████▊| 9778/10000 [00:25<00:00, 384.96it/s] 98%|█████████▊| 9818/10000 [00:25<00:00, 388.87it/s] 99%|█████████▉| 9891/10000 [00:25<00:00, 473.58it/s] 99%|█████████▉| 9939/10000 [00:25<00:00, 467.07it/s]100%|██████████| 10000/10000 [00:25<00:00, 385.34it/s]
test_neglected_p74 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p74
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p74.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:49,  1.27s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:06,  5.65it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 11.03it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 16.74it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 22.43it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 27.52it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 31.12it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:02<00:00, 35.04it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 18.27it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p74_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p74_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p74_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p74_Holmes_probs.npy
{'Accuracy': 0.0203, 'Precision': 0.0222, 'Recall': 0.02, 'F1-score': 0.0174}
starting gen taf script for test_neglected_p75
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 81/10000 [00:00<00:13, 727.55it/s]  2%|▏         | 154/10000 [00:00<00:28, 343.82it/s]  2%|▏         | 199/10000 [00:00<00:30, 323.59it/s]  2%|▏         | 237/10000 [00:00<00:31, 306.41it/s]  3%|▎         | 271/10000 [00:00<00:33, 292.60it/s]  3%|▎         | 302/10000 [00:00<00:34, 283.00it/s]  3%|▎         | 332/10000 [00:01<00:35, 271.24it/s]  4%|▎         | 360/10000 [00:01<00:35, 269.15it/s]  4%|▍         | 388/10000 [00:01<00:36, 259.98it/s]  4%|▍         | 415/10000 [00:01<00:37, 254.86it/s]  5%|▍         | 458/10000 [00:01<00:31, 299.68it/s]  5%|▍         | 498/10000 [00:01<00:29, 326.19it/s]  5%|▌         | 533/10000 [00:01<00:29, 326.07it/s]  6%|▌         | 570/10000 [00:01<00:28, 334.40it/s]  6%|▌         | 604/10000 [00:01<00:28, 328.41it/s]  6%|▋         | 638/10000 [00:02<00:29, 321.73it/s]  7%|▋         | 671/10000 [00:02<00:31, 297.63it/s]  7%|▋         | 702/10000 [00:02<00:33, 278.75it/s]  7%|▋         | 731/10000 [00:02<00:33, 278.96it/s]  8%|▊         | 763/10000 [00:02<00:32, 280.93it/s]  8%|▊         | 792/10000 [00:02<00:33, 277.20it/s]  8%|▊         | 820/10000 [00:02<00:35, 257.79it/s]  9%|▊         | 851/10000 [00:02<00:33, 271.37it/s]  9%|▉         | 889/10000 [00:02<00:30, 297.53it/s]  9%|▉         | 920/10000 [00:03<00:30, 298.25it/s] 10%|▉         | 951/10000 [00:03<00:31, 283.63it/s] 10%|█         | 1000/10000 [00:03<00:26, 336.31it/s] 10%|█         | 1038/10000 [00:03<00:26, 341.01it/s] 11%|█         | 1080/10000 [00:03<00:24, 360.90it/s] 11%|█         | 1117/10000 [00:03<00:25, 350.90it/s] 12%|█▏        | 1170/10000 [00:03<00:22, 395.17it/s] 12%|█▏        | 1210/10000 [00:03<00:22, 394.44it/s] 13%|█▎        | 1291/10000 [00:03<00:16, 513.57it/s] 13%|█▎        | 1343/10000 [00:04<00:20, 430.77it/s] 14%|█▍        | 1390/10000 [00:04<00:19, 435.30it/s] 14%|█▍        | 1436/10000 [00:04<00:24, 354.20it/s] 15%|█▍        | 1475/10000 [00:04<00:27, 313.25it/s] 15%|█▌        | 1510/10000 [00:04<00:31, 273.77it/s] 15%|█▌        | 1540/10000 [00:04<00:36, 232.75it/s] 16%|█▌        | 1566/10000 [00:05<00:37, 223.89it/s] 16%|█▌        | 1596/10000 [00:05<00:35, 238.31it/s] 17%|█▋        | 1658/10000 [00:05<00:25, 325.95it/s] 17%|█▋        | 1744/10000 [00:05<00:17, 458.85it/s] 18%|█▊        | 1798/10000 [00:05<00:17, 472.40it/s] 19%|█▊        | 1872/10000 [00:05<00:14, 543.49it/s] 20%|█▉        | 1958/10000 [00:05<00:12, 626.12it/s] 20%|██        | 2024/10000 [00:05<00:13, 605.42it/s] 21%|██        | 2087/10000 [00:05<00:15, 521.26it/s] 21%|██▏       | 2144/10000 [00:06<00:15, 517.84it/s] 22%|██▏       | 2199/10000 [00:06<00:16, 472.76it/s] 22%|██▏       | 2249/10000 [00:06<00:17, 438.35it/s] 23%|██▎       | 2295/10000 [00:06<00:19, 390.47it/s] 23%|██▎       | 2337/10000 [00:06<00:19, 388.83it/s] 24%|██▍       | 2377/10000 [00:06<00:21, 347.45it/s] 24%|██▍       | 2413/10000 [00:06<00:22, 342.48it/s] 25%|██▍       | 2475/10000 [00:06<00:18, 410.53it/s] 25%|██▌       | 2522/10000 [00:07<00:17, 423.08it/s] 26%|██▌       | 2573/10000 [00:07<00:16, 441.28it/s] 26%|██▌       | 2619/10000 [00:07<00:19, 371.33it/s] 27%|██▋       | 2659/10000 [00:07<00:23, 313.16it/s] 27%|██▋       | 2694/10000 [00:07<00:26, 276.97it/s] 27%|██▋       | 2725/10000 [00:07<00:29, 246.41it/s] 28%|██▊       | 2752/10000 [00:08<00:33, 217.05it/s] 28%|██▊       | 2776/10000 [00:08<00:33, 218.36it/s] 28%|██▊       | 2814/10000 [00:08<00:28, 247.82it/s] 29%|██▊       | 2852/10000 [00:08<00:26, 274.34it/s] 29%|██▉       | 2905/10000 [00:08<00:21, 334.99it/s] 29%|██▉       | 2945/10000 [00:08<00:20, 344.94it/s] 30%|██▉       | 2992/10000 [00:08<00:18, 377.68it/s] 30%|███       | 3032/10000 [00:08<00:18, 371.24it/s] 31%|███       | 3071/10000 [00:08<00:19, 352.24it/s] 31%|███       | 3114/10000 [00:09<00:18, 364.11it/s] 32%|███▏      | 3152/10000 [00:09<00:20, 328.59it/s] 32%|███▏      | 3186/10000 [00:09<00:21, 320.18it/s] 32%|███▏      | 3245/10000 [00:09<00:17, 386.68it/s] 33%|███▎      | 3313/10000 [00:09<00:14, 465.04it/s] 34%|███▎      | 3371/10000 [00:09<00:13, 496.32it/s] 34%|███▍      | 3429/10000 [00:09<00:12, 506.83it/s] 35%|███▍      | 3481/10000 [00:09<00:14, 446.85it/s] 35%|███▌      | 3530/10000 [00:09<00:14, 456.15it/s] 36%|███▌      | 3578/10000 [00:10<00:15, 401.40it/s] 37%|███▋      | 3661/10000 [00:10<00:12, 505.69it/s] 37%|███▋      | 3715/10000 [00:10<00:12, 485.90it/s] 38%|███▊      | 3766/10000 [00:10<00:12, 486.59it/s] 38%|███▊      | 3822/10000 [00:10<00:12, 486.85it/s] 39%|███▉      | 3878/10000 [00:10<00:12, 490.26it/s] 39%|███▉      | 3928/10000 [00:10<00:14, 423.03it/s] 40%|███▉      | 3980/10000 [00:10<00:13, 445.45it/s] 40%|████      | 4027/10000 [00:11<00:13, 444.19it/s] 41%|████      | 4079/10000 [00:11<00:12, 461.11it/s] 41%|████▏     | 4146/10000 [00:11<00:11, 507.28it/s] 42%|████▏     | 4216/10000 [00:11<00:10, 554.62it/s] 43%|████▎     | 4275/10000 [00:11<00:10, 558.39it/s] 43%|████▎     | 4332/10000 [00:11<00:10, 528.11it/s] 44%|████▍     | 4386/10000 [00:11<00:11, 499.28it/s] 44%|████▍     | 4437/10000 [00:11<00:12, 436.24it/s] 45%|████▍     | 4483/10000 [00:11<00:13, 423.57it/s] 45%|████▌     | 4527/10000 [00:12<00:15, 349.37it/s] 46%|████▌     | 4565/10000 [00:12<00:17, 314.73it/s] 46%|████▌     | 4599/10000 [00:12<00:18, 299.88it/s] 46%|████▋     | 4631/10000 [00:12<00:17, 302.38it/s] 47%|████▋     | 4663/10000 [00:12<00:17, 296.67it/s] 47%|████▋     | 4700/10000 [00:12<00:16, 311.94it/s] 47%|████▋     | 4732/10000 [00:12<00:17, 302.78it/s] 48%|████▊     | 4765/10000 [00:13<00:16, 308.44it/s] 48%|████▊     | 4797/10000 [00:13<00:17, 293.01it/s] 48%|████▊     | 4832/10000 [00:13<00:17, 288.11it/s] 49%|████▊     | 4862/10000 [00:13<00:17, 289.84it/s] 49%|████▉     | 4892/10000 [00:13<00:18, 273.64it/s] 49%|████▉     | 4920/10000 [00:13<00:21, 240.97it/s] 49%|████▉     | 4945/10000 [00:13<00:24, 210.43it/s] 50%|████▉     | 4973/10000 [00:13<00:22, 226.05it/s] 50%|█████     | 5015/10000 [00:14<00:18, 270.98it/s] 51%|█████     | 5090/10000 [00:14<00:12, 394.13it/s] 52%|█████▏    | 5154/10000 [00:14<00:10, 460.11it/s] 52%|█████▏    | 5203/10000 [00:14<00:10, 456.40it/s] 53%|█████▎    | 5251/10000 [00:14<00:14, 335.31it/s] 53%|█████▎    | 5291/10000 [00:14<00:17, 274.93it/s] 53%|█████▎    | 5324/10000 [00:14<00:16, 279.83it/s] 54%|█████▎    | 5356/10000 [00:15<00:18, 252.37it/s] 54%|█████▍    | 5385/10000 [00:15<00:18, 243.90it/s] 54%|█████▍    | 5417/10000 [00:15<00:18, 251.92it/s] 55%|█████▍    | 5472/10000 [00:15<00:14, 322.01it/s] 55%|█████▌    | 5508/10000 [00:15<00:13, 328.43it/s] 56%|█████▌    | 5558/10000 [00:15<00:12, 364.72it/s] 56%|█████▌    | 5597/10000 [00:15<00:12, 362.64it/s] 57%|█████▋    | 5664/10000 [00:15<00:10, 433.28it/s] 57%|█████▋    | 5740/10000 [00:15<00:08, 512.57it/s] 58%|█████▊    | 5800/10000 [00:16<00:08, 501.54it/s] 59%|█████▊    | 5851/10000 [00:16<00:09, 419.46it/s] 59%|█████▉    | 5896/10000 [00:16<00:10, 392.17it/s] 59%|█████▉    | 5938/10000 [00:16<00:11, 349.30it/s] 60%|█████▉    | 5975/10000 [00:16<00:12, 319.44it/s] 60%|██████    | 6031/10000 [00:16<00:10, 367.31it/s] 61%|██████    | 6089/10000 [00:16<00:09, 412.49it/s] 62%|██████▏   | 6151/10000 [00:16<00:08, 464.08it/s] 62%|██████▏   | 6209/10000 [00:17<00:07, 477.24it/s] 63%|██████▎   | 6259/10000 [00:17<00:09, 394.87it/s] 63%|██████▎   | 6302/10000 [00:17<00:10, 337.77it/s] 63%|██████▎   | 6340/10000 [00:17<00:12, 295.68it/s] 64%|██████▍   | 6378/10000 [00:17<00:12, 288.80it/s] 64%|██████▍   | 6416/10000 [00:17<00:11, 306.20it/s] 64%|██████▍   | 6449/10000 [00:18<00:12, 291.29it/s] 65%|██████▍   | 6480/10000 [00:18<00:13, 270.36it/s] 65%|██████▌   | 6523/10000 [00:18<00:11, 303.53it/s] 66%|██████▌   | 6563/10000 [00:18<00:10, 318.90it/s] 66%|██████▌   | 6602/10000 [00:18<00:10, 322.25it/s] 66%|██████▋   | 6635/10000 [00:18<00:11, 292.83it/s] 67%|██████▋   | 6677/10000 [00:18<00:10, 321.46it/s] 67%|██████▋   | 6724/10000 [00:18<00:09, 355.86it/s] 68%|██████▊   | 6761/10000 [00:18<00:09, 356.05it/s] 68%|██████▊   | 6803/10000 [00:19<00:08, 370.88it/s] 69%|██████▊   | 6855/10000 [00:19<00:07, 406.75it/s] 69%|██████▉   | 6922/10000 [00:19<00:06, 467.81it/s] 70%|███████   | 7000/10000 [00:19<00:05, 555.82it/s] 71%|███████   | 7058/10000 [00:19<00:05, 533.08it/s] 71%|███████   | 7112/10000 [00:19<00:05, 506.27it/s] 72%|███████▏  | 7166/10000 [00:19<00:05, 512.86it/s] 72%|███████▏  | 7235/10000 [00:19<00:04, 555.32it/s] 73%|███████▎  | 7292/10000 [00:19<00:04, 544.78it/s] 73%|███████▎  | 7347/10000 [00:20<00:05, 525.14it/s] 74%|███████▍  | 7400/10000 [00:20<00:05, 488.34it/s] 75%|███████▍  | 7452/10000 [00:20<00:05, 493.85it/s] 75%|███████▌  | 7507/10000 [00:20<00:04, 502.24it/s] 76%|███████▌  | 7558/10000 [00:20<00:05, 484.31it/s] 76%|███████▌  | 7607/10000 [00:20<00:06, 375.72it/s] 76%|███████▋  | 7649/10000 [00:20<00:06, 380.53it/s] 77%|███████▋  | 7690/10000 [00:20<00:07, 323.24it/s] 77%|███████▋  | 7726/10000 [00:21<00:07, 323.35it/s] 78%|███████▊  | 7761/10000 [00:21<00:07, 318.24it/s] 78%|███████▊  | 7796/10000 [00:21<00:06, 316.98it/s] 78%|███████▊  | 7835/10000 [00:21<00:06, 333.20it/s] 79%|███████▉  | 7921/10000 [00:21<00:04, 464.98it/s] 80%|███████▉  | 7971/10000 [00:21<00:04, 471.57it/s] 80%|████████  | 8026/10000 [00:21<00:04, 489.34it/s] 81%|████████  | 8076/10000 [00:21<00:03, 482.64it/s] 81%|████████▏ | 8125/10000 [00:21<00:04, 451.64it/s] 82%|████████▏ | 8175/10000 [00:22<00:04, 453.50it/s] 82%|████████▏ | 8226/10000 [00:22<00:03, 456.99it/s] 83%|████████▎ | 8273/10000 [00:22<00:04, 401.65it/s] 83%|████████▎ | 8315/10000 [00:22<00:04, 367.28it/s] 84%|████████▎ | 8353/10000 [00:22<00:05, 320.95it/s] 84%|████████▍ | 8387/10000 [00:22<00:05, 321.56it/s] 84%|████████▍ | 8422/10000 [00:22<00:04, 320.60it/s] 85%|████████▍ | 8459/10000 [00:22<00:04, 326.52it/s] 85%|████████▌ | 8505/10000 [00:23<00:04, 352.92it/s] 85%|████████▌ | 8541/10000 [00:23<00:04, 338.08it/s] 86%|████████▌ | 8596/10000 [00:23<00:03, 380.33it/s] 87%|████████▋ | 8683/10000 [00:23<00:02, 503.52it/s] 88%|████████▊ | 8758/10000 [00:23<00:02, 558.43it/s] 88%|████████▊ | 8815/10000 [00:23<00:02, 550.49it/s] 89%|████████▉ | 8882/10000 [00:23<00:01, 578.76it/s] 90%|████████▉ | 8985/10000 [00:23<00:01, 701.92it/s] 91%|█████████ | 9057/10000 [00:24<00:01, 592.35it/s] 91%|█████████▏| 9125/10000 [00:24<00:01, 601.08it/s] 92%|█████████▏| 9188/10000 [00:24<00:01, 564.99it/s] 92%|█████████▏| 9247/10000 [00:24<00:01, 517.73it/s] 93%|█████████▎| 9301/10000 [00:24<00:01, 404.59it/s] 93%|█████████▎| 9346/10000 [00:24<00:01, 371.11it/s] 94%|█████████▍| 9387/10000 [00:24<00:01, 318.53it/s] 94%|█████████▍| 9425/10000 [00:25<00:01, 327.36it/s] 95%|█████████▍| 9461/10000 [00:25<00:01, 317.51it/s] 95%|█████████▍| 9495/10000 [00:25<00:01, 314.21it/s] 95%|█████████▌| 9528/10000 [00:25<00:01, 311.74it/s] 96%|█████████▌| 9574/10000 [00:25<00:01, 347.07it/s] 96%|█████████▌| 9617/10000 [00:25<00:01, 365.11it/s] 97%|█████████▋| 9655/10000 [00:25<00:00, 348.15it/s] 97%|█████████▋| 9691/10000 [00:25<00:00, 336.05it/s] 97%|█████████▋| 9736/10000 [00:25<00:00, 364.99it/s] 98%|█████████▊| 9774/10000 [00:26<00:00, 366.87it/s] 98%|█████████▊| 9812/10000 [00:26<00:00, 356.07it/s] 99%|█████████▊| 9871/10000 [00:26<00:00, 420.81it/s] 99%|█████████▉| 9931/10000 [00:26<00:00, 465.76it/s]100%|██████████| 10000/10000 [00:26<00:00, 378.54it/s]
test_neglected_p75 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p75
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p75.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.06s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.50it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.30it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.34it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.07it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.24it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.65it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.27it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.33it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p75_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p75_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p75_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p75_Holmes_probs.npy
{'Accuracy': 0.0203, 'Precision': 0.0225, 'Recall': 0.02, 'F1-score': 0.0175}
starting gen taf script for test_neglected_p76
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 75/10000 [00:00<00:14, 700.46it/s]  1%|▏         | 146/10000 [00:00<00:25, 379.03it/s]  2%|▏         | 192/10000 [00:00<00:30, 319.24it/s]  2%|▏         | 228/10000 [00:00<00:31, 307.53it/s]  3%|▎         | 261/10000 [00:00<00:33, 286.97it/s]  3%|▎         | 291/10000 [00:00<00:34, 281.53it/s]  3%|▎         | 320/10000 [00:01<00:39, 244.32it/s]  3%|▎         | 349/10000 [00:01<00:38, 248.67it/s]  4%|▍         | 376/10000 [00:01<00:38, 250.96it/s]  4%|▍         | 409/10000 [00:01<00:36, 265.09it/s]  4%|▍         | 440/10000 [00:01<00:35, 270.55it/s]  5%|▍         | 489/10000 [00:01<00:29, 319.64it/s]  5%|▌         | 528/10000 [00:01<00:28, 331.61it/s]  6%|▌         | 571/10000 [00:01<00:26, 352.95it/s]  6%|▌         | 608/10000 [00:01<00:26, 354.55it/s]  6%|▋         | 644/10000 [00:02<00:26, 353.66it/s]  7%|▋         | 691/10000 [00:02<00:24, 378.78it/s]  7%|▋         | 749/10000 [00:02<00:21, 426.00it/s]  8%|▊         | 792/10000 [00:02<00:21, 426.95it/s]  9%|▊         | 851/10000 [00:02<00:19, 471.13it/s]  9%|▉         | 899/10000 [00:02<00:22, 407.55it/s]  9%|▉         | 947/10000 [00:02<00:21, 417.01it/s] 10%|▉         | 990/10000 [00:02<00:21, 410.34it/s] 10%|█         | 1032/10000 [00:02<00:22, 405.03it/s] 11%|█         | 1074/10000 [00:03<00:26, 342.54it/s] 11%|█         | 1111/10000 [00:03<00:25, 346.21it/s] 12%|█▏        | 1150/10000 [00:03<00:24, 356.78it/s] 12%|█▏        | 1187/10000 [00:03<00:26, 337.15it/s] 12%|█▏        | 1248/10000 [00:03<00:21, 404.58it/s] 13%|█▎        | 1306/10000 [00:03<00:19, 445.82it/s] 14%|█▎        | 1362/10000 [00:03<00:18, 472.41it/s] 14%|█▍        | 1411/10000 [00:03<00:20, 411.56it/s] 15%|█▍        | 1455/10000 [00:04<00:23, 368.99it/s] 15%|█▍        | 1494/10000 [00:04<00:24, 341.60it/s] 15%|█▌        | 1530/10000 [00:04<00:31, 269.65it/s] 16%|█▌        | 1560/10000 [00:04<00:32, 260.75it/s] 16%|█▌        | 1588/10000 [00:04<00:35, 236.64it/s] 17%|█▋        | 1654/10000 [00:04<00:26, 311.71it/s] 17%|█▋        | 1727/10000 [00:04<00:20, 394.87it/s] 18%|█▊        | 1781/10000 [00:05<00:19, 429.35it/s] 19%|█▊        | 1862/10000 [00:05<00:15, 519.68it/s] 20%|█▉        | 1961/10000 [00:05<00:12, 644.19it/s] 20%|██        | 2038/10000 [00:05<00:11, 663.68it/s] 21%|██        | 2108/10000 [00:05<00:13, 575.44it/s] 22%|██▏       | 2170/10000 [00:05<00:15, 503.46it/s] 22%|██▏       | 2225/10000 [00:05<00:15, 498.67it/s] 23%|██▎       | 2278/10000 [00:06<00:18, 407.54it/s] 23%|██▎       | 2323/10000 [00:06<00:20, 382.76it/s] 24%|██▎       | 2366/10000 [00:06<00:19, 385.36it/s] 24%|██▍       | 2407/10000 [00:06<00:21, 346.77it/s] 25%|██▍       | 2479/10000 [00:06<00:17, 426.01it/s] 25%|██▌       | 2525/10000 [00:06<00:18, 401.74it/s] 26%|██▌       | 2580/10000 [00:06<00:17, 418.01it/s] 26%|██▌       | 2624/10000 [00:06<00:20, 358.51it/s] 27%|██▋       | 2663/10000 [00:07<00:20, 359.82it/s] 27%|██▋       | 2701/10000 [00:07<00:25, 281.63it/s] 27%|██▋       | 2733/10000 [00:07<00:29, 244.74it/s] 28%|██▊       | 2761/10000 [00:07<00:33, 213.48it/s] 28%|██▊       | 2791/10000 [00:07<00:31, 228.15it/s] 29%|██▊       | 2858/10000 [00:07<00:22, 320.47it/s] 29%|██▉       | 2904/10000 [00:07<00:20, 349.76it/s] 30%|██▉       | 2962/10000 [00:08<00:17, 406.87it/s] 30%|███       | 3010/10000 [00:08<00:17, 410.88it/s] 31%|███       | 3054/10000 [00:08<00:18, 372.26it/s] 31%|███       | 3094/10000 [00:08<00:20, 328.88it/s] 31%|███▏      | 3130/10000 [00:08<00:21, 321.13it/s] 32%|███▏      | 3169/10000 [00:08<00:20, 329.30it/s] 32%|███▏      | 3224/10000 [00:08<00:17, 378.36it/s] 33%|███▎      | 3292/10000 [00:08<00:14, 457.31it/s] 34%|███▎      | 3368/10000 [00:09<00:12, 535.23it/s] 34%|███▍      | 3432/10000 [00:09<00:12, 543.14it/s] 35%|███▍      | 3488/10000 [00:09<00:13, 472.87it/s] 35%|███▌      | 3538/10000 [00:09<00:13, 464.21it/s] 36%|███▌      | 3597/10000 [00:09<00:13, 486.50it/s] 37%|███▋      | 3676/10000 [00:09<00:11, 563.56it/s] 37%|███▋      | 3735/10000 [00:09<00:11, 538.27it/s] 38%|███▊      | 3791/10000 [00:09<00:11, 521.13it/s] 38%|███▊      | 3845/10000 [00:10<00:13, 462.77it/s] 39%|███▉      | 3893/10000 [00:10<00:13, 463.89it/s] 39%|███▉      | 3941/10000 [00:10<00:14, 413.68it/s] 40%|███▉      | 3984/10000 [00:10<00:14, 411.73it/s] 41%|████      | 4063/10000 [00:10<00:11, 507.48it/s] 41%|████▏     | 4133/10000 [00:10<00:10, 552.93it/s] 42%|████▏     | 4194/10000 [00:10<00:10, 565.21it/s] 43%|████▎     | 4260/10000 [00:10<00:09, 587.75it/s] 43%|████▎     | 4320/10000 [00:10<00:09, 571.69it/s] 44%|████▍     | 4378/10000 [00:11<00:10, 540.03it/s] 44%|████▍     | 4433/10000 [00:11<00:10, 517.23it/s] 45%|████▍     | 4486/10000 [00:11<00:14, 393.55it/s] 45%|████▌     | 4530/10000 [00:11<00:14, 368.75it/s] 46%|████▌     | 4571/10000 [00:11<00:17, 313.06it/s] 46%|████▌     | 4615/10000 [00:11<00:16, 332.46it/s] 47%|████▋     | 4652/10000 [00:11<00:16, 330.97it/s] 47%|████▋     | 4688/10000 [00:12<00:16, 312.76it/s] 47%|████▋     | 4727/10000 [00:12<00:16, 322.45it/s] 48%|████▊     | 4774/10000 [00:12<00:15, 344.84it/s] 48%|████▊     | 4810/10000 [00:12<00:17, 294.73it/s] 48%|████▊     | 4842/10000 [00:12<00:17, 289.09it/s] 49%|████▉     | 4885/10000 [00:12<00:16, 318.33it/s] 49%|████▉     | 4919/10000 [00:12<00:17, 285.96it/s] 50%|████▉     | 4950/10000 [00:12<00:17, 286.85it/s] 50%|████▉     | 4980/10000 [00:13<00:20, 240.21it/s] 50%|█████     | 5029/10000 [00:13<00:16, 296.10it/s] 51%|█████     | 5072/10000 [00:13<00:14, 328.89it/s] 51%|█████▏    | 5145/10000 [00:13<00:11, 425.66it/s] 52%|█████▏    | 5191/10000 [00:13<00:11, 418.01it/s] 52%|█████▏    | 5235/10000 [00:13<00:12, 389.67it/s] 53%|█████▎    | 5276/10000 [00:13<00:14, 325.48it/s] 53%|█████▎    | 5312/10000 [00:14<00:17, 274.62it/s] 53%|█████▎    | 5343/10000 [00:14<00:18, 251.27it/s] 54%|█████▎    | 5371/10000 [00:14<00:19, 238.81it/s] 54%|█████▍    | 5404/10000 [00:14<00:18, 252.50it/s] 55%|█████▍    | 5453/10000 [00:14<00:15, 300.82it/s] 55%|█████▍    | 5496/10000 [00:14<00:13, 323.99it/s] 56%|█████▌    | 5550/10000 [00:14<00:11, 375.81it/s] 56%|█████▌    | 5592/10000 [00:14<00:11, 381.98it/s] 56%|█████▋    | 5647/10000 [00:14<00:10, 423.44it/s] 57%|█████▋    | 5706/10000 [00:15<00:09, 469.77it/s] 58%|█████▊    | 5766/10000 [00:15<00:08, 506.53it/s] 58%|█████▊    | 5818/10000 [00:15<00:08, 509.00it/s] 59%|█████▊    | 5870/10000 [00:15<00:09, 426.94it/s] 59%|█████▉    | 5916/10000 [00:15<00:11, 362.54it/s] 60%|█████▉    | 5956/10000 [00:15<00:11, 341.96it/s] 60%|█████▉    | 5994/10000 [00:15<00:11, 347.21it/s] 61%|██████    | 6071/10000 [00:15<00:09, 433.55it/s] 61%|██████    | 6121/10000 [00:16<00:08, 443.13it/s] 62%|██████▏   | 6167/10000 [00:16<00:08, 428.17it/s] 62%|██████▏   | 6211/10000 [00:16<00:09, 405.92it/s] 63%|██████▎   | 6253/10000 [00:16<00:10, 366.16it/s] 63%|██████▎   | 6291/10000 [00:16<00:11, 335.83it/s] 63%|██████▎   | 6326/10000 [00:16<00:11, 318.18it/s] 64%|██████▎   | 6361/10000 [00:16<00:11, 318.42it/s] 64%|██████▍   | 6394/10000 [00:16<00:12, 294.97it/s] 64%|██████▍   | 6430/10000 [00:17<00:11, 299.03it/s] 65%|██████▍   | 6461/10000 [00:17<00:13, 266.94it/s] 65%|██████▍   | 6489/10000 [00:17<00:13, 263.10it/s] 65%|██████▌   | 6539/10000 [00:17<00:10, 317.09it/s] 66%|██████▌   | 6580/10000 [00:17<00:10, 341.38it/s] 66%|██████▌   | 6616/10000 [00:17<00:10, 309.68it/s] 66%|██████▋   | 6649/10000 [00:17<00:11, 302.29it/s] 67%|██████▋   | 6699/10000 [00:17<00:09, 344.68it/s] 68%|██████▊   | 6753/10000 [00:18<00:08, 393.73it/s] 68%|██████▊   | 6794/10000 [00:18<00:08, 371.15it/s] 69%|██████▊   | 6858/10000 [00:18<00:07, 438.96it/s] 69%|██████▉   | 6922/10000 [00:18<00:06, 486.72it/s] 70%|███████   | 7003/10000 [00:18<00:05, 576.02it/s] 71%|███████   | 7063/10000 [00:18<00:05, 528.86it/s] 71%|███████   | 7118/10000 [00:18<00:05, 481.78it/s] 72%|███████▏  | 7168/10000 [00:18<00:05, 472.74it/s] 72%|███████▏  | 7235/10000 [00:18<00:05, 518.05it/s] 73%|███████▎  | 7291/10000 [00:19<00:05, 521.57it/s] 74%|███████▎  | 7355/10000 [00:19<00:04, 542.62it/s] 74%|███████▍  | 7415/10000 [00:19<00:04, 556.86it/s] 75%|███████▍  | 7479/10000 [00:19<00:04, 559.33it/s] 75%|███████▌  | 7536/10000 [00:19<00:04, 543.68it/s] 76%|███████▌  | 7592/10000 [00:19<00:04, 541.79it/s] 76%|███████▋  | 7647/10000 [00:19<00:04, 480.56it/s] 77%|███████▋  | 7697/10000 [00:19<00:05, 410.92it/s] 77%|███████▋  | 7741/10000 [00:20<00:05, 412.38it/s] 78%|███████▊  | 7784/10000 [00:20<00:05, 382.05it/s] 78%|███████▊  | 7833/10000 [00:20<00:05, 408.84it/s] 79%|███████▉  | 7881/10000 [00:20<00:05, 422.78it/s] 79%|███████▉  | 7941/10000 [00:20<00:04, 465.12it/s] 80%|███████▉  | 7989/10000 [00:20<00:04, 463.66it/s] 81%|████████  | 8056/10000 [00:20<00:03, 508.90it/s] 81%|████████  | 8114/10000 [00:20<00:03, 523.34it/s] 82%|████████▏ | 8174/10000 [00:20<00:03, 536.33it/s] 82%|████████▏ | 8237/10000 [00:21<00:03, 544.42it/s] 83%|████████▎ | 8292/10000 [00:21<00:03, 427.60it/s] 83%|████████▎ | 8339/10000 [00:21<00:03, 423.62it/s] 84%|████████▍ | 8384/10000 [00:21<00:04, 363.78it/s] 84%|████████▍ | 8426/10000 [00:21<00:04, 376.07it/s] 85%|████████▍ | 8466/10000 [00:21<00:04, 381.91it/s] 85%|████████▌ | 8516/10000 [00:21<00:03, 408.37it/s] 86%|████████▌ | 8574/10000 [00:21<00:03, 448.58it/s] 86%|████████▋ | 8632/10000 [00:22<00:02, 484.14it/s] 87%|████████▋ | 8691/10000 [00:22<00:02, 508.32it/s] 88%|████████▊ | 8781/10000 [00:22<00:01, 615.20it/s] 88%|████████▊ | 8844/10000 [00:22<00:01, 618.57it/s] 89%|████████▉ | 8909/10000 [00:22<00:01, 627.71it/s] 90%|████████▉ | 8973/10000 [00:22<00:01, 626.21it/s] 90%|█████████ | 9043/10000 [00:22<00:01, 632.35it/s] 91%|█████████ | 9107/10000 [00:22<00:01, 588.31it/s] 92%|█████████▏| 9173/10000 [00:22<00:01, 595.10it/s] 92%|█████████▏| 9234/10000 [00:23<00:01, 513.13it/s] 93%|█████████▎| 9288/10000 [00:23<00:01, 438.51it/s] 93%|█████████▎| 9335/10000 [00:23<00:01, 367.78it/s] 94%|█████████▍| 9376/10000 [00:23<00:01, 355.44it/s] 94%|█████████▍| 9414/10000 [00:23<00:01, 334.47it/s] 95%|█████████▍| 9453/10000 [00:23<00:01, 337.94it/s] 95%|█████████▍| 9496/10000 [00:23<00:01, 357.67it/s] 95%|█████████▌| 9533/10000 [00:23<00:01, 353.84it/s] 96%|█████████▌| 9570/10000 [00:24<00:01, 329.19it/s] 96%|█████████▌| 9617/10000 [00:24<00:01, 364.42it/s] 97%|█████████▋| 9655/10000 [00:24<00:00, 365.68it/s] 97%|█████████▋| 9693/10000 [00:24<00:00, 350.82it/s] 97%|█████████▋| 9743/10000 [00:24<00:00, 390.91it/s] 98%|█████████▊| 9783/10000 [00:24<00:00, 388.61it/s] 98%|█████████▊| 9837/10000 [00:24<00:00, 428.23it/s] 99%|█████████▉| 9881/10000 [00:24<00:00, 424.06it/s] 99%|█████████▉| 9937/10000 [00:24<00:00, 459.39it/s]100%|██████████| 10000/10000 [00:24<00:00, 400.03it/s]
test_neglected_p76 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p76
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p76.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:33,  1.17it/s]evaluating model with Holmes:   5%|▌         | 2/40 [00:00<00:16,  2.35it/s]evaluating model with Holmes:  18%|█▊        | 7/40 [00:01<00:03, 10.07it/s]evaluating model with Holmes:  30%|███       | 12/40 [00:01<00:01, 17.30it/s]evaluating model with Holmes:  42%|████▎     | 17/40 [00:01<00:00, 24.00it/s]evaluating model with Holmes:  55%|█████▌    | 22/40 [00:01<00:00, 29.77it/s]evaluating model with Holmes:  68%|██████▊   | 27/40 [00:01<00:00, 34.16it/s]evaluating model with Holmes:  80%|████████  | 32/40 [00:01<00:00, 37.64it/s]evaluating model with Holmes:  92%|█████████▎| 37/40 [00:01<00:00, 40.22it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.99it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p76_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p76_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p76_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p76_Holmes_probs.npy
{'Accuracy': 0.0204, 'Precision': 0.0226, 'Recall': 0.0201, 'F1-score': 0.0175}
starting gen taf script for test_neglected_p77
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 88/10000 [00:00<00:11, 873.30it/s]  2%|▏         | 176/10000 [00:00<00:34, 284.07it/s]  2%|▏         | 224/10000 [00:00<00:34, 287.37it/s]  3%|▎         | 264/10000 [00:00<00:37, 256.93it/s]  3%|▎         | 296/10000 [00:01<00:39, 247.87it/s]  3%|▎         | 325/10000 [00:01<00:38, 253.50it/s]  4%|▎         | 353/10000 [00:01<00:38, 250.66it/s]  4%|▍         | 380/10000 [00:01<00:38, 247.25it/s]  4%|▍         | 406/10000 [00:01<00:39, 243.98it/s]  4%|▍         | 447/10000 [00:01<00:33, 281.36it/s]  5%|▍         | 482/10000 [00:01<00:32, 295.81it/s]  5%|▌         | 520/10000 [00:01<00:30, 312.67it/s]  6%|▌         | 554/10000 [00:01<00:30, 310.22it/s]  6%|▌         | 593/10000 [00:02<00:29, 324.14it/s]  6%|▋         | 626/10000 [00:02<00:28, 325.03it/s]  7%|▋         | 662/10000 [00:02<00:27, 334.77it/s]  7%|▋         | 728/10000 [00:02<00:22, 421.33it/s]  8%|▊         | 815/10000 [00:02<00:16, 550.18it/s]  9%|▊         | 871/10000 [00:02<00:18, 485.26it/s]  9%|▉         | 922/10000 [00:02<00:21, 432.10it/s] 10%|▉         | 968/10000 [00:02<00:20, 438.33it/s] 10%|█         | 1014/10000 [00:02<00:21, 421.27it/s] 11%|█         | 1058/10000 [00:03<00:23, 382.94it/s] 11%|█         | 1098/10000 [00:03<00:23, 377.54it/s] 11%|█▏        | 1137/10000 [00:03<00:26, 330.02it/s] 12%|█▏        | 1187/10000 [00:03<00:23, 368.26it/s] 12%|█▏        | 1241/10000 [00:03<00:21, 411.64it/s] 13%|█▎        | 1288/10000 [00:03<00:20, 426.82it/s] 13%|█▎        | 1347/10000 [00:03<00:18, 470.26it/s] 14%|█▍        | 1401/10000 [00:03<00:18, 469.36it/s] 14%|█▍        | 1449/10000 [00:04<00:23, 359.29it/s] 15%|█▍        | 1490/10000 [00:04<00:27, 305.32it/s] 15%|█▌        | 1525/10000 [00:04<00:32, 257.81it/s] 16%|█▌        | 1555/10000 [00:04<00:35, 240.93it/s] 16%|█▌        | 1582/10000 [00:04<00:36, 230.43it/s] 16%|█▋        | 1640/10000 [00:04<00:27, 305.64it/s] 17%|█▋        | 1706/10000 [00:05<00:21, 388.95it/s] 18%|█▊        | 1762/10000 [00:05<00:19, 426.30it/s] 19%|█▊        | 1855/10000 [00:05<00:14, 555.22it/s] 20%|█▉        | 1961/10000 [00:05<00:11, 691.92it/s] 20%|██        | 2035/10000 [00:05<00:11, 690.27it/s] 21%|██        | 2108/10000 [00:05<00:13, 593.80it/s] 22%|██▏       | 2172/10000 [00:05<00:14, 547.42it/s] 22%|██▏       | 2231/10000 [00:05<00:15, 505.55it/s] 23%|██▎       | 2285/10000 [00:06<00:18, 422.10it/s] 23%|██▎       | 2331/10000 [00:06<00:21, 364.65it/s] 24%|██▎       | 2372/10000 [00:06<00:20, 373.60it/s] 24%|██▍       | 2412/10000 [00:06<00:22, 341.28it/s] 25%|██▍       | 2466/10000 [00:06<00:19, 383.67it/s] 25%|██▌       | 2519/10000 [00:06<00:18, 414.79it/s] 26%|██▌       | 2585/10000 [00:06<00:15, 473.24it/s] 26%|██▋       | 2635/10000 [00:07<00:20, 361.70it/s] 27%|██▋       | 2677/10000 [00:07<00:25, 286.97it/s] 27%|██▋       | 2712/10000 [00:07<00:28, 257.15it/s] 27%|██▋       | 2742/10000 [00:07<00:29, 244.81it/s] 28%|██▊       | 2770/10000 [00:07<00:30, 233.39it/s] 28%|██▊       | 2796/10000 [00:07<00:32, 221.76it/s] 28%|██▊       | 2836/10000 [00:07<00:27, 259.81it/s] 29%|██▉       | 2885/10000 [00:08<00:22, 313.91it/s] 29%|██▉       | 2940/10000 [00:08<00:19, 358.49it/s] 30%|██▉       | 2996/10000 [00:08<00:17, 400.56it/s] 30%|███       | 3039/10000 [00:08<00:17, 403.21it/s] 31%|███       | 3081/10000 [00:08<00:20, 341.63it/s] 31%|███       | 3124/10000 [00:08<00:18, 363.06it/s] 32%|███▏      | 3163/10000 [00:08<00:20, 332.17it/s] 32%|███▏      | 3204/10000 [00:08<00:19, 348.09it/s] 33%|███▎      | 3263/10000 [00:09<00:16, 410.46it/s] 33%|███▎      | 3348/10000 [00:09<00:12, 526.76it/s] 34%|███▍      | 3417/10000 [00:09<00:11, 564.39it/s] 35%|███▍      | 3476/10000 [00:09<00:12, 536.63it/s] 35%|███▌      | 3532/10000 [00:09<00:12, 517.97it/s] 36%|███▌      | 3585/10000 [00:09<00:14, 455.23it/s] 37%|███▋      | 3667/10000 [00:09<00:11, 539.64it/s] 37%|███▋      | 3724/10000 [00:09<00:11, 543.95it/s] 38%|███▊      | 3794/10000 [00:09<00:10, 585.04it/s] 39%|███▊      | 3855/10000 [00:10<00:11, 526.03it/s] 39%|███▉      | 3910/10000 [00:10<00:12, 498.50it/s] 40%|███▉      | 3962/10000 [00:10<00:12, 473.65it/s] 40%|████      | 4019/10000 [00:10<00:12, 494.83it/s] 41%|████      | 4081/10000 [00:10<00:11, 526.95it/s] 42%|████▏     | 4176/10000 [00:10<00:09, 633.89it/s] 43%|████▎     | 4257/10000 [00:10<00:08, 660.04it/s] 43%|████▎     | 4324/10000 [00:10<00:09, 629.74it/s] 44%|████▍     | 4401/10000 [00:10<00:09, 614.63it/s] 45%|████▍     | 4464/10000 [00:11<00:11, 501.37it/s] 45%|████▌     | 4518/10000 [00:11<00:13, 398.35it/s] 46%|████▌     | 4563/10000 [00:11<00:14, 369.36it/s] 46%|████▌     | 4604/10000 [00:11<00:15, 349.92it/s] 46%|████▋     | 4642/10000 [00:11<00:16, 328.18it/s] 47%|████▋     | 4677/10000 [00:11<00:16, 317.09it/s] 47%|████▋     | 4710/10000 [00:12<00:16, 316.04it/s] 47%|████▋     | 4743/10000 [00:12<00:16, 315.07it/s] 48%|████▊     | 4777/10000 [00:12<00:16, 321.50it/s] 48%|████▊     | 4812/10000 [00:12<00:16, 323.95it/s] 48%|████▊     | 4845/10000 [00:12<00:17, 292.78it/s] 49%|████▉     | 4875/10000 [00:12<00:17, 289.27it/s] 49%|████▉     | 4905/10000 [00:12<00:18, 268.23it/s] 49%|████▉     | 4933/10000 [00:12<00:20, 251.90it/s] 50%|████▉     | 4964/10000 [00:13<00:19, 254.84it/s] 50%|████▉     | 4994/10000 [00:13<00:18, 266.10it/s] 50%|█████     | 5035/10000 [00:13<00:16, 298.56it/s] 51%|█████     | 5082/10000 [00:13<00:14, 340.27it/s] 52%|█████▏    | 5153/10000 [00:13<00:11, 436.36it/s] 52%|█████▏    | 5200/10000 [00:13<00:11, 433.51it/s] 52%|█████▏    | 5244/10000 [00:13<00:13, 351.38it/s] 53%|█████▎    | 5282/10000 [00:13<00:14, 328.79it/s] 53%|█████▎    | 5317/10000 [00:14<00:17, 269.73it/s] 53%|█████▎    | 5347/10000 [00:14<00:18, 249.51it/s] 54%|█████▎    | 5374/10000 [00:14<00:18, 246.77it/s] 54%|█████▍    | 5426/10000 [00:14<00:14, 310.70it/s] 55%|█████▍    | 5466/10000 [00:14<00:13, 326.19it/s] 55%|█████▌    | 5508/10000 [00:14<00:13, 335.96it/s] 56%|█████▌    | 5571/10000 [00:14<00:10, 403.88it/s] 56%|█████▌    | 5620/10000 [00:14<00:10, 425.76it/s] 57%|█████▋    | 5673/10000 [00:14<00:09, 452.69it/s] 57%|█████▋    | 5733/10000 [00:15<00:08, 494.19it/s] 58%|█████▊    | 5796/10000 [00:15<00:07, 528.75it/s] 58%|█████▊    | 5850/10000 [00:15<00:09, 433.75it/s] 59%|█████▉    | 5897/10000 [00:15<00:09, 422.26it/s] 59%|█████▉    | 5942/10000 [00:15<00:11, 361.59it/s] 60%|█████▉    | 5981/10000 [00:15<00:11, 350.80it/s] 60%|██████    | 6029/10000 [00:15<00:10, 378.43it/s] 61%|██████    | 6087/10000 [00:15<00:09, 425.67it/s] 61%|██████▏   | 6138/10000 [00:16<00:08, 444.27it/s] 62%|██████▏   | 6194/10000 [00:16<00:08, 464.33it/s] 62%|██████▏   | 6242/10000 [00:16<00:08, 418.65it/s] 63%|██████▎   | 6286/10000 [00:16<00:10, 371.30it/s] 63%|██████▎   | 6325/10000 [00:16<00:12, 297.20it/s] 64%|██████▎   | 6361/10000 [00:16<00:12, 302.28it/s] 64%|██████▍   | 6394/10000 [00:16<00:13, 271.99it/s] 64%|██████▍   | 6424/10000 [00:17<00:13, 257.81it/s] 65%|██████▍   | 6451/10000 [00:17<00:14, 252.16it/s] 65%|██████▍   | 6492/10000 [00:17<00:13, 266.50it/s] 65%|██████▌   | 6534/10000 [00:17<00:11, 295.26it/s] 66%|██████▌   | 6565/10000 [00:17<00:12, 284.50it/s] 66%|██████▌   | 6605/10000 [00:17<00:10, 313.00it/s] 66%|██████▋   | 6638/10000 [00:17<00:11, 293.02it/s] 67%|██████▋   | 6686/10000 [00:17<00:10, 329.00it/s] 67%|██████▋   | 6720/10000 [00:18<00:10, 327.82it/s] 68%|██████▊   | 6754/10000 [00:18<00:10, 316.51it/s] 68%|██████▊   | 6819/10000 [00:18<00:07, 405.25it/s] 69%|██████▉   | 6882/10000 [00:18<00:06, 460.48it/s] 69%|██████▉   | 6944/10000 [00:18<00:06, 501.11it/s] 70%|███████   | 7005/10000 [00:18<00:05, 505.64it/s] 71%|███████   | 7083/10000 [00:18<00:05, 573.82it/s] 71%|███████▏  | 7142/10000 [00:18<00:05, 515.00it/s] 72%|███████▏  | 7198/10000 [00:18<00:05, 518.11it/s] 73%|███████▎  | 7266/10000 [00:19<00:04, 554.28it/s] 73%|███████▎  | 7348/10000 [00:19<00:04, 617.42it/s] 74%|███████▍  | 7411/10000 [00:19<00:04, 601.36it/s] 75%|███████▍  | 7472/10000 [00:19<00:04, 562.81it/s] 75%|███████▌  | 7530/10000 [00:19<00:05, 479.47it/s] 76%|███████▌  | 7585/10000 [00:19<00:04, 491.76it/s] 76%|███████▋  | 7645/10000 [00:19<00:04, 518.95it/s] 77%|███████▋  | 7699/10000 [00:19<00:05, 419.67it/s] 77%|███████▋  | 7745/10000 [00:20<00:05, 422.95it/s] 78%|███████▊  | 7791/10000 [00:20<00:06, 366.22it/s] 78%|███████▊  | 7850/10000 [00:20<00:05, 417.36it/s] 79%|███████▉  | 7906/10000 [00:20<00:04, 443.32it/s] 80%|███████▉  | 7963/10000 [00:20<00:04, 474.58it/s] 80%|████████  | 8013/10000 [00:20<00:04, 470.83it/s] 81%|████████  | 8081/10000 [00:20<00:03, 519.00it/s] 81%|████████▏ | 8146/10000 [00:20<00:03, 552.06it/s] 82%|████████▏ | 8207/10000 [00:20<00:03, 544.19it/s] 83%|████████▎ | 8263/10000 [00:21<00:04, 409.18it/s] 83%|████████▎ | 8310/10000 [00:21<00:04, 416.12it/s] 84%|████████▎ | 8356/10000 [00:21<00:04, 400.31it/s] 84%|████████▍ | 8399/10000 [00:21<00:04, 350.83it/s] 85%|████████▍ | 8453/10000 [00:21<00:03, 393.72it/s] 85%|████████▌ | 8510/10000 [00:21<00:03, 424.60it/s] 86%|████████▌ | 8555/10000 [00:21<00:03, 424.41it/s] 86%|████████▌ | 8600/10000 [00:22<00:03, 418.52it/s] 86%|████████▋ | 8647/10000 [00:22<00:03, 425.08it/s] 87%|████████▋ | 8730/10000 [00:22<00:02, 535.98it/s] 88%|████████▊ | 8798/10000 [00:22<00:02, 576.18it/s] 89%|████████▊ | 8858/10000 [00:22<00:01, 577.23it/s] 89%|████████▉ | 8935/10000 [00:22<00:01, 624.13it/s] 90%|████████▉ | 8999/10000 [00:22<00:01, 619.62it/s] 91%|█████████ | 9062/10000 [00:22<00:01, 564.96it/s] 91%|█████████▏| 9144/10000 [00:22<00:01, 616.91it/s] 92%|█████████▏| 9207/10000 [00:23<00:01, 509.71it/s] 93%|█████████▎| 9262/10000 [00:23<00:01, 445.53it/s] 93%|█████████▎| 9310/10000 [00:23<00:01, 403.26it/s] 94%|█████████▎| 9353/10000 [00:23<00:01, 365.37it/s] 94%|█████████▍| 9392/10000 [00:23<00:01, 335.29it/s] 94%|█████████▍| 9427/10000 [00:23<00:01, 314.54it/s] 95%|█████████▍| 9476/10000 [00:23<00:01, 354.75it/s] 95%|█████████▌| 9514/10000 [00:24<00:01, 337.05it/s] 96%|█████████▌| 9559/10000 [00:24<00:01, 357.52it/s] 96%|█████████▌| 9596/10000 [00:24<00:01, 356.12it/s] 96%|█████████▋| 9633/10000 [00:24<00:01, 312.98it/s] 97%|█████████▋| 9691/10000 [00:24<00:00, 355.12it/s] 97%|█████████▋| 9742/10000 [00:24<00:00, 391.96it/s] 98%|█████████▊| 9783/10000 [00:24<00:00, 374.21it/s] 98%|█████████▊| 9849/10000 [00:24<00:00, 440.85it/s] 99%|█████████▉| 9915/10000 [00:24<00:00, 494.78it/s]100%|██████████| 10000/10000 [00:25<00:00, 399.26it/s]
test_neglected_p77 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p77
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p77.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:45,  1.17s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.10it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.02it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 17.07it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 22.98it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 28.18it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 32.76it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 36.55it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 39.26it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 19.64it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p77_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p77_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p77_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p77_Holmes_probs.npy
{'Accuracy': 0.0197, 'Precision': 0.0216, 'Recall': 0.0194, 'F1-score': 0.0171}
starting gen taf script for test_neglected_p78
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 75/10000 [00:00<00:15, 636.06it/s]  1%|▏         | 139/10000 [00:00<00:29, 331.95it/s]  2%|▏         | 180/10000 [00:00<00:33, 296.76it/s]  2%|▏         | 214/10000 [00:00<00:33, 293.75it/s]  2%|▏         | 246/10000 [00:00<00:34, 283.86it/s]  3%|▎         | 276/10000 [00:00<00:35, 275.29it/s]  3%|▎         | 309/10000 [00:01<00:33, 285.96it/s]  3%|▎         | 342/10000 [00:01<00:32, 295.56it/s]  4%|▎         | 374/10000 [00:01<00:32, 300.80it/s]  4%|▍         | 405/10000 [00:01<00:35, 271.34it/s]  4%|▍         | 436/10000 [00:01<00:34, 279.71it/s]  5%|▍         | 480/10000 [00:01<00:29, 320.08it/s]  5%|▌         | 522/10000 [00:01<00:28, 332.25it/s]  6%|▌         | 559/10000 [00:01<00:27, 338.06it/s]  6%|▌         | 597/10000 [00:01<00:27, 347.35it/s]  7%|▋         | 653/10000 [00:02<00:23, 396.46it/s]  7%|▋         | 693/10000 [00:02<00:26, 354.91it/s]  7%|▋         | 737/10000 [00:02<00:24, 373.80it/s]  8%|▊         | 802/10000 [00:02<00:20, 447.09it/s]  8%|▊         | 848/10000 [00:02<00:21, 426.82it/s]  9%|▉         | 892/10000 [00:02<00:21, 414.68it/s]  9%|▉         | 935/10000 [00:02<00:23, 389.01it/s] 10%|▉         | 987/10000 [00:02<00:22, 409.25it/s] 10%|█         | 1029/10000 [00:02<00:22, 398.20it/s] 11%|█         | 1070/10000 [00:03<00:23, 385.50it/s] 11%|█         | 1109/10000 [00:03<00:26, 341.20it/s] 11%|█▏        | 1148/10000 [00:03<00:25, 353.25it/s] 12%|█▏        | 1186/10000 [00:03<00:24, 357.43it/s] 12%|█▏        | 1227/10000 [00:03<00:23, 371.79it/s] 13%|█▎        | 1279/10000 [00:03<00:21, 412.01it/s] 13%|█▎        | 1345/10000 [00:03<00:18, 480.05it/s] 14%|█▍        | 1399/10000 [00:03<00:18, 475.74it/s] 14%|█▍        | 1448/10000 [00:04<00:22, 381.38it/s] 15%|█▍        | 1490/10000 [00:04<00:27, 315.09it/s] 15%|█▌        | 1526/10000 [00:04<00:30, 279.63it/s] 16%|█▌        | 1557/10000 [00:04<00:33, 251.55it/s] 16%|█▌        | 1585/10000 [00:04<00:34, 244.20it/s] 16%|█▌        | 1622/10000 [00:04<00:30, 272.01it/s] 17%|█▋        | 1663/10000 [00:04<00:27, 304.40it/s] 17%|█▋        | 1721/10000 [00:04<00:22, 373.64it/s] 18%|█▊        | 1790/10000 [00:05<00:18, 452.22it/s] 19%|█▊        | 1863/10000 [00:05<00:15, 527.08it/s] 20%|█▉        | 1963/10000 [00:05<00:12, 658.72it/s] 20%|██        | 2032/10000 [00:05<00:12, 662.25it/s] 21%|██        | 2101/10000 [00:05<00:13, 582.13it/s] 22%|██▏       | 2163/10000 [00:05<00:15, 500.36it/s] 22%|██▏       | 2226/10000 [00:05<00:14, 520.94it/s] 23%|██▎       | 2282/10000 [00:06<00:19, 391.50it/s] 23%|██▎       | 2328/10000 [00:06<00:19, 401.84it/s] 24%|██▎       | 2374/10000 [00:06<00:21, 352.59it/s] 24%|██▍       | 2414/10000 [00:06<00:21, 357.17it/s] 25%|██▍       | 2468/10000 [00:06<00:19, 392.35it/s] 25%|██▌       | 2511/10000 [00:06<00:20, 370.53it/s] 26%|██▌       | 2551/10000 [00:06<00:19, 376.73it/s] 26%|██▌       | 2602/10000 [00:06<00:18, 410.57it/s] 26%|██▋       | 2645/10000 [00:07<00:24, 294.66it/s] 27%|██▋       | 2680/10000 [00:07<00:27, 271.05it/s] 27%|██▋       | 2711/10000 [00:07<00:28, 252.00it/s] 27%|██▋       | 2739/10000 [00:07<00:29, 243.52it/s] 28%|██▊       | 2766/10000 [00:07<00:36, 200.62it/s] 28%|██▊       | 2801/10000 [00:07<00:31, 230.23it/s] 28%|██▊       | 2846/10000 [00:08<00:26, 274.98it/s] 29%|██▉       | 2903/10000 [00:08<00:21, 336.00it/s] 30%|██▉       | 2955/10000 [00:08<00:18, 379.21it/s] 30%|███       | 3006/10000 [00:08<00:17, 409.49it/s] 30%|███       | 3050/10000 [00:08<00:19, 348.04it/s] 31%|███       | 3097/10000 [00:08<00:19, 361.84it/s] 31%|███▏      | 3136/10000 [00:08<00:19, 354.54it/s] 32%|███▏      | 3173/10000 [00:08<00:20, 334.18it/s] 32%|███▏      | 3216/10000 [00:08<00:19, 356.21it/s] 33%|███▎      | 3269/10000 [00:09<00:16, 397.36it/s] 34%|███▎      | 3363/10000 [00:09<00:12, 537.57it/s] 34%|███▍      | 3419/10000 [00:09<00:12, 542.55it/s] 35%|███▍      | 3483/10000 [00:09<00:11, 563.78it/s] 35%|███▌      | 3541/10000 [00:09<00:12, 518.91it/s] 36%|███▌      | 3597/10000 [00:09<00:12, 518.26it/s] 36%|███▋      | 3650/10000 [00:09<00:12, 499.51it/s] 37%|███▋      | 3703/10000 [00:09<00:12, 497.02it/s] 38%|███▊      | 3762/10000 [00:09<00:11, 522.37it/s] 38%|███▊      | 3816/10000 [00:10<00:11, 519.76it/s] 39%|███▊      | 3869/10000 [00:10<00:13, 470.62it/s] 39%|███▉      | 3918/10000 [00:10<00:13, 462.36it/s] 40%|███▉      | 3965/10000 [00:10<00:13, 446.00it/s] 40%|████      | 4011/10000 [00:10<00:14, 414.52it/s] 41%|████      | 4067/10000 [00:10<00:13, 447.16it/s] 41%|████      | 4115/10000 [00:10<00:12, 453.16it/s] 42%|████▏     | 4185/10000 [00:10<00:11, 511.77it/s] 43%|████▎     | 4269/10000 [00:10<00:09, 595.84it/s] 43%|████▎     | 4330/10000 [00:11<00:10, 554.63it/s] 44%|████▍     | 4393/10000 [00:11<00:09, 570.36it/s] 45%|████▍     | 4451/10000 [00:11<00:10, 512.53it/s] 45%|████▌     | 4504/10000 [00:11<00:13, 395.07it/s] 45%|████▌     | 4549/10000 [00:11<00:16, 333.24it/s] 46%|████▌     | 4587/10000 [00:11<00:16, 319.00it/s] 46%|████▌     | 4622/10000 [00:12<00:16, 323.25it/s] 47%|████▋     | 4657/10000 [00:12<00:16, 326.56it/s] 47%|████▋     | 4692/10000 [00:12<00:16, 313.46it/s] 47%|████▋     | 4726/10000 [00:12<00:16, 310.67it/s] 48%|████▊     | 4758/10000 [00:12<00:17, 305.72it/s] 48%|████▊     | 4799/10000 [00:12<00:15, 328.35it/s] 48%|████▊     | 4833/10000 [00:12<00:18, 280.90it/s] 49%|████▊     | 4869/10000 [00:12<00:17, 285.14it/s] 49%|████▉     | 4906/10000 [00:12<00:16, 305.36it/s] 49%|████▉     | 4938/10000 [00:13<00:19, 263.86it/s] 50%|████▉     | 4966/10000 [00:13<00:20, 250.86it/s] 50%|████▉     | 4993/10000 [00:13<00:20, 244.64it/s] 50%|█████     | 5042/10000 [00:13<00:16, 305.58it/s] 51%|█████     | 5103/10000 [00:13<00:12, 378.24it/s] 51%|█████▏    | 5145/10000 [00:13<00:12, 380.43it/s] 52%|█████▏    | 5211/10000 [00:13<00:10, 456.17it/s] 53%|█████▎    | 5259/10000 [00:13<00:13, 361.45it/s] 53%|█████▎    | 5300/10000 [00:14<00:17, 272.27it/s] 53%|█████▎    | 5333/10000 [00:14<00:16, 281.11it/s] 54%|█████▎    | 5366/10000 [00:14<00:17, 267.39it/s] 54%|█████▍    | 5399/10000 [00:14<00:16, 281.30it/s] 54%|█████▍    | 5449/10000 [00:14<00:13, 329.25it/s] 55%|█████▍    | 5488/10000 [00:14<00:13, 335.54it/s] 55%|█████▌    | 5540/10000 [00:14<00:11, 379.26it/s] 56%|█████▌    | 5600/10000 [00:15<00:10, 424.24it/s] 57%|█████▋    | 5679/10000 [00:15<00:08, 513.92it/s] 57%|█████▋    | 5733/10000 [00:15<00:08, 517.45it/s] 58%|█████▊    | 5804/10000 [00:15<00:07, 557.37it/s] 59%|█████▊    | 5861/10000 [00:15<00:09, 439.67it/s] 59%|█████▉    | 5910/10000 [00:15<00:11, 348.16it/s] 60%|█████▉    | 5951/10000 [00:15<00:11, 337.91it/s] 60%|█████▉    | 5994/10000 [00:15<00:11, 356.73it/s] 60%|██████    | 6049/10000 [00:16<00:09, 395.19it/s] 61%|██████    | 6100/10000 [00:16<00:09, 420.65it/s] 62%|██████▏   | 6160/10000 [00:16<00:08, 466.17it/s] 62%|██████▏   | 6210/10000 [00:16<00:08, 421.48it/s] 63%|██████▎   | 6255/10000 [00:16<00:09, 402.59it/s] 63%|██████▎   | 6297/10000 [00:16<00:09, 372.88it/s] 63%|██████▎   | 6336/10000 [00:16<00:10, 353.16it/s] 64%|██████▎   | 6373/10000 [00:16<00:11, 308.00it/s] 64%|██████▍   | 6406/10000 [00:17<00:11, 310.99it/s] 64%|██████▍   | 6439/10000 [00:17<00:11, 304.00it/s] 65%|██████▍   | 6471/10000 [00:17<00:12, 282.53it/s] 65%|██████▌   | 6504/10000 [00:17<00:11, 291.46it/s] 65%|██████▌   | 6541/10000 [00:17<00:11, 305.56it/s] 66%|██████▌   | 6574/10000 [00:17<00:11, 299.35it/s] 66%|██████▌   | 6621/10000 [00:17<00:10, 322.72it/s] 67%|██████▋   | 6654/10000 [00:17<00:10, 314.91it/s] 67%|██████▋   | 6705/10000 [00:18<00:09, 349.11it/s] 67%|██████▋   | 6740/10000 [00:18<00:09, 333.79it/s] 68%|██████▊   | 6787/10000 [00:18<00:09, 340.65it/s] 69%|██████▊   | 6854/10000 [00:18<00:07, 418.50it/s] 69%|██████▉   | 6920/10000 [00:18<00:06, 469.01it/s] 70%|██████▉   | 6971/10000 [00:18<00:06, 478.81it/s] 70%|███████   | 7030/10000 [00:18<00:05, 497.65it/s] 71%|███████   | 7081/10000 [00:18<00:06, 460.98it/s] 72%|███████▏  | 7151/10000 [00:18<00:05, 509.09it/s] 72%|███████▏  | 7206/10000 [00:19<00:05, 510.35it/s] 73%|███████▎  | 7261/10000 [00:19<00:05, 516.50it/s] 73%|███████▎  | 7322/10000 [00:19<00:05, 530.51it/s] 74%|███████▍  | 7378/10000 [00:19<00:04, 531.91it/s] 74%|███████▍  | 7440/10000 [00:19<00:04, 544.92it/s] 75%|███████▌  | 7501/10000 [00:19<00:04, 557.93it/s] 76%|███████▌  | 7577/10000 [00:19<00:04, 567.38it/s] 76%|███████▋  | 7634/10000 [00:19<00:04, 499.55it/s] 77%|███████▋  | 7686/10000 [00:20<00:05, 438.19it/s] 77%|███████▋  | 7732/10000 [00:20<00:05, 393.50it/s] 78%|███████▊  | 7790/10000 [00:20<00:05, 428.58it/s] 78%|███████▊  | 7835/10000 [00:20<00:05, 426.34it/s] 79%|███████▉  | 7894/10000 [00:20<00:04, 465.05it/s] 80%|███████▉  | 7956/10000 [00:20<00:04, 503.47it/s] 80%|████████  | 8039/10000 [00:20<00:03, 580.86it/s] 81%|████████  | 8115/10000 [00:20<00:03, 621.79it/s] 82%|████████▏ | 8179/10000 [00:20<00:03, 545.01it/s] 82%|████████▏ | 8236/10000 [00:21<00:03, 497.38it/s] 83%|████████▎ | 8288/10000 [00:21<00:04, 414.41it/s] 83%|████████▎ | 8333/10000 [00:21<00:04, 379.28it/s] 84%|████████▎ | 8374/10000 [00:21<00:04, 359.54it/s] 84%|████████▍ | 8412/10000 [00:21<00:04, 352.72it/s] 85%|████████▍ | 8454/10000 [00:21<00:04, 361.73it/s] 85%|████████▌ | 8506/10000 [00:21<00:03, 396.65it/s] 85%|████████▌ | 8547/10000 [00:22<00:03, 367.51it/s] 86%|████████▌ | 8611/10000 [00:22<00:03, 436.13it/s] 87%|████████▋ | 8682/10000 [00:22<00:02, 500.76it/s] 88%|████████▊ | 8759/10000 [00:22<00:02, 574.08it/s] 88%|████████▊ | 8819/10000 [00:22<00:02, 534.22it/s] 89%|████████▉ | 8887/10000 [00:22<00:01, 565.13it/s] 90%|████████▉ | 8960/10000 [00:22<00:01, 608.28it/s] 90%|█████████ | 9028/10000 [00:22<00:01, 612.46it/s] 91%|█████████ | 9091/10000 [00:22<00:01, 588.64it/s] 92%|█████████▏| 9151/10000 [00:23<00:01, 533.88it/s] 92%|█████████▏| 9206/10000 [00:23<00:01, 490.70it/s] 93%|█████████▎| 9258/10000 [00:23<00:01, 495.13it/s] 93%|█████████▎| 9309/10000 [00:23<00:01, 385.15it/s] 94%|█████████▎| 9352/10000 [00:23<00:01, 367.83it/s] 94%|█████████▍| 9392/10000 [00:23<00:01, 345.39it/s] 94%|█████████▍| 9429/10000 [00:23<00:01, 333.96it/s] 95%|█████████▍| 9473/10000 [00:24<00:01, 355.84it/s] 95%|█████████▌| 9510/10000 [00:24<00:01, 349.34it/s] 95%|█████████▌| 9546/10000 [00:24<00:01, 328.16it/s] 96%|█████████▌| 9591/10000 [00:24<00:01, 353.53it/s] 96%|█████████▋| 9628/10000 [00:24<00:01, 337.16it/s] 97%|█████████▋| 9663/10000 [00:24<00:01, 321.36it/s] 97%|█████████▋| 9701/10000 [00:24<00:00, 329.82it/s] 97%|█████████▋| 9743/10000 [00:24<00:00, 343.86it/s] 98%|█████████▊| 9785/10000 [00:24<00:00, 360.21it/s] 98%|█████████▊| 9842/10000 [00:25<00:00, 403.96it/s] 99%|█████████▉| 9942/10000 [00:25<00:00, 544.54it/s]100%|██████████| 10000/10000 [00:25<00:00, 396.42it/s]
test_neglected_p78 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p78
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p78.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.01s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.92it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.95it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.16it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.88it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.00it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.51it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.10it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.33it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p78_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p78_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p78_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p78_Holmes_probs.npy
{'Accuracy': 0.0198, 'Precision': 0.0223, 'Recall': 0.0195, 'F1-score': 0.0173}
starting gen taf script for test_neglected_p79
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 63/10000 [00:00<00:17, 562.58it/s]  1%|          | 120/10000 [00:00<00:20, 482.97it/s]  2%|▏         | 169/10000 [00:00<00:31, 310.01it/s]  2%|▏         | 205/10000 [00:00<00:33, 293.63it/s]  2%|▏         | 238/10000 [00:00<00:34, 284.93it/s]  3%|▎         | 269/10000 [00:00<00:33, 287.42it/s]  3%|▎         | 299/10000 [00:00<00:33, 287.34it/s]  3%|▎         | 329/10000 [00:01<00:34, 282.63it/s]  4%|▎         | 358/10000 [00:01<00:33, 283.71it/s]  4%|▍         | 389/10000 [00:01<00:33, 290.04it/s]  4%|▍         | 419/10000 [00:01<00:33, 288.01it/s]  5%|▍         | 459/10000 [00:01<00:30, 317.12it/s]  5%|▍         | 497/10000 [00:01<00:28, 332.73it/s]  5%|▌         | 531/10000 [00:01<00:29, 319.89it/s]  6%|▌         | 569/10000 [00:01<00:28, 336.80it/s]  6%|▌         | 604/10000 [00:01<00:27, 336.73it/s]  7%|▋         | 651/10000 [00:02<00:24, 374.82it/s]  7%|▋         | 691/10000 [00:02<00:24, 372.97it/s]  7%|▋         | 729/10000 [00:02<00:26, 352.39it/s]  8%|▊         | 772/10000 [00:02<00:24, 369.21it/s]  8%|▊         | 810/10000 [00:02<00:25, 358.24it/s]  8%|▊         | 849/10000 [00:02<00:24, 367.00it/s]  9%|▉         | 886/10000 [00:02<00:24, 365.30it/s]  9%|▉         | 928/10000 [00:02<00:25, 360.70it/s] 10%|▉         | 965/10000 [00:02<00:25, 355.39it/s] 10%|█         | 1001/10000 [00:02<00:26, 344.31it/s] 10%|█         | 1036/10000 [00:03<00:26, 338.74it/s] 11%|█         | 1085/10000 [00:03<00:23, 380.14it/s] 11%|█         | 1124/10000 [00:03<00:25, 342.07it/s] 12%|█▏        | 1168/10000 [00:03<00:24, 365.97it/s] 12%|█▏        | 1206/10000 [00:03<00:25, 340.20it/s] 13%|█▎        | 1282/10000 [00:03<00:19, 450.45it/s] 13%|█▎        | 1334/10000 [00:03<00:18, 457.77it/s] 14%|█▍        | 1395/10000 [00:03<00:17, 487.79it/s] 14%|█▍        | 1445/10000 [00:04<00:27, 316.81it/s] 15%|█▍        | 1485/10000 [00:04<00:27, 312.29it/s] 15%|█▌        | 1522/10000 [00:04<00:32, 264.88it/s] 16%|█▌        | 1554/10000 [00:04<00:35, 234.87it/s] 16%|█▌        | 1581/10000 [00:04<00:37, 224.37it/s] 16%|█▋        | 1627/10000 [00:04<00:30, 271.96it/s] 17%|█▋        | 1669/10000 [00:05<00:27, 305.49it/s] 17%|█▋        | 1729/10000 [00:05<00:22, 375.08it/s] 18%|█▊        | 1792/10000 [00:05<00:18, 438.57it/s] 19%|█▊        | 1864/10000 [00:05<00:15, 510.72it/s] 19%|█▉        | 1943/10000 [00:05<00:13, 586.10it/s] 20%|██        | 2013/10000 [00:05<00:12, 616.30it/s] 21%|██        | 2077/10000 [00:05<00:13, 604.70it/s] 21%|██▏       | 2140/10000 [00:05<00:15, 503.69it/s] 22%|██▏       | 2195/10000 [00:05<00:15, 500.21it/s] 22%|██▏       | 2248/10000 [00:06<00:18, 417.47it/s] 23%|██▎       | 2294/10000 [00:06<00:19, 395.35it/s] 23%|██▎       | 2337/10000 [00:06<00:21, 356.07it/s] 24%|██▍       | 2375/10000 [00:06<00:22, 332.90it/s] 24%|██▍       | 2421/10000 [00:06<00:21, 358.57it/s] 25%|██▍       | 2464/10000 [00:06<00:20, 373.40it/s] 25%|██▌       | 2514/10000 [00:06<00:18, 403.48it/s] 26%|██▌       | 2567/10000 [00:06<00:17, 433.46it/s] 26%|██▌       | 2612/10000 [00:07<00:17, 411.95it/s] 27%|██▋       | 2655/10000 [00:07<00:24, 295.70it/s] 27%|██▋       | 2690/10000 [00:07<00:28, 253.44it/s] 27%|██▋       | 2720/10000 [00:07<00:30, 236.38it/s] 27%|██▋       | 2747/10000 [00:07<00:34, 213.02it/s] 28%|██▊       | 2771/10000 [00:08<00:34, 212.27it/s] 28%|██▊       | 2794/10000 [00:08<00:33, 214.29it/s] 28%|██▊       | 2832/10000 [00:08<00:28, 249.94it/s] 29%|██▉       | 2882/10000 [00:08<00:23, 309.44it/s] 29%|██▉       | 2944/10000 [00:08<00:18, 385.93it/s] 30%|██▉       | 2992/10000 [00:08<00:17, 401.12it/s] 30%|███       | 3034/10000 [00:08<00:18, 378.28it/s] 31%|███       | 3074/10000 [00:08<00:20, 342.18it/s] 31%|███       | 3110/10000 [00:08<00:23, 298.23it/s] 31%|███▏      | 3142/10000 [00:09<00:23, 290.89it/s] 32%|███▏      | 3173/10000 [00:09<00:24, 280.69it/s] 32%|███▏      | 3242/10000 [00:09<00:17, 380.68it/s] 33%|███▎      | 3323/10000 [00:09<00:13, 485.89it/s] 34%|███▍      | 3389/10000 [00:09<00:12, 521.94it/s] 35%|███▍      | 3455/10000 [00:09<00:12, 536.61it/s] 35%|███▌      | 3511/10000 [00:09<00:13, 470.23it/s] 36%|███▌      | 3572/10000 [00:09<00:12, 496.41it/s] 36%|███▌      | 3624/10000 [00:10<00:12, 494.87it/s] 37%|███▋      | 3684/10000 [00:10<00:12, 515.19it/s] 37%|███▋      | 3737/10000 [00:10<00:12, 505.82it/s] 38%|███▊      | 3805/10000 [00:10<00:11, 547.28it/s] 39%|███▊      | 3861/10000 [00:10<00:13, 468.09it/s] 39%|███▉      | 3911/10000 [00:10<00:13, 446.73it/s] 40%|███▉      | 3958/10000 [00:10<00:13, 445.11it/s] 40%|████      | 4004/10000 [00:10<00:13, 445.13it/s] 41%|████      | 4074/10000 [00:10<00:11, 509.32it/s] 41%|████▏     | 4136/10000 [00:11<00:10, 533.32it/s] 42%|████▏     | 4215/10000 [00:11<00:09, 598.60it/s] 43%|████▎     | 4283/10000 [00:11<00:09, 616.40it/s] 43%|████▎     | 4346/10000 [00:11<00:09, 603.38it/s] 44%|████▍     | 4409/10000 [00:11<00:09, 574.19it/s] 45%|████▍     | 4468/10000 [00:11<00:12, 426.99it/s] 45%|████▌     | 4517/10000 [00:11<00:14, 381.40it/s] 46%|████▌     | 4560/10000 [00:12<00:15, 346.92it/s] 46%|████▌     | 4598/10000 [00:12<00:18, 297.68it/s] 46%|████▋     | 4638/10000 [00:12<00:16, 318.42it/s] 47%|████▋     | 4673/10000 [00:12<00:17, 305.03it/s] 47%|████▋     | 4706/10000 [00:12<00:17, 300.20it/s] 47%|████▋     | 4738/10000 [00:12<00:18, 288.65it/s] 48%|████▊     | 4776/10000 [00:12<00:17, 305.65it/s] 48%|████▊     | 4808/10000 [00:12<00:18, 284.79it/s] 48%|████▊     | 4840/10000 [00:13<00:18, 283.26it/s] 49%|████▊     | 4869/10000 [00:13<00:18, 272.90it/s] 49%|████▉     | 4897/10000 [00:13<00:19, 257.18it/s] 49%|████▉     | 4923/10000 [00:13<00:21, 237.84it/s] 50%|████▉     | 4961/10000 [00:13<00:18, 270.65it/s] 50%|████▉     | 4989/10000 [00:13<00:18, 271.30it/s] 50%|█████     | 5020/10000 [00:13<00:17, 277.56it/s] 51%|█████     | 5086/10000 [00:13<00:13, 362.32it/s] 51%|█████▏    | 5125/10000 [00:13<00:13, 360.44it/s] 52%|█████▏    | 5183/10000 [00:14<00:11, 420.69it/s] 52%|█████▏    | 5226/10000 [00:14<00:13, 350.34it/s] 53%|█████▎    | 5264/10000 [00:14<00:16, 292.46it/s] 53%|█████▎    | 5297/10000 [00:14<00:18, 251.06it/s] 53%|█████▎    | 5335/10000 [00:14<00:17, 264.92it/s] 54%|█████▎    | 5364/10000 [00:14<00:18, 248.92it/s] 54%|█████▍    | 5391/10000 [00:15<00:19, 238.66it/s] 54%|█████▍    | 5443/10000 [00:15<00:15, 299.93it/s] 55%|█████▍    | 5475/10000 [00:15<00:15, 297.68it/s] 55%|█████▌    | 5517/10000 [00:15<00:13, 324.95it/s] 56%|█████▌    | 5560/10000 [00:15<00:12, 345.24it/s] 56%|█████▌    | 5607/10000 [00:15<00:11, 376.81it/s] 57%|█████▋    | 5677/10000 [00:15<00:09, 466.02it/s] 57%|█████▋    | 5726/10000 [00:15<00:09, 469.12it/s] 58%|█████▊    | 5777/10000 [00:15<00:08, 471.07it/s] 58%|█████▊    | 5825/10000 [00:15<00:09, 437.89it/s] 59%|█████▊    | 5870/10000 [00:16<00:09, 434.32it/s] 59%|█████▉    | 5915/10000 [00:16<00:11, 362.50it/s] 60%|█████▉    | 5959/10000 [00:16<00:10, 374.96it/s] 60%|█████▉    | 5999/10000 [00:16<00:11, 347.24it/s] 60%|██████    | 6039/10000 [00:16<00:11, 344.16it/s] 61%|██████    | 6108/10000 [00:16<00:09, 428.53it/s] 62%|██████▏   | 6155/10000 [00:16<00:08, 439.38it/s] 62%|██████▏   | 6201/10000 [00:16<00:08, 430.64it/s] 62%|██████▏   | 6246/10000 [00:17<00:09, 399.28it/s] 63%|██████▎   | 6287/10000 [00:17<00:11, 334.33it/s] 63%|██████▎   | 6323/10000 [00:17<00:11, 327.03it/s] 64%|██████▎   | 6358/10000 [00:17<00:11, 317.15it/s] 64%|██████▍   | 6391/10000 [00:17<00:11, 302.68it/s] 64%|██████▍   | 6422/10000 [00:17<00:14, 250.03it/s] 65%|██████▍   | 6459/10000 [00:17<00:12, 273.06it/s] 65%|██████▍   | 6489/10000 [00:18<00:13, 264.65it/s] 65%|██████▌   | 6524/10000 [00:18<00:12, 283.73it/s] 66%|██████▌   | 6565/10000 [00:18<00:10, 313.28it/s] 66%|██████▌   | 6598/10000 [00:18<00:12, 279.89it/s] 67%|██████▋   | 6653/10000 [00:18<00:09, 338.57it/s] 67%|██████▋   | 6689/10000 [00:18<00:10, 321.71it/s] 67%|██████▋   | 6738/10000 [00:18<00:08, 364.40it/s] 68%|██████▊   | 6776/10000 [00:18<00:09, 343.78it/s] 68%|██████▊   | 6826/10000 [00:18<00:08, 377.96it/s] 69%|██████▉   | 6889/10000 [00:19<00:07, 440.85it/s] 70%|██████▉   | 6961/10000 [00:19<00:06, 503.62it/s] 70%|███████   | 7016/10000 [00:19<00:05, 512.10it/s] 71%|███████   | 7068/10000 [00:19<00:05, 501.21it/s] 71%|███████▏  | 7126/10000 [00:19<00:05, 509.49it/s] 72%|███████▏  | 7178/10000 [00:19<00:05, 475.44it/s] 72%|███████▏  | 7227/10000 [00:19<00:06, 462.01it/s] 73%|███████▎  | 7277/10000 [00:19<00:05, 466.73it/s] 74%|███████▎  | 7361/10000 [00:19<00:04, 559.21it/s] 74%|███████▍  | 7418/10000 [00:20<00:04, 536.74it/s] 75%|███████▍  | 7473/10000 [00:20<00:05, 493.28it/s] 75%|███████▌  | 7532/10000 [00:20<00:04, 518.40it/s] 76%|███████▌  | 7585/10000 [00:20<00:05, 480.75it/s] 76%|███████▋  | 7635/10000 [00:20<00:05, 445.44it/s] 77%|███████▋  | 7683/10000 [00:20<00:05, 453.56it/s] 77%|███████▋  | 7730/10000 [00:20<00:05, 400.44it/s] 78%|███████▊  | 7772/10000 [00:20<00:06, 352.18it/s] 78%|███████▊  | 7844/10000 [00:21<00:04, 437.92it/s] 79%|███████▉  | 7892/10000 [00:21<00:04, 445.68it/s] 80%|███████▉  | 7955/10000 [00:21<00:04, 486.51it/s] 80%|████████  | 8036/10000 [00:21<00:03, 560.15it/s] 81%|████████  | 8094/10000 [00:21<00:03, 552.89it/s] 82%|████████▏ | 8151/10000 [00:21<00:03, 521.00it/s] 82%|████████▏ | 8208/10000 [00:21<00:03, 527.19it/s] 83%|████████▎ | 8262/10000 [00:21<00:04, 389.09it/s] 83%|████████▎ | 8307/10000 [00:22<00:04, 392.61it/s] 84%|████████▎ | 8351/10000 [00:22<00:04, 367.98it/s] 84%|████████▍ | 8391/10000 [00:22<00:04, 333.03it/s] 84%|████████▍ | 8427/10000 [00:22<00:04, 333.39it/s] 85%|████████▍ | 8479/10000 [00:22<00:04, 368.10it/s] 85%|████████▌ | 8518/10000 [00:22<00:04, 346.76it/s] 86%|████████▌ | 8560/10000 [00:22<00:03, 362.66it/s] 86%|████████▌ | 8620/10000 [00:22<00:03, 424.92it/s] 87%|████████▋ | 8698/10000 [00:23<00:02, 516.94it/s] 88%|████████▊ | 8755/10000 [00:23<00:02, 524.28it/s] 88%|████████▊ | 8823/10000 [00:23<00:02, 561.92it/s] 89%|████████▉ | 8881/10000 [00:23<00:02, 555.12it/s] 89%|████████▉ | 8946/10000 [00:23<00:01, 580.02it/s] 90%|█████████ | 9005/10000 [00:23<00:01, 579.69it/s] 91%|█████████ | 9064/10000 [00:23<00:01, 570.93it/s] 91%|█████████ | 9122/10000 [00:23<00:01, 482.17it/s] 92%|█████████▏| 9173/10000 [00:23<00:01, 441.08it/s] 92%|█████████▏| 9220/10000 [00:24<00:01, 424.53it/s] 93%|█████████▎| 9264/10000 [00:24<00:01, 428.12it/s] 93%|█████████▎| 9308/10000 [00:24<00:02, 330.18it/s] 93%|█████████▎| 9345/10000 [00:24<00:01, 337.68it/s] 94%|█████████▍| 9382/10000 [00:24<00:02, 304.78it/s] 94%|█████████▍| 9415/10000 [00:24<00:01, 301.83it/s] 95%|█████████▍| 9451/10000 [00:24<00:01, 316.01it/s] 95%|█████████▍| 9487/10000 [00:24<00:01, 317.42it/s] 95%|█████████▌| 9520/10000 [00:25<00:01, 273.69it/s] 96%|█████████▌| 9556/10000 [00:25<00:01, 292.19it/s] 96%|█████████▌| 9604/10000 [00:25<00:01, 339.00it/s] 96%|█████████▋| 9641/10000 [00:25<00:01, 344.67it/s] 97%|█████████▋| 9683/10000 [00:25<00:00, 356.07it/s] 97%|█████████▋| 9720/10000 [00:25<00:00, 352.84it/s] 98%|█████████▊| 9765/10000 [00:25<00:00, 357.81it/s] 98%|█████████▊| 9814/10000 [00:25<00:00, 392.62it/s] 99%|█████████▊| 9872/10000 [00:26<00:00, 438.86it/s]100%|█████████▉| 9956/10000 [00:26<00:00, 551.05it/s]100%|██████████| 10000/10000 [00:26<00:00, 381.64it/s]
test_neglected_p79 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p79
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p79.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:46,  1.19s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  5.99it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 11.64it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 17.52it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 23.27it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 28.39it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 32.90it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 36.52it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 19.15it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p79_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p79_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p79_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p79_Holmes_probs.npy
{'Accuracy': 0.0197, 'Precision': 0.0207, 'Recall': 0.0194, 'F1-score': 0.0168}
starting gen taf script for test_neglected_p80
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 69/10000 [00:00<00:15, 623.21it/s]  1%|▏         | 132/10000 [00:00<00:26, 372.71it/s]  2%|▏         | 175/10000 [00:00<00:29, 335.10it/s]  2%|▏         | 211/10000 [00:00<00:32, 297.02it/s]  2%|▏         | 243/10000 [00:00<00:34, 285.08it/s]  3%|▎         | 273/10000 [00:00<00:34, 280.92it/s]  3%|▎         | 302/10000 [00:01<00:37, 261.69it/s]  3%|▎         | 329/10000 [00:01<00:37, 255.31it/s]  4%|▎         | 355/10000 [00:01<00:37, 254.94it/s]  4%|▍         | 381/10000 [00:01<00:39, 246.46it/s]  4%|▍         | 406/10000 [00:01<00:39, 243.63it/s]  4%|▍         | 436/10000 [00:01<00:37, 255.62it/s]  5%|▍         | 466/10000 [00:01<00:35, 267.55it/s]  5%|▍         | 496/10000 [00:01<00:34, 274.98it/s]  5%|▌         | 532/10000 [00:01<00:31, 296.20it/s]  6%|▌         | 578/10000 [00:01<00:27, 338.04it/s]  6%|▋         | 633/10000 [00:02<00:23, 396.27it/s]  7%|▋         | 694/10000 [00:02<00:20, 453.09it/s]  8%|▊         | 750/10000 [00:02<00:19, 484.04it/s]  8%|▊         | 804/10000 [00:02<00:18, 493.98it/s]  9%|▊         | 854/10000 [00:02<00:19, 468.52it/s]  9%|▉         | 902/10000 [00:02<00:20, 448.77it/s]  9%|▉         | 949/10000 [00:02<00:19, 452.79it/s] 10%|▉         | 995/10000 [00:02<00:22, 398.40it/s] 10%|█         | 1037/10000 [00:02<00:23, 384.99it/s] 11%|█         | 1077/10000 [00:03<00:23, 384.26it/s] 11%|█         | 1117/10000 [00:03<00:22, 387.91it/s] 12%|█▏        | 1157/10000 [00:03<00:23, 375.18it/s] 12%|█▏        | 1195/10000 [00:03<00:25, 347.89it/s] 13%|█▎        | 1284/10000 [00:03<00:17, 485.79it/s] 14%|█▎        | 1359/10000 [00:03<00:15, 546.36it/s] 14%|█▍        | 1415/10000 [00:03<00:16, 534.68it/s] 15%|█▍        | 1470/10000 [00:04<00:27, 312.86it/s] 15%|█▌        | 1513/10000 [00:04<00:26, 317.29it/s] 16%|█▌        | 1553/10000 [00:04<00:31, 265.91it/s] 16%|█▌        | 1587/10000 [00:04<00:33, 253.98it/s] 16%|█▌        | 1617/10000 [00:04<00:34, 244.48it/s] 17%|█▋        | 1693/10000 [00:04<00:23, 349.99it/s] 17%|█▋        | 1735/10000 [00:04<00:22, 364.11it/s] 18%|█▊        | 1789/10000 [00:05<00:20, 402.71it/s] 19%|█▊        | 1872/10000 [00:05<00:15, 510.58it/s] 20%|█▉        | 1956/10000 [00:05<00:13, 589.87it/s] 20%|██        | 2029/10000 [00:05<00:12, 627.25it/s] 21%|██        | 2095/10000 [00:05<00:15, 512.76it/s] 22%|██▏       | 2152/10000 [00:05<00:17, 455.40it/s] 22%|██▏       | 2216/10000 [00:05<00:15, 494.86it/s] 23%|██▎       | 2270/10000 [00:06<00:20, 385.31it/s] 23%|██▎       | 2315/10000 [00:06<00:21, 360.59it/s] 24%|██▎       | 2356/10000 [00:06<00:23, 330.41it/s] 24%|██▍       | 2394/10000 [00:06<00:22, 340.06it/s] 24%|██▍       | 2436/10000 [00:06<00:21, 353.37it/s] 25%|██▍       | 2490/10000 [00:06<00:18, 398.63it/s] 25%|██▌       | 2549/10000 [00:06<00:16, 447.70it/s] 26%|██▌       | 2597/10000 [00:06<00:18, 404.64it/s] 26%|██▋       | 2640/10000 [00:07<00:21, 348.13it/s] 27%|██▋       | 2678/10000 [00:07<00:23, 312.27it/s] 27%|██▋       | 2712/10000 [00:07<00:27, 267.93it/s] 27%|██▋       | 2741/10000 [00:07<00:30, 240.79it/s] 28%|██▊       | 2767/10000 [00:07<00:33, 216.02it/s] 28%|██▊       | 2790/10000 [00:07<00:34, 207.28it/s] 28%|██▊       | 2824/10000 [00:07<00:31, 230.20it/s] 29%|██▉       | 2899/10000 [00:08<00:20, 350.61it/s] 29%|██▉       | 2941/10000 [00:08<00:19, 367.79it/s] 30%|██▉       | 2998/10000 [00:08<00:16, 419.12it/s] 30%|███       | 3043/10000 [00:08<00:19, 359.83it/s] 31%|███       | 3083/10000 [00:08<00:19, 348.97it/s] 31%|███       | 3121/10000 [00:08<00:20, 336.97it/s] 32%|███▏      | 3157/10000 [00:08<00:22, 309.79it/s] 32%|███▏      | 3192/10000 [00:08<00:21, 319.05it/s] 32%|███▏      | 3244/10000 [00:09<00:18, 364.81it/s] 33%|███▎      | 3326/10000 [00:09<00:13, 485.63it/s] 34%|███▍      | 3403/10000 [00:09<00:11, 563.65it/s] 35%|███▍      | 3462/10000 [00:09<00:12, 542.60it/s] 35%|███▌      | 3518/10000 [00:09<00:12, 519.48it/s] 36%|███▌      | 3573/10000 [00:09<00:12, 511.19it/s] 36%|███▋      | 3627/10000 [00:09<00:12, 509.64it/s] 37%|███▋      | 3726/10000 [00:09<00:09, 642.99it/s] 38%|███▊      | 3799/10000 [00:09<00:09, 653.07it/s] 39%|███▊      | 3866/10000 [00:10<00:12, 502.85it/s] 39%|███▉      | 3923/10000 [00:10<00:12, 471.45it/s] 40%|███▉      | 3975/10000 [00:10<00:13, 436.57it/s] 40%|████      | 4043/10000 [00:10<00:12, 490.45it/s] 41%|████      | 4099/10000 [00:10<00:11, 503.27it/s] 42%|████▏     | 4184/10000 [00:10<00:09, 590.79it/s] 42%|████▏     | 4247/10000 [00:10<00:10, 552.91it/s] 43%|████▎     | 4312/10000 [00:10<00:09, 577.83it/s] 44%|████▎     | 4372/10000 [00:11<00:09, 582.42it/s] 44%|████▍     | 4432/10000 [00:11<00:10, 554.00it/s] 45%|████▍     | 4489/10000 [00:11<00:13, 395.43it/s] 45%|████▌     | 4536/10000 [00:11<00:14, 377.02it/s] 46%|████▌     | 4579/10000 [00:11<00:16, 328.40it/s] 46%|████▌     | 4616/10000 [00:11<00:16, 333.01it/s] 47%|████▋     | 4653/10000 [00:11<00:15, 334.61it/s] 47%|████▋     | 4689/10000 [00:12<00:16, 327.22it/s] 47%|████▋     | 4724/10000 [00:12<00:16, 325.95it/s] 48%|████▊     | 4758/10000 [00:12<00:16, 323.32it/s] 48%|████▊     | 4791/10000 [00:12<00:16, 309.70it/s] 48%|████▊     | 4823/10000 [00:12<00:19, 271.04it/s] 49%|████▊     | 4852/10000 [00:12<00:19, 270.58it/s] 49%|████▉     | 4880/10000 [00:12<00:20, 248.27it/s] 49%|████▉     | 4907/10000 [00:12<00:20, 251.94it/s] 49%|████▉     | 4933/10000 [00:13<00:21, 238.20it/s] 50%|████▉     | 4962/10000 [00:13<00:20, 251.46it/s] 50%|████▉     | 4988/10000 [00:13<00:21, 236.70it/s] 50%|█████     | 5024/10000 [00:13<00:18, 264.09it/s] 51%|█████     | 5068/10000 [00:13<00:15, 309.35it/s] 51%|█████▏    | 5125/10000 [00:13<00:12, 378.77it/s] 52%|█████▏    | 5183/10000 [00:13<00:11, 432.06it/s] 52%|█████▏    | 5228/10000 [00:13<00:13, 360.97it/s] 53%|█████▎    | 5267/10000 [00:14<00:14, 316.04it/s] 53%|█████▎    | 5302/10000 [00:14<00:16, 287.56it/s] 53%|█████▎    | 5333/10000 [00:14<00:16, 277.31it/s] 54%|█████▎    | 5362/10000 [00:14<00:17, 263.52it/s] 54%|█████▍    | 5390/10000 [00:14<00:20, 228.48it/s] 54%|█████▍    | 5431/10000 [00:14<00:16, 269.28it/s] 55%|█████▍    | 5460/10000 [00:14<00:17, 264.22it/s] 55%|█████▌    | 5527/10000 [00:14<00:12, 353.93it/s] 56%|█████▌    | 5578/10000 [00:15<00:11, 391.30it/s] 56%|█████▋    | 5631/10000 [00:15<00:10, 408.48it/s] 57%|█████▋    | 5683/10000 [00:15<00:10, 422.96it/s] 57%|█████▋    | 5744/10000 [00:15<00:09, 460.63it/s] 58%|█████▊    | 5791/10000 [00:15<00:09, 429.36it/s] 58%|█████▊    | 5846/10000 [00:15<00:09, 461.25it/s] 59%|█████▉    | 5894/10000 [00:15<00:10, 408.42it/s] 59%|█████▉    | 5937/10000 [00:15<00:10, 373.09it/s] 60%|█████▉    | 5976/10000 [00:16<00:11, 339.78it/s] 60%|██████    | 6016/10000 [00:16<00:11, 354.12it/s] 61%|██████    | 6053/10000 [00:16<00:11, 356.56it/s] 61%|██████    | 6116/10000 [00:16<00:09, 428.59it/s] 62%|██████▏   | 6161/10000 [00:16<00:09, 403.00it/s] 62%|██████▏   | 6211/10000 [00:16<00:08, 426.80it/s] 63%|██████▎   | 6255/10000 [00:16<00:10, 357.40it/s] 63%|██████▎   | 6294/10000 [00:16<00:12, 293.56it/s] 63%|██████▎   | 6327/10000 [00:17<00:12, 285.14it/s] 64%|██████▎   | 6358/10000 [00:17<00:13, 270.92it/s] 64%|██████▍   | 6392/10000 [00:17<00:12, 285.23it/s] 64%|██████▍   | 6422/10000 [00:17<00:13, 258.60it/s] 65%|██████▍   | 6454/10000 [00:17<00:13, 272.04it/s] 65%|██████▍   | 6492/10000 [00:17<00:12, 275.66it/s] 65%|██████▌   | 6525/10000 [00:17<00:12, 288.58it/s] 66%|██████▌   | 6555/10000 [00:17<00:12, 284.32it/s] 66%|██████▌   | 6584/10000 [00:18<00:12, 279.37it/s] 66%|██████▌   | 6614/10000 [00:18<00:11, 283.61it/s] 66%|██████▋   | 6649/10000 [00:18<00:11, 300.78it/s] 67%|██████▋   | 6682/10000 [00:18<00:11, 301.35it/s] 67%|██████▋   | 6729/10000 [00:18<00:09, 348.98it/s] 68%|██████▊   | 6765/10000 [00:18<00:10, 318.01it/s] 68%|██████▊   | 6809/10000 [00:18<00:09, 348.08it/s] 69%|██████▊   | 6852/10000 [00:18<00:08, 368.22it/s] 69%|██████▉   | 6927/10000 [00:18<00:06, 470.55it/s] 70%|██████▉   | 6986/10000 [00:19<00:06, 500.53it/s] 70%|███████   | 7037/10000 [00:19<00:07, 419.75it/s] 71%|███████   | 7098/10000 [00:19<00:06, 454.82it/s] 71%|███████▏  | 7149/10000 [00:19<00:06, 462.71it/s] 72%|███████▏  | 7203/10000 [00:19<00:06, 461.30it/s] 73%|███████▎  | 7259/10000 [00:19<00:05, 472.23it/s] 73%|███████▎  | 7308/10000 [00:19<00:05, 455.05it/s] 74%|███████▎  | 7356/10000 [00:19<00:05, 458.72it/s] 74%|███████▍  | 7403/10000 [00:19<00:05, 459.18it/s] 74%|███████▍  | 7450/10000 [00:20<00:05, 448.73it/s] 75%|███████▌  | 7502/10000 [00:20<00:05, 457.00it/s] 76%|███████▌  | 7561/10000 [00:20<00:05, 482.48it/s] 76%|███████▌  | 7615/10000 [00:20<00:04, 493.51it/s] 77%|███████▋  | 7665/10000 [00:20<00:05, 404.49it/s] 77%|███████▋  | 7709/10000 [00:20<00:06, 375.07it/s] 77%|███████▋  | 7749/10000 [00:20<00:06, 345.41it/s] 78%|███████▊  | 7786/10000 [00:20<00:06, 349.53it/s] 79%|███████▊  | 7854/10000 [00:21<00:04, 431.73it/s] 79%|███████▉  | 7922/10000 [00:21<00:04, 490.77it/s] 80%|███████▉  | 7974/10000 [00:21<00:04, 481.08it/s] 80%|████████  | 8048/10000 [00:21<00:03, 518.08it/s] 81%|████████  | 8101/10000 [00:21<00:03, 501.13it/s] 82%|████████▏ | 8172/10000 [00:21<00:03, 557.19it/s] 82%|████████▏ | 8229/10000 [00:21<00:03, 474.17it/s] 83%|████████▎ | 8280/10000 [00:21<00:04, 401.37it/s] 83%|████████▎ | 8324/10000 [00:22<00:04, 352.98it/s] 84%|████████▎ | 8363/10000 [00:22<00:04, 358.34it/s] 84%|████████▍ | 8402/10000 [00:22<00:04, 325.73it/s] 85%|████████▍ | 8454/10000 [00:22<00:04, 362.01it/s] 85%|████████▍ | 8493/10000 [00:22<00:04, 344.42it/s] 85%|████████▌ | 8542/10000 [00:22<00:03, 372.32it/s] 86%|████████▌ | 8585/10000 [00:22<00:03, 387.00it/s] 86%|████████▋ | 8636/10000 [00:22<00:03, 411.66it/s] 87%|████████▋ | 8688/10000 [00:23<00:02, 441.13it/s] 88%|████████▊ | 8765/10000 [00:23<00:02, 532.40it/s] 88%|████████▊ | 8820/10000 [00:23<00:02, 528.29it/s] 89%|████████▉ | 8907/10000 [00:23<00:01, 598.80it/s] 90%|████████▉ | 8990/10000 [00:23<00:01, 663.31it/s] 91%|█████████ | 9057/10000 [00:23<00:01, 589.19it/s] 91%|█████████ | 9122/10000 [00:23<00:01, 604.87it/s] 92%|█████████▏| 9184/10000 [00:23<00:01, 578.26it/s] 92%|█████████▏| 9243/10000 [00:24<00:01, 467.37it/s] 93%|█████████▎| 9294/10000 [00:24<00:01, 378.49it/s] 93%|█████████▎| 9337/10000 [00:24<00:01, 376.54it/s] 94%|█████████▍| 9378/10000 [00:24<00:01, 322.74it/s] 94%|█████████▍| 9415/10000 [00:24<00:01, 330.77it/s] 95%|█████████▍| 9451/10000 [00:24<00:01, 327.15it/s] 95%|█████████▍| 9486/10000 [00:24<00:01, 327.61it/s] 95%|█████████▌| 9520/10000 [00:24<00:01, 306.14it/s] 96%|█████████▌| 9552/10000 [00:25<00:01, 303.70it/s] 96%|█████████▌| 9592/10000 [00:25<00:01, 328.19it/s] 96%|█████████▋| 9626/10000 [00:25<00:01, 282.61it/s] 97%|█████████▋| 9673/10000 [00:25<00:00, 327.99it/s] 97%|█████████▋| 9715/10000 [00:25<00:00, 350.57it/s] 98%|█████████▊| 9752/10000 [00:25<00:00, 354.14it/s] 98%|█████████▊| 9798/10000 [00:25<00:00, 378.60it/s] 99%|█████████▉| 9890/10000 [00:25<00:00, 519.68it/s]100%|█████████▉| 9969/10000 [00:25<00:00, 580.18it/s]100%|██████████| 10000/10000 [00:25<00:00, 384.79it/s]
test_neglected_p80 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p80
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p80.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:43,  1.13s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.26it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.03it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 17.94it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 23.73it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 28.88it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.35it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 36.90it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 19.75it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p80_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p80_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p80_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p80_Holmes_probs.npy
{'Accuracy': 0.0204, 'Precision': 0.0231, 'Recall': 0.02, 'F1-score': 0.0177}
starting gen taf script for test_neglected_p81
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 81/10000 [00:00<00:12, 792.04it/s]  2%|▏         | 161/10000 [00:00<00:27, 352.33it/s]  2%|▏         | 209/10000 [00:00<00:29, 332.85it/s]  2%|▏         | 249/10000 [00:00<00:33, 294.54it/s]  3%|▎         | 282/10000 [00:00<00:37, 257.58it/s]  3%|▎         | 310/10000 [00:01<00:38, 251.21it/s]  3%|▎         | 337/10000 [00:01<00:38, 251.46it/s]  4%|▎         | 364/10000 [00:01<00:38, 251.97it/s]  4%|▍         | 390/10000 [00:01<00:37, 253.09it/s]  4%|▍         | 418/10000 [00:01<00:36, 260.09it/s]  4%|▍         | 448/10000 [00:01<00:35, 266.20it/s]  5%|▍         | 485/10000 [00:01<00:32, 292.62it/s]  5%|▌         | 517/10000 [00:01<00:32, 294.04it/s]  6%|▌         | 555/10000 [00:01<00:30, 312.35it/s]  6%|▌         | 602/10000 [00:02<00:27, 339.44it/s]  6%|▋         | 639/10000 [00:02<00:28, 329.52it/s]  7%|▋         | 674/10000 [00:02<00:27, 334.91it/s]  7%|▋         | 712/10000 [00:02<00:27, 334.77it/s]  8%|▊         | 767/10000 [00:02<00:24, 384.36it/s]  8%|▊         | 821/10000 [00:02<00:22, 401.63it/s]  9%|▉         | 875/10000 [00:02<00:21, 433.46it/s]  9%|▉         | 919/10000 [00:02<00:21, 428.08it/s] 10%|▉         | 962/10000 [00:02<00:23, 382.67it/s] 10%|█         | 1002/10000 [00:03<00:26, 340.52it/s] 10%|█         | 1038/10000 [00:03<00:26, 332.44it/s] 11%|█         | 1073/10000 [00:03<00:26, 331.56it/s] 11%|█         | 1107/10000 [00:03<00:27, 327.24it/s] 11%|█▏        | 1141/10000 [00:03<00:28, 309.38it/s] 12%|█▏        | 1188/10000 [00:03<00:25, 343.50it/s] 12%|█▏        | 1238/10000 [00:03<00:22, 381.76it/s] 13%|█▎        | 1277/10000 [00:03<00:24, 354.23it/s] 13%|█▎        | 1343/10000 [00:03<00:20, 424.20it/s] 14%|█▍        | 1391/10000 [00:04<00:19, 437.91it/s] 14%|█▍        | 1436/10000 [00:04<00:23, 360.75it/s] 15%|█▍        | 1475/10000 [00:04<00:28, 294.55it/s] 15%|█▌        | 1508/10000 [00:04<00:30, 281.72it/s] 15%|█▌        | 1539/10000 [00:04<00:34, 246.82it/s] 16%|█▌        | 1566/10000 [00:04<00:36, 232.49it/s] 16%|█▌        | 1591/10000 [00:05<00:37, 222.88it/s] 16%|█▋        | 1626/10000 [00:05<00:33, 248.61it/s] 17%|█▋        | 1699/10000 [00:05<00:23, 357.86it/s] 18%|█▊        | 1753/10000 [00:05<00:20, 397.88it/s] 18%|█▊        | 1839/10000 [00:05<00:15, 511.54it/s] 19%|█▉        | 1949/10000 [00:05<00:12, 659.65it/s] 20%|██        | 2018/10000 [00:05<00:12, 642.24it/s] 21%|██        | 2085/10000 [00:05<00:14, 538.83it/s] 21%|██▏       | 2143/10000 [00:06<00:15, 498.74it/s] 22%|██▏       | 2196/10000 [00:06<00:19, 398.78it/s] 22%|██▏       | 2241/10000 [00:06<00:20, 378.88it/s] 23%|██▎       | 2282/10000 [00:06<00:21, 361.44it/s] 23%|██▎       | 2321/10000 [00:06<00:22, 336.82it/s] 24%|██▎       | 2365/10000 [00:06<00:21, 356.55it/s] 24%|██▍       | 2403/10000 [00:06<00:22, 337.50it/s] 24%|██▍       | 2449/10000 [00:06<00:21, 358.91it/s] 25%|██▍       | 2493/10000 [00:07<00:20, 372.68it/s] 25%|██▌       | 2539/10000 [00:07<00:19, 390.38it/s] 26%|██▌       | 2596/10000 [00:07<00:17, 425.38it/s] 26%|██▋       | 2640/10000 [00:07<00:21, 343.76it/s] 27%|██▋       | 2678/10000 [00:07<00:25, 292.08it/s] 27%|██▋       | 2711/10000 [00:07<00:32, 225.35it/s] 27%|██▋       | 2738/10000 [00:08<00:33, 215.35it/s] 28%|██▊       | 2767/10000 [00:08<00:31, 228.98it/s] 28%|██▊       | 2793/10000 [00:08<00:31, 225.80it/s] 28%|██▊       | 2837/10000 [00:08<00:26, 274.88it/s] 29%|██▉       | 2875/10000 [00:08<00:23, 298.33it/s] 29%|██▉       | 2939/10000 [00:08<00:18, 377.25it/s] 30%|██▉       | 2996/10000 [00:08<00:16, 427.33it/s] 30%|███       | 3041/10000 [00:08<00:18, 382.48it/s] 31%|███       | 3082/10000 [00:09<00:22, 305.11it/s] 31%|███       | 3120/10000 [00:09<00:22, 312.40it/s] 32%|███▏      | 3155/10000 [00:09<00:22, 309.15it/s] 32%|███▏      | 3188/10000 [00:09<00:22, 298.78it/s] 33%|███▎      | 3265/10000 [00:09<00:16, 416.26it/s] 33%|███▎      | 3324/10000 [00:09<00:14, 460.91it/s] 34%|███▎      | 3373/10000 [00:09<00:14, 468.23it/s] 34%|███▍      | 3439/10000 [00:09<00:13, 498.14it/s] 35%|███▍      | 3491/10000 [00:09<00:13, 485.90it/s] 35%|███▌      | 3541/10000 [00:10<00:13, 470.07it/s] 36%|███▌      | 3589/10000 [00:10<00:14, 441.16it/s] 36%|███▋      | 3647/10000 [00:10<00:13, 458.68it/s] 37%|███▋      | 3708/10000 [00:10<00:12, 491.99it/s] 38%|███▊      | 3758/10000 [00:10<00:13, 477.34it/s] 38%|███▊      | 3811/10000 [00:10<00:12, 490.29it/s] 39%|███▊      | 3861/10000 [00:10<00:12, 479.62it/s] 39%|███▉      | 3910/10000 [00:10<00:13, 456.30it/s] 40%|███▉      | 3956/10000 [00:10<00:14, 419.94it/s] 40%|███▉      | 3999/10000 [00:11<00:14, 418.13it/s] 41%|████      | 4063/10000 [00:11<00:12, 473.62it/s] 41%|████      | 4112/10000 [00:11<00:12, 476.75it/s] 42%|████▏     | 4161/10000 [00:11<00:12, 472.20it/s] 42%|████▏     | 4209/10000 [00:11<00:12, 468.57it/s] 43%|████▎     | 4289/10000 [00:11<00:10, 547.74it/s] 44%|████▎     | 4365/10000 [00:11<00:09, 594.16it/s] 44%|████▍     | 4425/10000 [00:11<00:11, 474.06it/s] 45%|████▍     | 4477/10000 [00:12<00:12, 440.62it/s] 45%|████▌     | 4524/10000 [00:12<00:15, 362.58it/s] 46%|████▌     | 4564/10000 [00:12<00:17, 314.88it/s] 46%|████▌     | 4599/10000 [00:12<00:19, 284.08it/s] 46%|████▋     | 4646/10000 [00:12<00:16, 316.63it/s] 47%|████▋     | 4681/10000 [00:12<00:18, 287.26it/s] 47%|████▋     | 4727/10000 [00:12<00:16, 325.69it/s] 48%|████▊     | 4763/10000 [00:13<00:16, 321.33it/s] 48%|████▊     | 4797/10000 [00:13<00:16, 323.92it/s] 48%|████▊     | 4832/10000 [00:13<00:16, 311.09it/s] 49%|████▊     | 4865/10000 [00:13<00:16, 311.15it/s] 49%|████▉     | 4897/10000 [00:13<00:19, 258.22it/s] 49%|████▉     | 4925/10000 [00:13<00:20, 251.76it/s] 50%|████▉     | 4953/10000 [00:13<00:20, 251.39it/s] 50%|████▉     | 4983/10000 [00:13<00:19, 263.58it/s] 50%|█████     | 5011/10000 [00:14<00:20, 241.17it/s] 51%|█████     | 5086/10000 [00:14<00:13, 357.22it/s] 52%|█████▏    | 5152/10000 [00:14<00:11, 423.54it/s] 52%|█████▏    | 5198/10000 [00:14<00:11, 419.24it/s] 52%|█████▏    | 5241/10000 [00:14<00:15, 309.95it/s] 53%|█████▎    | 5277/10000 [00:14<00:17, 269.25it/s] 53%|█████▎    | 5308/10000 [00:14<00:17, 266.35it/s] 53%|█████▎    | 5338/10000 [00:15<00:17, 267.92it/s] 54%|█████▎    | 5367/10000 [00:15<00:18, 246.34it/s] 54%|█████▍    | 5393/10000 [00:15<00:19, 233.53it/s] 54%|█████▍    | 5423/10000 [00:15<00:18, 246.03it/s] 55%|█████▍    | 5489/10000 [00:15<00:13, 343.09it/s] 55%|█████▌    | 5526/10000 [00:15<00:14, 317.59it/s] 56%|█████▌    | 5588/10000 [00:15<00:11, 383.51it/s] 56%|█████▋    | 5643/10000 [00:15<00:10, 412.99it/s] 57%|█████▋    | 5696/10000 [00:16<00:09, 435.57it/s] 58%|█████▊    | 5762/10000 [00:16<00:08, 492.85it/s] 58%|█████▊    | 5813/10000 [00:16<00:09, 448.35it/s] 59%|█████▊    | 5860/10000 [00:16<00:09, 414.70it/s] 59%|█████▉    | 5903/10000 [00:16<00:10, 372.96it/s] 59%|█████▉    | 5942/10000 [00:16<00:11, 358.13it/s] 60%|█████▉    | 5979/10000 [00:16<00:12, 332.17it/s] 60%|██████    | 6013/10000 [00:16<00:12, 324.14it/s] 61%|██████    | 6060/10000 [00:17<00:10, 358.57it/s] 61%|██████▏   | 6128/10000 [00:17<00:08, 433.79it/s] 62%|██████▏   | 6184/10000 [00:17<00:08, 466.06it/s] 62%|██████▏   | 6232/10000 [00:17<00:10, 374.59it/s] 63%|██████▎   | 6273/10000 [00:17<00:10, 358.00it/s] 63%|██████▎   | 6312/10000 [00:17<00:11, 332.15it/s] 63%|██████▎   | 6347/10000 [00:17<00:13, 279.99it/s] 64%|██████▍   | 6378/10000 [00:18<00:13, 262.58it/s] 64%|██████▍   | 6409/10000 [00:18<00:13, 269.82it/s] 64%|██████▍   | 6440/10000 [00:18<00:12, 279.05it/s] 65%|██████▍   | 6474/10000 [00:18<00:12, 280.91it/s] 65%|██████▌   | 6505/10000 [00:18<00:12, 286.57it/s] 65%|██████▌   | 6535/10000 [00:18<00:12, 282.15it/s] 66%|██████▌   | 6564/10000 [00:18<00:12, 272.14it/s] 66%|██████▌   | 6597/10000 [00:18<00:11, 287.13it/s] 66%|██████▋   | 6633/10000 [00:18<00:11, 305.25it/s] 67%|██████▋   | 6670/10000 [00:18<00:10, 315.26it/s] 67%|██████▋   | 6702/10000 [00:19<00:10, 310.85it/s] 68%|██████▊   | 6753/10000 [00:19<00:08, 367.38it/s] 68%|██████▊   | 6791/10000 [00:19<00:09, 336.13it/s] 69%|██████▊   | 6851/10000 [00:19<00:07, 398.68it/s] 69%|██████▉   | 6916/10000 [00:19<00:06, 466.68it/s] 70%|██████▉   | 6964/10000 [00:19<00:07, 425.99it/s] 70%|███████   | 7011/10000 [00:19<00:07, 425.52it/s] 71%|███████   | 7062/10000 [00:19<00:06, 441.18it/s] 71%|███████▏  | 7127/10000 [00:20<00:05, 491.93it/s] 72%|███████▏  | 7178/10000 [00:20<00:05, 487.56it/s] 72%|███████▏  | 7228/10000 [00:20<00:05, 479.63it/s] 73%|███████▎  | 7287/10000 [00:20<00:05, 505.99it/s] 73%|███████▎  | 7338/10000 [00:20<00:05, 497.33it/s] 74%|███████▍  | 7388/10000 [00:20<00:05, 447.40it/s] 74%|███████▍  | 7439/10000 [00:20<00:05, 455.70it/s] 75%|███████▍  | 7492/10000 [00:20<00:05, 464.51it/s] 75%|███████▌  | 7540/10000 [00:20<00:05, 456.02it/s] 76%|███████▌  | 7586/10000 [00:21<00:05, 425.55it/s] 76%|███████▋  | 7630/10000 [00:21<00:05, 403.62it/s] 77%|███████▋  | 7671/10000 [00:21<00:05, 389.71it/s] 77%|███████▋  | 7711/10000 [00:21<00:05, 390.58it/s] 78%|███████▊  | 7751/10000 [00:21<00:06, 343.00it/s] 78%|███████▊  | 7787/10000 [00:21<00:06, 331.82it/s] 78%|███████▊  | 7827/10000 [00:21<00:06, 342.58it/s] 79%|███████▉  | 7876/10000 [00:21<00:05, 377.34it/s] 79%|███████▉  | 7940/10000 [00:21<00:04, 446.22it/s] 80%|████████  | 8020/10000 [00:22<00:03, 541.25it/s] 81%|████████  | 8076/10000 [00:22<00:03, 487.01it/s] 81%|████████▏ | 8127/10000 [00:22<00:03, 477.48it/s] 82%|████████▏ | 8177/10000 [00:22<00:03, 468.86it/s] 82%|████████▏ | 8225/10000 [00:22<00:04, 432.53it/s] 83%|████████▎ | 8270/10000 [00:22<00:04, 350.63it/s] 83%|████████▎ | 8308/10000 [00:22<00:04, 341.99it/s] 83%|████████▎ | 8345/10000 [00:22<00:04, 333.49it/s] 84%|████████▍ | 8380/10000 [00:23<00:05, 318.24it/s] 84%|████████▍ | 8413/10000 [00:23<00:05, 306.03it/s] 85%|████████▍ | 8462/10000 [00:23<00:04, 347.20it/s] 85%|████████▌ | 8515/10000 [00:23<00:03, 387.14it/s] 86%|████████▌ | 8555/10000 [00:23<00:03, 390.32it/s] 86%|████████▌ | 8595/10000 [00:23<00:03, 390.60it/s] 87%|████████▋ | 8653/10000 [00:23<00:03, 437.96it/s] 87%|████████▋ | 8711/10000 [00:23<00:02, 476.59it/s] 88%|████████▊ | 8783/10000 [00:23<00:02, 535.95it/s] 89%|████████▊ | 8853/10000 [00:24<00:01, 574.89it/s] 89%|████████▉ | 8918/10000 [00:24<00:01, 586.87it/s] 90%|█████████ | 9014/10000 [00:24<00:01, 677.08it/s] 91%|█████████ | 9082/10000 [00:24<00:01, 674.64it/s] 92%|█████████▏| 9150/10000 [00:24<00:01, 638.05it/s] 92%|█████████▏| 9215/10000 [00:24<00:01, 523.62it/s] 93%|█████████▎| 9271/10000 [00:24<00:01, 443.26it/s] 93%|█████████▎| 9320/10000 [00:25<00:01, 360.73it/s] 94%|█████████▎| 9361/10000 [00:25<00:01, 324.03it/s] 94%|█████████▍| 9397/10000 [00:25<00:02, 295.20it/s] 94%|█████████▍| 9431/10000 [00:25<00:01, 304.03it/s] 95%|█████████▍| 9470/10000 [00:25<00:01, 311.90it/s] 95%|█████████▌| 9507/10000 [00:25<00:01, 323.59it/s] 95%|█████████▌| 9542/10000 [00:25<00:01, 328.58it/s] 96%|█████████▌| 9579/10000 [00:25<00:01, 324.97it/s] 96%|█████████▌| 9613/10000 [00:26<00:01, 328.80it/s] 96%|█████████▋| 9647/10000 [00:26<00:01, 326.70it/s] 97%|█████████▋| 9689/10000 [00:26<00:00, 337.86it/s] 97%|█████████▋| 9724/10000 [00:26<00:00, 334.21it/s] 98%|█████████▊| 9759/10000 [00:26<00:00, 337.76it/s] 98%|█████████▊| 9821/10000 [00:26<00:00, 415.92it/s] 99%|█████████▉| 9881/10000 [00:26<00:00, 467.82it/s] 99%|█████████▉| 9939/10000 [00:26<00:00, 492.95it/s]100%|██████████| 10000/10000 [00:26<00:00, 372.70it/s]
test_neglected_p81 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p81
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p81.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:51,  1.31s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:07,  4.61it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:03,  9.99it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 15.75it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 21.56it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 26.98it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 31.71it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:02<00:00, 35.59it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 38.46it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 18.03it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p81_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p81_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p81_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p81_Holmes_probs.npy
{'Accuracy': 0.0197, 'Precision': 0.0218, 'Recall': 0.0194, 'F1-score': 0.0169}
starting gen taf script for test_neglected_p82
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 79/10000 [00:00<00:14, 684.65it/s]  1%|▏         | 148/10000 [00:00<00:24, 401.23it/s]  2%|▏         | 194/10000 [00:00<00:28, 343.47it/s]  2%|▏         | 232/10000 [00:00<00:28, 346.51it/s]  3%|▎         | 269/10000 [00:00<00:31, 311.99it/s]  3%|▎         | 302/10000 [00:00<00:31, 304.17it/s]  3%|▎         | 335/10000 [00:00<00:31, 309.72it/s]  4%|▎         | 367/10000 [00:01<00:33, 284.84it/s]  4%|▍         | 396/10000 [00:01<00:35, 273.40it/s]  4%|▍         | 429/10000 [00:01<00:33, 283.39it/s]  5%|▍         | 464/10000 [00:01<00:32, 297.66it/s]  5%|▍         | 498/10000 [00:01<00:30, 309.16it/s]  5%|▌         | 542/10000 [00:01<00:27, 339.71it/s]  6%|▌         | 594/10000 [00:01<00:24, 384.87it/s]  6%|▋         | 633/10000 [00:01<00:26, 350.53it/s]  7%|▋         | 669/10000 [00:02<00:28, 329.26it/s]  7%|▋         | 703/10000 [00:02<00:32, 282.91it/s]  7%|▋         | 733/10000 [00:02<00:33, 272.87it/s]  8%|▊         | 763/10000 [00:02<00:33, 279.49it/s]  8%|▊         | 799/10000 [00:02<00:30, 299.80it/s]  8%|▊         | 830/10000 [00:02<00:31, 291.69it/s]  9%|▊         | 860/10000 [00:02<00:33, 272.38it/s]  9%|▉         | 889/10000 [00:02<00:34, 266.90it/s]  9%|▉         | 943/10000 [00:02<00:27, 331.27it/s] 10%|▉         | 977/10000 [00:03<00:29, 304.04it/s] 10%|█         | 1009/10000 [00:03<00:29, 300.12it/s] 10%|█         | 1042/10000 [00:03<00:29, 305.99it/s] 11%|█         | 1075/10000 [00:03<00:28, 311.46it/s] 11%|█         | 1107/10000 [00:03<00:29, 303.44it/s] 11%|█▏        | 1145/10000 [00:03<00:28, 315.24it/s] 12%|█▏        | 1177/10000 [00:03<00:29, 298.94it/s] 12%|█▏        | 1219/10000 [00:03<00:26, 328.81it/s] 13%|█▎        | 1281/10000 [00:03<00:21, 402.78it/s] 13%|█▎        | 1322/10000 [00:04<00:21, 402.56it/s] 14%|█▎        | 1363/10000 [00:04<00:23, 370.04it/s] 14%|█▍        | 1407/10000 [00:04<00:22, 377.86it/s] 14%|█▍        | 1446/10000 [00:04<00:28, 295.53it/s] 15%|█▍        | 1479/10000 [00:04<00:30, 275.99it/s] 15%|█▌        | 1509/10000 [00:04<00:32, 260.70it/s] 15%|█▌        | 1537/10000 [00:05<00:38, 221.20it/s] 16%|█▌        | 1572/10000 [00:05<00:34, 243.40it/s] 16%|█▌        | 1599/10000 [00:05<00:36, 231.82it/s] 17%|█▋        | 1657/10000 [00:05<00:26, 314.12it/s] 17%|█▋        | 1706/10000 [00:05<00:23, 357.13it/s] 18%|█▊        | 1777/10000 [00:05<00:18, 442.48it/s] 19%|█▊        | 1857/10000 [00:05<00:15, 533.20it/s] 20%|█▉        | 1953/10000 [00:05<00:12, 645.33it/s] 20%|██        | 2021/10000 [00:05<00:12, 637.55it/s] 21%|██        | 2087/10000 [00:06<00:14, 560.19it/s] 21%|██▏       | 2146/10000 [00:06<00:14, 551.11it/s] 22%|██▏       | 2203/10000 [00:06<00:15, 512.11it/s] 23%|██▎       | 2256/10000 [00:06<00:18, 429.57it/s] 23%|██▎       | 2302/10000 [00:06<00:19, 400.74it/s] 23%|██▎       | 2345/10000 [00:06<00:22, 340.26it/s] 24%|██▍       | 2382/10000 [00:06<00:23, 325.67it/s] 24%|██▍       | 2422/10000 [00:07<00:22, 332.85it/s] 25%|██▍       | 2489/10000 [00:07<00:18, 408.84it/s] 25%|██▌       | 2541/10000 [00:07<00:17, 436.60it/s] 26%|██▌       | 2587/10000 [00:07<00:19, 385.31it/s] 26%|██▋       | 2628/10000 [00:07<00:23, 310.10it/s] 27%|██▋       | 2663/10000 [00:07<00:28, 254.91it/s] 27%|██▋       | 2694/10000 [00:07<00:27, 264.66it/s] 27%|██▋       | 2724/10000 [00:08<00:28, 258.41it/s] 28%|██▊       | 2752/10000 [00:08<00:30, 236.92it/s] 28%|██▊       | 2778/10000 [00:08<00:35, 203.30it/s] 28%|██▊       | 2833/10000 [00:08<00:25, 277.54it/s] 29%|██▉       | 2876/10000 [00:08<00:22, 313.34it/s] 29%|██▉       | 2926/10000 [00:08<00:19, 359.25it/s] 30%|██▉       | 2981/10000 [00:08<00:17, 408.68it/s] 30%|███       | 3026/10000 [00:08<00:16, 417.75it/s] 31%|███       | 3071/10000 [00:08<00:17, 385.95it/s] 31%|███       | 3112/10000 [00:09<00:22, 309.98it/s] 31%|███▏      | 3147/10000 [00:09<00:22, 306.55it/s] 32%|███▏      | 3189/10000 [00:09<00:20, 332.06it/s] 32%|███▏      | 3243/10000 [00:09<00:17, 383.23it/s] 33%|███▎      | 3314/10000 [00:09<00:14, 466.17it/s] 34%|███▍      | 3400/10000 [00:09<00:11, 572.95it/s] 35%|███▍      | 3461/10000 [00:09<00:12, 542.60it/s] 35%|███▌      | 3518/10000 [00:10<00:13, 480.50it/s] 36%|███▌      | 3572/10000 [00:10<00:13, 479.37it/s] 36%|███▌      | 3622/10000 [00:10<00:13, 478.89it/s] 37%|███▋      | 3690/10000 [00:10<00:11, 530.69it/s] 38%|███▊      | 3772/10000 [00:10<00:10, 601.94it/s] 38%|███▊      | 3835/10000 [00:10<00:10, 607.08it/s] 39%|███▉      | 3897/10000 [00:10<00:12, 474.21it/s] 40%|███▉      | 3951/10000 [00:10<00:12, 485.45it/s] 40%|████      | 4006/10000 [00:10<00:11, 501.81it/s] 41%|████      | 4067/10000 [00:11<00:11, 521.01it/s] 41%|████▏     | 4134/10000 [00:11<00:10, 550.18it/s] 42%|████▏     | 4204/10000 [00:11<00:09, 580.00it/s] 43%|████▎     | 4264/10000 [00:11<00:10, 535.64it/s] 43%|████▎     | 4323/10000 [00:11<00:10, 550.09it/s] 44%|████▍     | 4387/10000 [00:11<00:09, 570.49it/s] 44%|████▍     | 4446/10000 [00:11<00:11, 477.39it/s] 45%|████▍     | 4497/10000 [00:11<00:13, 396.07it/s] 45%|████▌     | 4541/10000 [00:12<00:14, 370.70it/s] 46%|████▌     | 4581/10000 [00:12<00:17, 305.38it/s] 46%|████▌     | 4620/10000 [00:12<00:16, 322.88it/s] 47%|████▋     | 4656/10000 [00:12<00:17, 301.78it/s] 47%|████▋     | 4692/10000 [00:12<00:17, 310.81it/s] 47%|████▋     | 4725/10000 [00:12<00:18, 291.56it/s] 48%|████▊     | 4756/10000 [00:12<00:17, 294.52it/s] 48%|████▊     | 4806/10000 [00:12<00:15, 339.40it/s] 48%|████▊     | 4841/10000 [00:13<00:15, 322.59it/s] 49%|████▉     | 4875/10000 [00:13<00:19, 263.18it/s] 49%|████▉     | 4912/10000 [00:13<00:18, 281.70it/s] 49%|████▉     | 4943/10000 [00:13<00:20, 252.19it/s] 50%|████▉     | 4974/10000 [00:13<00:19, 259.65it/s] 50%|█████     | 5002/10000 [00:13<00:19, 254.37it/s] 50%|█████     | 5038/10000 [00:13<00:17, 279.21it/s] 51%|█████     | 5114/10000 [00:14<00:12, 397.80it/s] 52%|█████▏    | 5157/10000 [00:14<00:12, 396.78it/s] 52%|█████▏    | 5209/10000 [00:14<00:11, 429.16it/s] 53%|█████▎    | 5253/10000 [00:14<00:16, 291.51it/s] 53%|█████▎    | 5289/10000 [00:14<00:17, 266.77it/s] 53%|█████▎    | 5321/10000 [00:14<00:17, 267.75it/s] 54%|█████▎    | 5363/10000 [00:14<00:16, 277.59it/s] 54%|█████▍    | 5398/10000 [00:15<00:15, 288.79it/s] 54%|█████▍    | 5434/10000 [00:15<00:15, 302.71it/s] 55%|█████▍    | 5485/10000 [00:15<00:12, 348.64it/s] 55%|█████▌    | 5526/10000 [00:15<00:12, 363.24it/s] 56%|█████▌    | 5564/10000 [00:15<00:12, 354.76it/s] 56%|█████▌    | 5612/10000 [00:15<00:11, 381.69it/s] 57%|█████▋    | 5689/10000 [00:15<00:09, 473.54it/s] 57%|█████▋    | 5749/10000 [00:15<00:08, 508.12it/s] 58%|█████▊    | 5802/10000 [00:15<00:08, 483.44it/s] 59%|█████▊    | 5852/10000 [00:16<00:10, 384.24it/s] 59%|█████▉    | 5902/10000 [00:16<00:09, 411.52it/s] 59%|█████▉    | 5947/10000 [00:16<00:11, 367.88it/s] 60%|█████▉    | 5987/10000 [00:16<00:12, 325.86it/s] 60%|██████    | 6032/10000 [00:16<00:11, 348.68it/s] 61%|██████    | 6093/10000 [00:16<00:09, 403.63it/s] 62%|██████▏   | 6153/10000 [00:16<00:08, 444.54it/s] 62%|██████▏   | 6200/10000 [00:16<00:09, 410.12it/s] 62%|██████▏   | 6243/10000 [00:17<00:11, 338.48it/s] 63%|██████▎   | 6280/10000 [00:17<00:11, 321.51it/s] 63%|██████▎   | 6315/10000 [00:17<00:11, 318.33it/s] 63%|██████▎   | 6349/10000 [00:17<00:13, 270.00it/s] 64%|██████▍   | 6378/10000 [00:17<00:14, 251.26it/s] 64%|██████▍   | 6415/10000 [00:17<00:13, 274.57it/s] 64%|██████▍   | 6444/10000 [00:17<00:13, 273.35it/s] 65%|██████▍   | 6475/10000 [00:18<00:12, 278.80it/s] 65%|██████▌   | 6508/10000 [00:18<00:12, 288.60it/s] 65%|██████▌   | 6538/10000 [00:18<00:11, 289.97it/s] 66%|██████▌   | 6570/10000 [00:18<00:11, 296.68it/s] 66%|██████▌   | 6602/10000 [00:18<00:11, 300.71it/s] 66%|██████▋   | 6640/10000 [00:18<00:10, 317.68it/s] 67%|██████▋   | 6680/10000 [00:18<00:09, 341.17it/s] 67%|██████▋   | 6715/10000 [00:18<00:10, 298.80it/s] 67%|██████▋   | 6746/10000 [00:18<00:10, 301.09it/s] 68%|██████▊   | 6799/10000 [00:19<00:08, 363.83it/s] 68%|██████▊   | 6846/10000 [00:19<00:08, 382.99it/s] 69%|██████▉   | 6905/10000 [00:19<00:07, 429.61it/s] 70%|██████▉   | 6987/10000 [00:19<00:05, 528.96it/s] 70%|███████   | 7041/10000 [00:19<00:06, 467.82it/s] 71%|███████   | 7109/10000 [00:19<00:05, 507.16it/s] 72%|███████▏  | 7162/10000 [00:19<00:05, 501.06it/s] 72%|███████▏  | 7213/10000 [00:19<00:05, 491.60it/s] 73%|███████▎  | 7275/10000 [00:19<00:05, 526.68it/s] 73%|███████▎  | 7340/10000 [00:20<00:04, 548.57it/s] 74%|███████▍  | 7417/10000 [00:20<00:04, 603.41it/s] 75%|███████▍  | 7478/10000 [00:20<00:04, 520.63it/s] 76%|███████▌  | 7563/10000 [00:20<00:04, 575.37it/s] 76%|███████▌  | 7623/10000 [00:20<00:04, 519.32it/s] 77%|███████▋  | 7677/10000 [00:20<00:05, 462.61it/s] 77%|███████▋  | 7726/10000 [00:20<00:05, 389.99it/s] 78%|███████▊  | 7768/10000 [00:21<00:05, 393.61it/s] 78%|███████▊  | 7810/10000 [00:21<00:05, 396.74it/s] 79%|███████▊  | 7872/10000 [00:21<00:04, 453.10it/s] 80%|███████▉  | 7950/10000 [00:21<00:03, 538.17it/s] 80%|████████  | 8019/10000 [00:21<00:03, 579.75it/s] 81%|████████  | 8080/10000 [00:21<00:03, 584.81it/s] 81%|████████▏ | 8141/10000 [00:21<00:03, 581.95it/s] 82%|████████▏ | 8201/10000 [00:21<00:03, 522.33it/s] 83%|████████▎ | 8256/10000 [00:21<00:03, 513.36it/s] 83%|████████▎ | 8309/10000 [00:22<00:03, 447.31it/s] 84%|████████▎ | 8356/10000 [00:22<00:04, 348.28it/s] 84%|████████▍ | 8402/10000 [00:22<00:04, 366.21it/s] 84%|████████▍ | 8443/10000 [00:22<00:04, 362.60it/s] 85%|████████▍ | 8499/10000 [00:22<00:03, 407.52it/s] 85%|████████▌ | 8543/10000 [00:22<00:03, 405.50it/s] 86%|████████▌ | 8593/10000 [00:22<00:03, 422.62it/s] 86%|████████▋ | 8650/10000 [00:22<00:02, 456.59it/s] 87%|████████▋ | 8724/10000 [00:23<00:02, 523.81it/s] 88%|████████▊ | 8786/10000 [00:23<00:02, 547.02it/s] 88%|████████▊ | 8849/10000 [00:23<00:02, 562.15it/s] 89%|████████▉ | 8913/10000 [00:23<00:01, 584.02it/s] 90%|████████▉ | 8982/10000 [00:23<00:01, 613.08it/s] 90%|█████████ | 9050/10000 [00:23<00:01, 616.54it/s] 91%|█████████ | 9112/10000 [00:23<00:01, 610.20it/s] 92%|█████████▏| 9187/10000 [00:23<00:01, 640.86it/s] 93%|█████████▎| 9252/10000 [00:23<00:01, 529.92it/s] 93%|█████████▎| 9309/10000 [00:24<00:01, 412.42it/s] 94%|█████████▎| 9357/10000 [00:24<00:01, 398.52it/s] 94%|█████████▍| 9401/10000 [00:24<00:01, 338.23it/s] 94%|█████████▍| 9439/10000 [00:24<00:01, 307.91it/s] 95%|█████████▍| 9485/10000 [00:24<00:01, 334.39it/s] 95%|█████████▌| 9522/10000 [00:24<00:01, 296.87it/s] 96%|█████████▌| 9565/10000 [00:25<00:01, 316.22it/s] 96%|█████████▌| 9603/10000 [00:25<00:01, 322.61it/s] 96%|█████████▋| 9649/10000 [00:25<00:00, 353.39it/s] 97%|█████████▋| 9687/10000 [00:25<00:00, 359.01it/s] 97%|█████████▋| 9728/10000 [00:25<00:00, 368.96it/s] 98%|█████████▊| 9771/10000 [00:25<00:00, 381.50it/s] 98%|█████████▊| 9810/10000 [00:25<00:00, 351.08it/s] 99%|█████████▉| 9888/10000 [00:25<00:00, 455.61it/s]100%|█████████▉| 9955/10000 [00:25<00:00, 513.02it/s]100%|██████████| 10000/10000 [00:25<00:00, 385.56it/s]
test_neglected_p82 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p82
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p82.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.09s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.44it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.61it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 17.90it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 23.89it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.24it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.75it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.35it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.75it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.49it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p82_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p82_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p82_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p82_Holmes_probs.npy
{'Accuracy': 0.0198, 'Precision': 0.022, 'Recall': 0.0195, 'F1-score': 0.017}
starting gen taf script for test_neglected_p83
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 80/10000 [00:00<00:12, 798.04it/s]  2%|▏         | 160/10000 [00:00<00:26, 365.15it/s]  2%|▏         | 209/10000 [00:00<00:31, 315.28it/s]  2%|▏         | 247/10000 [00:00<00:34, 280.72it/s]  3%|▎         | 279/10000 [00:00<00:34, 278.95it/s]  3%|▎         | 309/10000 [00:01<00:36, 268.82it/s]  3%|▎         | 340/10000 [00:01<00:34, 276.37it/s]  4%|▎         | 369/10000 [00:01<00:35, 272.20it/s]  4%|▍         | 397/10000 [00:01<00:37, 253.67it/s]  4%|▍         | 423/10000 [00:01<00:38, 250.96it/s]  5%|▍         | 458/10000 [00:01<00:34, 275.71it/s]  5%|▍         | 489/10000 [00:01<00:34, 275.99it/s]  5%|▌         | 533/10000 [00:01<00:30, 308.22it/s]  6%|▌         | 573/10000 [00:01<00:28, 329.05it/s]  6%|▌         | 607/10000 [00:02<00:30, 305.82it/s]  7%|▋         | 661/10000 [00:02<00:25, 360.34it/s]  7%|▋         | 721/10000 [00:02<00:22, 419.40it/s]  8%|▊         | 787/10000 [00:02<00:19, 473.51it/s]  8%|▊         | 836/10000 [00:02<00:20, 457.72it/s]  9%|▉         | 883/10000 [00:02<00:23, 389.70it/s]  9%|▉         | 924/10000 [00:02<00:23, 386.35it/s] 10%|▉         | 969/10000 [00:02<00:22, 400.57it/s] 10%|█         | 1011/10000 [00:02<00:22, 399.89it/s] 11%|█         | 1052/10000 [00:03<00:22, 393.08it/s] 11%|█         | 1092/10000 [00:03<00:23, 372.11it/s] 11%|█▏        | 1130/10000 [00:03<00:26, 330.41it/s] 12%|█▏        | 1183/10000 [00:03<00:23, 378.61it/s] 12%|█▏        | 1223/10000 [00:03<00:23, 369.00it/s] 13%|█▎        | 1270/10000 [00:03<00:22, 392.30it/s] 13%|█▎        | 1330/10000 [00:03<00:19, 439.40it/s] 14%|█▍        | 1381/10000 [00:03<00:19, 447.50it/s] 14%|█▍        | 1427/10000 [00:03<00:19, 433.85it/s] 15%|█▍        | 1471/10000 [00:04<00:25, 332.70it/s] 15%|█▌        | 1508/10000 [00:04<00:29, 283.61it/s] 15%|█▌        | 1540/10000 [00:04<00:33, 249.38it/s] 16%|█▌        | 1568/10000 [00:04<00:37, 224.65it/s] 16%|█▌        | 1615/10000 [00:04<00:30, 273.55it/s] 17%|█▋        | 1662/10000 [00:04<00:26, 314.01it/s] 17%|█▋        | 1722/10000 [00:05<00:21, 383.10it/s] 18%|█▊        | 1787/10000 [00:05<00:18, 451.66it/s] 19%|█▊        | 1861/10000 [00:05<00:15, 525.81it/s] 20%|█▉        | 1964/10000 [00:05<00:12, 658.58it/s] 20%|██        | 2034/10000 [00:05<00:12, 636.23it/s] 21%|██        | 2100/10000 [00:05<00:14, 556.72it/s] 22%|██▏       | 2159/10000 [00:05<00:14, 544.45it/s] 22%|██▏       | 2216/10000 [00:05<00:16, 465.82it/s] 23%|██▎       | 2266/10000 [00:06<00:19, 397.43it/s] 23%|██▎       | 2310/10000 [00:06<00:20, 373.02it/s] 24%|██▎       | 2350/10000 [00:06<00:21, 350.79it/s] 24%|██▍       | 2387/10000 [00:06<00:22, 343.90it/s] 24%|██▍       | 2423/10000 [00:06<00:23, 320.44it/s] 25%|██▍       | 2479/10000 [00:06<00:20, 371.10it/s] 25%|██▌       | 2536/10000 [00:06<00:18, 412.32it/s] 26%|██▌       | 2588/10000 [00:06<00:17, 428.84it/s] 26%|██▋       | 2632/10000 [00:07<00:18, 390.49it/s] 27%|██▋       | 2673/10000 [00:07<00:26, 273.54it/s] 27%|██▋       | 2706/10000 [00:07<00:27, 264.98it/s] 27%|██▋       | 2737/10000 [00:07<00:31, 228.06it/s] 28%|██▊       | 2763/10000 [00:07<00:31, 233.15it/s] 28%|██▊       | 2789/10000 [00:07<00:33, 215.33it/s] 28%|██▊       | 2825/10000 [00:08<00:29, 247.37it/s] 29%|██▊       | 2872/10000 [00:08<00:23, 297.58it/s] 29%|██▉       | 2932/10000 [00:08<00:18, 374.16it/s] 30%|██▉       | 2973/10000 [00:08<00:18, 373.90it/s] 30%|███       | 3013/10000 [00:08<00:18, 372.39it/s] 31%|███       | 3056/10000 [00:08<00:18, 368.82it/s] 31%|███       | 3094/10000 [00:08<00:21, 327.49it/s] 31%|███▏      | 3129/10000 [00:08<00:20, 332.96it/s] 32%|███▏      | 3164/10000 [00:08<00:20, 336.93it/s] 32%|███▏      | 3199/10000 [00:09<00:21, 310.94it/s] 33%|███▎      | 3260/10000 [00:09<00:17, 389.42it/s] 34%|███▎      | 3353/10000 [00:09<00:12, 527.72it/s] 34%|███▍      | 3408/10000 [00:09<00:12, 523.78it/s] 35%|███▍      | 3462/10000 [00:09<00:14, 439.67it/s] 35%|███▌      | 3509/10000 [00:09<00:15, 430.46it/s] 36%|███▌      | 3559/10000 [00:09<00:15, 425.22it/s] 36%|███▌      | 3610/10000 [00:09<00:14, 444.82it/s] 37%|███▋      | 3699/10000 [00:10<00:11, 547.88it/s] 38%|███▊      | 3756/10000 [00:10<00:11, 541.26it/s] 38%|███▊      | 3812/10000 [00:10<00:11, 538.35it/s] 39%|███▊      | 3867/10000 [00:10<00:11, 523.08it/s] 39%|███▉      | 3920/10000 [00:10<00:12, 486.92it/s] 40%|███▉      | 3970/10000 [00:10<00:14, 425.24it/s] 40%|████      | 4016/10000 [00:10<00:13, 427.69it/s] 41%|████      | 4081/10000 [00:10<00:12, 480.47it/s] 42%|████▏     | 4172/10000 [00:10<00:09, 592.68it/s] 42%|████▏     | 4234/10000 [00:11<00:10, 531.80it/s] 43%|████▎     | 4311/10000 [00:11<00:09, 593.10it/s] 44%|████▎     | 4373/10000 [00:11<00:10, 553.17it/s] 44%|████▍     | 4431/10000 [00:11<00:11, 503.40it/s] 45%|████▍     | 4484/10000 [00:11<00:13, 418.97it/s] 45%|████▌     | 4530/10000 [00:11<00:15, 363.57it/s] 46%|████▌     | 4570/10000 [00:11<00:16, 331.40it/s] 46%|████▌     | 4606/10000 [00:12<00:16, 318.73it/s] 46%|████▋     | 4645/10000 [00:12<00:16, 328.68it/s] 47%|████▋     | 4680/10000 [00:12<00:17, 297.56it/s] 47%|████▋     | 4711/10000 [00:12<00:19, 271.37it/s] 48%|████▊     | 4759/10000 [00:12<00:16, 318.91it/s] 48%|████▊     | 4793/10000 [00:12<00:16, 320.06it/s] 48%|████▊     | 4827/10000 [00:12<00:18, 285.55it/s] 49%|████▊     | 4857/10000 [00:13<00:19, 265.28it/s] 49%|████▉     | 4885/10000 [00:13<00:19, 268.03it/s] 49%|████▉     | 4913/10000 [00:13<00:21, 237.73it/s] 49%|████▉     | 4942/10000 [00:13<00:20, 245.97it/s] 50%|████▉     | 4968/10000 [00:13<00:22, 221.14it/s] 50%|█████     | 5000/10000 [00:13<00:20, 240.49it/s] 51%|█████     | 5064/10000 [00:13<00:14, 342.15it/s] 51%|█████     | 5101/10000 [00:13<00:14, 348.46it/s] 52%|█████▏    | 5168/10000 [00:13<00:11, 430.26it/s] 52%|█████▏    | 5213/10000 [00:14<00:11, 402.24it/s] 53%|█████▎    | 5255/10000 [00:14<00:14, 332.22it/s] 53%|█████▎    | 5292/10000 [00:14<00:19, 243.24it/s] 53%|█████▎    | 5326/10000 [00:14<00:18, 256.81it/s] 54%|█████▎    | 5356/10000 [00:14<00:18, 253.91it/s] 54%|█████▍    | 5385/10000 [00:14<00:19, 236.96it/s] 54%|█████▍    | 5419/10000 [00:14<00:17, 258.57it/s] 55%|█████▍    | 5459/10000 [00:15<00:15, 288.55it/s] 55%|█████▍    | 5498/10000 [00:15<00:14, 313.45it/s] 55%|█████▌    | 5532/10000 [00:15<00:14, 307.72it/s] 56%|█████▌    | 5600/10000 [00:15<00:10, 407.15it/s] 56%|█████▋    | 5646/10000 [00:15<00:10, 418.26it/s] 57%|█████▋    | 5706/10000 [00:15<00:09, 453.27it/s] 58%|█████▊    | 5772/10000 [00:15<00:08, 489.95it/s] 58%|█████▊    | 5822/10000 [00:15<00:09, 440.31it/s] 59%|█████▊    | 5868/10000 [00:16<00:10, 385.24it/s] 59%|█████▉    | 5909/10000 [00:16<00:12, 325.72it/s] 59%|█████▉    | 5947/10000 [00:16<00:12, 334.15it/s] 60%|█████▉    | 5983/10000 [00:16<00:12, 329.09it/s] 60%|██████    | 6018/10000 [00:16<00:13, 297.88it/s] 61%|██████    | 6085/10000 [00:16<00:10, 380.66it/s] 61%|██████▏   | 6149/10000 [00:16<00:09, 425.90it/s] 62%|██████▏   | 6198/10000 [00:16<00:09, 422.12it/s] 62%|██████▏   | 6242/10000 [00:17<00:09, 401.08it/s] 63%|██████▎   | 6284/10000 [00:17<00:11, 332.43it/s] 63%|██████▎   | 6320/10000 [00:17<00:11, 330.84it/s] 64%|██████▎   | 6355/10000 [00:17<00:11, 315.05it/s] 64%|██████▍   | 6388/10000 [00:17<00:11, 318.44it/s] 64%|██████▍   | 6421/10000 [00:17<00:12, 298.24it/s] 65%|██████▍   | 6452/10000 [00:17<00:12, 279.93it/s] 65%|██████▍   | 6490/10000 [00:17<00:11, 303.94it/s] 65%|██████▌   | 6522/10000 [00:18<00:12, 280.47it/s] 66%|██████▌   | 6551/10000 [00:18<00:12, 274.23it/s] 66%|██████▌   | 6579/10000 [00:18<00:13, 253.82it/s] 66%|██████▋   | 6625/10000 [00:18<00:11, 301.99it/s] 67%|██████▋   | 6657/10000 [00:18<00:11, 299.00it/s] 67%|██████▋   | 6688/10000 [00:18<00:11, 299.31it/s] 67%|██████▋   | 6744/10000 [00:18<00:09, 357.06it/s] 68%|██████▊   | 6780/10000 [00:18<00:09, 346.76it/s] 68%|██████▊   | 6824/10000 [00:18<00:08, 369.60it/s] 69%|██████▉   | 6909/10000 [00:19<00:06, 498.60it/s] 70%|██████▉   | 6964/10000 [00:19<00:05, 508.19it/s] 70%|███████   | 7016/10000 [00:19<00:06, 474.18it/s] 71%|███████   | 7083/10000 [00:19<00:05, 528.04it/s] 71%|███████▏  | 7137/10000 [00:19<00:05, 487.20it/s] 72%|███████▏  | 7187/10000 [00:19<00:06, 442.73it/s] 72%|███████▏  | 7241/10000 [00:19<00:05, 463.86it/s] 73%|███████▎  | 7289/10000 [00:19<00:06, 446.10it/s] 73%|███████▎  | 7347/10000 [00:20<00:05, 470.60it/s] 74%|███████▍  | 7403/10000 [00:20<00:05, 492.69it/s] 75%|███████▍  | 7467/10000 [00:20<00:04, 512.29it/s] 75%|███████▌  | 7519/10000 [00:20<00:05, 495.49it/s] 76%|███████▌  | 7569/10000 [00:20<00:04, 488.20it/s] 76%|███████▋  | 7631/10000 [00:20<00:04, 509.60it/s] 77%|███████▋  | 7683/10000 [00:20<00:05, 410.83it/s] 77%|███████▋  | 7730/10000 [00:20<00:05, 419.79it/s] 78%|███████▊  | 7775/10000 [00:21<00:06, 368.40it/s] 79%|███████▊  | 7858/10000 [00:21<00:04, 473.52it/s] 79%|███████▉  | 7910/10000 [00:21<00:04, 474.20it/s] 80%|███████▉  | 7969/10000 [00:21<00:04, 497.01it/s] 80%|████████  | 8021/10000 [00:21<00:03, 499.65it/s] 81%|████████  | 8073/10000 [00:21<00:03, 499.51it/s] 81%|████████▏ | 8134/10000 [00:21<00:03, 528.64it/s] 82%|████████▏ | 8188/10000 [00:21<00:03, 494.38it/s] 82%|████████▏ | 8245/10000 [00:21<00:03, 502.50it/s] 83%|████████▎ | 8296/10000 [00:22<00:04, 421.30it/s] 83%|████████▎ | 8341/10000 [00:22<00:04, 358.62it/s] 84%|████████▍ | 8380/10000 [00:22<00:05, 312.68it/s] 84%|████████▍ | 8414/10000 [00:22<00:05, 309.27it/s] 85%|████████▍ | 8452/10000 [00:22<00:04, 319.13it/s] 85%|████████▍ | 8499/10000 [00:22<00:04, 354.28it/s] 85%|████████▌ | 8537/10000 [00:22<00:04, 351.66it/s] 86%|████████▌ | 8582/10000 [00:22<00:03, 377.09it/s] 87%|████████▋ | 8664/10000 [00:23<00:02, 497.79it/s] 87%|████████▋ | 8716/10000 [00:23<00:02, 486.29it/s] 88%|████████▊ | 8788/10000 [00:23<00:02, 544.65it/s] 89%|████████▊ | 8862/10000 [00:23<00:01, 596.96it/s] 89%|████████▉ | 8930/10000 [00:23<00:01, 613.35it/s] 90%|████████▉ | 8997/10000 [00:23<00:01, 629.57it/s] 91%|█████████ | 9061/10000 [00:23<00:01, 604.84it/s] 91%|█████████ | 9123/10000 [00:23<00:01, 598.71it/s] 92%|█████████▏| 9184/10000 [00:23<00:01, 597.17it/s] 92%|█████████▏| 9245/10000 [00:24<00:01, 515.46it/s] 93%|█████████▎| 9299/10000 [00:24<00:01, 412.26it/s] 93%|█████████▎| 9345/10000 [00:24<00:01, 349.18it/s] 94%|█████████▍| 9385/10000 [00:24<00:01, 316.85it/s] 94%|█████████▍| 9420/10000 [00:24<00:01, 296.42it/s] 95%|█████████▍| 9463/10000 [00:24<00:01, 298.13it/s] 95%|█████████▍| 9496/10000 [00:25<00:01, 301.15it/s] 95%|█████████▌| 9538/10000 [00:25<00:01, 322.97it/s] 96%|█████████▌| 9573/10000 [00:25<00:01, 319.09it/s] 96%|█████████▌| 9615/10000 [00:25<00:01, 338.79it/s] 97%|█████████▋| 9651/10000 [00:25<00:01, 343.75it/s] 97%|█████████▋| 9694/10000 [00:25<00:00, 359.00it/s] 97%|█████████▋| 9740/10000 [00:25<00:00, 386.88it/s] 98%|█████████▊| 9780/10000 [00:25<00:00, 349.91it/s] 98%|█████████▊| 9844/10000 [00:25<00:00, 413.27it/s] 99%|█████████▉| 9892/10000 [00:26<00:00, 422.34it/s]100%|█████████▉| 9951/10000 [00:26<00:00, 466.51it/s]100%|██████████| 10000/10000 [00:26<00:00, 382.54it/s]
test_neglected_p83 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p83
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p83.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.02it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.97it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.60it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.14it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.21it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.35it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.61it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.91it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.36it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.69it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p83_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p83_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p83_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p83_Holmes_probs.npy
{'Accuracy': 0.02, 'Precision': 0.0224, 'Recall': 0.0197, 'F1-score': 0.0174}
starting gen taf script for test_neglected_p84
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 72/10000 [00:00<00:14, 696.87it/s]  1%|▏         | 142/10000 [00:00<00:25, 381.90it/s]  2%|▏         | 188/10000 [00:00<00:32, 306.57it/s]  2%|▏         | 224/10000 [00:00<00:35, 278.62it/s]  3%|▎         | 255/10000 [00:00<00:34, 278.44it/s]  3%|▎         | 285/10000 [00:00<00:36, 265.45it/s]  3%|▎         | 313/10000 [00:01<00:36, 264.54it/s]  3%|▎         | 340/10000 [00:01<00:37, 260.38it/s]  4%|▎         | 367/10000 [00:01<00:38, 250.18it/s]  4%|▍         | 393/10000 [00:01<00:44, 216.66it/s]  4%|▍         | 427/10000 [00:01<00:38, 245.55it/s]  5%|▍         | 461/10000 [00:01<00:35, 266.26it/s]  5%|▌         | 500/10000 [00:01<00:32, 294.01it/s]  5%|▌         | 535/10000 [00:01<00:31, 305.25it/s]  6%|▌         | 567/10000 [00:01<00:31, 294.84it/s]  6%|▌         | 598/10000 [00:02<00:31, 296.94it/s]  6%|▋         | 633/10000 [00:02<00:30, 310.19it/s]  7%|▋         | 667/10000 [00:02<00:29, 317.10it/s]  7%|▋         | 705/10000 [00:02<00:28, 331.01it/s]  7%|▋         | 739/10000 [00:02<00:29, 311.26it/s]  8%|▊         | 789/10000 [00:02<00:25, 362.58it/s]  8%|▊         | 839/10000 [00:02<00:22, 400.58it/s]  9%|▉         | 880/10000 [00:02<00:23, 393.19it/s]  9%|▉         | 920/10000 [00:02<00:23, 378.72it/s] 10%|▉         | 979/10000 [00:03<00:21, 424.77it/s] 10%|█         | 1022/10000 [00:03<00:23, 388.39it/s] 11%|█         | 1062/10000 [00:03<00:23, 381.93it/s] 11%|█         | 1101/10000 [00:03<00:25, 346.95it/s] 11%|█▏        | 1137/10000 [00:03<00:27, 327.62it/s] 12%|█▏        | 1186/10000 [00:03<00:24, 359.78it/s] 12%|█▏        | 1238/10000 [00:03<00:21, 399.80it/s] 13%|█▎        | 1279/10000 [00:03<00:21, 399.75it/s] 13%|█▎        | 1332/10000 [00:03<00:19, 434.72it/s] 14%|█▍        | 1377/10000 [00:04<00:19, 437.52it/s] 14%|█▍        | 1422/10000 [00:04<00:21, 395.66it/s] 15%|█▍        | 1463/10000 [00:04<00:26, 325.55it/s] 15%|█▍        | 1499/10000 [00:04<00:31, 269.63it/s] 15%|█▌        | 1529/10000 [00:04<00:34, 246.84it/s] 16%|█▌        | 1556/10000 [00:04<00:34, 242.86it/s] 16%|█▌        | 1582/10000 [00:05<00:36, 230.83it/s] 16%|█▌        | 1611/10000 [00:05<00:34, 244.56it/s] 17%|█▋        | 1662/10000 [00:05<00:26, 309.97it/s] 17%|█▋        | 1730/10000 [00:05<00:20, 403.31it/s] 18%|█▊        | 1795/10000 [00:05<00:17, 464.85it/s] 19%|█▉        | 1887/10000 [00:05<00:13, 587.04it/s] 20%|█▉        | 1963/10000 [00:05<00:12, 635.72it/s] 20%|██        | 2029/10000 [00:05<00:13, 594.25it/s] 21%|██        | 2091/10000 [00:05<00:14, 539.05it/s] 21%|██▏       | 2147/10000 [00:06<00:16, 479.67it/s] 22%|██▏       | 2198/10000 [00:06<00:16, 473.44it/s] 22%|██▏       | 2247/10000 [00:06<00:19, 400.72it/s] 23%|██▎       | 2290/10000 [00:06<00:21, 364.99it/s] 23%|██▎       | 2329/10000 [00:06<00:23, 326.73it/s] 24%|██▎       | 2371/10000 [00:06<00:22, 342.41it/s] 24%|██▍       | 2407/10000 [00:06<00:24, 315.32it/s] 25%|██▍       | 2455/10000 [00:06<00:21, 345.21it/s] 25%|██▌       | 2515/10000 [00:07<00:18, 394.31it/s] 26%|██▌       | 2589/10000 [00:07<00:15, 482.58it/s] 26%|██▋       | 2640/10000 [00:07<00:22, 334.34it/s] 27%|██▋       | 2682/10000 [00:07<00:24, 294.23it/s] 27%|██▋       | 2718/10000 [00:07<00:28, 259.05it/s] 27%|██▋       | 2749/10000 [00:08<00:31, 231.93it/s] 28%|██▊       | 2776/10000 [00:08<00:31, 231.66it/s] 28%|██▊       | 2802/10000 [00:08<00:32, 220.48it/s] 28%|██▊       | 2841/10000 [00:08<00:28, 255.23it/s] 29%|██▉       | 2898/10000 [00:08<00:21, 327.60it/s] 30%|██▉       | 2963/10000 [00:08<00:17, 400.22it/s] 30%|███       | 3007/10000 [00:08<00:17, 408.96it/s] 31%|███       | 3051/10000 [00:08<00:18, 366.93it/s] 31%|███       | 3091/10000 [00:09<00:20, 343.08it/s] 31%|███▏      | 3128/10000 [00:09<00:20, 331.53it/s] 32%|███▏      | 3163/10000 [00:09<00:24, 284.66it/s] 32%|███▏      | 3197/10000 [00:09<00:22, 296.59it/s] 33%|███▎      | 3279/10000 [00:09<00:15, 421.66it/s] 33%|███▎      | 3343/10000 [00:09<00:13, 478.27it/s] 34%|███▍      | 3417/10000 [00:09<00:12, 521.37it/s] 35%|███▍      | 3472/10000 [00:09<00:15, 431.57it/s] 35%|███▌      | 3519/10000 [00:10<00:14, 438.62it/s] 36%|███▌      | 3566/10000 [00:10<00:16, 399.10it/s] 36%|███▌      | 3612/10000 [00:10<00:15, 404.17it/s] 37%|███▋      | 3665/10000 [00:10<00:14, 430.87it/s] 37%|███▋      | 3737/10000 [00:10<00:12, 506.79it/s] 38%|███▊      | 3790/10000 [00:10<00:12, 482.55it/s] 38%|███▊      | 3845/10000 [00:10<00:12, 484.12it/s] 39%|███▉      | 3897/10000 [00:10<00:12, 493.20it/s] 39%|███▉      | 3948/10000 [00:10<00:14, 420.69it/s] 40%|███▉      | 3993/10000 [00:11<00:14, 405.87it/s] 41%|████      | 4067/10000 [00:11<00:12, 479.38it/s] 41%|████▏     | 4129/10000 [00:11<00:11, 511.03it/s] 42%|████▏     | 4207/10000 [00:11<00:10, 567.58it/s] 43%|████▎     | 4267/10000 [00:11<00:09, 574.34it/s] 43%|████▎     | 4328/10000 [00:11<00:09, 574.19it/s] 44%|████▍     | 4399/10000 [00:11<00:09, 570.72it/s] 45%|████▍     | 4457/10000 [00:11<00:12, 428.93it/s] 45%|████▌     | 4506/10000 [00:12<00:14, 387.09it/s] 45%|████▌     | 4549/10000 [00:12<00:16, 331.53it/s] 46%|████▌     | 4586/10000 [00:12<00:18, 292.58it/s] 46%|████▌     | 4624/10000 [00:12<00:17, 307.66it/s] 47%|████▋     | 4658/10000 [00:12<00:17, 300.30it/s] 47%|████▋     | 4690/10000 [00:12<00:19, 266.68it/s] 47%|████▋     | 4729/10000 [00:13<00:18, 279.72it/s] 48%|████▊     | 4770/10000 [00:13<00:16, 310.13it/s] 48%|████▊     | 4803/10000 [00:13<00:17, 300.62it/s] 48%|████▊     | 4836/10000 [00:13<00:17, 303.11it/s] 49%|████▊     | 4868/10000 [00:13<00:16, 302.31it/s] 49%|████▉     | 4899/10000 [00:13<00:19, 262.62it/s] 49%|████▉     | 4927/10000 [00:13<00:19, 253.79it/s] 50%|████▉     | 4954/10000 [00:13<00:20, 242.69it/s] 50%|████▉     | 4983/10000 [00:13<00:20, 247.09it/s] 50%|█████     | 5009/10000 [00:14<00:21, 232.79it/s] 51%|█████     | 5066/10000 [00:14<00:15, 319.39it/s] 51%|█████     | 5119/10000 [00:14<00:13, 372.14it/s] 52%|█████▏    | 5178/10000 [00:14<00:11, 425.01it/s] 52%|█████▏    | 5222/10000 [00:14<00:13, 366.22it/s] 53%|█████▎    | 5261/10000 [00:14<00:17, 268.57it/s] 53%|█████▎    | 5293/10000 [00:14<00:17, 276.72it/s] 53%|█████▎    | 5325/10000 [00:15<00:16, 283.11it/s] 54%|█████▎    | 5357/10000 [00:15<00:17, 264.44it/s] 54%|█████▍    | 5386/10000 [00:15<00:18, 252.89it/s] 54%|█████▍    | 5430/10000 [00:15<00:16, 284.14it/s] 55%|█████▍    | 5465/10000 [00:15<00:15, 298.97it/s] 55%|█████▌    | 5518/10000 [00:15<00:12, 353.51it/s] 56%|█████▌    | 5560/10000 [00:15<00:12, 369.62it/s] 56%|█████▌    | 5599/10000 [00:15<00:11, 367.32it/s] 56%|█████▋    | 5637/10000 [00:15<00:11, 365.84it/s] 57%|█████▋    | 5707/10000 [00:16<00:09, 447.02it/s] 58%|█████▊    | 5769/10000 [00:16<00:08, 483.39it/s] 58%|█████▊    | 5818/10000 [00:16<00:10, 400.34it/s] 59%|█████▊    | 5861/10000 [00:16<00:10, 403.15it/s] 59%|█████▉    | 5904/10000 [00:16<00:10, 386.94it/s] 59%|█████▉    | 5944/10000 [00:16<00:10, 380.51it/s] 60%|█████▉    | 5983/10000 [00:16<00:11, 363.26it/s] 60%|██████    | 6020/10000 [00:16<00:12, 313.84it/s] 61%|██████    | 6076/10000 [00:17<00:10, 372.36it/s] 61%|██████▏   | 6144/10000 [00:17<00:09, 427.83it/s] 62%|██████▏   | 6189/10000 [00:17<00:08, 425.84it/s] 62%|██████▏   | 6233/10000 [00:17<00:09, 396.46it/s] 63%|██████▎   | 6274/10000 [00:17<00:10, 344.11it/s] 63%|██████▎   | 6310/10000 [00:17<00:13, 271.96it/s] 63%|██████▎   | 6341/10000 [00:17<00:13, 270.28it/s] 64%|██████▍   | 6389/10000 [00:18<00:11, 317.68it/s] 64%|██████▍   | 6424/10000 [00:18<00:12, 287.65it/s] 65%|██████▍   | 6462/10000 [00:18<00:11, 305.65it/s] 65%|██████▍   | 6495/10000 [00:18<00:12, 271.75it/s] 65%|██████▌   | 6525/10000 [00:18<00:13, 257.38it/s] 66%|██████▌   | 6558/10000 [00:18<00:12, 266.38it/s] 66%|██████▌   | 6591/10000 [00:18<00:12, 276.58it/s] 66%|██████▋   | 6627/10000 [00:18<00:11, 295.05it/s] 67%|██████▋   | 6673/10000 [00:19<00:10, 329.72it/s] 67%|██████▋   | 6712/10000 [00:19<00:09, 340.20it/s] 67%|██████▋   | 6749/10000 [00:19<00:09, 331.97it/s] 68%|██████▊   | 6788/10000 [00:19<00:09, 338.85it/s] 68%|██████▊   | 6843/10000 [00:19<00:08, 386.80it/s] 69%|██████▉   | 6904/10000 [00:19<00:06, 445.24it/s] 70%|██████▉   | 6971/10000 [00:19<00:06, 496.41it/s] 70%|███████   | 7022/10000 [00:19<00:05, 496.72it/s] 71%|███████   | 7080/10000 [00:19<00:05, 510.09it/s] 71%|███████▏  | 7132/10000 [00:20<00:06, 476.99it/s] 72%|███████▏  | 7191/10000 [00:20<00:05, 491.33it/s] 72%|███████▏  | 7241/10000 [00:20<00:05, 490.23it/s] 73%|███████▎  | 7291/10000 [00:20<00:05, 466.03it/s] 74%|███████▎  | 7365/10000 [00:20<00:04, 541.36it/s] 74%|███████▍  | 7421/10000 [00:20<00:05, 481.38it/s] 75%|███████▍  | 7471/10000 [00:20<00:05, 448.54it/s] 75%|███████▌  | 7524/10000 [00:20<00:05, 460.87it/s] 76%|███████▌  | 7592/10000 [00:20<00:04, 495.26it/s] 76%|███████▋  | 7643/10000 [00:21<00:05, 397.55it/s] 77%|███████▋  | 7687/10000 [00:21<00:05, 386.04it/s] 77%|███████▋  | 7728/10000 [00:21<00:06, 357.78it/s] 78%|███████▊  | 7778/10000 [00:21<00:05, 382.51it/s] 78%|███████▊  | 7831/10000 [00:21<00:05, 411.33it/s] 79%|███████▊  | 7874/10000 [00:21<00:05, 415.72it/s] 79%|███████▉  | 7924/10000 [00:21<00:04, 436.28it/s] 80%|███████▉  | 7991/10000 [00:21<00:04, 493.78it/s] 81%|████████  | 8055/10000 [00:22<00:03, 528.45it/s] 81%|████████  | 8109/10000 [00:22<00:03, 516.39it/s] 82%|████████▏ | 8162/10000 [00:22<00:03, 502.59it/s] 82%|████████▏ | 8213/10000 [00:22<00:04, 403.94it/s] 83%|████████▎ | 8257/10000 [00:22<00:04, 352.20it/s] 83%|████████▎ | 8304/10000 [00:22<00:04, 377.86it/s] 83%|████████▎ | 8345/10000 [00:22<00:04, 340.10it/s] 84%|████████▍ | 8382/10000 [00:23<00:05, 312.08it/s] 84%|████████▍ | 8426/10000 [00:23<00:04, 333.21it/s] 85%|████████▍ | 8471/10000 [00:23<00:04, 355.33it/s] 85%|████████▌ | 8509/10000 [00:23<00:04, 358.36it/s] 85%|████████▌ | 8547/10000 [00:23<00:04, 356.52it/s] 86%|████████▌ | 8592/10000 [00:23<00:03, 381.62it/s] 86%|████████▋ | 8647/10000 [00:23<00:03, 425.21it/s] 87%|████████▋ | 8720/10000 [00:23<00:02, 508.55it/s] 88%|████████▊ | 8783/10000 [00:23<00:02, 543.38it/s] 89%|████████▊ | 8862/10000 [00:23<00:01, 614.12it/s] 89%|████████▉ | 8931/10000 [00:24<00:01, 630.06it/s] 90%|█████████ | 9007/10000 [00:24<00:01, 659.82it/s] 91%|█████████ | 9074/10000 [00:24<00:01, 650.16it/s] 91%|█████████▏| 9140/10000 [00:24<00:01, 597.96it/s] 92%|█████████▏| 9201/10000 [00:24<00:01, 563.37it/s] 93%|█████████▎| 9259/10000 [00:24<00:01, 482.52it/s] 93%|█████████▎| 9310/10000 [00:24<00:01, 377.17it/s] 94%|█████████▎| 9353/10000 [00:25<00:01, 327.25it/s] 94%|█████████▍| 9390/10000 [00:25<00:01, 317.80it/s] 94%|█████████▍| 9432/10000 [00:25<00:01, 339.10it/s] 95%|█████████▍| 9469/10000 [00:25<00:01, 326.90it/s] 95%|█████████▌| 9504/10000 [00:25<00:01, 286.44it/s] 95%|█████████▌| 9535/10000 [00:25<00:01, 286.99it/s] 96%|█████████▌| 9573/10000 [00:25<00:01, 303.09it/s] 96%|█████████▌| 9613/10000 [00:25<00:01, 323.67it/s] 97%|█████████▋| 9652/10000 [00:26<00:01, 337.37it/s] 97%|█████████▋| 9709/10000 [00:26<00:00, 386.08it/s] 97%|█████████▋| 9749/10000 [00:26<00:00, 363.38it/s] 98%|█████████▊| 9786/10000 [00:26<00:00, 358.31it/s] 98%|█████████▊| 9843/10000 [00:26<00:00, 411.95it/s] 99%|█████████▉| 9898/10000 [00:26<00:00, 442.32it/s]100%|█████████▉| 9960/10000 [00:26<00:00, 490.61it/s]100%|██████████| 10000/10000 [00:26<00:00, 373.91it/s]
test_neglected_p84 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p84
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p84.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:36,  1.06it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.12it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.58it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.98it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.80it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.95it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.20it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.63it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.14it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.67it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p84_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p84_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p84_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p84_Holmes_probs.npy
{'Accuracy': 0.02, 'Precision': 0.0224, 'Recall': 0.0197, 'F1-score': 0.0175}
starting gen taf script for test_neglected_p85
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 57/10000 [00:00<00:19, 504.61it/s]  1%|          | 108/10000 [00:00<00:32, 306.95it/s]  1%|▏         | 143/10000 [00:00<00:33, 290.69it/s]  2%|▏         | 174/10000 [00:00<00:33, 290.24it/s]  2%|▏         | 205/10000 [00:00<00:37, 259.38it/s]  2%|▏         | 232/10000 [00:00<00:38, 254.16it/s]  3%|▎         | 259/10000 [00:00<00:39, 244.13it/s]  3%|▎         | 286/10000 [00:01<00:39, 246.97it/s]  3%|▎         | 311/10000 [00:01<00:41, 232.06it/s]  4%|▎         | 350/10000 [00:01<00:35, 269.25it/s]  4%|▍         | 378/10000 [00:01<00:37, 255.39it/s]  4%|▍         | 407/10000 [00:01<00:36, 264.48it/s]  4%|▍         | 435/10000 [00:01<00:35, 268.59it/s]  5%|▍         | 470/10000 [00:01<00:32, 289.93it/s]  5%|▌         | 500/10000 [00:01<00:32, 289.35it/s]  5%|▌         | 534/10000 [00:01<00:31, 300.02it/s]  6%|▌         | 565/10000 [00:02<00:31, 296.03it/s]  6%|▌         | 596/10000 [00:02<00:31, 298.94it/s]  6%|▋         | 626/10000 [00:02<00:32, 284.43it/s]  7%|▋         | 662/10000 [00:02<00:30, 302.66it/s]  7%|▋         | 703/10000 [00:02<00:27, 332.64it/s]  7%|▋         | 737/10000 [00:02<00:29, 314.67it/s]  8%|▊         | 788/10000 [00:02<00:25, 365.42it/s]  8%|▊         | 837/10000 [00:02<00:23, 395.21it/s]  9%|▉         | 880/10000 [00:02<00:22, 397.55it/s]  9%|▉         | 921/10000 [00:02<00:22, 398.40it/s] 10%|▉         | 963/10000 [00:03<00:22, 396.44it/s] 10%|█         | 1003/10000 [00:03<00:23, 385.47it/s] 10%|█         | 1042/10000 [00:03<00:23, 384.49it/s] 11%|█         | 1098/10000 [00:03<00:20, 433.42it/s] 11%|█▏        | 1142/10000 [00:03<00:26, 339.45it/s] 12%|█▏        | 1180/10000 [00:03<00:29, 297.39it/s] 12%|█▏        | 1242/10000 [00:03<00:23, 365.59it/s] 13%|█▎        | 1294/10000 [00:04<00:22, 391.50it/s] 14%|█▎        | 1350/10000 [00:04<00:20, 428.01it/s] 14%|█▍        | 1411/10000 [00:04<00:18, 463.11it/s] 15%|█▍        | 1460/10000 [00:04<00:24, 351.00it/s] 15%|█▌        | 1501/10000 [00:04<00:28, 296.53it/s] 15%|█▌        | 1536/10000 [00:04<00:34, 245.53it/s] 16%|█▌        | 1565/10000 [00:04<00:33, 248.75it/s] 16%|█▌        | 1593/10000 [00:05<00:36, 230.82it/s] 17%|█▋        | 1652/10000 [00:05<00:28, 296.79it/s] 17%|█▋        | 1715/10000 [00:05<00:22, 362.38it/s] 18%|█▊        | 1792/10000 [00:05<00:17, 460.18it/s] 19%|█▉        | 1875/10000 [00:05<00:14, 550.83it/s] 20%|█▉        | 1962/10000 [00:05<00:12, 631.81it/s] 20%|██        | 2030/10000 [00:05<00:14, 548.71it/s] 21%|██        | 2095/10000 [00:05<00:13, 572.17it/s] 22%|██▏       | 2157/10000 [00:06<00:15, 502.14it/s] 22%|██▏       | 2212/10000 [00:06<00:18, 419.44it/s] 23%|██▎       | 2259/10000 [00:06<00:21, 367.18it/s] 23%|██▎       | 2300/10000 [00:06<00:20, 366.87it/s] 23%|██▎       | 2340/10000 [00:06<00:26, 294.24it/s] 24%|██▎       | 2373/10000 [00:06<00:25, 301.30it/s] 24%|██▍       | 2407/10000 [00:07<00:24, 304.44it/s] 25%|██▍       | 2455/10000 [00:07<00:21, 343.72it/s] 25%|██▍       | 2497/10000 [00:07<00:20, 358.27it/s] 26%|██▌       | 2558/10000 [00:07<00:17, 420.72it/s] 26%|██▌       | 2603/10000 [00:07<00:18, 391.97it/s] 26%|██▋       | 2644/10000 [00:07<00:22, 321.45it/s] 27%|██▋       | 2680/10000 [00:07<00:30, 238.24it/s] 27%|██▋       | 2713/10000 [00:08<00:29, 251.04it/s] 27%|██▋       | 2743/10000 [00:08<00:30, 237.55it/s] 28%|██▊       | 2770/10000 [00:08<00:34, 206.80it/s] 28%|██▊       | 2794/10000 [00:08<00:34, 211.60it/s] 28%|██▊       | 2829/10000 [00:08<00:30, 238.59it/s] 29%|██▊       | 2874/10000 [00:08<00:24, 286.15it/s] 29%|██▉       | 2933/10000 [00:08<00:20, 351.97it/s] 30%|██▉       | 2988/10000 [00:08<00:17, 394.09it/s] 30%|███       | 3031/10000 [00:09<00:17, 392.40it/s] 31%|███       | 3072/10000 [00:09<00:20, 333.12it/s] 31%|███       | 3108/10000 [00:09<00:21, 326.69it/s] 31%|███▏      | 3143/10000 [00:09<00:22, 301.78it/s] 32%|███▏      | 3175/10000 [00:09<00:22, 301.80it/s] 32%|███▏      | 3210/10000 [00:09<00:21, 313.32it/s] 33%|███▎      | 3290/10000 [00:09<00:15, 439.08it/s] 34%|███▍      | 3375/10000 [00:09<00:12, 551.89it/s] 34%|███▍      | 3433/10000 [00:09<00:13, 481.68it/s] 35%|███▍      | 3488/10000 [00:10<00:13, 487.40it/s] 35%|███▌      | 3539/10000 [00:10<00:14, 450.28it/s] 36%|███▌      | 3586/10000 [00:10<00:15, 426.08it/s] 36%|███▋      | 3630/10000 [00:10<00:14, 427.71it/s] 37%|███▋      | 3682/10000 [00:10<00:14, 449.22it/s] 37%|███▋      | 3747/10000 [00:10<00:12, 487.47it/s] 38%|███▊      | 3824/10000 [00:10<00:11, 542.88it/s] 39%|███▉      | 3879/10000 [00:10<00:12, 495.98it/s] 39%|███▉      | 3930/10000 [00:11<00:13, 441.99it/s] 40%|███▉      | 3991/10000 [00:11<00:12, 482.02it/s] 41%|████      | 4051/10000 [00:11<00:11, 500.10it/s] 41%|████▏     | 4125/10000 [00:11<00:10, 548.28it/s] 42%|████▏     | 4186/10000 [00:11<00:10, 557.26it/s] 43%|████▎     | 4260/10000 [00:11<00:09, 601.50it/s] 43%|████▎     | 4322/10000 [00:11<00:09, 604.55it/s] 44%|████▍     | 4384/10000 [00:11<00:09, 588.45it/s] 44%|████▍     | 4444/10000 [00:11<00:10, 507.65it/s] 45%|████▍     | 4497/10000 [00:12<00:14, 381.29it/s] 45%|████▌     | 4541/10000 [00:12<00:15, 354.66it/s] 46%|████▌     | 4581/10000 [00:12<00:16, 319.81it/s] 46%|████▌     | 4620/10000 [00:12<00:16, 318.07it/s] 47%|████▋     | 4654/10000 [00:12<00:16, 314.50it/s] 47%|████▋     | 4687/10000 [00:12<00:20, 260.68it/s] 47%|████▋     | 4733/10000 [00:13<00:17, 299.43it/s] 48%|████▊     | 4766/10000 [00:13<00:17, 291.34it/s] 48%|████▊     | 4800/10000 [00:13<00:17, 299.55it/s] 48%|████▊     | 4832/10000 [00:13<00:19, 262.28it/s] 49%|████▊     | 4861/10000 [00:13<00:20, 254.94it/s] 49%|████▉     | 4896/10000 [00:13<00:18, 274.66it/s] 49%|████▉     | 4925/10000 [00:13<00:20, 244.47it/s] 50%|████▉     | 4957/10000 [00:13<00:19, 254.37it/s] 50%|████▉     | 4984/10000 [00:14<00:20, 249.72it/s] 50%|█████     | 5010/10000 [00:14<00:20, 243.73it/s] 51%|█████     | 5063/10000 [00:14<00:15, 311.03it/s] 51%|█████▏    | 5139/10000 [00:14<00:11, 423.68it/s] 52%|█████▏    | 5192/10000 [00:14<00:10, 452.13it/s] 52%|█████▏    | 5239/10000 [00:14<00:14, 332.91it/s] 53%|█████▎    | 5278/10000 [00:14<00:14, 317.71it/s] 53%|█████▎    | 5314/10000 [00:15<00:16, 276.05it/s] 53%|█████▎    | 5345/10000 [00:15<00:18, 255.93it/s] 54%|█████▎    | 5373/10000 [00:15<00:18, 247.99it/s] 54%|█████▍    | 5400/10000 [00:15<00:19, 238.76it/s] 54%|█████▍    | 5430/10000 [00:15<00:18, 242.05it/s] 55%|█████▍    | 5490/10000 [00:15<00:13, 327.49it/s] 55%|█████▌    | 5526/10000 [00:15<00:13, 334.79it/s] 56%|█████▌    | 5587/10000 [00:15<00:10, 404.33it/s] 56%|█████▋    | 5632/10000 [00:15<00:10, 416.87it/s] 57%|█████▋    | 5690/10000 [00:16<00:09, 444.00it/s] 57%|█████▋    | 5746/10000 [00:16<00:08, 475.96it/s] 58%|█████▊    | 5801/10000 [00:16<00:08, 483.54it/s] 58%|█████▊    | 5850/10000 [00:16<00:09, 429.85it/s] 59%|█████▉    | 5895/10000 [00:16<00:10, 375.64it/s] 59%|█████▉    | 5935/10000 [00:16<00:11, 361.08it/s] 60%|█████▉    | 5973/10000 [00:16<00:11, 336.64it/s] 60%|██████    | 6015/10000 [00:16<00:11, 357.17it/s] 61%|██████    | 6063/10000 [00:17<00:10, 379.64it/s] 61%|██████    | 6105/10000 [00:17<00:10, 384.10it/s] 62%|██████▏   | 6154/10000 [00:17<00:09, 411.85it/s] 62%|██████▏   | 6205/10000 [00:17<00:08, 426.22it/s] 62%|██████▏   | 6249/10000 [00:17<00:09, 402.54it/s] 63%|██████▎   | 6290/10000 [00:17<00:12, 302.45it/s] 63%|██████▎   | 6325/10000 [00:17<00:11, 310.01it/s] 64%|██████▎   | 6359/10000 [00:18<00:13, 271.16it/s] 64%|██████▍   | 6395/10000 [00:18<00:12, 286.13it/s] 64%|██████▍   | 6432/10000 [00:18<00:12, 289.91it/s] 65%|██████▍   | 6465/10000 [00:18<00:12, 293.27it/s] 65%|██████▍   | 6496/10000 [00:18<00:12, 277.87it/s] 65%|██████▌   | 6525/10000 [00:18<00:12, 269.74it/s] 66%|██████▌   | 6559/10000 [00:18<00:12, 281.56it/s] 66%|██████▌   | 6592/10000 [00:18<00:11, 293.85it/s] 66%|██████▋   | 6633/10000 [00:18<00:10, 325.74it/s] 67%|██████▋   | 6667/10000 [00:19<00:11, 294.89it/s] 67%|██████▋   | 6712/10000 [00:19<00:10, 324.76it/s] 67%|██████▋   | 6748/10000 [00:19<00:10, 321.10it/s] 68%|██████▊   | 6783/10000 [00:19<00:09, 327.07it/s] 68%|██████▊   | 6828/10000 [00:19<00:08, 359.63it/s] 69%|██████▉   | 6882/10000 [00:19<00:07, 401.92it/s] 70%|██████▉   | 6965/10000 [00:19<00:05, 516.88it/s] 70%|███████   | 7018/10000 [00:19<00:05, 504.09it/s] 71%|███████   | 7090/10000 [00:19<00:05, 564.38it/s] 71%|███████▏  | 7148/10000 [00:20<00:05, 499.67it/s] 72%|███████▏  | 7200/10000 [00:20<00:06, 456.49it/s] 72%|███████▏  | 7248/10000 [00:20<00:06, 456.07it/s] 73%|███████▎  | 7295/10000 [00:20<00:05, 452.62it/s] 74%|███████▎  | 7365/10000 [00:20<00:05, 513.50it/s] 74%|███████▍  | 7418/10000 [00:20<00:05, 456.45it/s] 75%|███████▍  | 7485/10000 [00:20<00:05, 499.95it/s] 75%|███████▌  | 7537/10000 [00:20<00:05, 482.90it/s] 76%|███████▌  | 7587/10000 [00:21<00:05, 471.36it/s] 76%|███████▋  | 7635/10000 [00:21<00:05, 454.27it/s] 77%|███████▋  | 7681/10000 [00:21<00:05, 394.79it/s] 77%|███████▋  | 7724/10000 [00:21<00:05, 401.37it/s] 78%|███████▊  | 7766/10000 [00:21<00:05, 387.63it/s] 78%|███████▊  | 7808/10000 [00:21<00:05, 388.31it/s] 79%|███████▊  | 7867/10000 [00:21<00:04, 434.78it/s] 79%|███████▉  | 7940/10000 [00:21<00:04, 496.24it/s] 80%|████████  | 8020/10000 [00:21<00:03, 571.15it/s] 81%|████████  | 8078/10000 [00:22<00:03, 555.55it/s] 81%|████████▏ | 8139/10000 [00:22<00:03, 561.97it/s] 82%|████████▏ | 8196/10000 [00:22<00:03, 524.57it/s] 82%|████████▎ | 8250/10000 [00:22<00:04, 427.37it/s] 83%|████████▎ | 8296/10000 [00:22<00:04, 384.25it/s] 83%|████████▎ | 8337/10000 [00:22<00:04, 368.83it/s] 84%|████████▍ | 8376/10000 [00:22<00:04, 332.12it/s] 84%|████████▍ | 8411/10000 [00:23<00:04, 320.38it/s] 84%|████████▍ | 8444/10000 [00:23<00:04, 320.22it/s] 85%|████████▍ | 8477/10000 [00:23<00:05, 297.78it/s] 85%|████████▌ | 8544/10000 [00:23<00:03, 376.32it/s] 86%|████████▌ | 8583/10000 [00:23<00:04, 351.60it/s] 86%|████████▋ | 8644/10000 [00:23<00:03, 416.52it/s] 87%|████████▋ | 8733/10000 [00:23<00:02, 534.36it/s] 88%|████████▊ | 8797/10000 [00:23<00:02, 552.22it/s] 89%|████████▊ | 8864/10000 [00:23<00:01, 584.40it/s] 90%|████████▉ | 8953/10000 [00:24<00:01, 670.58it/s] 90%|█████████ | 9022/10000 [00:24<00:01, 675.42it/s] 91%|█████████ | 9091/10000 [00:24<00:01, 647.29it/s] 92%|█████████▏| 9157/10000 [00:24<00:01, 557.84it/s] 92%|█████████▏| 9216/10000 [00:24<00:01, 548.98it/s] 93%|█████████▎| 9273/10000 [00:24<00:01, 401.11it/s] 93%|█████████▎| 9320/10000 [00:24<00:02, 338.06it/s] 94%|█████████▎| 9360/10000 [00:25<00:02, 303.81it/s] 94%|█████████▍| 9399/10000 [00:25<00:01, 315.96it/s] 94%|█████████▍| 9436/10000 [00:25<00:01, 321.28it/s] 95%|█████████▍| 9476/10000 [00:25<00:01, 328.16it/s] 95%|█████████▌| 9511/10000 [00:25<00:01, 303.01it/s] 96%|█████████▌| 9554/10000 [00:25<00:01, 332.02it/s] 96%|█████████▌| 9589/10000 [00:25<00:01, 328.32it/s] 96%|█████████▋| 9637/10000 [00:25<00:00, 365.28it/s] 97%|█████████▋| 9675/10000 [00:26<00:00, 349.84it/s] 97%|█████████▋| 9715/10000 [00:26<00:00, 357.01it/s] 98%|█████████▊| 9752/10000 [00:26<00:00, 334.43it/s] 98%|█████████▊| 9794/10000 [00:26<00:00, 346.78it/s] 99%|█████████▊| 9854/10000 [00:26<00:00, 414.68it/s] 99%|█████████▉| 9910/10000 [00:26<00:00, 451.16it/s]100%|██████████| 10000/10000 [00:26<00:00, 374.51it/s]
test_neglected_p85 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p85
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p85.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.00it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.88it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.39it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.86it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.85it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.92it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.17it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.61it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.84it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.21it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p85_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p85_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p85_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p85_Holmes_probs.npy
{'Accuracy': 0.0202, 'Precision': 0.0226, 'Recall': 0.0199, 'F1-score': 0.0175}
starting gen taf script for test_neglected_p86
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 58/10000 [00:00<00:17, 571.37it/s]  1%|          | 116/10000 [00:00<00:29, 331.25it/s]  2%|▏         | 155/10000 [00:00<00:35, 279.80it/s]  2%|▏         | 186/10000 [00:00<00:37, 261.46it/s]  2%|▏         | 214/10000 [00:00<00:39, 247.45it/s]  2%|▏         | 242/10000 [00:00<00:39, 248.12it/s]  3%|▎         | 268/10000 [00:00<00:39, 248.39it/s]  3%|▎         | 294/10000 [00:01<00:39, 245.87it/s]  3%|▎         | 319/10000 [00:01<00:42, 229.25it/s]  3%|▎         | 344/10000 [00:01<00:41, 234.68it/s]  4%|▎         | 369/10000 [00:01<00:40, 236.70it/s]  4%|▍         | 393/10000 [00:01<00:42, 225.14it/s]  4%|▍         | 425/10000 [00:01<00:38, 250.44it/s]  5%|▍         | 451/10000 [00:01<00:40, 236.73it/s]  5%|▍         | 493/10000 [00:01<00:33, 284.12it/s]  5%|▌         | 528/10000 [00:01<00:32, 295.23it/s]  6%|▌         | 569/10000 [00:02<00:28, 325.73it/s]  6%|▌         | 603/10000 [00:02<00:30, 310.06it/s]  6%|▋         | 646/10000 [00:02<00:27, 341.25it/s]  7%|▋         | 684/10000 [00:02<00:26, 352.01it/s]  7%|▋         | 731/10000 [00:02<00:24, 382.67it/s]  8%|▊         | 792/10000 [00:02<00:21, 438.44it/s]  8%|▊         | 837/10000 [00:02<00:25, 355.84it/s]  9%|▉         | 876/10000 [00:02<00:26, 348.60it/s]  9%|▉         | 923/10000 [00:03<00:24, 377.59it/s] 10%|▉         | 972/10000 [00:03<00:22, 401.07it/s] 10%|█         | 1014/10000 [00:03<00:23, 375.56it/s] 11%|█         | 1060/10000 [00:03<00:22, 393.70it/s] 11%|█         | 1101/10000 [00:03<00:24, 362.68it/s] 11%|█▏        | 1139/10000 [00:03<00:24, 357.47it/s] 12%|█▏        | 1178/10000 [00:03<00:24, 365.46it/s] 12%|█▏        | 1216/10000 [00:03<00:25, 343.27it/s] 13%|█▎        | 1287/10000 [00:03<00:20, 422.89it/s] 14%|█▎        | 1369/10000 [00:04<00:16, 518.71it/s] 14%|█▍        | 1422/10000 [00:04<00:19, 434.26it/s] 15%|█▍        | 1469/10000 [00:04<00:28, 297.90it/s] 15%|█▌        | 1506/10000 [00:04<00:31, 272.18it/s] 15%|█▌        | 1539/10000 [00:04<00:34, 243.44it/s] 16%|█▌        | 1567/10000 [00:05<00:37, 223.47it/s] 16%|█▌        | 1592/10000 [00:05<00:37, 224.32it/s] 17%|█▋        | 1662/10000 [00:05<00:25, 324.95it/s] 17%|█▋        | 1715/10000 [00:05<00:22, 364.05it/s] 18%|█▊        | 1775/10000 [00:05<00:19, 416.79it/s] 18%|█▊        | 1842/10000 [00:05<00:17, 478.13it/s] 19%|█▉        | 1929/10000 [00:05<00:13, 579.51it/s] 20%|██        | 2000/10000 [00:05<00:13, 599.51it/s] 21%|██        | 2063/10000 [00:05<00:14, 544.71it/s] 21%|██        | 2121/10000 [00:06<00:14, 527.62it/s] 22%|██▏       | 2176/10000 [00:06<00:16, 483.93it/s] 22%|██▏       | 2227/10000 [00:06<00:17, 434.35it/s] 23%|██▎       | 2273/10000 [00:06<00:21, 364.94it/s] 23%|██▎       | 2313/10000 [00:06<00:23, 327.81it/s] 23%|██▎       | 2348/10000 [00:06<00:25, 295.59it/s] 24%|██▍       | 2390/10000 [00:06<00:24, 312.43it/s] 24%|██▍       | 2430/10000 [00:07<00:23, 329.01it/s] 25%|██▍       | 2481/10000 [00:07<00:20, 373.55it/s] 25%|██▌       | 2521/10000 [00:07<00:19, 375.59it/s] 26%|██▌       | 2572/10000 [00:07<00:18, 395.57it/s] 26%|██▌       | 2613/10000 [00:07<00:20, 355.00it/s] 26%|██▋       | 2650/10000 [00:07<00:26, 275.69it/s] 27%|██▋       | 2681/10000 [00:07<00:32, 228.63it/s] 27%|██▋       | 2713/10000 [00:08<00:29, 246.96it/s] 27%|██▋       | 2741/10000 [00:08<00:30, 236.44it/s] 28%|██▊       | 2767/10000 [00:08<00:35, 202.49it/s] 28%|██▊       | 2790/10000 [00:08<00:39, 182.93it/s] 28%|██▊       | 2831/10000 [00:08<00:31, 228.53it/s] 29%|██▉       | 2878/10000 [00:08<00:25, 281.14it/s] 29%|██▉       | 2921/10000 [00:08<00:22, 313.95it/s] 30%|██▉       | 2991/10000 [00:08<00:16, 413.01it/s] 30%|███       | 3036/10000 [00:09<00:23, 295.40it/s] 31%|███       | 3081/10000 [00:09<00:21, 318.33it/s] 31%|███       | 3119/10000 [00:09<00:21, 326.50it/s] 32%|███▏      | 3156/10000 [00:09<00:21, 312.32it/s] 32%|███▏      | 3191/10000 [00:09<00:23, 288.22it/s] 32%|███▏      | 3241/10000 [00:09<00:20, 336.70it/s] 33%|███▎      | 3313/10000 [00:09<00:15, 424.72it/s] 34%|███▍      | 3380/10000 [00:10<00:13, 481.13it/s] 34%|███▍      | 3440/10000 [00:10<00:13, 492.92it/s] 35%|███▍      | 3492/10000 [00:10<00:13, 480.05it/s] 35%|███▌      | 3542/10000 [00:10<00:15, 415.76it/s] 36%|███▌      | 3586/10000 [00:10<00:15, 405.61it/s] 36%|███▋      | 3639/10000 [00:10<00:14, 437.20it/s] 37%|███▋      | 3692/10000 [00:10<00:13, 457.05it/s] 37%|███▋      | 3745/10000 [00:10<00:13, 471.50it/s] 38%|███▊      | 3803/10000 [00:10<00:12, 490.53it/s] 39%|███▊      | 3859/10000 [00:11<00:12, 498.27it/s] 39%|███▉      | 3910/10000 [00:11<00:13, 442.23it/s] 40%|███▉      | 3966/10000 [00:11<00:13, 461.15it/s] 40%|████      | 4026/10000 [00:11<00:12, 487.69it/s] 41%|████      | 4114/10000 [00:11<00:10, 584.88it/s] 42%|████▏     | 4185/10000 [00:11<00:09, 598.07it/s] 42%|████▏     | 4246/10000 [00:11<00:09, 577.68it/s] 43%|████▎     | 4323/10000 [00:11<00:09, 622.73it/s] 44%|████▍     | 4395/10000 [00:12<00:08, 627.88it/s] 45%|████▍     | 4459/10000 [00:12<00:12, 442.87it/s] 45%|████▌     | 4511/10000 [00:12<00:14, 367.90it/s] 46%|████▌     | 4555/10000 [00:12<00:16, 335.09it/s] 46%|████▌     | 4594/10000 [00:12<00:16, 318.27it/s] 46%|████▋     | 4633/10000 [00:12<00:16, 329.57it/s] 47%|████▋     | 4670/10000 [00:13<00:16, 329.44it/s] 47%|████▋     | 4705/10000 [00:13<00:17, 311.14it/s] 47%|████▋     | 4738/10000 [00:13<00:16, 315.17it/s] 48%|████▊     | 4779/10000 [00:13<00:15, 338.73it/s] 48%|████▊     | 4814/10000 [00:13<00:16, 314.48it/s] 48%|████▊     | 4847/10000 [00:13<00:17, 287.69it/s] 49%|████▉     | 4877/10000 [00:13<00:18, 278.25it/s] 49%|████▉     | 4906/10000 [00:13<00:19, 263.23it/s] 49%|████▉     | 4933/10000 [00:13<00:20, 248.39it/s] 50%|████▉     | 4959/10000 [00:14<00:20, 246.25it/s] 50%|████▉     | 4986/10000 [00:14<00:19, 252.39it/s] 50%|█████     | 5012/10000 [00:14<00:19, 251.58it/s] 51%|█████     | 5079/10000 [00:14<00:13, 366.68it/s] 51%|█████▏    | 5131/10000 [00:14<00:11, 408.94it/s] 52%|█████▏    | 5179/10000 [00:14<00:11, 416.38it/s] 52%|█████▏    | 5222/10000 [00:14<00:12, 382.16it/s] 53%|█████▎    | 5262/10000 [00:14<00:13, 339.31it/s] 53%|█████▎    | 5298/10000 [00:15<00:16, 279.06it/s] 53%|█████▎    | 5329/10000 [00:15<00:18, 248.21it/s] 54%|█████▎    | 5361/10000 [00:15<00:17, 260.56it/s] 54%|█████▍    | 5389/10000 [00:15<00:19, 230.91it/s] 54%|█████▍    | 5435/10000 [00:15<00:16, 278.32it/s] 55%|█████▍    | 5466/10000 [00:15<00:16, 276.76it/s] 55%|█████▌    | 5520/10000 [00:15<00:13, 338.81it/s] 56%|█████▌    | 5575/10000 [00:15<00:11, 384.52it/s] 56%|█████▋    | 5642/10000 [00:16<00:09, 447.52it/s] 57%|█████▋    | 5689/10000 [00:16<00:09, 435.89it/s] 58%|█████▊    | 5760/10000 [00:16<00:08, 498.40it/s] 58%|█████▊    | 5813/10000 [00:16<00:08, 505.41it/s] 59%|█████▊    | 5865/10000 [00:16<00:09, 419.08it/s] 59%|█████▉    | 5910/10000 [00:16<00:10, 389.69it/s] 60%|█████▉    | 5952/10000 [00:16<00:11, 367.31it/s] 60%|█████▉    | 5991/10000 [00:17<00:12, 327.17it/s] 61%|██████    | 6077/10000 [00:17<00:08, 445.13it/s] 61%|██████▏   | 6145/10000 [00:17<00:07, 503.08it/s] 62%|██████▏   | 6201/10000 [00:17<00:07, 511.61it/s] 63%|██████▎   | 6255/10000 [00:17<00:08, 428.59it/s] 63%|██████▎   | 6302/10000 [00:17<00:11, 328.58it/s] 63%|██████▎   | 6341/10000 [00:17<00:11, 306.94it/s] 64%|██████▍   | 6376/10000 [00:17<00:11, 315.37it/s] 64%|██████▍   | 6411/10000 [00:18<00:11, 306.93it/s] 64%|██████▍   | 6444/10000 [00:18<00:12, 288.38it/s] 65%|██████▍   | 6484/10000 [00:18<00:11, 310.73it/s] 65%|██████▌   | 6517/10000 [00:18<00:11, 304.71it/s] 66%|██████▌   | 6553/10000 [00:18<00:11, 310.30it/s] 66%|██████▌   | 6585/10000 [00:18<00:11, 291.36it/s] 66%|██████▌   | 6621/10000 [00:18<00:11, 298.86it/s] 67%|██████▋   | 6652/10000 [00:18<00:11, 286.69it/s] 67%|██████▋   | 6683/10000 [00:19<00:11, 287.73it/s] 67%|██████▋   | 6722/10000 [00:19<00:10, 306.26it/s] 68%|██████▊   | 6759/10000 [00:19<00:10, 307.69it/s] 68%|██████▊   | 6800/10000 [00:19<00:09, 327.43it/s] 68%|██████▊   | 6842/10000 [00:19<00:08, 352.68it/s] 69%|██████▉   | 6914/10000 [00:19<00:06, 453.28it/s] 70%|██████▉   | 6971/10000 [00:19<00:06, 486.12it/s] 70%|███████   | 7021/10000 [00:19<00:06, 478.01it/s] 71%|███████   | 7070/10000 [00:19<00:06, 434.50it/s] 71%|███████▏  | 7140/10000 [00:20<00:05, 482.58it/s] 72%|███████▏  | 7189/10000 [00:20<00:05, 470.07it/s] 73%|███████▎  | 7252/10000 [00:20<00:05, 508.18it/s] 73%|███████▎  | 7316/10000 [00:20<00:04, 544.43it/s] 74%|███████▍  | 7375/10000 [00:20<00:04, 544.90it/s] 74%|███████▍  | 7430/10000 [00:20<00:04, 530.69it/s] 75%|███████▍  | 7484/10000 [00:20<00:04, 509.39it/s] 75%|███████▌  | 7547/10000 [00:20<00:04, 539.83it/s] 76%|███████▌  | 7602/10000 [00:20<00:04, 482.00it/s] 77%|███████▋  | 7652/10000 [00:21<00:05, 449.64it/s] 77%|███████▋  | 7699/10000 [00:21<00:05, 412.35it/s] 77%|███████▋  | 7744/10000 [00:21<00:05, 405.62it/s] 78%|███████▊  | 7786/10000 [00:21<00:05, 374.86it/s] 78%|███████▊  | 7838/10000 [00:21<00:05, 400.99it/s] 79%|███████▉  | 7910/10000 [00:21<00:04, 483.50it/s] 80%|███████▉  | 7961/10000 [00:21<00:04, 464.51it/s] 80%|████████  | 8016/10000 [00:21<00:04, 472.01it/s] 81%|████████  | 8090/10000 [00:22<00:03, 535.14it/s] 82%|████████▏ | 8152/10000 [00:22<00:03, 553.66it/s] 82%|████████▏ | 8209/10000 [00:22<00:03, 531.81it/s] 83%|████████▎ | 8263/10000 [00:22<00:04, 404.10it/s] 83%|████████▎ | 8309/10000 [00:22<00:04, 367.57it/s] 84%|████████▎ | 8350/10000 [00:22<00:04, 339.00it/s] 84%|████████▍ | 8387/10000 [00:22<00:04, 339.71it/s] 84%|████████▍ | 8423/10000 [00:22<00:04, 328.31it/s] 85%|████████▍ | 8464/10000 [00:23<00:04, 345.29it/s] 85%|████████▌ | 8503/10000 [00:23<00:04, 353.07it/s] 86%|████████▌ | 8552/10000 [00:23<00:03, 381.42it/s] 86%|████████▌ | 8596/10000 [00:23<00:03, 390.88it/s] 87%|████████▋ | 8676/10000 [00:23<00:02, 498.37it/s] 87%|████████▋ | 8746/10000 [00:23<00:02, 554.57it/s] 88%|████████▊ | 8813/10000 [00:23<00:02, 586.14it/s] 89%|████████▉ | 8890/10000 [00:23<00:01, 635.28it/s] 90%|████████▉ | 8969/10000 [00:23<00:01, 667.75it/s] 90%|█████████ | 9037/10000 [00:24<00:01, 603.83it/s] 91%|█████████ | 9099/10000 [00:24<00:01, 582.80it/s] 92%|█████████▏| 9178/10000 [00:24<00:01, 628.57it/s] 92%|█████████▏| 9242/10000 [00:24<00:01, 476.08it/s] 93%|█████████▎| 9296/10000 [00:24<00:01, 424.08it/s] 93%|█████████▎| 9344/10000 [00:24<00:01, 374.68it/s] 94%|█████████▍| 9386/10000 [00:25<00:01, 328.85it/s] 94%|█████████▍| 9422/10000 [00:25<00:01, 322.23it/s] 95%|█████████▍| 9459/10000 [00:25<00:01, 328.83it/s] 95%|█████████▌| 9500/10000 [00:25<00:01, 308.15it/s] 95%|█████████▌| 9539/10000 [00:25<00:01, 319.82it/s] 96%|█████████▌| 9573/10000 [00:25<00:01, 322.44it/s] 96%|█████████▌| 9607/10000 [00:25<00:01, 304.46it/s] 97%|█████████▋| 9657/10000 [00:25<00:00, 345.68it/s] 97%|█████████▋| 9706/10000 [00:25<00:00, 383.47it/s] 97%|█████████▋| 9746/10000 [00:26<00:00, 336.87it/s] 98%|█████████▊| 9782/10000 [00:26<00:00, 335.85it/s] 98%|█████████▊| 9842/10000 [00:26<00:00, 403.56it/s] 99%|█████████▉| 9914/10000 [00:26<00:00, 483.47it/s]100%|██████████| 10000/10000 [00:26<00:00, 376.90it/s]
test_neglected_p86 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p86
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p86.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.02s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.90it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.98it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.11it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.75it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.64it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.81it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.17it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.99it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p86_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p86_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p86_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p86_Holmes_probs.npy
{'Accuracy': 0.0202, 'Precision': 0.0231, 'Recall': 0.0199, 'F1-score': 0.0178}
starting gen taf script for test_neglected_p87
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 57/10000 [00:00<00:17, 563.66it/s]  1%|          | 114/10000 [00:00<00:33, 296.06it/s]  2%|▏         | 151/10000 [00:00<00:36, 267.73it/s]  2%|▏         | 182/10000 [00:00<00:38, 257.01it/s]  2%|▏         | 213/10000 [00:00<00:37, 263.91it/s]  2%|▏         | 241/10000 [00:00<00:40, 239.69it/s]  3%|▎         | 266/10000 [00:01<00:43, 221.89it/s]  3%|▎         | 289/10000 [00:01<00:44, 219.69it/s]  3%|▎         | 317/10000 [00:01<00:42, 229.88it/s]  3%|▎         | 341/10000 [00:01<00:42, 225.27it/s]  4%|▎         | 365/10000 [00:01<00:42, 228.60it/s]  4%|▍         | 389/10000 [00:01<00:41, 231.00it/s]  4%|▍         | 414/10000 [00:01<00:43, 222.20it/s]  4%|▍         | 442/10000 [00:01<00:40, 237.59it/s]  5%|▍         | 476/10000 [00:01<00:35, 266.27it/s]  5%|▌         | 517/10000 [00:02<00:31, 304.09it/s]  6%|▌         | 572/10000 [00:02<00:25, 367.92it/s]  6%|▋         | 647/10000 [00:02<00:19, 473.26it/s]  7%|▋         | 703/10000 [00:02<00:19, 475.44it/s]  8%|▊         | 788/10000 [00:02<00:16, 567.88it/s]  8%|▊         | 845/10000 [00:02<00:18, 507.92it/s]  9%|▉         | 897/10000 [00:02<00:20, 451.81it/s] 10%|▉         | 950/10000 [00:02<00:19, 462.43it/s] 10%|▉         | 998/10000 [00:03<00:23, 380.03it/s] 10%|█         | 1039/10000 [00:03<00:24, 367.97it/s] 11%|█         | 1078/10000 [00:03<00:25, 349.88it/s] 11%|█         | 1119/10000 [00:03<00:24, 359.11it/s] 12%|█▏        | 1156/10000 [00:03<00:24, 358.15it/s] 12%|█▏        | 1193/10000 [00:03<00:25, 346.23it/s] 13%|█▎        | 1264/10000 [00:03<00:20, 436.23it/s] 13%|█▎        | 1319/10000 [00:03<00:18, 458.41it/s] 14%|█▍        | 1387/10000 [00:03<00:16, 517.36it/s] 14%|█▍        | 1440/10000 [00:04<00:20, 422.75it/s] 15%|█▍        | 1486/10000 [00:04<00:27, 313.61it/s] 15%|█▌        | 1524/10000 [00:04<00:28, 296.31it/s] 16%|█▌        | 1558/10000 [00:04<00:32, 260.21it/s] 16%|█▌        | 1588/10000 [00:04<00:34, 243.11it/s] 16%|█▋        | 1630/10000 [00:04<00:29, 279.79it/s] 17%|█▋        | 1667/10000 [00:05<00:28, 292.80it/s] 17%|█▋        | 1726/10000 [00:05<00:22, 363.37it/s] 18%|█▊        | 1786/10000 [00:05<00:19, 423.92it/s] 19%|█▉        | 1880/10000 [00:05<00:14, 552.31it/s] 20%|█▉        | 1971/10000 [00:05<00:12, 648.51it/s] 20%|██        | 2040/10000 [00:05<00:13, 596.31it/s] 21%|██        | 2103/10000 [00:05<00:14, 551.21it/s] 22%|██▏       | 2161/10000 [00:05<00:15, 490.92it/s] 22%|██▏       | 2213/10000 [00:06<00:16, 462.46it/s] 23%|██▎       | 2262/10000 [00:06<00:19, 387.82it/s] 23%|██▎       | 2304/10000 [00:06<00:21, 355.16it/s] 23%|██▎       | 2342/10000 [00:06<00:25, 304.63it/s] 24%|██▍       | 2375/10000 [00:06<00:25, 297.21it/s] 24%|██▍       | 2413/10000 [00:06<00:24, 310.98it/s] 25%|██▍       | 2470/10000 [00:06<00:20, 371.02it/s] 25%|██▌       | 2511/10000 [00:06<00:19, 380.53it/s] 26%|██▌       | 2551/10000 [00:07<00:19, 383.63it/s] 26%|██▌       | 2591/10000 [00:07<00:19, 377.96it/s] 26%|██▋       | 2630/10000 [00:07<00:19, 374.94it/s] 27%|██▋       | 2669/10000 [00:07<00:26, 275.69it/s] 27%|██▋       | 2701/10000 [00:07<00:30, 236.18it/s] 27%|██▋       | 2729/10000 [00:07<00:32, 225.18it/s] 28%|██▊       | 2755/10000 [00:07<00:32, 223.88it/s] 28%|██▊       | 2781/10000 [00:08<00:32, 225.45it/s] 28%|██▊       | 2806/10000 [00:08<00:31, 226.33it/s] 28%|██▊       | 2844/10000 [00:08<00:27, 264.68it/s] 29%|██▉       | 2893/10000 [00:08<00:21, 324.03it/s] 30%|██▉       | 2951/10000 [00:08<00:18, 388.11it/s] 30%|██▉       | 2997/10000 [00:08<00:17, 404.44it/s] 30%|███       | 3039/10000 [00:08<00:18, 369.61it/s] 31%|███       | 3078/10000 [00:08<00:19, 347.81it/s] 31%|███       | 3116/10000 [00:08<00:19, 347.96it/s] 32%|███▏      | 3152/10000 [00:09<00:20, 327.97it/s] 32%|███▏      | 3186/10000 [00:09<00:22, 307.25it/s] 32%|███▏      | 3225/10000 [00:09<00:20, 326.45it/s] 33%|███▎      | 3277/10000 [00:09<00:17, 377.43it/s] 34%|███▎      | 3360/10000 [00:09<00:13, 502.42it/s] 34%|███▍      | 3412/10000 [00:09<00:13, 475.36it/s] 35%|███▍      | 3461/10000 [00:09<00:13, 469.78it/s] 35%|███▌      | 3509/10000 [00:09<00:16, 405.52it/s] 36%|███▌      | 3571/10000 [00:10<00:13, 459.38it/s] 36%|███▌      | 3620/10000 [00:10<00:13, 464.57it/s] 37%|███▋      | 3669/10000 [00:10<00:13, 463.76it/s] 37%|███▋      | 3723/10000 [00:10<00:12, 482.92it/s] 38%|███▊      | 3787/10000 [00:10<00:12, 517.14it/s] 38%|███▊      | 3840/10000 [00:10<00:12, 479.91it/s] 39%|███▉      | 3891/10000 [00:10<00:12, 475.42it/s] 39%|███▉      | 3940/10000 [00:10<00:12, 476.61it/s] 40%|███▉      | 3989/10000 [00:10<00:13, 437.54it/s] 40%|████      | 4048/10000 [00:11<00:12, 476.34it/s] 41%|████▏     | 4137/10000 [00:11<00:10, 573.81it/s] 42%|████▏     | 4196/10000 [00:11<00:10, 562.54it/s] 43%|████▎     | 4278/10000 [00:11<00:09, 630.75it/s] 44%|████▎     | 4350/10000 [00:11<00:08, 655.93it/s] 44%|████▍     | 4417/10000 [00:11<00:11, 479.29it/s] 45%|████▍     | 4473/10000 [00:11<00:13, 415.62it/s] 45%|████▌     | 4521/10000 [00:12<00:14, 384.26it/s] 46%|████▌     | 4564/10000 [00:12<00:15, 362.06it/s] 46%|████▌     | 4603/10000 [00:12<00:16, 329.92it/s] 46%|████▋     | 4638/10000 [00:12<00:18, 283.43it/s] 47%|████▋     | 4674/10000 [00:12<00:18, 293.37it/s] 47%|████▋     | 4710/10000 [00:12<00:17, 306.61it/s] 47%|████▋     | 4743/10000 [00:12<00:17, 297.76it/s] 48%|████▊     | 4774/10000 [00:12<00:17, 296.16it/s] 48%|████▊     | 4805/10000 [00:13<00:17, 295.08it/s] 48%|████▊     | 4841/10000 [00:13<00:16, 306.12it/s] 49%|████▊     | 4873/10000 [00:13<00:17, 288.01it/s] 49%|████▉     | 4903/10000 [00:13<00:20, 254.67it/s] 49%|████▉     | 4930/10000 [00:13<00:20, 241.58it/s] 50%|████▉     | 4955/10000 [00:13<00:21, 237.06it/s] 50%|████▉     | 4992/10000 [00:13<00:19, 263.58it/s] 50%|█████     | 5036/10000 [00:13<00:16, 309.84it/s] 51%|█████     | 5102/10000 [00:13<00:12, 394.97it/s] 52%|█████▏    | 5155/10000 [00:14<00:11, 423.38it/s] 52%|█████▏    | 5207/10000 [00:14<00:10, 439.04it/s] 53%|█████▎    | 5252/10000 [00:14<00:14, 320.19it/s] 53%|█████▎    | 5289/10000 [00:14<00:17, 264.14it/s] 53%|█████▎    | 5320/10000 [00:14<00:17, 260.60it/s] 54%|█████▎    | 5350/10000 [00:14<00:19, 243.62it/s] 54%|█████▍    | 5377/10000 [00:15<00:18, 243.83it/s] 54%|█████▍    | 5428/10000 [00:15<00:15, 299.87it/s] 55%|█████▍    | 5486/10000 [00:15<00:12, 366.96it/s] 55%|█████▌    | 5526/10000 [00:15<00:12, 348.14it/s] 56%|█████▌    | 5567/10000 [00:15<00:12, 360.72it/s] 57%|█████▋    | 5651/10000 [00:15<00:09, 465.55it/s] 57%|█████▋    | 5715/10000 [00:15<00:08, 507.40it/s] 58%|█████▊    | 5767/10000 [00:15<00:08, 504.63it/s] 58%|█████▊    | 5820/10000 [00:15<00:08, 498.15it/s] 59%|█████▊    | 5871/10000 [00:16<00:09, 420.09it/s] 59%|█████▉    | 5916/10000 [00:16<00:10, 376.97it/s] 60%|█████▉    | 5956/10000 [00:16<00:10, 369.10it/s] 60%|█████▉    | 5995/10000 [00:16<00:11, 348.60it/s] 60%|██████    | 6036/10000 [00:16<00:10, 361.87it/s] 61%|██████    | 6082/10000 [00:16<00:10, 387.38it/s] 61%|██████▏   | 6146/10000 [00:16<00:08, 447.00it/s] 62%|██████▏   | 6199/10000 [00:16<00:08, 466.11it/s] 62%|██████▏   | 6247/10000 [00:17<00:10, 374.72it/s] 63%|██████▎   | 6288/10000 [00:17<00:10, 354.10it/s] 63%|██████▎   | 6326/10000 [00:17<00:12, 300.44it/s] 64%|██████▎   | 6359/10000 [00:17<00:12, 298.63it/s] 64%|██████▍   | 6391/10000 [00:17<00:11, 300.77it/s] 64%|██████▍   | 6423/10000 [00:17<00:12, 279.25it/s] 65%|██████▍   | 6452/10000 [00:17<00:12, 276.77it/s] 65%|██████▍   | 6485/10000 [00:18<00:13, 266.15it/s] 65%|██████▌   | 6513/10000 [00:18<00:13, 252.20it/s] 65%|██████▌   | 6545/10000 [00:18<00:13, 262.46it/s] 66%|██████▌   | 6572/10000 [00:18<00:12, 264.19it/s] 66%|██████▌   | 6614/10000 [00:18<00:11, 295.89it/s] 66%|██████▋   | 6649/10000 [00:18<00:11, 304.49it/s] 67%|██████▋   | 6694/10000 [00:18<00:09, 341.78it/s] 67%|██████▋   | 6729/10000 [00:18<00:09, 340.07it/s] 68%|██████▊   | 6764/10000 [00:18<00:09, 339.92it/s] 68%|██████▊   | 6809/10000 [00:18<00:08, 368.56it/s] 69%|██████▊   | 6859/10000 [00:19<00:07, 401.59it/s] 69%|██████▉   | 6928/10000 [00:19<00:06, 475.36it/s] 70%|██████▉   | 6979/10000 [00:19<00:06, 479.38it/s] 71%|███████   | 7051/10000 [00:19<00:05, 527.27it/s] 71%|███████   | 7104/10000 [00:19<00:06, 461.86it/s] 72%|███████▏  | 7152/10000 [00:19<00:07, 402.51it/s] 72%|███████▏  | 7215/10000 [00:19<00:06, 457.78it/s] 73%|███████▎  | 7278/10000 [00:19<00:05, 501.87it/s] 74%|███████▎  | 7351/10000 [00:20<00:04, 543.12it/s] 74%|███████▍  | 7417/10000 [00:20<00:04, 570.62it/s] 75%|███████▍  | 7476/10000 [00:20<00:04, 556.75it/s] 75%|███████▌  | 7541/10000 [00:20<00:04, 577.05it/s] 76%|███████▌  | 7600/10000 [00:20<00:04, 555.34it/s] 77%|███████▋  | 7657/10000 [00:20<00:05, 424.75it/s] 77%|███████▋  | 7706/10000 [00:20<00:05, 436.07it/s] 78%|███████▊  | 7754/10000 [00:20<00:05, 409.65it/s] 78%|███████▊  | 7798/10000 [00:21<00:05, 399.74it/s] 78%|███████▊  | 7840/10000 [00:21<00:05, 387.97it/s] 79%|███████▉  | 7891/10000 [00:21<00:05, 413.20it/s] 80%|███████▉  | 7953/10000 [00:21<00:04, 464.07it/s] 80%|████████  | 8038/10000 [00:21<00:03, 556.32it/s] 81%|████████  | 8095/10000 [00:21<00:03, 554.49it/s] 82%|████████▏ | 8152/10000 [00:21<00:03, 554.97it/s] 82%|████████▏ | 8209/10000 [00:21<00:03, 522.64it/s] 83%|████████▎ | 8263/10000 [00:21<00:04, 428.19it/s] 83%|████████▎ | 8309/10000 [00:22<00:04, 395.70it/s] 84%|████████▎ | 8351/10000 [00:22<00:04, 352.03it/s] 84%|████████▍ | 8389/10000 [00:22<00:05, 294.19it/s] 84%|████████▍ | 8437/10000 [00:22<00:04, 330.29it/s] 85%|████████▍ | 8482/10000 [00:22<00:04, 351.93it/s] 85%|████████▌ | 8534/10000 [00:22<00:03, 390.65it/s] 86%|████████▌ | 8576/10000 [00:22<00:03, 398.19it/s] 86%|████████▋ | 8626/10000 [00:23<00:03, 413.29it/s] 87%|████████▋ | 8704/10000 [00:23<00:02, 503.08it/s] 88%|████████▊ | 8768/10000 [00:23<00:02, 532.29it/s] 89%|████████▊ | 8852/10000 [00:23<00:01, 614.64it/s] 89%|████████▉ | 8923/10000 [00:23<00:01, 641.65it/s] 90%|████████▉ | 8995/10000 [00:23<00:01, 664.07it/s] 91%|█████████ | 9063/10000 [00:23<00:01, 658.36it/s] 91%|█████████▏| 9130/10000 [00:23<00:01, 648.52it/s] 92%|█████████▏| 9196/10000 [00:23<00:01, 581.87it/s] 93%|█████████▎| 9256/10000 [00:23<00:01, 559.56it/s] 93%|█████████▎| 9314/10000 [00:24<00:01, 422.43it/s] 94%|█████████▎| 9362/10000 [00:24<00:01, 371.12it/s] 94%|█████████▍| 9404/10000 [00:24<00:01, 328.40it/s] 94%|█████████▍| 9441/10000 [00:24<00:01, 332.85it/s] 95%|█████████▍| 9478/10000 [00:24<00:01, 333.37it/s] 95%|█████████▌| 9521/10000 [00:24<00:01, 354.35it/s] 96%|█████████▌| 9559/10000 [00:25<00:01, 324.99it/s] 96%|█████████▌| 9597/10000 [00:25<00:01, 334.29it/s] 96%|█████████▋| 9632/10000 [00:25<00:01, 301.77it/s] 97%|█████████▋| 9682/10000 [00:25<00:00, 348.34it/s] 97%|█████████▋| 9726/10000 [00:25<00:00, 347.35it/s] 98%|█████████▊| 9762/10000 [00:25<00:00, 320.22it/s] 98%|█████████▊| 9817/10000 [00:25<00:00, 369.86it/s] 99%|█████████▉| 9910/10000 [00:25<00:00, 508.24it/s]100%|█████████▉| 9971/10000 [00:25<00:00, 535.29it/s]100%|██████████| 10000/10000 [00:25<00:00, 384.82it/s]
test_neglected_p87 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p87
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p87.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.03s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.71it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.09it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.24it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 23.91it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 28.99it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 32.76it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 36.22it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 38.59it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.70it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p87_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p87_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p87_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p87_Holmes_probs.npy
{'Accuracy': 0.0205, 'Precision': 0.023, 'Recall': 0.0202, 'F1-score': 0.0179}
starting gen taf script for test_neglected_p88
  0%|          | 0/10000 [00:00<?, ?it/s]  0%|          | 38/10000 [00:00<00:27, 365.53it/s]  1%|          | 83/10000 [00:00<00:24, 408.51it/s]  1%|          | 124/10000 [00:00<00:33, 298.03it/s]  2%|▏         | 157/10000 [00:00<00:33, 290.95it/s]  2%|▏         | 188/10000 [00:00<00:35, 277.52it/s]  2%|▏         | 217/10000 [00:00<00:35, 279.15it/s]  2%|▏         | 246/10000 [00:00<00:39, 247.74it/s]  3%|▎         | 272/10000 [00:01<00:43, 222.10it/s]  3%|▎         | 302/10000 [00:01<00:41, 231.17it/s]  3%|▎         | 334/10000 [00:01<00:38, 253.25it/s]  4%|▎         | 361/10000 [00:01<00:37, 254.84it/s]  4%|▍         | 388/10000 [00:01<00:38, 251.28it/s]  4%|▍         | 414/10000 [00:01<00:38, 247.60it/s]  4%|▍         | 440/10000 [00:01<00:38, 249.38it/s]  5%|▍         | 478/10000 [00:01<00:33, 281.80it/s]  5%|▌         | 514/10000 [00:01<00:31, 303.34it/s]  6%|▌         | 557/10000 [00:01<00:28, 336.19it/s]  6%|▌         | 611/10000 [00:02<00:23, 392.93it/s]  7%|▋         | 706/10000 [00:02<00:16, 555.25it/s]  8%|▊         | 777/10000 [00:02<00:15, 592.92it/s]  8%|▊         | 837/10000 [00:02<00:17, 537.63it/s]  9%|▉         | 893/10000 [00:02<00:19, 472.67it/s]  9%|▉         | 943/10000 [00:02<00:19, 473.82it/s] 10%|▉         | 992/10000 [00:02<00:21, 412.75it/s] 10%|█         | 1036/10000 [00:02<00:22, 405.18it/s] 11%|█         | 1078/10000 [00:03<00:26, 341.75it/s] 11%|█▏        | 1126/10000 [00:03<00:24, 368.32it/s] 12%|█▏        | 1166/10000 [00:03<00:24, 358.05it/s] 12%|█▏        | 1204/10000 [00:03<00:24, 357.76it/s] 13%|█▎        | 1275/10000 [00:03<00:19, 441.73it/s] 13%|█▎        | 1322/10000 [00:03<00:19, 438.20it/s] 14%|█▎        | 1367/10000 [00:03<00:20, 429.48it/s] 14%|█▍        | 1411/10000 [00:03<00:20, 423.34it/s] 15%|█▍        | 1454/10000 [00:04<00:25, 330.12it/s] 15%|█▍        | 1491/10000 [00:04<00:29, 284.36it/s] 15%|█▌        | 1523/10000 [00:04<00:35, 237.94it/s] 16%|█▌        | 1553/10000 [00:04<00:34, 247.09it/s] 16%|█▌        | 1581/10000 [00:04<00:33, 252.59it/s] 16%|█▌        | 1609/10000 [00:04<00:34, 241.31it/s] 17%|█▋        | 1664/10000 [00:04<00:26, 315.99it/s] 17%|█▋        | 1714/10000 [00:05<00:22, 362.45it/s] 18%|█▊        | 1775/10000 [00:05<00:19, 426.21it/s] 18%|█▊        | 1850/10000 [00:05<00:15, 515.21it/s] 19%|█▉        | 1925/10000 [00:05<00:14, 572.80it/s] 20%|██        | 2003/10000 [00:05<00:12, 626.52it/s] 21%|██        | 2068/10000 [00:05<00:13, 566.94it/s] 21%|██▏       | 2127/10000 [00:05<00:14, 543.33it/s] 22%|██▏       | 2183/10000 [00:05<00:16, 464.84it/s] 22%|██▏       | 2233/10000 [00:06<00:17, 451.23it/s] 23%|██▎       | 2280/10000 [00:06<00:22, 348.77it/s] 23%|██▎       | 2320/10000 [00:06<00:23, 332.90it/s] 24%|██▎       | 2357/10000 [00:06<00:23, 318.47it/s] 24%|██▍       | 2391/10000 [00:06<00:24, 314.78it/s] 24%|██▍       | 2450/10000 [00:06<00:20, 370.57it/s] 25%|██▍       | 2489/10000 [00:06<00:20, 372.30it/s] 26%|██▌       | 2558/10000 [00:06<00:17, 432.88it/s] 26%|██▌       | 2603/10000 [00:07<00:19, 386.98it/s] 26%|██▋       | 2643/10000 [00:07<00:24, 300.88it/s] 27%|██▋       | 2677/10000 [00:07<00:30, 239.39it/s] 27%|██▋       | 2705/10000 [00:07<00:31, 234.85it/s] 27%|██▋       | 2732/10000 [00:07<00:30, 235.73it/s] 28%|██▊       | 2758/10000 [00:07<00:32, 224.50it/s] 28%|██▊       | 2782/10000 [00:08<00:33, 215.15it/s] 28%|██▊       | 2811/10000 [00:08<00:31, 225.05it/s] 29%|██▊       | 2868/10000 [00:08<00:23, 302.44it/s] 29%|██▉       | 2926/10000 [00:08<00:18, 372.91it/s] 30%|██▉       | 2966/10000 [00:08<00:19, 369.15it/s] 30%|███       | 3016/10000 [00:08<00:17, 390.05it/s] 31%|███       | 3057/10000 [00:08<00:20, 341.09it/s] 31%|███       | 3093/10000 [00:08<00:21, 328.89it/s] 31%|███▏      | 3128/10000 [00:09<00:22, 304.32it/s] 32%|███▏      | 3160/10000 [00:09<00:24, 277.12it/s] 32%|███▏      | 3196/10000 [00:09<00:22, 297.08it/s] 33%|███▎      | 3262/10000 [00:09<00:17, 384.76it/s] 34%|███▎      | 3354/10000 [00:09<00:12, 512.64it/s] 34%|███▍      | 3408/10000 [00:09<00:12, 509.66it/s] 35%|███▍      | 3461/10000 [00:09<00:14, 464.96it/s] 35%|███▌      | 3510/10000 [00:09<00:13, 463.98it/s] 36%|███▌      | 3558/10000 [00:09<00:14, 459.16it/s] 36%|███▌      | 3614/10000 [00:10<00:13, 471.17it/s] 37%|███▋      | 3681/10000 [00:10<00:12, 520.45it/s] 37%|███▋      | 3739/10000 [00:10<00:11, 536.73it/s] 38%|███▊      | 3814/10000 [00:10<00:10, 596.47it/s] 39%|███▉      | 3875/10000 [00:10<00:12, 485.36it/s] 39%|███▉      | 3928/10000 [00:10<00:15, 398.97it/s] 40%|███▉      | 3980/10000 [00:10<00:14, 423.10it/s] 40%|████      | 4047/10000 [00:10<00:12, 476.33it/s] 41%|████      | 4099/10000 [00:11<00:12, 482.61it/s] 42%|████▏     | 4175/10000 [00:11<00:10, 544.98it/s] 42%|████▏     | 4236/10000 [00:11<00:10, 560.32it/s] 43%|████▎     | 4304/10000 [00:11<00:09, 580.26it/s] 44%|████▎     | 4364/10000 [00:11<00:10, 529.38it/s] 44%|████▍     | 4419/10000 [00:11<00:12, 448.87it/s] 45%|████▍     | 4467/10000 [00:11<00:12, 434.22it/s] 45%|████▌     | 4513/10000 [00:11<00:13, 393.57it/s] 46%|████▌     | 4555/10000 [00:12<00:16, 333.88it/s] 46%|████▌     | 4591/10000 [00:12<00:17, 312.05it/s] 46%|████▌     | 4624/10000 [00:12<00:17, 305.40it/s] 47%|████▋     | 4656/10000 [00:12<00:17, 297.90it/s] 47%|████▋     | 4687/10000 [00:12<00:20, 264.58it/s] 47%|████▋     | 4719/10000 [00:12<00:19, 275.20it/s] 47%|████▋     | 4748/10000 [00:12<00:19, 265.56it/s] 48%|████▊     | 4780/10000 [00:12<00:19, 271.12it/s] 48%|████▊     | 4810/10000 [00:13<00:19, 270.88it/s] 48%|████▊     | 4842/10000 [00:13<00:18, 281.74it/s] 49%|████▊     | 4871/10000 [00:13<00:19, 258.43it/s] 49%|████▉     | 4898/10000 [00:13<00:20, 250.91it/s] 49%|████▉     | 4924/10000 [00:13<00:20, 245.51it/s] 49%|████▉     | 4949/10000 [00:13<00:22, 221.96it/s] 50%|████▉     | 4994/10000 [00:13<00:18, 271.23it/s] 50%|█████     | 5031/10000 [00:13<00:17, 287.87it/s] 51%|█████     | 5084/10000 [00:14<00:14, 349.88it/s] 51%|█████▏    | 5131/10000 [00:14<00:12, 378.36it/s] 52%|█████▏    | 5188/10000 [00:14<00:11, 414.46it/s] 52%|█████▏    | 5230/10000 [00:14<00:11, 408.86it/s] 53%|█████▎    | 5272/10000 [00:14<00:14, 315.93it/s] 53%|█████▎    | 5307/10000 [00:14<00:17, 263.43it/s] 53%|█████▎    | 5337/10000 [00:14<00:17, 263.35it/s] 54%|█████▎    | 5366/10000 [00:15<00:19, 242.71it/s] 54%|█████▍    | 5392/10000 [00:15<00:19, 233.52it/s] 54%|█████▍    | 5438/10000 [00:15<00:16, 280.57it/s] 55%|█████▍    | 5472/10000 [00:15<00:15, 288.82it/s] 55%|█████▌    | 5506/10000 [00:15<00:15, 294.36it/s] 56%|█████▌    | 5560/10000 [00:15<00:12, 354.66it/s] 56%|█████▌    | 5598/10000 [00:15<00:12, 358.11it/s] 57%|█████▋    | 5651/10000 [00:15<00:10, 395.43it/s] 57%|█████▋    | 5721/10000 [00:15<00:08, 479.51it/s] 58%|█████▊    | 5774/10000 [00:16<00:08, 486.84it/s] 58%|█████▊    | 5824/10000 [00:16<00:09, 457.17it/s] 59%|█████▊    | 5871/10000 [00:16<00:10, 381.94it/s] 59%|█████▉    | 5912/10000 [00:16<00:11, 370.34it/s] 60%|█████▉    | 5951/10000 [00:16<00:11, 339.72it/s] 60%|█████▉    | 5987/10000 [00:16<00:13, 303.09it/s] 60%|██████    | 6041/10000 [00:16<00:11, 350.73it/s] 61%|██████    | 6119/10000 [00:16<00:08, 452.36it/s] 62%|██████▏   | 6169/10000 [00:17<00:08, 444.71it/s] 62%|██████▏   | 6216/10000 [00:17<00:08, 431.70it/s] 63%|██████▎   | 6261/10000 [00:17<00:11, 332.43it/s] 63%|██████▎   | 6299/10000 [00:17<00:11, 324.80it/s] 63%|██████▎   | 6335/10000 [00:17<00:13, 270.81it/s] 64%|██████▎   | 6366/10000 [00:17<00:13, 278.30it/s] 64%|██████▍   | 6397/10000 [00:17<00:13, 267.82it/s] 64%|██████▍   | 6426/10000 [00:18<00:14, 241.49it/s] 65%|██████▍   | 6452/10000 [00:18<00:14, 243.82it/s] 65%|██████▍   | 6483/10000 [00:18<00:13, 258.60it/s] 65%|██████▌   | 6510/10000 [00:18<00:14, 240.95it/s] 65%|██████▌   | 6549/10000 [00:18<00:13, 265.38it/s] 66%|██████▌   | 6593/10000 [00:18<00:11, 307.50it/s] 66%|██████▋   | 6625/10000 [00:18<00:11, 284.49it/s] 67%|██████▋   | 6655/10000 [00:18<00:11, 286.39it/s] 67%|██████▋   | 6687/10000 [00:19<00:12, 267.87it/s] 67%|██████▋   | 6719/10000 [00:19<00:11, 276.31it/s] 67%|██████▋   | 6748/10000 [00:19<00:12, 269.17it/s] 68%|██████▊   | 6788/10000 [00:19<00:11, 291.73it/s] 68%|██████▊   | 6828/10000 [00:19<00:09, 317.80it/s] 69%|██████▉   | 6882/10000 [00:19<00:08, 374.08it/s] 70%|██████▉   | 6955/10000 [00:19<00:06, 462.32it/s] 70%|███████   | 7002/10000 [00:19<00:06, 435.47it/s] 71%|███████   | 7053/10000 [00:19<00:06, 455.00it/s] 71%|███████   | 7107/10000 [00:20<00:06, 462.96it/s] 72%|███████▏  | 7154/10000 [00:20<00:07, 383.12it/s] 72%|███████▏  | 7211/10000 [00:20<00:06, 422.27it/s] 73%|███████▎  | 7279/10000 [00:20<00:05, 480.16it/s] 74%|███████▎  | 7354/10000 [00:20<00:04, 551.41it/s] 74%|███████▍  | 7415/10000 [00:20<00:04, 551.43it/s] 75%|███████▍  | 7472/10000 [00:20<00:04, 527.38it/s] 75%|███████▌  | 7533/10000 [00:20<00:04, 545.83it/s] 76%|███████▌  | 7589/10000 [00:21<00:05, 455.94it/s] 76%|███████▋  | 7638/10000 [00:21<00:05, 462.54it/s] 77%|███████▋  | 7687/10000 [00:21<00:05, 397.81it/s] 77%|███████▋  | 7730/10000 [00:21<00:06, 342.27it/s] 78%|███████▊  | 7768/10000 [00:21<00:06, 329.69it/s] 78%|███████▊  | 7846/10000 [00:21<00:05, 430.17it/s] 79%|███████▉  | 7893/10000 [00:21<00:04, 435.25it/s] 79%|███████▉  | 7947/10000 [00:21<00:04, 456.19it/s] 80%|████████  | 8003/10000 [00:22<00:04, 475.47it/s] 81%|████████  | 8053/10000 [00:22<00:04, 471.37it/s] 81%|████████  | 8104/10000 [00:22<00:03, 477.44it/s] 82%|████████▏ | 8189/10000 [00:22<00:03, 578.31it/s] 82%|████████▏ | 8248/10000 [00:22<00:03, 466.38it/s] 83%|████████▎ | 8299/10000 [00:22<00:04, 391.75it/s] 83%|████████▎ | 8343/10000 [00:22<00:04, 349.43it/s] 84%|████████▍ | 8382/10000 [00:23<00:05, 300.34it/s] 84%|████████▍ | 8421/10000 [00:23<00:05, 312.04it/s] 85%|████████▍ | 8456/10000 [00:23<00:04, 315.43it/s] 85%|████████▌ | 8503/10000 [00:23<00:04, 341.80it/s] 85%|████████▌ | 8545/10000 [00:23<00:04, 359.66it/s] 86%|████████▌ | 8595/10000 [00:23<00:03, 394.87it/s] 87%|████████▋ | 8658/10000 [00:23<00:02, 454.82it/s] 87%|████████▋ | 8706/10000 [00:23<00:02, 435.03it/s] 88%|████████▊ | 8793/10000 [00:23<00:02, 538.54it/s] 89%|████████▉ | 8875/10000 [00:24<00:01, 576.17it/s] 89%|████████▉ | 8947/10000 [00:24<00:01, 607.15it/s] 90%|█████████ | 9012/10000 [00:24<00:01, 604.19it/s] 91%|█████████ | 9084/10000 [00:24<00:01, 631.50it/s] 91%|█████████▏| 9148/10000 [00:24<00:01, 578.67it/s] 92%|█████████▏| 9207/10000 [00:24<00:01, 512.79it/s] 93%|█████████▎| 9261/10000 [00:24<00:01, 396.81it/s] 93%|█████████▎| 9306/10000 [00:25<00:02, 334.26it/s] 93%|█████████▎| 9344/10000 [00:25<00:02, 320.74it/s] 94%|█████████▍| 9379/10000 [00:25<00:02, 297.73it/s] 94%|█████████▍| 9411/10000 [00:25<00:02, 286.72it/s] 94%|█████████▍| 9441/10000 [00:25<00:02, 278.59it/s] 95%|█████████▍| 9488/10000 [00:25<00:01, 323.90it/s] 95%|█████████▌| 9529/10000 [00:25<00:01, 330.31it/s] 96%|█████████▌| 9571/10000 [00:25<00:01, 329.39it/s] 96%|█████████▌| 9605/10000 [00:26<00:01, 293.86it/s] 96%|█████████▋| 9644/10000 [00:26<00:01, 312.36it/s] 97%|█████████▋| 9693/10000 [00:26<00:00, 356.51it/s] 97%|█████████▋| 9731/10000 [00:26<00:00, 329.05it/s] 98%|█████████▊| 9771/10000 [00:26<00:00, 345.77it/s] 98%|█████████▊| 9829/10000 [00:26<00:00, 408.28it/s] 99%|█████████▉| 9882/10000 [00:26<00:00, 440.13it/s]100%|█████████▉| 9966/10000 [00:26<00:00, 551.56it/s]100%|██████████| 10000/10000 [00:26<00:00, 371.97it/s]
test_neglected_p88 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p88
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p88.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.01s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.81it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.23it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.48it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.45it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.60it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.95it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.51it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.72it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.15it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p88_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p88_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p88_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p88_Holmes_probs.npy
{'Accuracy': 0.0206, 'Precision': 0.0241, 'Recall': 0.0203, 'F1-score': 0.0183}
starting gen taf script for test_neglected_p89
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 61/10000 [00:00<00:16, 594.51it/s]  1%|          | 121/10000 [00:00<00:26, 371.76it/s]  2%|▏         | 163/10000 [00:00<00:33, 289.59it/s]  2%|▏         | 196/10000 [00:00<00:33, 292.87it/s]  2%|▏         | 228/10000 [00:00<00:35, 276.54it/s]  3%|▎         | 260/10000 [00:00<00:33, 286.91it/s]  3%|▎         | 290/10000 [00:00<00:34, 282.27it/s]  3%|▎         | 319/10000 [00:01<00:34, 277.66it/s]  4%|▎         | 350/10000 [00:01<00:34, 278.11it/s]  4%|▍         | 379/10000 [00:01<00:35, 270.42it/s]  4%|▍         | 409/10000 [00:01<00:34, 276.19it/s]  4%|▍         | 437/10000 [00:01<00:35, 267.43it/s]  5%|▍         | 488/10000 [00:01<00:28, 329.40it/s]  5%|▌         | 522/10000 [00:01<00:28, 327.86it/s]  6%|▌         | 556/10000 [00:01<00:28, 328.77it/s]  6%|▌         | 593/10000 [00:01<00:28, 335.45it/s]  6%|▋         | 627/10000 [00:02<00:28, 329.95it/s]  7%|▋         | 676/10000 [00:02<00:24, 375.59it/s]  7%|▋         | 723/10000 [00:02<00:23, 400.78it/s]  8%|▊         | 801/10000 [00:02<00:19, 479.67it/s]  8%|▊         | 849/10000 [00:02<00:21, 431.48it/s]  9%|▉         | 895/10000 [00:02<00:20, 438.85it/s]  9%|▉         | 943/10000 [00:02<00:20, 439.23it/s] 10%|▉         | 988/10000 [00:02<00:22, 397.59it/s] 10%|█         | 1029/10000 [00:02<00:22, 399.65it/s] 11%|█         | 1070/10000 [00:03<00:25, 343.47it/s] 11%|█         | 1106/10000 [00:03<00:26, 338.19it/s] 11%|█▏        | 1145/10000 [00:03<00:25, 344.37it/s] 12%|█▏        | 1181/10000 [00:03<00:25, 344.81it/s] 12%|█▏        | 1217/10000 [00:03<00:27, 323.24it/s] 13%|█▎        | 1269/10000 [00:03<00:23, 366.92it/s] 13%|█▎        | 1338/10000 [00:03<00:19, 454.00it/s] 14%|█▍        | 1405/10000 [00:03<00:16, 510.23it/s] 15%|█▍        | 1458/10000 [00:04<00:23, 365.87it/s] 15%|█▌        | 1502/10000 [00:04<00:29, 291.80it/s] 15%|█▌        | 1538/10000 [00:04<00:33, 252.36it/s] 16%|█▌        | 1569/10000 [00:04<00:33, 254.48it/s] 16%|█▌        | 1599/10000 [00:04<00:36, 228.37it/s] 17%|█▋        | 1653/10000 [00:04<00:28, 289.35it/s] 17%|█▋        | 1711/10000 [00:05<00:23, 349.70it/s] 18%|█▊        | 1770/10000 [00:05<00:20, 400.94it/s] 18%|█▊        | 1848/10000 [00:05<00:16, 494.00it/s] 19%|█▉        | 1923/10000 [00:05<00:14, 554.17it/s] 20%|█▉        | 1993/10000 [00:05<00:13, 591.36it/s] 21%|██        | 2056/10000 [00:05<00:14, 543.86it/s] 21%|██        | 2114/10000 [00:05<00:17, 459.89it/s] 22%|██▏       | 2184/10000 [00:05<00:15, 514.57it/s] 22%|██▏       | 2240/10000 [00:06<00:18, 410.32it/s] 23%|██▎       | 2287/10000 [00:06<00:20, 369.77it/s] 23%|██▎       | 2329/10000 [00:06<00:23, 330.67it/s] 24%|██▎       | 2366/10000 [00:06<00:24, 316.28it/s] 24%|██▍       | 2400/10000 [00:06<00:25, 298.85it/s] 24%|██▍       | 2440/10000 [00:06<00:23, 321.29it/s] 25%|██▌       | 2502/10000 [00:06<00:19, 388.63it/s] 26%|██▌       | 2560/10000 [00:07<00:17, 431.45it/s] 26%|██▌       | 2606/10000 [00:07<00:20, 354.96it/s] 26%|██▋       | 2646/10000 [00:07<00:22, 323.87it/s] 27%|██▋       | 2682/10000 [00:07<00:26, 271.63it/s] 27%|██▋       | 2713/10000 [00:07<00:28, 251.78it/s] 27%|██▋       | 2741/10000 [00:07<00:31, 229.00it/s] 28%|██▊       | 2766/10000 [00:08<00:32, 219.73it/s] 28%|██▊       | 2789/10000 [00:08<00:36, 196.64it/s] 28%|██▊       | 2843/10000 [00:08<00:26, 269.24it/s] 29%|██▉       | 2889/10000 [00:08<00:22, 311.81it/s] 29%|██▉       | 2945/10000 [00:08<00:18, 372.03it/s] 30%|██▉       | 2995/10000 [00:08<00:17, 391.16it/s] 30%|███       | 3037/10000 [00:08<00:18, 369.56it/s] 31%|███       | 3076/10000 [00:08<00:20, 338.54it/s] 31%|███       | 3112/10000 [00:08<00:21, 321.73it/s] 31%|███▏      | 3146/10000 [00:09<00:23, 295.64it/s] 32%|███▏      | 3181/10000 [00:09<00:22, 307.08it/s] 32%|███▏      | 3213/10000 [00:09<00:22, 300.70it/s] 33%|███▎      | 3291/10000 [00:09<00:15, 421.22it/s] 34%|███▎      | 3370/10000 [00:09<00:12, 513.95it/s] 34%|███▍      | 3424/10000 [00:09<00:13, 482.53it/s] 35%|███▍      | 3474/10000 [00:09<00:13, 483.50it/s] 35%|███▌      | 3526/10000 [00:09<00:13, 491.90it/s] 36%|███▌      | 3576/10000 [00:10<00:14, 444.24it/s] 36%|███▌      | 3622/10000 [00:10<00:15, 416.00it/s] 37%|███▋      | 3693/10000 [00:10<00:12, 492.47it/s] 37%|███▋      | 3745/10000 [00:10<00:12, 489.51it/s] 38%|███▊      | 3811/10000 [00:10<00:11, 520.09it/s] 39%|███▊      | 3864/10000 [00:10<00:13, 453.77it/s] 39%|███▉      | 3914/10000 [00:10<00:13, 447.47it/s] 40%|███▉      | 3961/10000 [00:10<00:14, 406.39it/s] 40%|████      | 4014/10000 [00:11<00:13, 432.43it/s] 41%|████      | 4083/10000 [00:11<00:12, 492.07it/s] 42%|████▏     | 4152/10000 [00:11<00:10, 540.20it/s] 42%|████▏     | 4211/10000 [00:11<00:10, 544.90it/s] 43%|████▎     | 4273/10000 [00:11<00:10, 556.92it/s] 43%|████▎     | 4330/10000 [00:11<00:10, 551.99it/s] 44%|████▍     | 4386/10000 [00:11<00:10, 542.47it/s] 44%|████▍     | 4441/10000 [00:11<00:13, 414.97it/s] 45%|████▍     | 4488/10000 [00:11<00:12, 425.96it/s] 45%|████▌     | 4535/10000 [00:12<00:14, 379.41it/s] 46%|████▌     | 4577/10000 [00:12<00:16, 319.14it/s] 46%|████▌     | 4613/10000 [00:12<00:16, 317.24it/s] 46%|████▋     | 4650/10000 [00:12<00:16, 322.14it/s] 47%|████▋     | 4684/10000 [00:12<00:19, 274.93it/s] 47%|████▋     | 4718/10000 [00:12<00:18, 283.79it/s] 48%|████▊     | 4763/10000 [00:12<00:16, 321.69it/s] 48%|████▊     | 4798/10000 [00:13<00:18, 285.78it/s] 48%|████▊     | 4834/10000 [00:13<00:17, 296.63it/s] 49%|████▊     | 4866/10000 [00:13<00:18, 275.45it/s] 49%|████▉     | 4895/10000 [00:13<00:21, 233.63it/s] 49%|████▉     | 4920/10000 [00:13<00:24, 210.10it/s] 50%|████▉     | 4950/10000 [00:13<00:21, 230.09it/s] 50%|████▉     | 4985/10000 [00:13<00:19, 253.27it/s] 50%|█████     | 5012/10000 [00:13<00:19, 255.82it/s] 51%|█████     | 5071/10000 [00:14<00:14, 337.78it/s] 51%|█████▏    | 5139/10000 [00:14<00:11, 421.44it/s] 52%|█████▏    | 5183/10000 [00:14<00:11, 422.99it/s] 52%|█████▏    | 5227/10000 [00:14<00:14, 319.32it/s] 53%|█████▎    | 5264/10000 [00:14<00:15, 296.46it/s] 53%|█████▎    | 5299/10000 [00:14<00:15, 303.83it/s] 53%|█████▎    | 5332/10000 [00:14<00:16, 284.21it/s] 54%|█████▎    | 5363/10000 [00:15<00:17, 264.93it/s] 54%|█████▍    | 5391/10000 [00:15<00:18, 253.71it/s] 54%|█████▍    | 5432/10000 [00:15<00:15, 289.27it/s] 55%|█████▍    | 5467/10000 [00:15<00:15, 300.71it/s] 55%|█████▌    | 5532/10000 [00:15<00:11, 375.41it/s] 56%|█████▌    | 5581/10000 [00:15<00:11, 395.55it/s] 56%|█████▋    | 5633/10000 [00:15<00:10, 425.74it/s] 57%|█████▋    | 5677/10000 [00:15<00:10, 423.04it/s] 57%|█████▋    | 5735/10000 [00:15<00:09, 466.98it/s] 58%|█████▊    | 5794/10000 [00:16<00:08, 501.74it/s] 58%|█████▊    | 5845/10000 [00:16<00:09, 436.03it/s] 59%|█████▉    | 5891/10000 [00:16<00:10, 379.24it/s] 59%|█████▉    | 5932/10000 [00:16<00:10, 385.80it/s] 60%|█████▉    | 5973/10000 [00:16<00:12, 321.19it/s] 60%|██████    | 6026/10000 [00:16<00:10, 362.03it/s] 61%|██████    | 6067/10000 [00:16<00:10, 368.57it/s] 61%|██████    | 6115/10000 [00:16<00:09, 388.54it/s] 62%|██████▏   | 6178/10000 [00:17<00:08, 450.34it/s] 62%|██████▏   | 6227/10000 [00:17<00:08, 422.64it/s] 63%|██████▎   | 6271/10000 [00:17<00:10, 350.14it/s] 63%|██████▎   | 6309/10000 [00:17<00:12, 289.26it/s] 63%|██████▎   | 6342/10000 [00:17<00:14, 259.77it/s] 64%|██████▍   | 6378/10000 [00:17<00:12, 279.16it/s] 64%|██████▍   | 6415/10000 [00:17<00:12, 296.70it/s] 64%|██████▍   | 6447/10000 [00:18<00:11, 300.83it/s] 65%|██████▍   | 6479/10000 [00:18<00:11, 296.40it/s] 65%|██████▌   | 6510/10000 [00:18<00:12, 280.04it/s] 65%|██████▌   | 6539/10000 [00:18<00:13, 265.33it/s] 66%|██████▌   | 6584/10000 [00:18<00:10, 312.12it/s] 66%|██████▌   | 6617/10000 [00:18<00:12, 266.57it/s] 67%|██████▋   | 6671/10000 [00:18<00:10, 318.92it/s] 67%|██████▋   | 6708/10000 [00:18<00:10, 319.89it/s] 67%|██████▋   | 6749/10000 [00:19<00:09, 342.33it/s] 68%|██████▊   | 6785/10000 [00:19<00:10, 318.53it/s] 68%|██████▊   | 6846/10000 [00:19<00:08, 388.96it/s] 69%|██████▉   | 6897/10000 [00:19<00:07, 414.80it/s] 70%|██████▉   | 6974/10000 [00:19<00:05, 510.25it/s] 70%|███████   | 7031/10000 [00:19<00:05, 513.60it/s] 71%|███████   | 7084/10000 [00:19<00:05, 498.49it/s] 71%|███████▏  | 7135/10000 [00:19<00:05, 484.49it/s] 72%|███████▏  | 7185/10000 [00:19<00:06, 465.09it/s] 73%|███████▎  | 7259/10000 [00:20<00:05, 518.97it/s] 73%|███████▎  | 7329/10000 [00:20<00:04, 557.73it/s] 74%|███████▍  | 7386/10000 [00:20<00:04, 555.97it/s] 74%|███████▍  | 7442/10000 [00:20<00:04, 541.12it/s] 75%|███████▍  | 7497/10000 [00:20<00:04, 512.13it/s] 76%|███████▌  | 7554/10000 [00:20<00:04, 520.53it/s] 76%|███████▌  | 7607/10000 [00:20<00:04, 497.54it/s] 77%|███████▋  | 7658/10000 [00:20<00:05, 420.32it/s] 77%|███████▋  | 7705/10000 [00:20<00:05, 430.90it/s] 78%|███████▊  | 7750/10000 [00:21<00:05, 401.48it/s] 78%|███████▊  | 7792/10000 [00:21<00:05, 388.93it/s] 78%|███████▊  | 7848/10000 [00:21<00:05, 427.67it/s] 79%|███████▉  | 7910/10000 [00:21<00:04, 473.14it/s] 80%|███████▉  | 7959/10000 [00:21<00:04, 453.06it/s] 80%|████████  | 8027/10000 [00:21<00:03, 500.07it/s] 81%|████████  | 8083/10000 [00:21<00:03, 510.19it/s] 81%|████████▏ | 8139/10000 [00:21<00:03, 515.41it/s] 82%|████████▏ | 8193/10000 [00:21<00:03, 519.50it/s] 82%|████████▏ | 8246/10000 [00:22<00:03, 504.50it/s] 83%|████████▎ | 8297/10000 [00:22<00:04, 374.21it/s] 83%|████████▎ | 8340/10000 [00:22<00:04, 346.03it/s] 84%|████████▍ | 8379/10000 [00:22<00:05, 311.37it/s] 84%|████████▍ | 8419/10000 [00:22<00:04, 326.35it/s] 85%|████████▍ | 8463/10000 [00:22<00:04, 350.72it/s] 85%|████████▌ | 8501/10000 [00:22<00:04, 354.21it/s] 85%|████████▌ | 8539/10000 [00:23<00:04, 348.99it/s] 86%|████████▌ | 8581/10000 [00:23<00:03, 362.26it/s] 87%|████████▋ | 8652/10000 [00:23<00:03, 446.66it/s] 87%|████████▋ | 8740/10000 [00:23<00:02, 563.02it/s] 88%|████████▊ | 8799/10000 [00:23<00:02, 565.00it/s] 89%|████████▉ | 8880/10000 [00:23<00:01, 628.68it/s] 90%|████████▉ | 8974/10000 [00:23<00:01, 711.47it/s] 90%|█████████ | 9047/10000 [00:23<00:01, 709.93it/s] 91%|█████████ | 9119/10000 [00:23<00:01, 676.51it/s] 92%|█████████▏| 9188/10000 [00:24<00:01, 583.45it/s] 92%|█████████▏| 9249/10000 [00:24<00:01, 519.78it/s] 93%|█████████▎| 9304/10000 [00:24<00:01, 429.82it/s] 94%|█████████▎| 9351/10000 [00:24<00:01, 382.22it/s] 94%|█████████▍| 9393/10000 [00:24<00:01, 332.28it/s] 94%|█████████▍| 9430/10000 [00:24<00:01, 337.97it/s] 95%|█████████▍| 9466/10000 [00:25<00:01, 309.40it/s] 95%|█████████▍| 9499/10000 [00:25<00:01, 313.93it/s] 95%|█████████▌| 9532/10000 [00:25<00:01, 274.20it/s] 96%|█████████▌| 9566/10000 [00:25<00:01, 288.06it/s] 96%|█████████▌| 9609/10000 [00:25<00:01, 316.22it/s] 97%|█████████▋| 9655/10000 [00:25<00:00, 351.36it/s] 97%|█████████▋| 9692/10000 [00:25<00:00, 349.59it/s] 97%|█████████▋| 9731/10000 [00:25<00:00, 352.52it/s] 98%|█████████▊| 9767/10000 [00:25<00:00, 336.88it/s] 98%|█████████▊| 9810/10000 [00:26<00:00, 359.52it/s] 99%|█████████▊| 9869/10000 [00:26<00:00, 420.94it/s]100%|█████████▉| 9953/10000 [00:26<00:00, 536.59it/s]100%|██████████| 10000/10000 [00:26<00:00, 380.49it/s]
test_neglected_p89 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p89
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p89.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.02it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.94it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.56it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.10it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.05it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.19it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.35it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.66it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.87it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.45it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p89_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p89_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p89_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p89_Holmes_probs.npy
{'Accuracy': 0.0204, 'Precision': 0.0243, 'Recall': 0.0201, 'F1-score': 0.018}
starting gen taf script for test_neglected_p90
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 85/10000 [00:00<00:11, 842.46it/s]  2%|▏         | 170/10000 [00:00<00:28, 350.90it/s]  2%|▏         | 220/10000 [00:00<00:32, 298.43it/s]  3%|▎         | 258/10000 [00:00<00:31, 308.04it/s]  3%|▎         | 294/10000 [00:00<00:32, 298.65it/s]  3%|▎         | 327/10000 [00:01<00:33, 285.11it/s]  4%|▎         | 358/10000 [00:01<00:34, 279.95it/s]  4%|▍         | 388/10000 [00:01<00:35, 270.69it/s]  4%|▍         | 421/10000 [00:01<00:33, 284.02it/s]  5%|▍         | 451/10000 [00:01<00:33, 286.53it/s]  5%|▍         | 481/10000 [00:01<00:33, 282.03it/s]  5%|▌         | 516/10000 [00:01<00:31, 298.24it/s]  6%|▌         | 558/10000 [00:01<00:28, 331.41it/s]  6%|▌         | 592/10000 [00:01<00:28, 329.17it/s]  6%|▋         | 628/10000 [00:01<00:27, 336.23it/s]  7%|▋         | 662/10000 [00:02<00:27, 335.57it/s]  7%|▋         | 696/10000 [00:02<00:29, 317.03it/s]  7%|▋         | 733/10000 [00:02<00:28, 330.66it/s]  8%|▊         | 793/10000 [00:02<00:22, 407.69it/s]  8%|▊         | 841/10000 [00:02<00:22, 406.72it/s]  9%|▉         | 883/10000 [00:02<00:23, 380.46it/s]  9%|▉         | 933/10000 [00:02<00:22, 399.11it/s] 10%|▉         | 995/10000 [00:02<00:19, 451.05it/s] 10%|█         | 1041/10000 [00:03<00:22, 404.02it/s] 11%|█         | 1083/10000 [00:03<00:25, 343.73it/s] 11%|█         | 1120/10000 [00:03<00:31, 280.73it/s] 12%|█▏        | 1163/10000 [00:03<00:28, 308.64it/s] 12%|█▏        | 1197/10000 [00:03<00:29, 300.50it/s] 13%|█▎        | 1274/10000 [00:03<00:21, 406.87it/s] 13%|█▎        | 1324/10000 [00:03<00:20, 428.18it/s] 14%|█▎        | 1370/10000 [00:03<00:19, 431.62it/s] 14%|█▍        | 1416/10000 [00:04<00:23, 365.91it/s] 15%|█▍        | 1456/10000 [00:04<00:29, 286.34it/s] 15%|█▍        | 1489/10000 [00:04<00:32, 264.14it/s] 15%|█▌        | 1519/10000 [00:04<00:32, 260.61it/s] 15%|█▌        | 1548/10000 [00:04<00:37, 224.00it/s] 16%|█▌        | 1574/10000 [00:04<00:37, 222.32it/s] 16%|█▌        | 1598/10000 [00:05<00:37, 225.60it/s] 16%|█▋        | 1650/10000 [00:05<00:28, 288.29it/s] 17%|█▋        | 1704/10000 [00:05<00:25, 330.66it/s] 18%|█▊        | 1767/10000 [00:05<00:20, 399.71it/s] 18%|█▊        | 1849/10000 [00:05<00:16, 501.69it/s] 19%|█▉        | 1920/10000 [00:05<00:14, 550.29it/s] 20%|█▉        | 1993/10000 [00:05<00:13, 599.70it/s] 21%|██        | 2055/10000 [00:05<00:15, 515.57it/s] 21%|██        | 2110/10000 [00:06<00:17, 440.88it/s] 22%|██▏       | 2158/10000 [00:06<00:18, 420.80it/s] 22%|██▏       | 2217/10000 [00:06<00:18, 429.98it/s] 23%|██▎       | 2262/10000 [00:06<00:21, 351.99it/s] 23%|██▎       | 2305/10000 [00:06<00:21, 365.23it/s] 23%|██▎       | 2345/10000 [00:06<00:24, 316.20it/s] 24%|██▍       | 2380/10000 [00:06<00:24, 306.06it/s] 24%|██▍       | 2423/10000 [00:06<00:23, 327.49it/s] 25%|██▍       | 2481/10000 [00:07<00:19, 383.72it/s] 25%|██▌       | 2540/10000 [00:07<00:17, 436.00it/s] 26%|██▌       | 2595/10000 [00:07<00:15, 464.94it/s] 26%|██▋       | 2644/10000 [00:07<00:23, 315.19it/s] 27%|██▋       | 2684/10000 [00:07<00:26, 272.17it/s] 27%|██▋       | 2718/10000 [00:07<00:30, 242.40it/s] 27%|██▋       | 2747/10000 [00:08<00:32, 220.79it/s] 28%|██▊       | 2773/10000 [00:08<00:31, 226.75it/s] 28%|██▊       | 2799/10000 [00:08<00:34, 207.24it/s] 29%|██▊       | 2851/10000 [00:08<00:26, 273.09it/s] 29%|██▉       | 2901/10000 [00:08<00:22, 321.88it/s] 29%|██▉       | 2937/10000 [00:08<00:22, 307.43it/s] 30%|██▉       | 2993/10000 [00:08<00:19, 361.87it/s] 30%|███       | 3035/10000 [00:08<00:18, 374.86it/s] 31%|███       | 3075/10000 [00:09<00:21, 323.90it/s] 31%|███       | 3110/10000 [00:09<00:22, 310.59it/s] 31%|███▏      | 3143/10000 [00:09<00:25, 273.84it/s] 32%|███▏      | 3173/10000 [00:09<00:25, 268.32it/s] 32%|███▏      | 3233/10000 [00:09<00:19, 348.08it/s] 33%|███▎      | 3318/10000 [00:09<00:14, 469.99it/s] 34%|███▎      | 3374/10000 [00:09<00:13, 488.92it/s] 34%|███▍      | 3431/10000 [00:09<00:12, 510.63it/s] 35%|███▍      | 3484/10000 [00:10<00:14, 451.69it/s] 35%|███▌      | 3532/10000 [00:10<00:14, 457.76it/s] 36%|███▌      | 3580/10000 [00:10<00:14, 431.34it/s] 36%|███▋      | 3625/10000 [00:10<00:14, 430.79it/s] 37%|███▋      | 3688/10000 [00:10<00:13, 484.47it/s] 37%|███▋      | 3738/10000 [00:10<00:13, 480.20it/s] 38%|███▊      | 3814/10000 [00:10<00:11, 548.95it/s] 39%|███▊      | 3870/10000 [00:10<00:12, 473.29it/s] 39%|███▉      | 3920/10000 [00:11<00:14, 430.65it/s] 40%|███▉      | 3966/10000 [00:11<00:13, 432.56it/s] 40%|████      | 4011/10000 [00:11<00:14, 425.50it/s] 41%|████      | 4055/10000 [00:11<00:14, 422.79it/s] 41%|████▏     | 4136/10000 [00:11<00:11, 526.46it/s] 42%|████▏     | 4194/10000 [00:11<00:10, 533.73it/s] 43%|████▎     | 4256/10000 [00:11<00:10, 558.03it/s] 43%|████▎     | 4316/10000 [00:11<00:10, 557.98it/s] 44%|████▎     | 4373/10000 [00:11<00:10, 543.12it/s] 44%|████▍     | 4428/10000 [00:12<00:11, 475.94it/s] 45%|████▍     | 4478/10000 [00:12<00:13, 398.16it/s] 45%|████▌     | 4521/10000 [00:12<00:16, 339.97it/s] 46%|████▌     | 4559/10000 [00:12<00:20, 268.33it/s] 46%|████▌     | 4590/10000 [00:12<00:19, 275.25it/s] 46%|████▋     | 4628/10000 [00:12<00:18, 296.24it/s] 47%|████▋     | 4664/10000 [00:12<00:17, 311.26it/s] 47%|████▋     | 4698/10000 [00:13<00:18, 287.38it/s] 47%|████▋     | 4729/10000 [00:13<00:18, 282.83it/s] 48%|████▊     | 4767/10000 [00:13<00:17, 291.48it/s] 48%|████▊     | 4798/10000 [00:13<00:19, 263.43it/s] 48%|████▊     | 4826/10000 [00:13<00:19, 261.54it/s] 49%|████▊     | 4853/10000 [00:13<00:19, 261.38it/s] 49%|████▉     | 4887/10000 [00:13<00:18, 281.38it/s] 49%|████▉     | 4916/10000 [00:13<00:19, 262.14it/s] 49%|████▉     | 4943/10000 [00:14<00:21, 236.59it/s] 50%|████▉     | 4971/10000 [00:14<00:20, 247.03it/s] 50%|████▉     | 4997/10000 [00:14<00:20, 250.14it/s] 50%|█████     | 5040/10000 [00:14<00:17, 291.33it/s] 51%|█████     | 5076/10000 [00:14<00:15, 310.02it/s] 51%|█████     | 5123/10000 [00:14<00:13, 353.85it/s] 52%|█████▏    | 5167/10000 [00:14<00:13, 368.54it/s] 52%|█████▏    | 5205/10000 [00:14<00:13, 358.95it/s] 52%|█████▏    | 5242/10000 [00:14<00:14, 335.91it/s] 53%|█████▎    | 5277/10000 [00:15<00:17, 270.59it/s] 53%|█████▎    | 5307/10000 [00:15<00:18, 256.08it/s] 53%|█████▎    | 5342/10000 [00:15<00:17, 270.09it/s] 54%|█████▎    | 5371/10000 [00:15<00:18, 248.67it/s] 54%|█████▍    | 5405/10000 [00:15<00:17, 269.92it/s] 54%|█████▍    | 5445/10000 [00:15<00:15, 296.55it/s] 55%|█████▍    | 5481/10000 [00:15<00:14, 306.31it/s] 55%|█████▌    | 5531/10000 [00:15<00:12, 349.42it/s] 56%|█████▌    | 5567/10000 [00:16<00:12, 346.13it/s] 56%|█████▌    | 5620/10000 [00:16<00:11, 392.94it/s] 57%|█████▋    | 5681/10000 [00:16<00:09, 446.22it/s] 58%|█████▊    | 5751/10000 [00:16<00:08, 498.57it/s] 58%|█████▊    | 5802/10000 [00:16<00:09, 422.76it/s] 58%|█████▊    | 5847/10000 [00:16<00:09, 424.88it/s] 59%|█████▉    | 5891/10000 [00:16<00:09, 419.02it/s] 59%|█████▉    | 5934/10000 [00:16<00:10, 393.85it/s] 60%|█████▉    | 5975/10000 [00:17<00:11, 348.91it/s] 60%|██████    | 6012/10000 [00:17<00:11, 350.98it/s] 61%|██████    | 6061/10000 [00:17<00:10, 379.04it/s] 61%|██████    | 6123/10000 [00:17<00:08, 443.09it/s] 62%|██████▏   | 6169/10000 [00:17<00:08, 439.84it/s] 62%|██████▏   | 6214/10000 [00:17<00:08, 433.27it/s] 63%|██████▎   | 6258/10000 [00:17<00:10, 344.61it/s] 63%|██████▎   | 6296/10000 [00:17<00:11, 320.72it/s] 63%|██████▎   | 6331/10000 [00:18<00:12, 304.00it/s] 64%|██████▎   | 6363/10000 [00:18<00:14, 257.33it/s] 64%|██████▍   | 6396/10000 [00:18<00:13, 267.59it/s] 64%|██████▍   | 6425/10000 [00:18<00:14, 252.59it/s] 65%|██████▍   | 6452/10000 [00:18<00:13, 255.65it/s] 65%|██████▍   | 6492/10000 [00:18<00:12, 287.94it/s] 65%|██████▌   | 6522/10000 [00:18<00:12, 275.84it/s] 66%|██████▌   | 6551/10000 [00:18<00:14, 243.28it/s] 66%|██████▌   | 6597/10000 [00:19<00:11, 290.47it/s] 66%|██████▋   | 6628/10000 [00:19<00:12, 272.04it/s] 67%|██████▋   | 6665/10000 [00:19<00:11, 296.67it/s] 67%|██████▋   | 6696/10000 [00:19<00:12, 270.32it/s] 67%|██████▋   | 6737/10000 [00:19<00:11, 294.62it/s] 68%|██████▊   | 6768/10000 [00:19<00:11, 277.12it/s] 68%|██████▊   | 6820/10000 [00:19<00:09, 337.81it/s] 69%|██████▉   | 6898/10000 [00:19<00:07, 430.63it/s] 70%|██████▉   | 6955/10000 [00:20<00:06, 457.54it/s] 70%|███████   | 7021/10000 [00:20<00:05, 507.37it/s] 71%|███████   | 7073/10000 [00:20<00:06, 461.47it/s] 71%|███████   | 7122/10000 [00:20<00:06, 466.39it/s] 72%|███████▏  | 7170/10000 [00:20<00:06, 438.60it/s] 72%|███████▏  | 7239/10000 [00:20<00:05, 481.61it/s] 73%|███████▎  | 7288/10000 [00:20<00:05, 467.96it/s] 73%|███████▎  | 7340/10000 [00:20<00:05, 479.65it/s] 74%|███████▍  | 7409/10000 [00:20<00:04, 531.14it/s] 75%|███████▍  | 7466/10000 [00:21<00:04, 523.61it/s] 75%|███████▌  | 7519/10000 [00:21<00:04, 509.85it/s] 76%|███████▌  | 7571/10000 [00:21<00:05, 450.49it/s] 76%|███████▌  | 7618/10000 [00:21<00:05, 422.67it/s] 77%|███████▋  | 7662/10000 [00:21<00:06, 388.84it/s] 77%|███████▋  | 7711/10000 [00:21<00:05, 413.18it/s] 78%|███████▊  | 7754/10000 [00:21<00:06, 373.00it/s] 78%|███████▊  | 7793/10000 [00:21<00:06, 357.58it/s] 78%|███████▊  | 7847/10000 [00:22<00:05, 396.27it/s] 79%|███████▉  | 7926/10000 [00:22<00:04, 489.05it/s] 80%|███████▉  | 7983/10000 [00:22<00:04, 498.98it/s] 80%|████████  | 8050/10000 [00:22<00:03, 542.96it/s] 81%|████████  | 8107/10000 [00:22<00:03, 539.26it/s] 82%|████████▏ | 8162/10000 [00:22<00:03, 510.53it/s] 82%|████████▏ | 8214/10000 [00:22<00:03, 506.05it/s] 83%|████████▎ | 8266/10000 [00:22<00:04, 419.73it/s] 83%|████████▎ | 8311/10000 [00:23<00:04, 359.09it/s] 84%|████████▎ | 8350/10000 [00:23<00:04, 357.51it/s] 84%|████████▍ | 8388/10000 [00:23<00:05, 309.05it/s] 84%|████████▍ | 8424/10000 [00:23<00:04, 320.06it/s] 85%|████████▍ | 8461/10000 [00:23<00:04, 332.27it/s] 85%|████████▍ | 8499/10000 [00:23<00:04, 337.78it/s] 85%|████████▌ | 8534/10000 [00:23<00:04, 322.81it/s] 86%|████████▌ | 8592/10000 [00:23<00:03, 379.26it/s] 87%|████████▋ | 8665/10000 [00:23<00:02, 460.72it/s] 87%|████████▋ | 8731/10000 [00:24<00:02, 501.26it/s] 88%|████████▊ | 8794/10000 [00:24<00:02, 532.43it/s] 88%|████████▊ | 8849/10000 [00:24<00:02, 524.29it/s] 89%|████████▉ | 8906/10000 [00:24<00:02, 530.22it/s] 90%|█████████ | 9006/10000 [00:24<00:01, 632.28it/s] 91%|█████████ | 9069/10000 [00:24<00:01, 582.87it/s] 91%|█████████▏| 9128/10000 [00:24<00:01, 534.53it/s] 92%|█████████▏| 9192/10000 [00:24<00:01, 543.25it/s] 92%|█████████▏| 9247/10000 [00:25<00:01, 428.75it/s] 93%|█████████▎| 9294/10000 [00:25<00:01, 396.93it/s] 93%|█████████▎| 9337/10000 [00:25<00:01, 336.00it/s] 94%|█████████▎| 9374/10000 [00:25<00:02, 301.16it/s] 94%|█████████▍| 9411/10000 [00:25<00:01, 315.16it/s] 94%|█████████▍| 9446/10000 [00:25<00:01, 323.13it/s] 95%|█████████▍| 9480/10000 [00:25<00:01, 308.65it/s] 95%|█████████▌| 9516/10000 [00:26<00:01, 315.44it/s] 95%|█████████▌| 9549/10000 [00:26<00:01, 278.03it/s] 96%|█████████▌| 9588/10000 [00:26<00:01, 301.68it/s] 96%|█████████▋| 9634/10000 [00:26<00:01, 319.35it/s] 97%|█████████▋| 9667/10000 [00:26<00:01, 310.33it/s] 97%|█████████▋| 9716/10000 [00:26<00:00, 354.90it/s] 98%|█████████▊| 9753/10000 [00:26<00:00, 355.57it/s] 98%|█████████▊| 9790/10000 [00:26<00:00, 343.48it/s] 98%|█████████▊| 9850/10000 [00:26<00:00, 407.06it/s] 99%|█████████▉| 9913/10000 [00:27<00:00, 468.66it/s]100%|█████████▉| 9998/10000 [00:27<00:00, 576.61it/s]100%|██████████| 10000/10000 [00:27<00:00, 368.01it/s]
test_neglected_p90 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p90
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p90.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.05it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  6.14it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.69it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 19.09it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.94it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.80it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.80it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 36.71it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 38.72it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.50it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p90_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p90_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p90_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p90_Holmes_probs.npy
{'Accuracy': 0.0206, 'Precision': 0.0245, 'Recall': 0.0203, 'F1-score': 0.0182}
starting gen taf script for test_neglected_p91
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 65/10000 [00:00<00:16, 616.63it/s]  1%|▏         | 127/10000 [00:00<00:30, 319.27it/s]  2%|▏         | 167/10000 [00:00<00:37, 263.14it/s]  2%|▏         | 200/10000 [00:00<00:36, 269.77it/s]  2%|▏         | 231/10000 [00:00<00:34, 279.89it/s]  3%|▎         | 262/10000 [00:00<00:36, 270.42it/s]  3%|▎         | 291/10000 [00:01<00:36, 265.34it/s]  3%|▎         | 319/10000 [00:01<00:38, 251.85it/s]  3%|▎         | 345/10000 [00:01<00:39, 246.47it/s]  4%|▎         | 371/10000 [00:01<00:38, 248.58it/s]  4%|▍         | 399/10000 [00:01<00:37, 255.65it/s]  4%|▍         | 440/10000 [00:01<00:32, 293.00it/s]  5%|▍         | 480/10000 [00:01<00:30, 315.46it/s]  5%|▌         | 513/10000 [00:01<00:30, 316.02it/s]  6%|▌         | 550/10000 [00:01<00:28, 329.33it/s]  6%|▌         | 590/10000 [00:01<00:27, 343.87it/s]  6%|▋         | 626/10000 [00:02<00:27, 342.81it/s]  7%|▋         | 662/10000 [00:02<00:27, 338.36it/s]  7%|▋         | 701/10000 [00:02<00:27, 342.62it/s]  8%|▊         | 770/10000 [00:02<00:21, 434.68it/s]  8%|▊         | 814/10000 [00:02<00:21, 432.39it/s]  9%|▊         | 870/10000 [00:02<00:19, 462.42it/s]  9%|▉         | 917/10000 [00:02<00:23, 389.62it/s] 10%|▉         | 958/10000 [00:02<00:23, 390.73it/s] 10%|▉         | 999/10000 [00:03<00:24, 363.39it/s] 10%|█         | 1040/10000 [00:03<00:24, 370.11it/s] 11%|█         | 1078/10000 [00:03<00:29, 305.16it/s] 11%|█▏        | 1128/10000 [00:03<00:25, 343.20it/s] 12%|█▏        | 1165/10000 [00:03<00:27, 325.79it/s] 12%|█▏        | 1200/10000 [00:03<00:28, 311.42it/s] 12%|█▏        | 1237/10000 [00:03<00:27, 314.68it/s] 13%|█▎        | 1286/10000 [00:03<00:24, 352.19it/s] 13%|█▎        | 1343/10000 [00:04<00:21, 409.57it/s] 14%|█▍        | 1388/10000 [00:04<00:20, 410.28it/s] 14%|█▍        | 1431/10000 [00:04<00:25, 341.46it/s] 15%|█▍        | 1468/10000 [00:04<00:26, 320.61it/s] 15%|█▌        | 1502/10000 [00:04<00:31, 265.92it/s] 15%|█▌        | 1532/10000 [00:04<00:33, 255.13it/s] 16%|█▌        | 1560/10000 [00:04<00:36, 230.12it/s] 16%|█▌        | 1585/10000 [00:05<00:36, 230.34it/s] 16%|█▌        | 1613/10000 [00:05<00:35, 238.77it/s] 17%|█▋        | 1678/10000 [00:05<00:24, 338.89it/s] 17%|█▋        | 1736/10000 [00:05<00:21, 384.47it/s] 18%|█▊        | 1810/10000 [00:05<00:17, 477.54it/s] 19%|█▉        | 1907/10000 [00:05<00:13, 606.26it/s] 20%|█▉        | 1991/10000 [00:05<00:11, 671.09it/s] 21%|██        | 2061/10000 [00:05<00:12, 632.25it/s] 21%|██▏       | 2127/10000 [00:05<00:15, 493.54it/s] 22%|██▏       | 2191/10000 [00:06<00:15, 520.25it/s] 22%|██▏       | 2248/10000 [00:06<00:19, 406.05it/s] 23%|██▎       | 2296/10000 [00:06<00:20, 381.56it/s] 23%|██▎       | 2339/10000 [00:06<00:24, 312.10it/s] 24%|██▍       | 2379/10000 [00:06<00:23, 318.65it/s] 24%|██▍       | 2415/10000 [00:06<00:25, 293.50it/s] 25%|██▍       | 2462/10000 [00:07<00:22, 331.30it/s] 25%|██▍       | 2499/10000 [00:07<00:22, 339.46it/s] 26%|██▌       | 2552/10000 [00:07<00:20, 371.16it/s] 26%|██▌       | 2599/10000 [00:07<00:19, 389.43it/s] 26%|██▋       | 2640/10000 [00:07<00:24, 297.83it/s] 27%|██▋       | 2674/10000 [00:07<00:28, 257.83it/s] 27%|██▋       | 2704/10000 [00:07<00:31, 228.58it/s] 27%|██▋       | 2730/10000 [00:08<00:32, 226.58it/s] 28%|██▊       | 2755/10000 [00:08<00:36, 198.93it/s] 28%|██▊       | 2777/10000 [00:08<00:36, 196.21it/s] 28%|██▊       | 2810/10000 [00:08<00:32, 223.62it/s] 29%|██▊       | 2855/10000 [00:08<00:26, 268.33it/s] 29%|██▉       | 2905/10000 [00:08<00:22, 317.31it/s] 30%|██▉       | 2958/10000 [00:08<00:19, 360.67it/s] 30%|███       | 3000/10000 [00:08<00:18, 376.22it/s] 30%|███       | 3040/10000 [00:09<00:18, 376.92it/s] 31%|███       | 3079/10000 [00:09<00:19, 350.76it/s] 31%|███       | 3115/10000 [00:09<00:21, 314.28it/s] 31%|███▏      | 3148/10000 [00:09<00:24, 285.45it/s] 32%|███▏      | 3182/10000 [00:09<00:24, 279.93it/s] 33%|███▎      | 3252/10000 [00:09<00:17, 383.73it/s] 33%|███▎      | 3317/10000 [00:09<00:14, 448.82it/s] 34%|███▍      | 3394/10000 [00:09<00:13, 485.41it/s] 34%|███▍      | 3448/10000 [00:10<00:13, 479.69it/s] 35%|███▌      | 3507/10000 [00:10<00:13, 498.65it/s] 36%|███▌      | 3558/10000 [00:10<00:16, 397.99it/s] 36%|███▌      | 3620/10000 [00:10<00:14, 443.01it/s] 37%|███▋      | 3676/10000 [00:10<00:13, 471.72it/s] 38%|███▊      | 3750/10000 [00:10<00:11, 532.51it/s] 38%|███▊      | 3806/10000 [00:10<00:11, 539.40it/s] 39%|███▊      | 3862/10000 [00:10<00:12, 481.32it/s] 39%|███▉      | 3913/10000 [00:11<00:13, 442.02it/s] 40%|███▉      | 3960/10000 [00:11<00:14, 422.51it/s] 40%|████      | 4009/10000 [00:11<00:13, 429.73it/s] 41%|████      | 4067/10000 [00:11<00:12, 459.60it/s] 41%|████▏     | 4133/10000 [00:11<00:11, 508.76it/s] 42%|████▏     | 4202/10000 [00:11<00:10, 550.98it/s] 43%|████▎     | 4259/10000 [00:11<00:11, 517.40it/s] 43%|████▎     | 4312/10000 [00:11<00:11, 508.09it/s] 44%|████▍     | 4375/10000 [00:11<00:10, 523.25it/s] 44%|████▍     | 4428/10000 [00:12<00:13, 417.45it/s] 45%|████▍     | 4474/10000 [00:12<00:15, 363.34it/s] 45%|████▌     | 4514/10000 [00:12<00:15, 347.30it/s] 46%|████▌     | 4554/10000 [00:12<00:16, 331.68it/s] 46%|████▌     | 4589/10000 [00:12<00:17, 315.60it/s] 46%|████▌     | 4622/10000 [00:12<00:18, 291.10it/s] 47%|████▋     | 4652/10000 [00:12<00:19, 271.57it/s] 47%|████▋     | 4690/10000 [00:13<00:17, 297.37it/s] 47%|████▋     | 4721/10000 [00:13<00:18, 291.54it/s] 48%|████▊     | 4751/10000 [00:13<00:19, 266.26it/s] 48%|████▊     | 4779/10000 [00:13<00:19, 266.59it/s] 48%|████▊     | 4808/10000 [00:13<00:19, 270.08it/s] 48%|████▊     | 4836/10000 [00:13<00:19, 259.77it/s] 49%|████▊     | 4869/10000 [00:13<00:18, 276.23it/s] 49%|████▉     | 4897/10000 [00:13<00:20, 247.23it/s] 49%|████▉     | 4923/10000 [00:14<00:21, 235.01it/s] 49%|████▉     | 4948/10000 [00:14<00:23, 211.56it/s] 50%|████▉     | 4970/10000 [00:14<00:23, 213.13it/s] 50%|█████     | 5000/10000 [00:14<00:21, 228.68it/s] 50%|█████     | 5045/10000 [00:14<00:17, 285.89it/s] 51%|█████     | 5092/10000 [00:14<00:14, 336.20it/s] 51%|█████▏    | 5147/10000 [00:14<00:12, 393.05it/s] 52%|█████▏    | 5192/10000 [00:14<00:12, 398.53it/s] 52%|█████▏    | 5233/10000 [00:14<00:13, 362.67it/s] 53%|█████▎    | 5271/10000 [00:15<00:14, 321.90it/s] 53%|█████▎    | 5305/10000 [00:15<00:16, 280.36it/s] 53%|█████▎    | 5335/10000 [00:15<00:18, 248.61it/s] 54%|█████▎    | 5364/10000 [00:15<00:18, 256.36it/s] 54%|█████▍    | 5391/10000 [00:15<00:18, 245.78it/s] 54%|█████▍    | 5423/10000 [00:15<00:17, 259.79it/s] 55%|█████▍    | 5459/10000 [00:15<00:15, 284.98it/s] 55%|█████▍    | 5493/10000 [00:15<00:15, 297.42it/s] 55%|█████▌    | 5546/10000 [00:16<00:12, 361.05it/s] 56%|█████▌    | 5602/10000 [00:16<00:10, 416.47it/s] 56%|█████▋    | 5645/10000 [00:16<00:10, 400.56it/s] 57%|█████▋    | 5698/10000 [00:16<00:10, 426.06it/s] 58%|█████▊    | 5761/10000 [00:16<00:09, 467.49it/s] 58%|█████▊    | 5811/10000 [00:16<00:08, 469.94it/s] 59%|█████▊    | 5859/10000 [00:16<00:10, 404.88it/s] 59%|█████▉    | 5902/10000 [00:16<00:12, 330.04it/s] 59%|█████▉    | 5940/10000 [00:17<00:12, 324.48it/s] 60%|█████▉    | 5975/10000 [00:17<00:12, 318.51it/s] 60%|██████    | 6009/10000 [00:17<00:12, 319.72it/s] 61%|██████    | 6061/10000 [00:17<00:10, 366.25it/s] 61%|██████    | 6105/10000 [00:17<00:10, 374.42it/s] 62%|██████▏   | 6167/10000 [00:17<00:08, 440.27it/s] 62%|██████▏   | 6213/10000 [00:17<00:09, 386.17it/s] 63%|██████▎   | 6257/10000 [00:17<00:09, 396.64it/s] 63%|██████▎   | 6299/10000 [00:18<00:11, 332.70it/s] 63%|██████▎   | 6335/10000 [00:18<00:12, 301.68it/s] 64%|██████▎   | 6368/10000 [00:18<00:13, 264.77it/s] 64%|██████▍   | 6397/10000 [00:18<00:13, 266.64it/s] 64%|██████▍   | 6426/10000 [00:18<00:13, 264.61it/s] 65%|██████▍   | 6455/10000 [00:18<00:13, 267.69it/s] 65%|██████▍   | 6487/10000 [00:18<00:13, 269.48it/s] 65%|██████▌   | 6515/10000 [00:18<00:13, 258.02it/s] 65%|██████▌   | 6549/10000 [00:19<00:12, 279.51it/s] 66%|██████▌   | 6578/10000 [00:19<00:13, 261.20it/s] 66%|██████▌   | 6614/10000 [00:19<00:11, 286.95it/s] 67%|██████▋   | 6659/10000 [00:19<00:10, 324.56it/s] 67%|██████▋   | 6693/10000 [00:19<00:10, 308.56it/s] 67%|██████▋   | 6725/10000 [00:19<00:11, 296.37it/s] 68%|██████▊   | 6766/10000 [00:19<00:10, 320.92it/s] 68%|██████▊   | 6799/10000 [00:19<00:10, 300.80it/s] 69%|██████▊   | 6852/10000 [00:19<00:08, 358.04it/s] 69%|██████▉   | 6914/10000 [00:20<00:07, 420.49it/s] 70%|██████▉   | 6974/10000 [00:20<00:06, 462.85it/s] 70%|███████   | 7022/10000 [00:20<00:06, 452.76it/s] 71%|███████   | 7073/10000 [00:20<00:06, 465.20it/s] 71%|███████   | 7120/10000 [00:20<00:06, 439.52it/s] 72%|███████▏  | 7173/10000 [00:20<00:06, 463.80it/s] 72%|███████▏  | 7220/10000 [00:20<00:06, 461.24it/s] 73%|███████▎  | 7267/10000 [00:20<00:06, 440.09it/s] 73%|███████▎  | 7325/10000 [00:20<00:05, 478.88it/s] 74%|███████▍  | 7375/10000 [00:21<00:05, 483.37it/s] 74%|███████▍  | 7424/10000 [00:21<00:05, 468.07it/s] 75%|███████▍  | 7480/10000 [00:21<00:05, 473.42it/s] 75%|███████▌  | 7528/10000 [00:21<00:05, 470.61it/s] 76%|███████▌  | 7582/10000 [00:21<00:05, 462.96it/s] 76%|███████▋  | 7642/10000 [00:21<00:04, 480.19it/s] 77%|███████▋  | 7691/10000 [00:21<00:05, 418.13it/s] 77%|███████▋  | 7735/10000 [00:21<00:05, 404.05it/s] 78%|███████▊  | 7777/10000 [00:22<00:05, 372.46it/s] 78%|███████▊  | 7832/10000 [00:22<00:05, 411.68it/s] 79%|███████▉  | 7875/10000 [00:22<00:05, 409.57it/s] 80%|███████▉  | 7951/10000 [00:22<00:04, 499.59it/s] 80%|████████  | 8003/10000 [00:22<00:04, 477.60it/s] 81%|████████  | 8052/10000 [00:22<00:04, 455.65it/s] 81%|████████  | 8099/10000 [00:22<00:04, 441.88it/s] 81%|████████▏ | 8145/10000 [00:22<00:04, 437.60it/s] 82%|████████▏ | 8190/10000 [00:22<00:04, 436.69it/s] 82%|████████▏ | 8234/10000 [00:23<00:04, 411.80it/s] 83%|████████▎ | 8276/10000 [00:23<00:04, 349.17it/s] 83%|████████▎ | 8313/10000 [00:23<00:05, 288.87it/s] 83%|████████▎ | 8347/10000 [00:23<00:05, 287.91it/s] 84%|████████▍ | 8378/10000 [00:23<00:05, 273.58it/s] 84%|████████▍ | 8407/10000 [00:23<00:05, 269.81it/s] 84%|████████▍ | 8435/10000 [00:23<00:05, 266.65it/s] 85%|████████▍ | 8491/10000 [00:23<00:04, 337.16it/s] 85%|████████▌ | 8530/10000 [00:24<00:04, 336.72it/s] 86%|████████▌ | 8565/10000 [00:24<00:04, 314.34it/s] 86%|████████▋ | 8626/10000 [00:24<00:03, 377.17it/s] 87%|████████▋ | 8716/10000 [00:24<00:02, 515.17it/s] 88%|████████▊ | 8788/10000 [00:24<00:02, 568.58it/s] 89%|████████▊ | 8870/10000 [00:24<00:01, 638.39it/s] 89%|████████▉ | 8943/10000 [00:24<00:01, 651.63it/s] 90%|█████████ | 9026/10000 [00:24<00:01, 689.00it/s] 91%|█████████ | 9096/10000 [00:25<00:01, 591.93it/s] 92%|█████████▏| 9170/10000 [00:25<00:01, 629.40it/s] 92%|█████████▏| 9236/10000 [00:25<00:01, 457.28it/s] 93%|█████████▎| 9290/10000 [00:25<00:01, 420.72it/s] 93%|█████████▎| 9338/10000 [00:25<00:01, 361.14it/s] 94%|█████████▍| 9379/10000 [00:25<00:02, 301.81it/s] 94%|█████████▍| 9417/10000 [00:26<00:01, 315.51it/s] 95%|█████████▍| 9456/10000 [00:26<00:01, 325.14it/s] 95%|█████████▌| 9500/10000 [00:26<00:01, 331.63it/s] 95%|█████████▌| 9536/10000 [00:26<00:01, 337.43it/s] 96%|█████████▌| 9572/10000 [00:26<00:01, 305.75it/s] 96%|█████████▌| 9606/10000 [00:26<00:01, 307.50it/s] 96%|█████████▋| 9645/10000 [00:26<00:01, 327.12it/s] 97%|█████████▋| 9679/10000 [00:26<00:01, 300.07it/s] 97%|█████████▋| 9711/10000 [00:26<00:00, 295.72it/s] 98%|█████████▊| 9760/10000 [00:27<00:00, 341.12it/s] 98%|█████████▊| 9796/10000 [00:27<00:00, 331.21it/s] 99%|█████████▊| 9874/10000 [00:27<00:00, 451.68it/s] 99%|█████████▉| 9922/10000 [00:27<00:00, 432.80it/s]100%|██████████| 10000/10000 [00:27<00:00, 363.37it/s]
test_neglected_p91 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p91
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p91.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.02it/s]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:05,  5.93it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.44it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.88it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 25.01it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 30.25it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.66it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 38.13it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.39it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.51it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p91_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p91_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p91_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p91_Holmes_probs.npy
{'Accuracy': 0.0207, 'Precision': 0.0244, 'Recall': 0.0204, 'F1-score': 0.0184}
starting gen taf script for test_neglected_p92
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 54/10000 [00:00<00:18, 534.83it/s]  1%|          | 108/10000 [00:00<00:31, 318.61it/s]  1%|▏         | 145/10000 [00:00<00:40, 241.78it/s]  2%|▏         | 173/10000 [00:00<00:39, 250.44it/s]  2%|▏         | 204/10000 [00:00<00:36, 264.84it/s]  2%|▏         | 233/10000 [00:00<00:37, 258.34it/s]  3%|▎         | 261/10000 [00:00<00:37, 261.67it/s]  3%|▎         | 289/10000 [00:01<00:38, 250.30it/s]  3%|▎         | 320/10000 [00:01<00:37, 260.50it/s]  3%|▎         | 347/10000 [00:01<00:37, 257.38it/s]  4%|▎         | 374/10000 [00:01<00:38, 252.27it/s]  4%|▍         | 405/10000 [00:01<00:36, 264.79it/s]  4%|▍         | 439/10000 [00:01<00:33, 281.33it/s]  5%|▍         | 473/10000 [00:01<00:32, 295.72it/s]  5%|▌         | 510/10000 [00:01<00:30, 310.73it/s]  5%|▌         | 548/10000 [00:01<00:29, 318.66it/s]  6%|▌         | 591/10000 [00:02<00:27, 346.45it/s]  6%|▋         | 629/10000 [00:02<00:26, 347.25it/s]  7%|▋         | 671/10000 [00:02<00:25, 364.43it/s]  7%|▋         | 719/10000 [00:02<00:23, 390.36it/s]  8%|▊         | 775/10000 [00:02<00:21, 433.45it/s]  8%|▊         | 830/10000 [00:02<00:19, 467.01it/s]  9%|▉         | 877/10000 [00:02<00:21, 430.57it/s]  9%|▉         | 921/10000 [00:02<00:22, 401.96it/s] 10%|▉         | 962/10000 [00:02<00:24, 370.09it/s] 10%|█         | 1000/10000 [00:03<00:24, 361.22it/s] 10%|█         | 1039/10000 [00:03<00:26, 337.97it/s] 11%|█         | 1078/10000 [00:03<00:25, 350.77it/s] 11%|█         | 1114/10000 [00:03<00:27, 324.73it/s] 11%|█▏        | 1148/10000 [00:03<00:27, 320.19it/s] 12%|█▏        | 1181/10000 [00:03<00:28, 313.53it/s] 12%|█▏        | 1227/10000 [00:03<00:25, 343.73it/s] 13%|█▎        | 1269/10000 [00:03<00:24, 361.77it/s] 13%|█▎        | 1321/10000 [00:03<00:21, 404.10it/s] 14%|█▍        | 1381/10000 [00:04<00:19, 444.48it/s] 14%|█▍        | 1426/10000 [00:04<00:23, 364.79it/s] 15%|█▍        | 1465/10000 [00:04<00:25, 335.70it/s] 15%|█▌        | 1501/10000 [00:04<00:30, 280.15it/s] 15%|█▌        | 1532/10000 [00:04<00:33, 251.66it/s] 16%|█▌        | 1560/10000 [00:04<00:41, 203.51it/s] 16%|█▌        | 1589/10000 [00:05<00:38, 220.35it/s] 16%|█▋        | 1634/10000 [00:05<00:31, 269.14it/s] 17%|█▋        | 1682/10000 [00:05<00:26, 315.51it/s] 18%|█▊        | 1757/10000 [00:05<00:19, 423.70it/s] 18%|█▊        | 1819/10000 [00:05<00:17, 473.50it/s] 19%|█▉        | 1919/10000 [00:05<00:13, 611.66it/s] 20%|█▉        | 1985/10000 [00:05<00:13, 610.29it/s] 20%|██        | 2049/10000 [00:05<00:15, 521.94it/s] 21%|██        | 2106/10000 [00:06<00:15, 498.86it/s] 22%|██▏       | 2159/10000 [00:06<00:15, 499.45it/s] 22%|██▏       | 2211/10000 [00:06<00:18, 422.71it/s] 23%|██▎       | 2257/10000 [00:06<00:23, 329.34it/s] 23%|██▎       | 2295/10000 [00:06<00:24, 310.14it/s] 23%|██▎       | 2330/10000 [00:06<00:25, 296.58it/s] 24%|██▎       | 2368/10000 [00:06<00:24, 308.26it/s] 24%|██▍       | 2408/10000 [00:07<00:23, 327.27it/s] 25%|██▍       | 2467/10000 [00:07<00:19, 381.10it/s] 25%|██▌       | 2507/10000 [00:07<00:20, 374.18it/s] 26%|██▌       | 2555/10000 [00:07<00:18, 399.91it/s] 26%|██▌       | 2597/10000 [00:07<00:19, 373.59it/s] 26%|██▋       | 2636/10000 [00:07<00:22, 321.41it/s] 27%|██▋       | 2670/10000 [00:07<00:24, 294.39it/s] 27%|██▋       | 2701/10000 [00:07<00:30, 241.02it/s] 27%|██▋       | 2728/10000 [00:08<00:30, 236.08it/s] 28%|██▊       | 2753/10000 [00:08<00:33, 213.92it/s] 28%|██▊       | 2776/10000 [00:08<00:35, 201.30it/s] 28%|██▊       | 2797/10000 [00:08<00:36, 194.71it/s] 28%|██▊       | 2843/10000 [00:08<00:28, 252.98it/s] 29%|██▉       | 2878/10000 [00:08<00:26, 271.11it/s] 29%|██▉       | 2910/10000 [00:08<00:25, 273.22it/s] 30%|██▉       | 2963/10000 [00:08<00:20, 340.70it/s] 30%|███       | 3017/10000 [00:09<00:17, 394.11it/s] 31%|███       | 3058/10000 [00:09<00:20, 341.87it/s] 31%|███       | 3095/10000 [00:09<00:21, 320.37it/s] 31%|███▏      | 3129/10000 [00:09<00:22, 305.40it/s] 32%|███▏      | 3161/10000 [00:09<00:24, 284.20it/s] 32%|███▏      | 3191/10000 [00:09<00:26, 255.70it/s] 33%|███▎      | 3266/10000 [00:09<00:18, 370.95it/s] 33%|███▎      | 3328/10000 [00:09<00:15, 428.19it/s] 34%|███▍      | 3388/10000 [00:10<00:14, 472.26it/s] 34%|███▍      | 3438/10000 [00:10<00:15, 424.99it/s] 35%|███▍      | 3484/10000 [00:10<00:15, 411.21it/s] 35%|███▌      | 3542/10000 [00:10<00:14, 442.74it/s] 36%|███▌      | 3588/10000 [00:10<00:14, 428.44it/s] 36%|███▋      | 3646/10000 [00:10<00:13, 459.29it/s] 37%|███▋      | 3704/10000 [00:10<00:12, 488.51it/s] 38%|███▊      | 3769/10000 [00:10<00:11, 532.32it/s] 38%|███▊      | 3824/10000 [00:10<00:11, 534.13it/s] 39%|███▉      | 3879/10000 [00:11<00:11, 517.18it/s] 39%|███▉      | 3932/10000 [00:11<00:13, 434.52it/s] 40%|███▉      | 3978/10000 [00:11<00:14, 417.30it/s] 40%|████      | 4022/10000 [00:11<00:14, 408.73it/s] 41%|████      | 4085/10000 [00:11<00:12, 458.61it/s] 42%|████▏     | 4151/10000 [00:11<00:11, 509.22it/s] 42%|████▏     | 4219/10000 [00:11<00:10, 544.10it/s] 43%|████▎     | 4286/10000 [00:11<00:09, 578.41it/s] 44%|████▎     | 4356/10000 [00:12<00:09, 611.58it/s] 44%|████▍     | 4419/10000 [00:12<00:11, 504.05it/s] 45%|████▍     | 4474/10000 [00:12<00:13, 399.03it/s] 45%|████▌     | 4520/10000 [00:12<00:15, 352.62it/s] 46%|████▌     | 4560/10000 [00:12<00:18, 302.15it/s] 46%|████▌     | 4594/10000 [00:12<00:18, 289.55it/s] 46%|████▋     | 4626/10000 [00:13<00:19, 277.35it/s] 47%|████▋     | 4656/10000 [00:13<00:19, 267.94it/s] 47%|████▋     | 4684/10000 [00:13<00:20, 256.14it/s] 47%|████▋     | 4711/10000 [00:13<00:20, 252.37it/s] 48%|████▊     | 4753/10000 [00:13<00:18, 285.16it/s] 48%|████▊     | 4786/10000 [00:13<00:18, 289.29it/s] 48%|████▊     | 4816/10000 [00:13<00:18, 285.69it/s] 48%|████▊     | 4845/10000 [00:13<00:19, 270.52it/s] 49%|████▊     | 4873/10000 [00:13<00:20, 247.28it/s] 49%|████▉     | 4899/10000 [00:14<00:21, 237.55it/s] 49%|████▉     | 4924/10000 [00:14<00:22, 227.40it/s] 49%|████▉     | 4949/10000 [00:14<00:22, 228.15it/s] 50%|████▉     | 4972/10000 [00:14<00:23, 209.77it/s] 50%|█████     | 5005/10000 [00:14<00:21, 234.03it/s] 51%|█████     | 5066/10000 [00:14<00:14, 331.96it/s] 51%|█████     | 5115/10000 [00:14<00:13, 367.12it/s] 52%|█████▏    | 5163/10000 [00:14<00:12, 396.07it/s] 52%|█████▏    | 5204/10000 [00:15<00:12, 384.17it/s] 52%|█████▏    | 5244/10000 [00:15<00:12, 377.30it/s] 53%|█████▎    | 5283/10000 [00:15<00:15, 298.65it/s] 53%|█████▎    | 5316/10000 [00:15<00:17, 261.38it/s] 53%|█████▎    | 5345/10000 [00:15<00:20, 231.89it/s] 54%|█████▍    | 5377/10000 [00:15<00:18, 247.93it/s] 54%|█████▍    | 5404/10000 [00:15<00:18, 246.42it/s] 54%|█████▍    | 5441/10000 [00:15<00:16, 273.30it/s] 55%|█████▍    | 5475/10000 [00:16<00:15, 289.06it/s] 55%|█████▌    | 5547/10000 [00:16<00:11, 382.33it/s] 56%|█████▌    | 5591/10000 [00:16<00:11, 386.94it/s] 56%|█████▋    | 5641/10000 [00:16<00:10, 417.18it/s] 57%|█████▋    | 5686/10000 [00:16<00:10, 419.12it/s] 57%|█████▊    | 5750/10000 [00:16<00:09, 453.26it/s] 58%|█████▊    | 5797/10000 [00:16<00:09, 456.74it/s] 58%|█████▊    | 5843/10000 [00:16<00:10, 390.51it/s] 59%|█████▉    | 5884/10000 [00:17<00:11, 374.03it/s] 59%|█████▉    | 5923/10000 [00:17<00:11, 365.75it/s] 60%|█████▉    | 5961/10000 [00:17<00:11, 357.22it/s] 60%|█████▉    | 5998/10000 [00:17<00:12, 313.32it/s] 60%|██████    | 6049/10000 [00:17<00:11, 353.78it/s] 61%|██████    | 6103/10000 [00:17<00:09, 400.47it/s] 62%|██████▏   | 6162/10000 [00:17<00:08, 447.24it/s] 62%|██████▏   | 6209/10000 [00:17<00:09, 397.67it/s] 63%|██████▎   | 6251/10000 [00:17<00:09, 402.33it/s] 63%|██████▎   | 6293/10000 [00:18<00:11, 335.29it/s] 63%|██████▎   | 6330/10000 [00:18<00:13, 274.72it/s] 64%|██████▎   | 6361/10000 [00:18<00:14, 256.83it/s] 64%|██████▍   | 6393/10000 [00:18<00:13, 270.48it/s] 64%|██████▍   | 6426/10000 [00:18<00:12, 283.86it/s] 65%|██████▍   | 6457/10000 [00:18<00:13, 264.82it/s] 65%|██████▍   | 6494/10000 [00:18<00:12, 282.21it/s] 65%|██████▌   | 6524/10000 [00:19<00:13, 259.42it/s] 66%|██████▌   | 6565/10000 [00:19<00:11, 292.36it/s] 66%|██████▌   | 6596/10000 [00:19<00:12, 272.18it/s] 66%|██████▋   | 6625/10000 [00:19<00:12, 266.99it/s] 67%|██████▋   | 6674/10000 [00:19<00:10, 315.19it/s] 67%|██████▋   | 6709/10000 [00:19<00:10, 314.71it/s] 67%|██████▋   | 6746/10000 [00:19<00:10, 310.33it/s] 68%|██████▊   | 6786/10000 [00:19<00:09, 332.67it/s] 68%|██████▊   | 6820/10000 [00:20<00:10, 314.36it/s] 69%|██████▉   | 6899/10000 [00:20<00:07, 440.02it/s] 70%|██████▉   | 6950/10000 [00:20<00:06, 454.26it/s] 70%|██████▉   | 6997/10000 [00:20<00:07, 414.75it/s] 70%|███████   | 7043/10000 [00:20<00:07, 412.50it/s] 71%|███████   | 7089/10000 [00:20<00:07, 414.22it/s] 71%|███████▏  | 7132/10000 [00:20<00:06, 412.52it/s] 72%|███████▏  | 7189/10000 [00:20<00:06, 447.79it/s] 72%|███████▏  | 7235/10000 [00:20<00:06, 450.74it/s] 73%|███████▎  | 7284/10000 [00:21<00:05, 461.77it/s] 74%|███████▎  | 7352/10000 [00:21<00:05, 524.80it/s] 74%|███████▍  | 7411/10000 [00:21<00:04, 542.05it/s] 75%|███████▍  | 7466/10000 [00:21<00:05, 503.07it/s] 75%|███████▌  | 7524/10000 [00:21<00:04, 522.80it/s] 76%|███████▌  | 7577/10000 [00:21<00:04, 524.31it/s] 76%|███████▋  | 7630/10000 [00:21<00:05, 428.99it/s] 77%|███████▋  | 7676/10000 [00:21<00:05, 433.85it/s] 77%|███████▋  | 7722/10000 [00:21<00:05, 412.71it/s] 78%|███████▊  | 7765/10000 [00:22<00:05, 374.34it/s] 78%|███████▊  | 7804/10000 [00:22<00:06, 343.47it/s] 79%|███████▉  | 7877/10000 [00:22<00:05, 424.38it/s] 80%|███████▉  | 7950/10000 [00:22<00:04, 495.30it/s] 80%|████████  | 8002/10000 [00:22<00:04, 469.78it/s] 81%|████████  | 8081/10000 [00:22<00:03, 544.06it/s] 81%|████████▏ | 8140/10000 [00:22<00:03, 551.60it/s] 82%|████████▏ | 8197/10000 [00:22<00:03, 543.02it/s] 83%|████████▎ | 8253/10000 [00:23<00:04, 431.79it/s] 83%|████████▎ | 8301/10000 [00:23<00:04, 363.73it/s] 83%|████████▎ | 8342/10000 [00:23<00:04, 348.07it/s] 84%|████████▍ | 8380/10000 [00:23<00:05, 316.00it/s] 84%|████████▍ | 8414/10000 [00:23<00:05, 276.29it/s] 85%|████████▍ | 8451/10000 [00:23<00:05, 296.35it/s] 85%|████████▍ | 8492/10000 [00:23<00:04, 320.61it/s] 85%|████████▌ | 8527/10000 [00:24<00:04, 296.26it/s] 86%|████████▌ | 8577/10000 [00:24<00:04, 337.53it/s] 86%|████████▌ | 8614/10000 [00:24<00:04, 341.25it/s] 87%|████████▋ | 8675/10000 [00:24<00:03, 404.02it/s] 87%|████████▋ | 8739/10000 [00:24<00:02, 457.33it/s] 88%|████████▊ | 8796/10000 [00:24<00:02, 480.54it/s] 89%|████████▉ | 8879/10000 [00:24<00:01, 569.44it/s] 90%|████████▉ | 8953/10000 [00:24<00:01, 604.48it/s] 90%|█████████ | 9025/10000 [00:24<00:01, 610.35it/s] 91%|█████████ | 9087/10000 [00:25<00:01, 602.93it/s] 92%|█████████▏| 9151/10000 [00:25<00:01, 612.87it/s] 92%|█████████▏| 9213/10000 [00:25<00:01, 589.12it/s] 93%|█████████▎| 9273/10000 [00:25<00:01, 444.73it/s] 93%|█████████▎| 9323/10000 [00:25<00:01, 381.31it/s] 94%|█████████▎| 9366/10000 [00:25<00:02, 287.17it/s] 94%|█████████▍| 9406/10000 [00:26<00:01, 299.20it/s] 95%|█████████▍| 9460/10000 [00:26<00:01, 346.00it/s] 95%|█████████▌| 9500/10000 [00:26<00:01, 326.69it/s] 95%|█████████▌| 9537/10000 [00:26<00:01, 294.10it/s] 96%|█████████▌| 9570/10000 [00:26<00:01, 282.84it/s] 96%|█████████▌| 9620/10000 [00:26<00:01, 327.51it/s] 97%|█████████▋| 9656/10000 [00:26<00:01, 323.15it/s] 97%|█████████▋| 9690/10000 [00:26<00:00, 318.21it/s] 97%|█████████▋| 9723/10000 [00:27<00:00, 295.55it/s] 98%|█████████▊| 9758/10000 [00:27<00:00, 303.20it/s] 98%|█████████▊| 9805/10000 [00:27<00:00, 343.03it/s] 99%|█████████▊| 9858/10000 [00:27<00:00, 390.18it/s] 99%|█████████▉| 9938/10000 [00:27<00:00, 503.20it/s]100%|██████████| 10000/10000 [00:27<00:00, 362.41it/s]
test_neglected_p92 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p92
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p92.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:37,  1.05it/s]evaluating model with Holmes:   8%|▊         | 3/40 [00:01<00:10,  3.51it/s]evaluating model with Holmes:  20%|██        | 8/40 [00:01<00:03, 10.62it/s]evaluating model with Holmes:  32%|███▎      | 13/40 [00:01<00:01, 17.61it/s]evaluating model with Holmes:  45%|████▌     | 18/40 [00:01<00:00, 24.12it/s]evaluating model with Holmes:  57%|█████▊    | 23/40 [00:01<00:00, 29.75it/s]evaluating model with Holmes:  70%|███████   | 28/40 [00:01<00:00, 34.28it/s]evaluating model with Holmes:  82%|████████▎ | 33/40 [00:01<00:00, 37.85it/s]evaluating model with Holmes:  95%|█████████▌| 38/40 [00:01<00:00, 40.61it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.35it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p92_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p92_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p92_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p92_Holmes_probs.npy
{'Accuracy': 0.0212, 'Precision': 0.0249, 'Recall': 0.0208, 'F1-score': 0.0189}
starting gen taf script for test_neglected_p93
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 51/10000 [00:00<00:19, 509.05it/s]  1%|          | 102/10000 [00:00<00:33, 296.94it/s]  1%|▏         | 137/10000 [00:00<00:32, 301.72it/s]  2%|▏         | 170/10000 [00:00<00:35, 276.30it/s]  2%|▏         | 200/10000 [00:00<00:36, 271.33it/s]  2%|▏         | 229/10000 [00:00<00:36, 270.81it/s]  3%|▎         | 260/10000 [00:00<00:36, 265.11it/s]  3%|▎         | 289/10000 [00:01<00:36, 269.30it/s]  3%|▎         | 317/10000 [00:01<00:38, 251.03it/s]  3%|▎         | 344/10000 [00:01<00:39, 242.87it/s]  4%|▍         | 379/10000 [00:01<00:36, 265.39it/s]  4%|▍         | 406/10000 [00:01<00:38, 249.14it/s]  4%|▍         | 435/10000 [00:01<00:36, 260.00it/s]  5%|▍         | 473/10000 [00:01<00:32, 291.11it/s]  5%|▌         | 505/10000 [00:01<00:31, 297.30it/s]  5%|▌         | 540/10000 [00:01<00:30, 311.28it/s]  6%|▌         | 576/10000 [00:02<00:29, 318.91it/s]  6%|▌         | 620/10000 [00:02<00:26, 351.99it/s]  7%|▋         | 658/10000 [00:02<00:27, 334.12it/s]  7%|▋         | 694/10000 [00:02<00:27, 335.40it/s]  7%|▋         | 734/10000 [00:02<00:26, 353.52it/s]  8%|▊         | 770/10000 [00:02<00:29, 311.32it/s]  8%|▊         | 824/10000 [00:02<00:25, 352.97it/s]  9%|▊         | 870/10000 [00:02<00:24, 369.58it/s]  9%|▉         | 929/10000 [00:02<00:21, 426.97it/s] 10%|▉         | 973/10000 [00:03<00:23, 386.19it/s] 10%|█         | 1013/10000 [00:03<00:23, 376.49it/s] 11%|█         | 1052/10000 [00:03<00:25, 347.17it/s] 11%|█         | 1088/10000 [00:03<00:27, 320.90it/s] 11%|█         | 1121/10000 [00:03<00:27, 320.19it/s] 12%|█▏        | 1159/10000 [00:03<00:26, 334.70it/s] 12%|█▏        | 1194/10000 [00:03<00:27, 325.65it/s] 12%|█▏        | 1246/10000 [00:03<00:23, 375.70it/s] 13%|█▎        | 1302/10000 [00:03<00:20, 414.99it/s] 14%|█▎        | 1371/10000 [00:04<00:17, 488.59it/s] 14%|█▍        | 1421/10000 [00:04<00:20, 419.84it/s] 15%|█▍        | 1466/10000 [00:04<00:26, 320.84it/s] 15%|█▌        | 1503/10000 [00:04<00:29, 288.54it/s] 15%|█▌        | 1536/10000 [00:04<00:36, 230.60it/s] 16%|█▌        | 1563/10000 [00:05<00:38, 221.89it/s] 16%|█▌        | 1588/10000 [00:05<00:40, 210.18it/s] 16%|█▋        | 1638/10000 [00:05<00:30, 270.48it/s] 17%|█▋        | 1720/10000 [00:05<00:21, 386.84it/s] 18%|█▊        | 1774/10000 [00:05<00:19, 413.96it/s] 18%|█▊        | 1850/10000 [00:05<00:16, 496.80it/s] 20%|█▉        | 1981/10000 [00:05<00:11, 701.96it/s] 21%|██        | 2056/10000 [00:05<00:14, 557.67it/s] 21%|██        | 2120/10000 [00:06<00:15, 507.85it/s] 22%|██▏       | 2177/10000 [00:06<00:15, 517.20it/s] 22%|██▏       | 2234/10000 [00:06<00:17, 435.44it/s] 23%|██▎       | 2283/10000 [00:06<00:20, 374.22it/s] 23%|██▎       | 2325/10000 [00:06<00:21, 349.81it/s] 24%|██▎       | 2363/10000 [00:06<00:24, 316.99it/s] 24%|██▍       | 2397/10000 [00:06<00:24, 311.92it/s] 24%|██▍       | 2438/10000 [00:07<00:22, 332.82it/s] 25%|██▍       | 2497/10000 [00:07<00:20, 374.09it/s] 26%|██▌       | 2552/10000 [00:07<00:18, 393.89it/s] 26%|██▌       | 2593/10000 [00:07<00:19, 373.76it/s] 26%|██▋       | 2631/10000 [00:07<00:20, 353.93it/s] 27%|██▋       | 2667/10000 [00:07<00:26, 281.37it/s] 27%|██▋       | 2698/10000 [00:07<00:28, 257.56it/s] 27%|██▋       | 2726/10000 [00:08<00:33, 215.61it/s] 28%|██▊       | 2750/10000 [00:08<00:40, 179.16it/s] 28%|██▊       | 2772/10000 [00:08<00:39, 181.37it/s] 28%|██▊       | 2802/10000 [00:08<00:35, 204.39it/s] 28%|██▊       | 2844/10000 [00:08<00:28, 250.97it/s] 29%|██▉       | 2890/10000 [00:08<00:23, 302.14it/s] 29%|██▉       | 2941/10000 [00:08<00:20, 346.29it/s] 30%|██▉       | 2987/10000 [00:08<00:18, 373.20it/s] 30%|███       | 3027/10000 [00:09<00:18, 375.63it/s] 31%|███       | 3066/10000 [00:09<00:21, 321.18it/s] 31%|███       | 3101/10000 [00:09<00:25, 274.65it/s] 31%|███▏      | 3141/10000 [00:09<00:24, 284.45it/s] 32%|███▏      | 3172/10000 [00:09<00:24, 278.06it/s] 32%|███▏      | 3203/10000 [00:09<00:24, 276.17it/s] 33%|███▎      | 3263/10000 [00:09<00:19, 352.08it/s] 34%|███▎      | 3352/10000 [00:10<00:13, 487.49it/s] 34%|███▍      | 3410/10000 [00:10<00:13, 503.50it/s] 35%|███▍      | 3463/10000 [00:10<00:14, 460.33it/s] 35%|███▌      | 3511/10000 [00:10<00:15, 416.12it/s] 36%|███▌      | 3555/10000 [00:10<00:15, 413.32it/s] 36%|███▌      | 3598/10000 [00:10<00:15, 415.84it/s] 37%|███▋      | 3663/10000 [00:10<00:13, 478.79it/s] 37%|███▋      | 3713/10000 [00:10<00:13, 466.19it/s] 38%|███▊      | 3778/10000 [00:10<00:12, 511.34it/s] 38%|███▊      | 3831/10000 [00:11<00:12, 502.79it/s] 39%|███▉      | 3882/10000 [00:11<00:12, 473.14it/s] 39%|███▉      | 3931/10000 [00:11<00:14, 422.63it/s] 40%|███▉      | 3975/10000 [00:11<00:15, 396.47it/s] 40%|████      | 4031/10000 [00:11<00:13, 436.14it/s] 41%|████      | 4110/10000 [00:11<00:11, 513.58it/s] 42%|████▏     | 4182/10000 [00:11<00:10, 546.02it/s] 43%|████▎     | 4259/10000 [00:11<00:09, 606.23it/s] 43%|████▎     | 4321/10000 [00:12<00:10, 547.61it/s] 44%|████▍     | 4378/10000 [00:12<00:10, 546.19it/s] 44%|████▍     | 4434/10000 [00:12<00:12, 430.91it/s] 45%|████▍     | 4482/10000 [00:12<00:14, 380.55it/s] 45%|████▌     | 4524/10000 [00:12<00:15, 350.59it/s] 46%|████▌     | 4562/10000 [00:12<00:17, 305.08it/s] 46%|████▌     | 4595/10000 [00:12<00:20, 268.07it/s] 46%|████▋     | 4627/10000 [00:13<00:19, 272.83it/s] 47%|████▋     | 4656/10000 [00:13<00:20, 260.19it/s] 47%|████▋     | 4693/10000 [00:13<00:18, 283.70it/s] 47%|████▋     | 4723/10000 [00:13<00:19, 272.16it/s] 48%|████▊     | 4758/10000 [00:13<00:18, 288.44it/s] 48%|████▊     | 4788/10000 [00:13<00:18, 286.95it/s] 48%|████▊     | 4818/10000 [00:13<00:20, 249.70it/s] 49%|████▊     | 4855/10000 [00:13<00:18, 278.07it/s] 49%|████▉     | 4885/10000 [00:14<00:22, 227.43it/s] 49%|████▉     | 4922/10000 [00:14<00:19, 255.79it/s] 50%|████▉     | 4950/10000 [00:14<00:20, 242.25it/s] 50%|████▉     | 4976/10000 [00:14<00:21, 239.13it/s] 50%|█████     | 5001/10000 [00:14<00:21, 230.24it/s] 50%|█████     | 5049/10000 [00:14<00:17, 286.53it/s] 51%|█████     | 5098/10000 [00:14<00:14, 339.41it/s] 52%|█████▏    | 5158/10000 [00:14<00:11, 404.77it/s] 52%|█████▏    | 5209/10000 [00:15<00:11, 420.87it/s] 53%|█████▎    | 5253/10000 [00:15<00:13, 344.22it/s] 53%|█████▎    | 5291/10000 [00:15<00:17, 271.53it/s] 53%|█████▎    | 5323/10000 [00:15<00:18, 258.74it/s] 54%|█████▎    | 5359/10000 [00:15<00:16, 274.61it/s] 54%|█████▍    | 5389/10000 [00:15<00:18, 246.57it/s] 54%|█████▍    | 5440/10000 [00:15<00:14, 305.92it/s] 55%|█████▍    | 5480/10000 [00:16<00:13, 325.69it/s] 55%|█████▌    | 5519/10000 [00:16<00:13, 333.17it/s] 56%|█████▌    | 5565/10000 [00:16<00:12, 366.52it/s] 56%|█████▌    | 5605/10000 [00:16<00:11, 375.36it/s] 57%|█████▋    | 5655/10000 [00:16<00:10, 401.30it/s] 57%|█████▋    | 5702/10000 [00:16<00:10, 416.81it/s] 57%|█████▋    | 5748/10000 [00:16<00:10, 415.59it/s] 58%|█████▊    | 5812/10000 [00:16<00:08, 471.05it/s] 59%|█████▊    | 5860/10000 [00:16<00:09, 439.91it/s] 59%|█████▉    | 5905/10000 [00:17<00:10, 378.68it/s] 59%|█████▉    | 5945/10000 [00:17<00:11, 364.42it/s] 60%|█████▉    | 5983/10000 [00:17<00:12, 328.43it/s] 60%|██████    | 6022/10000 [00:17<00:11, 341.81it/s] 61%|██████    | 6075/10000 [00:17<00:10, 386.69it/s] 61%|██████▏   | 6149/10000 [00:17<00:08, 467.68it/s] 62%|██████▏   | 6198/10000 [00:17<00:08, 457.38it/s] 62%|██████▏   | 6245/10000 [00:17<00:10, 365.55it/s] 63%|██████▎   | 6285/10000 [00:18<00:10, 344.87it/s] 63%|██████▎   | 6322/10000 [00:18<00:12, 291.38it/s] 64%|██████▎   | 6354/10000 [00:18<00:12, 284.30it/s] 64%|██████▍   | 6385/10000 [00:18<00:12, 284.75it/s] 64%|██████▍   | 6415/10000 [00:18<00:13, 271.69it/s] 64%|██████▍   | 6443/10000 [00:18<00:14, 245.82it/s] 65%|██████▍   | 6469/10000 [00:18<00:14, 248.27it/s] 65%|██████▌   | 6500/10000 [00:18<00:13, 255.94it/s] 65%|██████▌   | 6533/10000 [00:19<00:13, 263.40it/s] 66%|██████▌   | 6564/10000 [00:19<00:13, 262.51it/s] 66%|██████▌   | 6591/10000 [00:19<00:12, 263.76it/s] 66%|██████▌   | 6618/10000 [00:19<00:13, 257.95it/s] 67%|██████▋   | 6655/10000 [00:19<00:11, 287.18it/s] 67%|██████▋   | 6694/10000 [00:19<00:11, 299.87it/s] 67%|██████▋   | 6735/10000 [00:19<00:09, 330.21it/s] 68%|██████▊   | 6769/10000 [00:19<00:11, 287.39it/s] 68%|██████▊   | 6820/10000 [00:20<00:09, 338.94it/s] 69%|██████▊   | 6871/10000 [00:20<00:08, 376.94it/s] 70%|██████▉   | 6954/10000 [00:20<00:06, 495.32it/s] 70%|███████   | 7006/10000 [00:20<00:06, 455.93it/s] 71%|███████   | 7054/10000 [00:20<00:06, 459.31it/s] 71%|███████   | 7110/10000 [00:20<00:06, 475.34it/s] 72%|███████▏  | 7159/10000 [00:20<00:06, 443.72it/s] 72%|███████▏  | 7205/10000 [00:20<00:06, 412.78it/s] 73%|███████▎  | 7270/10000 [00:20<00:05, 471.81it/s] 73%|███████▎  | 7335/10000 [00:21<00:05, 511.54it/s] 74%|███████▍  | 7388/10000 [00:21<00:05, 485.06it/s] 75%|███████▍  | 7453/10000 [00:21<00:05, 505.16it/s] 75%|███████▌  | 7505/10000 [00:21<00:05, 467.48it/s] 76%|███████▌  | 7556/10000 [00:21<00:05, 473.49it/s] 76%|███████▌  | 7604/10000 [00:21<00:05, 453.30it/s] 76%|███████▋  | 7650/10000 [00:21<00:05, 441.31it/s] 77%|███████▋  | 7695/10000 [00:21<00:05, 408.02it/s] 77%|███████▋  | 7737/10000 [00:22<00:05, 387.98it/s] 78%|███████▊  | 7777/10000 [00:22<00:06, 357.14it/s] 78%|███████▊  | 7814/10000 [00:22<00:06, 359.27it/s] 79%|███████▊  | 7857/10000 [00:22<00:05, 374.85it/s] 79%|███████▉  | 7924/10000 [00:22<00:04, 455.33it/s] 80%|███████▉  | 7994/10000 [00:22<00:03, 511.11it/s] 80%|████████  | 8046/10000 [00:22<00:03, 494.24it/s] 81%|████████  | 8122/10000 [00:22<00:03, 568.22it/s] 82%|████████▏ | 8184/10000 [00:22<00:03, 550.67it/s] 82%|████████▏ | 8240/10000 [00:23<00:04, 408.53it/s] 83%|████████▎ | 8287/10000 [00:23<00:04, 369.92it/s] 83%|████████▎ | 8329/10000 [00:23<00:04, 346.61it/s] 84%|████████▎ | 8367/10000 [00:23<00:04, 343.09it/s] 84%|████████▍ | 8404/10000 [00:23<00:05, 317.91it/s] 84%|████████▍ | 8438/10000 [00:23<00:05, 296.32it/s] 85%|████████▍ | 8479/10000 [00:23<00:05, 302.20it/s] 85%|████████▌ | 8521/10000 [00:24<00:04, 324.06it/s] 86%|████████▌ | 8555/10000 [00:24<00:04, 302.69it/s] 86%|████████▌ | 8595/10000 [00:24<00:04, 321.50it/s] 87%|████████▋ | 8662/10000 [00:24<00:03, 410.73it/s] 87%|████████▋ | 8711/10000 [00:24<00:03, 426.54it/s] 88%|████████▊ | 8770/10000 [00:24<00:02, 461.97it/s] 89%|████████▊ | 8859/10000 [00:24<00:02, 568.70it/s] 89%|████████▉ | 8930/10000 [00:24<00:01, 605.16it/s] 90%|████████▉ | 8992/10000 [00:24<00:01, 602.27it/s] 91%|█████████ | 9053/10000 [00:25<00:01, 574.18it/s] 91%|█████████ | 9116/10000 [00:25<00:01, 572.78it/s] 92%|█████████▏| 9183/10000 [00:25<00:01, 587.46it/s] 92%|█████████▏| 9243/10000 [00:25<00:01, 478.77it/s] 93%|█████████▎| 9295/10000 [00:25<00:01, 366.53it/s] 93%|█████████▎| 9338/10000 [00:25<00:02, 324.51it/s] 94%|█████████▍| 9375/10000 [00:26<00:02, 311.02it/s] 94%|█████████▍| 9409/10000 [00:26<00:01, 306.01it/s] 94%|█████████▍| 9447/10000 [00:26<00:01, 315.07it/s] 95%|█████████▍| 9487/10000 [00:26<00:01, 328.82it/s] 95%|█████████▌| 9525/10000 [00:26<00:01, 330.88it/s] 96%|█████████▌| 9560/10000 [00:26<00:01, 308.25it/s] 96%|█████████▌| 9594/10000 [00:26<00:01, 310.80it/s] 96%|█████████▋| 9626/10000 [00:26<00:01, 306.78it/s] 97%|█████████▋| 9661/10000 [00:26<00:01, 303.86it/s] 97%|█████████▋| 9692/10000 [00:27<00:01, 297.38it/s] 97%|█████████▋| 9722/10000 [00:27<00:01, 277.33it/s] 98%|█████████▊| 9761/10000 [00:27<00:00, 298.80it/s] 98%|█████████▊| 9832/10000 [00:27<00:00, 407.26it/s] 99%|█████████▉| 9895/10000 [00:27<00:00, 465.81it/s] 99%|█████████▉| 9948/10000 [00:27<00:00, 475.87it/s]100%|██████████| 10000/10000 [00:27<00:00, 361.71it/s]
test_neglected_p93 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p93
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p93.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:41,  1.06s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.59it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 11.83it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.07it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.07it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.41it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 33.83it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.40it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.88it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.61it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p93_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p93_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p93_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p93_Holmes_probs.npy
{'Accuracy': 0.0212, 'Precision': 0.0247, 'Recall': 0.0209, 'F1-score': 0.0189}
starting gen taf script for test_neglected_p94
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 64/10000 [00:00<00:16, 599.19it/s]  1%|          | 124/10000 [00:00<00:25, 381.26it/s]  2%|▏         | 167/10000 [00:00<00:27, 355.89it/s]  2%|▏         | 205/10000 [00:00<00:30, 324.63it/s]  2%|▏         | 239/10000 [00:00<00:32, 298.51it/s]  3%|▎         | 270/10000 [00:00<00:32, 297.47it/s]  3%|▎         | 301/10000 [00:00<00:33, 291.89it/s]  3%|▎         | 331/10000 [00:01<00:33, 285.57it/s]  4%|▎         | 360/10000 [00:01<00:34, 276.01it/s]  4%|▍         | 392/10000 [00:01<00:34, 277.85it/s]  4%|▍         | 421/10000 [00:01<00:35, 270.55it/s]  5%|▍         | 455/10000 [00:01<00:33, 289.13it/s]  5%|▍         | 485/10000 [00:01<00:34, 276.18it/s]  5%|▌         | 513/10000 [00:01<00:36, 261.03it/s]  6%|▌         | 560/10000 [00:01<00:30, 309.43it/s]  6%|▌         | 595/10000 [00:01<00:29, 315.15it/s]  6%|▋         | 638/10000 [00:02<00:27, 344.15it/s]  7%|▋         | 676/10000 [00:02<00:26, 352.70it/s]  7%|▋         | 712/10000 [00:02<00:27, 337.69it/s]  8%|▊         | 756/10000 [00:02<00:25, 365.27it/s]  8%|▊         | 793/10000 [00:02<00:25, 365.31it/s]  8%|▊         | 843/10000 [00:02<00:22, 402.96it/s]  9%|▉         | 884/10000 [00:02<00:26, 340.25it/s]  9%|▉         | 941/10000 [00:02<00:22, 399.03it/s] 10%|▉         | 984/10000 [00:02<00:22, 400.30it/s] 10%|█         | 1026/10000 [00:03<00:25, 355.63it/s] 11%|█         | 1064/10000 [00:03<00:26, 340.37it/s] 11%|█         | 1100/10000 [00:03<00:29, 302.97it/s] 11%|█▏        | 1132/10000 [00:03<00:30, 289.44it/s] 12%|█▏        | 1174/10000 [00:03<00:27, 317.16it/s] 12%|█▏        | 1230/10000 [00:03<00:23, 372.97it/s] 13%|█▎        | 1290/10000 [00:03<00:20, 432.44it/s] 14%|█▎        | 1368/10000 [00:03<00:16, 522.53it/s] 14%|█▍        | 1423/10000 [00:04<00:20, 414.10it/s] 15%|█▍        | 1470/10000 [00:04<00:27, 310.39it/s] 15%|█▌        | 1508/10000 [00:04<00:30, 276.63it/s] 15%|█▌        | 1541/10000 [00:04<00:32, 262.90it/s] 16%|█▌        | 1571/10000 [00:04<00:36, 233.90it/s] 16%|█▌        | 1597/10000 [00:05<00:36, 227.13it/s] 16%|█▋        | 1641/10000 [00:05<00:31, 268.93it/s] 17%|█▋        | 1713/10000 [00:05<00:22, 373.31it/s] 18%|█▊        | 1764/10000 [00:05<00:20, 406.86it/s] 18%|█▊        | 1816/10000 [00:05<00:18, 433.29it/s] 19%|█▉        | 1915/10000 [00:05<00:13, 581.63it/s] 20%|█▉        | 1979/10000 [00:05<00:13, 597.47it/s] 20%|██        | 2042/10000 [00:05<00:13, 593.94it/s] 21%|██        | 2104/10000 [00:05<00:15, 504.34it/s] 22%|██▏       | 2158/10000 [00:06<00:17, 455.51it/s] 22%|██▏       | 2207/10000 [00:06<00:17, 441.58it/s] 23%|██▎       | 2254/10000 [00:06<00:21, 367.15it/s] 23%|██▎       | 2294/10000 [00:06<00:22, 336.61it/s] 23%|██▎       | 2330/10000 [00:06<00:23, 332.31it/s] 24%|██▎       | 2365/10000 [00:06<00:25, 302.01it/s] 24%|██▍       | 2403/10000 [00:06<00:23, 320.12it/s] 24%|██▍       | 2438/10000 [00:06<00:23, 324.18it/s] 25%|██▍       | 2497/10000 [00:07<00:19, 384.81it/s] 25%|██▌       | 2548/10000 [00:07<00:17, 418.16it/s] 26%|██▌       | 2592/10000 [00:07<00:20, 359.42it/s] 26%|██▋       | 2631/10000 [00:07<00:20, 352.85it/s] 27%|██▋       | 2668/10000 [00:07<00:29, 251.32it/s] 27%|██▋       | 2698/10000 [00:07<00:30, 240.00it/s] 27%|██▋       | 2726/10000 [00:08<00:32, 226.07it/s] 28%|██▊       | 2751/10000 [00:08<00:32, 220.54it/s] 28%|██▊       | 2775/10000 [00:08<00:36, 198.92it/s] 28%|██▊       | 2808/10000 [00:08<00:32, 224.71it/s] 29%|██▊       | 2868/10000 [00:08<00:24, 296.85it/s] 29%|██▉       | 2933/10000 [00:08<00:18, 381.87it/s] 30%|██▉       | 2975/10000 [00:08<00:19, 355.01it/s] 30%|███       | 3014/10000 [00:08<00:19, 361.84it/s] 31%|███       | 3052/10000 [00:08<00:19, 362.58it/s] 31%|███       | 3090/10000 [00:09<00:25, 272.04it/s] 31%|███       | 3124/10000 [00:09<00:24, 282.06it/s] 32%|███▏      | 3156/10000 [00:09<00:25, 267.86it/s] 32%|███▏      | 3185/10000 [00:09<00:25, 268.84it/s] 32%|███▏      | 3231/10000 [00:09<00:21, 310.56it/s] 33%|███▎      | 3296/10000 [00:09<00:16, 398.77it/s] 33%|███▎      | 3344/10000 [00:09<00:15, 419.00it/s] 34%|███▍      | 3392/10000 [00:09<00:15, 435.35it/s] 34%|███▍      | 3442/10000 [00:10<00:14, 442.76it/s] 35%|███▍      | 3488/10000 [00:10<00:15, 411.93it/s] 35%|███▌      | 3531/10000 [00:10<00:15, 414.12it/s] 36%|███▌      | 3574/10000 [00:10<00:16, 394.17it/s] 36%|███▌      | 3615/10000 [00:10<00:16, 394.64it/s] 37%|███▋      | 3663/10000 [00:10<00:15, 416.93it/s] 37%|███▋      | 3735/10000 [00:10<00:12, 495.38it/s] 38%|███▊      | 3790/10000 [00:10<00:12, 510.78it/s] 38%|███▊      | 3842/10000 [00:10<00:13, 467.26it/s] 39%|███▉      | 3890/10000 [00:11<00:13, 439.57it/s] 39%|███▉      | 3935/10000 [00:11<00:13, 440.95it/s] 40%|███▉      | 3986/10000 [00:11<00:13, 446.45it/s] 40%|████      | 4040/10000 [00:11<00:12, 463.35it/s] 41%|████      | 4123/10000 [00:11<00:10, 553.04it/s] 42%|████▏     | 4216/10000 [00:11<00:08, 654.09it/s] 43%|████▎     | 4283/10000 [00:11<00:10, 567.67it/s] 43%|████▎     | 4343/10000 [00:11<00:09, 571.22it/s] 44%|████▍     | 4402/10000 [00:12<00:12, 463.35it/s] 45%|████▍     | 4453/10000 [00:12<00:14, 386.74it/s] 45%|████▍     | 4497/10000 [00:12<00:14, 378.86it/s] 45%|████▌     | 4538/10000 [00:12<00:16, 335.51it/s] 46%|████▌     | 4575/10000 [00:12<00:16, 321.61it/s] 46%|████▌     | 4609/10000 [00:12<00:17, 305.83it/s] 46%|████▋     | 4641/10000 [00:13<00:20, 261.81it/s] 47%|████▋     | 4677/10000 [00:13<00:19, 278.78it/s] 47%|████▋     | 4707/10000 [00:13<00:19, 267.90it/s] 47%|████▋     | 4738/10000 [00:13<00:19, 272.18it/s] 48%|████▊     | 4773/10000 [00:13<00:18, 282.22it/s] 48%|████▊     | 4802/10000 [00:13<00:19, 271.91it/s] 48%|████▊     | 4830/10000 [00:13<00:19, 259.94it/s] 49%|████▊     | 4857/10000 [00:13<00:21, 242.90it/s] 49%|████▉     | 4882/10000 [00:13<00:21, 237.83it/s] 49%|████▉     | 4906/10000 [00:14<00:22, 228.52it/s] 49%|████▉     | 4929/10000 [00:14<00:22, 223.29it/s] 50%|████▉     | 4952/10000 [00:14<00:22, 221.47it/s] 50%|████▉     | 4975/10000 [00:14<00:23, 217.51it/s] 50%|████▉     | 4998/10000 [00:14<00:22, 220.65it/s] 51%|█████     | 5052/10000 [00:14<00:16, 306.83it/s] 51%|█████     | 5107/10000 [00:14<00:13, 369.08it/s] 52%|█████▏    | 5161/10000 [00:14<00:11, 413.03it/s] 52%|█████▏    | 5203/10000 [00:14<00:12, 375.57it/s] 52%|█████▏    | 5242/10000 [00:15<00:14, 330.27it/s] 53%|█████▎    | 5277/10000 [00:15<00:16, 286.43it/s] 53%|█████▎    | 5308/10000 [00:15<00:18, 252.30it/s] 53%|█████▎    | 5335/10000 [00:15<00:19, 234.98it/s] 54%|█████▎    | 5363/10000 [00:15<00:19, 241.96it/s] 54%|█████▍    | 5389/10000 [00:15<00:18, 246.16it/s] 54%|█████▍    | 5419/10000 [00:15<00:17, 255.80it/s] 55%|█████▍    | 5461/10000 [00:15<00:15, 296.20it/s] 55%|█████▌    | 5510/10000 [00:16<00:13, 330.18it/s] 55%|█████▌    | 5544/10000 [00:16<00:15, 294.48it/s] 56%|█████▌    | 5591/10000 [00:16<00:13, 337.87it/s] 56%|█████▋    | 5631/10000 [00:16<00:12, 344.74it/s] 57%|█████▋    | 5694/10000 [00:16<00:10, 404.31it/s] 57%|█████▋    | 5737/10000 [00:16<00:10, 408.84it/s] 58%|█████▊    | 5780/10000 [00:16<00:10, 409.07it/s] 58%|█████▊    | 5822/10000 [00:16<00:10, 383.72it/s] 59%|█████▊    | 5861/10000 [00:17<00:12, 344.49it/s] 59%|█████▉    | 5897/10000 [00:17<00:12, 324.08it/s] 59%|█████▉    | 5931/10000 [00:17<00:13, 309.47it/s] 60%|█████▉    | 5968/10000 [00:17<00:12, 323.39it/s] 60%|██████    | 6001/10000 [00:17<00:12, 318.04it/s] 60%|██████    | 6041/10000 [00:17<00:11, 334.98it/s] 61%|██████    | 6107/10000 [00:17<00:09, 422.35it/s] 62%|██████▏   | 6151/10000 [00:17<00:09, 422.47it/s] 62%|██████▏   | 6207/10000 [00:17<00:08, 432.41it/s] 63%|██████▎   | 6251/10000 [00:18<00:09, 383.89it/s] 63%|██████▎   | 6291/10000 [00:18<00:11, 317.48it/s] 63%|██████▎   | 6326/10000 [00:18<00:12, 291.31it/s] 64%|██████▎   | 6357/10000 [00:18<00:13, 267.13it/s] 64%|██████▍   | 6395/10000 [00:18<00:12, 292.42it/s] 64%|██████▍   | 6426/10000 [00:18<00:13, 262.63it/s] 65%|██████▍   | 6454/10000 [00:18<00:13, 261.89it/s] 65%|██████▍   | 6482/10000 [00:19<00:14, 244.45it/s] 65%|██████▌   | 6514/10000 [00:19<00:13, 257.98it/s] 65%|██████▌   | 6541/10000 [00:19<00:13, 253.25it/s] 66%|██████▌   | 6580/10000 [00:19<00:12, 281.65it/s] 66%|██████▌   | 6613/10000 [00:19<00:11, 292.35it/s] 67%|██████▋   | 6657/10000 [00:19<00:10, 327.53it/s] 67%|██████▋   | 6691/10000 [00:19<00:10, 313.51it/s] 67%|██████▋   | 6723/10000 [00:19<00:10, 310.88it/s] 68%|██████▊   | 6764/10000 [00:19<00:10, 315.82it/s] 68%|██████▊   | 6800/10000 [00:20<00:09, 323.25it/s] 68%|██████▊   | 6833/10000 [00:20<00:09, 319.26it/s] 69%|██████▉   | 6915/10000 [00:20<00:07, 438.05it/s] 70%|██████▉   | 6959/10000 [00:20<00:07, 418.24it/s] 70%|███████   | 7013/10000 [00:20<00:06, 451.47it/s] 71%|███████   | 7059/10000 [00:20<00:07, 413.64it/s] 71%|███████   | 7101/10000 [00:20<00:07, 413.41it/s] 72%|███████▏  | 7163/10000 [00:20<00:06, 457.76it/s] 72%|███████▏  | 7210/10000 [00:20<00:06, 455.83it/s] 73%|███████▎  | 7265/10000 [00:21<00:05, 480.38it/s] 73%|███████▎  | 7314/10000 [00:21<00:05, 459.78it/s] 74%|███████▎  | 7373/10000 [00:21<00:05, 494.78it/s] 74%|███████▍  | 7425/10000 [00:21<00:05, 493.84it/s] 75%|███████▍  | 7475/10000 [00:21<00:05, 493.80it/s] 75%|███████▌  | 7525/10000 [00:21<00:05, 478.62it/s] 76%|███████▌  | 7580/10000 [00:21<00:04, 487.80it/s] 76%|███████▋  | 7629/10000 [00:21<00:05, 402.25it/s] 77%|███████▋  | 7672/10000 [00:21<00:05, 406.58it/s] 77%|███████▋  | 7715/10000 [00:22<00:05, 382.52it/s] 78%|███████▊  | 7755/10000 [00:22<00:05, 386.57it/s] 78%|███████▊  | 7795/10000 [00:22<00:05, 372.12it/s] 78%|███████▊  | 7849/10000 [00:22<00:05, 407.23it/s] 79%|███████▉  | 7893/10000 [00:22<00:05, 411.06it/s] 80%|███████▉  | 7978/10000 [00:22<00:03, 515.14it/s] 80%|████████  | 8046/10000 [00:22<00:03, 546.01it/s] 81%|████████  | 8106/10000 [00:22<00:03, 543.88it/s] 82%|████████▏ | 8161/10000 [00:23<00:03, 503.35it/s] 82%|████████▏ | 8212/10000 [00:23<00:03, 486.91it/s] 83%|████████▎ | 8262/10000 [00:23<00:04, 396.52it/s] 83%|████████▎ | 8305/10000 [00:23<00:04, 341.42it/s] 83%|████████▎ | 8342/10000 [00:23<00:05, 329.98it/s] 84%|████████▍ | 8377/10000 [00:23<00:05, 303.58it/s] 84%|████████▍ | 8409/10000 [00:23<00:05, 284.70it/s] 84%|████████▍ | 8439/10000 [00:24<00:05, 285.34it/s] 85%|████████▍ | 8482/10000 [00:24<00:04, 320.58it/s] 85%|████████▌ | 8530/10000 [00:24<00:04, 356.86it/s] 86%|████████▌ | 8567/10000 [00:24<00:04, 331.67it/s] 86%|████████▌ | 8602/10000 [00:24<00:04, 315.91it/s] 87%|████████▋ | 8684/10000 [00:24<00:03, 438.39it/s] 88%|████████▊ | 8761/10000 [00:24<00:02, 520.81it/s] 88%|████████▊ | 8817/10000 [00:24<00:02, 527.94it/s] 89%|████████▉ | 8921/10000 [00:24<00:01, 661.00it/s] 90%|█████████ | 9028/10000 [00:25<00:01, 754.35it/s] 91%|█████████ | 9105/10000 [00:25<00:01, 663.16it/s] 92%|█████████▏| 9174/10000 [00:25<00:01, 629.54it/s] 92%|█████████▏| 9239/10000 [00:25<00:01, 522.77it/s] 93%|█████████▎| 9295/10000 [00:25<00:01, 445.65it/s] 93%|█████████▎| 9344/10000 [00:25<00:01, 409.91it/s] 94%|█████████▍| 9388/10000 [00:25<00:01, 342.98it/s] 94%|█████████▍| 9426/10000 [00:26<00:01, 315.62it/s] 95%|█████████▍| 9470/10000 [00:26<00:01, 339.09it/s] 95%|█████████▌| 9507/10000 [00:26<00:01, 297.90it/s] 95%|█████████▌| 9542/10000 [00:26<00:01, 299.40it/s] 96%|█████████▌| 9574/10000 [00:26<00:01, 289.33it/s] 96%|█████████▌| 9613/10000 [00:26<00:01, 311.68it/s] 97%|█████████▋| 9651/10000 [00:26<00:01, 321.21it/s] 97%|█████████▋| 9685/10000 [00:27<00:01, 293.65it/s] 97%|█████████▋| 9726/10000 [00:27<00:00, 318.70it/s] 98%|█████████▊| 9764/10000 [00:27<00:00, 323.71it/s] 98%|█████████▊| 9798/10000 [00:27<00:00, 312.55it/s] 99%|█████████▊| 9856/10000 [00:27<00:00, 378.15it/s] 99%|█████████▉| 9918/10000 [00:27<00:00, 433.61it/s]100%|██████████| 10000/10000 [00:27<00:00, 361.70it/s]
test_neglected_p94 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p94
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p94.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:44,  1.15s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.19it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 11.84it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 17.81it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 23.47it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 28.68it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.18it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 36.88it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:02<00:00, 19.81it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p94_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p94_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p94_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p94_Holmes_probs.npy
{'Accuracy': 0.0211, 'Precision': 0.0246, 'Recall': 0.0208, 'F1-score': 0.0187}
starting gen taf script for test_neglected_p95
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 69/10000 [00:00<00:15, 646.10it/s]  1%|▏         | 134/10000 [00:00<00:26, 377.82it/s]  2%|▏         | 178/10000 [00:00<00:26, 369.40it/s]  2%|▏         | 218/10000 [00:00<00:27, 355.14it/s]  3%|▎         | 256/10000 [00:00<00:27, 355.86it/s]  3%|▎         | 293/10000 [00:00<00:29, 329.76it/s]  3%|▎         | 327/10000 [00:00<00:30, 319.70it/s]  4%|▎         | 360/10000 [00:01<00:31, 303.64it/s]  4%|▍         | 391/10000 [00:01<00:31, 304.87it/s]  4%|▍         | 422/10000 [00:01<00:31, 301.44it/s]  5%|▍         | 455/10000 [00:01<00:30, 309.04it/s]  5%|▍         | 491/10000 [00:01<00:29, 322.51it/s]  5%|▌         | 529/10000 [00:01<00:28, 335.11it/s]  6%|▌         | 567/10000 [00:01<00:27, 345.18it/s]  6%|▌         | 607/10000 [00:01<00:26, 352.31it/s]  6%|▋         | 644/10000 [00:01<00:26, 351.43it/s]  7%|▋         | 680/10000 [00:01<00:26, 351.02it/s]  7%|▋         | 716/10000 [00:02<00:26, 344.97it/s]  8%|▊         | 775/10000 [00:02<00:22, 404.03it/s]  8%|▊         | 816/10000 [00:02<00:23, 392.44it/s]  9%|▊         | 865/10000 [00:02<00:21, 416.23it/s]  9%|▉         | 907/10000 [00:02<00:22, 407.21it/s]  9%|▉         | 948/10000 [00:02<00:23, 379.47it/s] 10%|█         | 1001/10000 [00:02<00:21, 419.52it/s] 10%|█         | 1044/10000 [00:02<00:25, 354.03it/s] 11%|█         | 1082/10000 [00:03<00:26, 337.91it/s] 11%|█         | 1118/10000 [00:03<00:28, 314.38it/s] 12%|█▏        | 1162/10000 [00:03<00:26, 338.18it/s] 12%|█▏        | 1197/10000 [00:03<00:26, 337.76it/s] 13%|█▎        | 1253/10000 [00:03<00:22, 397.01it/s] 13%|█▎        | 1303/10000 [00:03<00:20, 419.99it/s] 14%|█▎        | 1356/10000 [00:03<00:19, 450.37it/s] 14%|█▍        | 1410/10000 [00:03<00:18, 467.64it/s] 15%|█▍        | 1458/10000 [00:04<00:27, 309.27it/s] 15%|█▍        | 1497/10000 [00:04<00:34, 247.96it/s] 15%|█▌        | 1529/10000 [00:04<00:37, 228.22it/s] 16%|█▌        | 1557/10000 [00:04<00:42, 200.05it/s] 16%|█▌        | 1581/10000 [00:04<00:43, 194.54it/s] 16%|█▌        | 1622/10000 [00:04<00:35, 235.63it/s] 17%|█▋        | 1671/10000 [00:05<00:28, 290.35it/s] 17%|█▋        | 1730/10000 [00:05<00:22, 360.43it/s] 18%|█▊        | 1789/10000 [00:05<00:19, 415.50it/s] 19%|█▊        | 1857/10000 [00:05<00:17, 478.32it/s] 19%|█▉        | 1947/10000 [00:05<00:13, 589.11it/s] 20%|██        | 2010/10000 [00:05<00:13, 591.10it/s] 21%|██        | 2072/10000 [00:05<00:16, 476.47it/s] 21%|██▏       | 2125/10000 [00:05<00:17, 438.09it/s] 22%|██▏       | 2173/10000 [00:06<00:17, 435.74it/s] 22%|██▏       | 2220/10000 [00:06<00:19, 400.06it/s] 23%|██▎       | 2263/10000 [00:06<00:23, 325.11it/s] 23%|██▎       | 2299/10000 [00:06<00:24, 314.64it/s] 23%|██▎       | 2333/10000 [00:06<00:25, 305.93it/s] 24%|██▎       | 2368/10000 [00:06<00:24, 314.77it/s] 24%|██▍       | 2401/10000 [00:06<00:26, 292.11it/s] 25%|██▍       | 2459/10000 [00:06<00:20, 363.21it/s] 25%|██▌       | 2512/10000 [00:07<00:18, 404.88it/s] 26%|██▌       | 2555/10000 [00:07<00:18, 409.92it/s] 26%|██▌       | 2598/10000 [00:07<00:18, 401.73it/s] 26%|██▋       | 2640/10000 [00:07<00:24, 299.00it/s] 27%|██▋       | 2675/10000 [00:07<00:29, 249.74it/s] 27%|██▋       | 2705/10000 [00:07<00:31, 232.99it/s] 27%|██▋       | 2732/10000 [00:07<00:31, 233.59it/s] 28%|██▊       | 2758/10000 [00:08<00:33, 214.34it/s] 28%|██▊       | 2781/10000 [00:08<00:33, 215.56it/s] 28%|██▊       | 2804/10000 [00:08<00:34, 209.09it/s] 29%|██▊       | 2858/10000 [00:08<00:24, 290.13it/s] 29%|██▉       | 2916/10000 [00:08<00:19, 356.81it/s] 30%|██▉       | 2968/10000 [00:08<00:18, 374.98it/s] 30%|███       | 3025/10000 [00:08<00:16, 422.64it/s] 31%|███       | 3069/10000 [00:09<00:20, 336.59it/s] 31%|███       | 3107/10000 [00:09<00:23, 295.42it/s] 31%|███▏      | 3140/10000 [00:09<00:25, 267.27it/s] 32%|███▏      | 3178/10000 [00:09<00:23, 286.09it/s] 32%|███▏      | 3209/10000 [00:09<00:23, 287.45it/s] 33%|███▎      | 3289/10000 [00:09<00:16, 413.96it/s] 34%|███▍      | 3389/10000 [00:09<00:12, 549.52it/s] 34%|███▍      | 3448/10000 [00:09<00:12, 522.57it/s] 35%|███▌      | 3503/10000 [00:10<00:13, 481.48it/s] 36%|███▌      | 3554/10000 [00:10<00:14, 436.76it/s] 36%|███▌      | 3600/10000 [00:10<00:15, 410.59it/s] 37%|███▋      | 3651/10000 [00:10<00:14, 434.07it/s] 37%|███▋      | 3709/10000 [00:10<00:13, 469.63it/s] 38%|███▊      | 3775/10000 [00:10<00:12, 515.50it/s] 38%|███▊      | 3831/10000 [00:10<00:11, 518.90it/s] 39%|███▉      | 3884/10000 [00:10<00:13, 467.78it/s] 39%|███▉      | 3933/10000 [00:11<00:15, 402.71it/s] 40%|███▉      | 3979/10000 [00:11<00:14, 410.56it/s] 40%|████      | 4043/10000 [00:11<00:12, 460.84it/s] 41%|████      | 4106/10000 [00:11<00:11, 501.16it/s] 42%|████▏     | 4186/10000 [00:11<00:09, 582.14it/s] 42%|████▏     | 4247/10000 [00:11<00:10, 542.06it/s] 43%|████▎     | 4311/10000 [00:11<00:10, 561.89it/s] 44%|████▍     | 4379/10000 [00:11<00:09, 579.12it/s] 44%|████▍     | 4439/10000 [00:12<00:12, 456.11it/s] 45%|████▍     | 4490/10000 [00:12<00:15, 354.12it/s] 45%|████▌     | 4532/10000 [00:12<00:16, 337.55it/s] 46%|████▌     | 4570/10000 [00:12<00:17, 307.98it/s] 46%|████▌     | 4604/10000 [00:12<00:19, 282.79it/s] 46%|████▋     | 4635/10000 [00:12<00:19, 276.86it/s] 47%|████▋     | 4664/10000 [00:12<00:19, 278.99it/s] 47%|████▋     | 4693/10000 [00:13<00:23, 227.90it/s] 47%|████▋     | 4743/10000 [00:13<00:18, 279.95it/s] 48%|████▊     | 4774/10000 [00:13<00:18, 286.00it/s] 48%|████▊     | 4811/10000 [00:13<00:17, 289.68it/s] 48%|████▊     | 4842/10000 [00:13<00:19, 260.07it/s] 49%|████▊     | 4870/10000 [00:13<00:22, 225.61it/s] 49%|████▉     | 4898/10000 [00:13<00:21, 232.98it/s] 49%|████▉     | 4930/10000 [00:13<00:20, 252.56it/s] 50%|████▉     | 4957/10000 [00:14<00:23, 217.80it/s] 50%|████▉     | 4987/10000 [00:14<00:21, 228.51it/s] 50%|█████     | 5027/10000 [00:14<00:18, 263.91it/s] 51%|█████     | 5070/10000 [00:14<00:16, 291.42it/s] 51%|█████     | 5116/10000 [00:14<00:15, 320.89it/s] 52%|█████▏    | 5175/10000 [00:14<00:12, 372.51it/s] 52%|█████▏    | 5213/10000 [00:14<00:14, 327.05it/s] 53%|█████▎    | 5257/10000 [00:15<00:14, 336.88it/s] 53%|█████▎    | 5292/10000 [00:15<00:15, 297.33it/s] 53%|█████▎    | 5323/10000 [00:15<00:20, 229.99it/s] 54%|█████▎    | 5351/10000 [00:15<00:19, 234.08it/s] 54%|█████▍    | 5378/10000 [00:15<00:19, 239.31it/s] 54%|█████▍    | 5404/10000 [00:15<00:18, 242.35it/s] 55%|█████▍    | 5467/10000 [00:15<00:13, 340.42it/s] 55%|█████▌    | 5504/10000 [00:15<00:12, 346.32it/s] 55%|█████▌    | 5541/10000 [00:16<00:13, 339.39it/s] 56%|█████▌    | 5583/10000 [00:16<00:12, 357.68it/s] 56%|█████▌    | 5623/10000 [00:16<00:12, 360.58it/s] 57%|█████▋    | 5695/10000 [00:16<00:09, 451.86it/s] 58%|█████▊    | 5756/10000 [00:16<00:08, 494.27it/s] 58%|█████▊    | 5807/10000 [00:16<00:09, 463.64it/s] 59%|█████▊    | 5855/10000 [00:16<00:11, 375.74it/s] 59%|█████▉    | 5896/10000 [00:16<00:12, 327.97it/s] 59%|█████▉    | 5932/10000 [00:17<00:12, 329.00it/s] 60%|█████▉    | 5967/10000 [00:17<00:12, 310.77it/s] 60%|██████    | 6000/10000 [00:17<00:13, 294.86it/s] 61%|██████    | 6064/10000 [00:17<00:11, 357.76it/s] 61%|██████    | 6119/10000 [00:17<00:09, 402.26it/s] 62%|██████▏   | 6172/10000 [00:17<00:08, 430.54it/s] 62%|██████▏   | 6217/10000 [00:17<00:08, 421.74it/s] 63%|██████▎   | 6261/10000 [00:17<00:10, 347.79it/s] 63%|██████▎   | 6299/10000 [00:18<00:12, 304.10it/s] 63%|██████▎   | 6332/10000 [00:18<00:12, 286.61it/s] 64%|██████▎   | 6363/10000 [00:18<00:13, 273.58it/s] 64%|██████▍   | 6392/10000 [00:18<00:14, 251.08it/s] 64%|██████▍   | 6418/10000 [00:18<00:15, 226.32it/s] 64%|██████▍   | 6449/10000 [00:18<00:15, 236.66it/s] 65%|██████▍   | 6474/10000 [00:18<00:14, 238.36it/s] 65%|██████▌   | 6503/10000 [00:18<00:13, 250.50it/s] 65%|██████▌   | 6529/10000 [00:19<00:14, 231.84it/s] 66%|██████▌   | 6558/10000 [00:19<00:13, 246.41it/s] 66%|██████▌   | 6584/10000 [00:19<00:14, 238.73it/s] 66%|██████▌   | 6619/10000 [00:19<00:12, 263.28it/s] 67%|██████▋   | 6652/10000 [00:19<00:11, 279.86it/s] 67%|██████▋   | 6692/10000 [00:19<00:10, 312.87it/s] 67%|██████▋   | 6724/10000 [00:19<00:10, 299.76it/s] 68%|██████▊   | 6759/10000 [00:19<00:10, 304.24it/s] 68%|██████▊   | 6792/10000 [00:19<00:10, 308.07it/s] 68%|██████▊   | 6831/10000 [00:20<00:09, 329.03it/s] 69%|██████▉   | 6902/10000 [00:20<00:07, 426.16it/s] 70%|██████▉   | 6969/10000 [00:20<00:06, 483.78it/s] 70%|███████   | 7018/10000 [00:20<00:07, 417.67it/s] 71%|███████   | 7078/10000 [00:20<00:06, 455.73it/s] 71%|███████▏  | 7125/10000 [00:20<00:06, 418.47it/s] 72%|███████▏  | 7169/10000 [00:20<00:07, 388.68it/s] 72%|███████▏  | 7214/10000 [00:20<00:07, 397.59it/s] 73%|███████▎  | 7275/10000 [00:21<00:06, 446.49it/s] 73%|███████▎  | 7328/10000 [00:21<00:05, 464.83it/s] 74%|███████▍  | 7376/10000 [00:21<00:05, 465.78it/s] 74%|███████▍  | 7424/10000 [00:21<00:05, 440.77it/s] 75%|███████▍  | 7469/10000 [00:21<00:05, 437.83it/s] 75%|███████▌  | 7514/10000 [00:21<00:05, 423.02it/s] 76%|███████▌  | 7572/10000 [00:21<00:05, 461.58it/s] 76%|███████▌  | 7619/10000 [00:21<00:05, 429.97it/s] 77%|███████▋  | 7663/10000 [00:21<00:06, 383.43it/s] 77%|███████▋  | 7703/10000 [00:22<00:06, 328.76it/s] 77%|███████▋  | 7738/10000 [00:22<00:06, 329.67it/s] 78%|███████▊  | 7784/10000 [00:22<00:06, 353.57it/s] 78%|███████▊  | 7840/10000 [00:22<00:05, 404.06it/s] 79%|███████▉  | 7901/10000 [00:22<00:04, 449.93it/s] 80%|███████▉  | 7963/10000 [00:22<00:04, 490.63it/s] 80%|████████  | 8036/10000 [00:22<00:03, 552.34it/s] 81%|████████  | 8093/10000 [00:22<00:03, 512.54it/s] 81%|████████▏ | 8146/10000 [00:23<00:04, 460.53it/s] 82%|████████▏ | 8194/10000 [00:23<00:04, 430.62it/s] 82%|████████▏ | 8240/10000 [00:23<00:04, 416.85it/s] 83%|████████▎ | 8283/10000 [00:23<00:04, 369.17it/s] 83%|████████▎ | 8322/10000 [00:23<00:05, 326.74it/s] 84%|████████▎ | 8357/10000 [00:23<00:05, 294.41it/s] 84%|████████▍ | 8391/10000 [00:23<00:05, 300.08it/s] 84%|████████▍ | 8425/10000 [00:24<00:05, 295.29it/s] 85%|████████▍ | 8461/10000 [00:24<00:05, 307.58it/s] 85%|████████▌ | 8505/10000 [00:24<00:04, 337.67it/s] 85%|████████▌ | 8540/10000 [00:24<00:04, 312.06it/s] 86%|████████▌ | 8587/10000 [00:24<00:04, 343.83it/s] 86%|████████▌ | 8623/10000 [00:24<00:04, 336.15it/s] 87%|████████▋ | 8680/10000 [00:24<00:03, 398.57it/s] 88%|████████▊ | 8773/10000 [00:24<00:02, 531.87it/s] 88%|████████▊ | 8831/10000 [00:24<00:02, 533.63it/s] 89%|████████▉ | 8907/10000 [00:25<00:01, 585.41it/s] 90%|████████▉ | 8972/10000 [00:25<00:01, 602.28it/s] 90%|█████████ | 9033/10000 [00:25<00:01, 570.01it/s] 91%|█████████ | 9091/10000 [00:25<00:01, 552.31it/s] 91%|█████████▏| 9147/10000 [00:25<00:01, 496.25it/s] 92%|█████████▏| 9198/10000 [00:25<00:01, 461.32it/s] 92%|█████████▏| 9246/10000 [00:25<00:01, 405.37it/s] 93%|█████████▎| 9289/10000 [00:25<00:01, 365.70it/s] 93%|█████████▎| 9327/10000 [00:26<00:02, 331.66it/s] 94%|█████████▎| 9362/10000 [00:26<00:02, 301.81it/s] 94%|█████████▍| 9404/10000 [00:26<00:01, 328.76it/s] 94%|█████████▍| 9439/10000 [00:26<00:01, 288.00it/s] 95%|█████████▍| 9470/10000 [00:26<00:01, 270.29it/s] 95%|█████████▌| 9519/10000 [00:26<00:01, 309.07it/s] 96%|█████████▌| 9552/10000 [00:26<00:01, 298.36it/s] 96%|█████████▌| 9583/10000 [00:26<00:01, 290.17it/s] 96%|█████████▌| 9615/10000 [00:27<00:01, 293.86it/s] 97%|█████████▋| 9659/10000 [00:27<00:01, 327.35it/s] 97%|█████████▋| 9693/10000 [00:27<00:00, 322.58it/s] 97%|█████████▋| 9726/10000 [00:27<00:00, 323.34it/s] 98%|█████████▊| 9762/10000 [00:27<00:00, 323.50it/s] 98%|█████████▊| 9806/10000 [00:27<00:00, 345.80it/s] 99%|█████████▊| 9863/10000 [00:27<00:00, 404.90it/s] 99%|█████████▉| 9924/10000 [00:27<00:00, 460.81it/s]100%|██████████| 10000/10000 [00:27<00:00, 357.91it/s]
test_neglected_p95 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p95
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p95.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.03s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.70it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.10it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.53it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.60it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.90it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.33it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.89it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 39.92it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.14it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p95_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p95_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p95_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p95_Holmes_probs.npy
{'Accuracy': 0.0207, 'Precision': 0.0237, 'Recall': 0.0204, 'F1-score': 0.0183}
starting gen taf script for test_neglected_p96
  0%|          | 0/10000 [00:00<?, ?it/s]  0%|          | 49/10000 [00:00<00:21, 454.75it/s]  1%|          | 95/10000 [00:00<00:29, 337.84it/s]  1%|▏         | 131/10000 [00:00<00:34, 283.41it/s]  2%|▏         | 161/10000 [00:00<00:34, 282.78it/s]  2%|▏         | 191/10000 [00:00<00:40, 243.98it/s]  2%|▏         | 221/10000 [00:00<00:38, 254.15it/s]  2%|▏         | 248/10000 [00:00<00:41, 236.51it/s]  3%|▎         | 274/10000 [00:01<00:41, 237.13it/s]  3%|▎         | 307/10000 [00:01<00:38, 251.88it/s]  3%|▎         | 339/10000 [00:01<00:35, 269.56it/s]  4%|▎         | 367/10000 [00:01<00:35, 270.04it/s]  4%|▍         | 395/10000 [00:01<00:36, 262.42it/s]  5%|▍         | 470/10000 [00:01<00:24, 394.00it/s]  5%|▌         | 516/10000 [00:01<00:22, 412.66it/s]  6%|▌         | 581/10000 [00:01<00:19, 480.83it/s]  6%|▋         | 630/10000 [00:01<00:20, 452.45it/s]  7%|▋         | 677/10000 [00:02<00:21, 440.62it/s]  8%|▊         | 768/10000 [00:02<00:16, 570.77it/s]  8%|▊         | 827/10000 [00:02<00:18, 508.83it/s]  9%|▉         | 881/10000 [00:02<00:18, 489.92it/s]  9%|▉         | 932/10000 [00:02<00:20, 444.63it/s] 10%|▉         | 979/10000 [00:02<00:20, 435.73it/s] 10%|█         | 1024/10000 [00:02<00:24, 369.66it/s] 11%|█         | 1064/10000 [00:02<00:24, 362.42it/s] 11%|█         | 1102/10000 [00:03<00:26, 334.31it/s] 12%|█▏        | 1154/10000 [00:03<00:23, 375.56it/s] 12%|█▏        | 1194/10000 [00:03<00:24, 357.15it/s] 12%|█▏        | 1236/10000 [00:03<00:23, 368.36it/s] 13%|█▎        | 1303/10000 [00:03<00:19, 445.69it/s] 14%|█▍        | 1376/10000 [00:03<00:16, 509.06it/s] 14%|█▍        | 1429/10000 [00:03<00:21, 395.62it/s] 15%|█▍        | 1474/10000 [00:04<00:28, 300.82it/s] 15%|█▌        | 1511/10000 [00:04<00:36, 233.24it/s] 15%|█▌        | 1541/10000 [00:04<00:36, 231.72it/s] 16%|█▌        | 1569/10000 [00:04<00:36, 234.19it/s] 16%|█▌        | 1596/10000 [00:04<00:38, 218.45it/s] 16%|█▋        | 1640/10000 [00:04<00:31, 261.84it/s] 17%|█▋        | 1706/10000 [00:04<00:23, 353.07it/s] 18%|█▊        | 1760/10000 [00:05<00:20, 393.83it/s] 18%|█▊        | 1807/10000 [00:05<00:19, 410.17it/s] 19%|█▊        | 1869/10000 [00:05<00:17, 463.93it/s] 19%|█▉        | 1941/10000 [00:05<00:15, 522.52it/s] 20%|██        | 2009/10000 [00:05<00:14, 562.28it/s] 21%|██        | 2067/10000 [00:05<00:16, 467.85it/s] 21%|██▏       | 2127/10000 [00:05<00:16, 488.42it/s] 22%|██▏       | 2179/10000 [00:05<00:19, 396.80it/s] 22%|██▏       | 2231/10000 [00:06<00:18, 423.88it/s] 23%|██▎       | 2278/10000 [00:06<00:21, 367.39it/s] 23%|██▎       | 2319/10000 [00:06<00:23, 324.30it/s] 24%|██▎       | 2355/10000 [00:06<00:24, 309.23it/s] 24%|██▍       | 2388/10000 [00:06<00:27, 277.96it/s] 24%|██▍       | 2426/10000 [00:06<00:25, 298.40it/s] 25%|██▍       | 2494/10000 [00:06<00:19, 383.76it/s] 25%|██▌       | 2545/10000 [00:07<00:18, 404.92it/s] 26%|██▌       | 2588/10000 [00:07<00:18, 399.91it/s] 26%|██▋       | 2630/10000 [00:07<00:21, 335.39it/s] 27%|██▋       | 2667/10000 [00:07<00:27, 267.21it/s] 27%|██▋       | 2698/10000 [00:07<00:30, 241.51it/s] 27%|██▋       | 2725/10000 [00:07<00:32, 224.89it/s] 28%|██▊       | 2750/10000 [00:08<00:35, 203.14it/s] 28%|██▊       | 2772/10000 [00:08<00:38, 186.55it/s] 28%|██▊       | 2792/10000 [00:08<00:40, 179.17it/s] 28%|██▊       | 2838/10000 [00:08<00:29, 239.47it/s] 29%|██▉       | 2879/10000 [00:08<00:25, 276.80it/s] 29%|██▉       | 2937/10000 [00:08<00:20, 340.58it/s] 30%|██▉       | 2996/10000 [00:08<00:17, 397.82it/s] 30%|███       | 3038/10000 [00:08<00:20, 343.73it/s] 31%|███       | 3075/10000 [00:09<00:21, 325.58it/s] 31%|███       | 3110/10000 [00:09<00:22, 308.02it/s] 31%|███▏      | 3142/10000 [00:09<00:24, 274.79it/s] 32%|███▏      | 3171/10000 [00:09<00:25, 272.87it/s] 32%|███▏      | 3200/10000 [00:09<00:26, 260.07it/s] 33%|███▎      | 3266/10000 [00:09<00:18, 354.83it/s] 33%|███▎      | 3344/10000 [00:09<00:14, 459.57it/s] 34%|███▍      | 3393/10000 [00:09<00:14, 442.67it/s] 34%|███▍      | 3439/10000 [00:09<00:15, 429.67it/s] 35%|███▍      | 3484/10000 [00:10<00:15, 418.87it/s] 35%|███▌      | 3529/10000 [00:10<00:15, 413.69it/s] 36%|███▌      | 3571/10000 [00:10<00:15, 415.37it/s] 36%|███▋      | 3625/10000 [00:10<00:14, 441.62it/s] 37%|███▋      | 3689/10000 [00:10<00:12, 489.21it/s] 37%|███▋      | 3739/10000 [00:10<00:13, 480.16it/s] 38%|███▊      | 3806/10000 [00:10<00:11, 520.53it/s] 39%|███▊      | 3859/10000 [00:10<00:12, 511.74it/s] 39%|███▉      | 3911/10000 [00:10<00:12, 480.84it/s] 40%|███▉      | 3960/10000 [00:11<00:14, 429.71it/s] 40%|████      | 4009/10000 [00:11<00:13, 437.87it/s] 41%|████      | 4079/10000 [00:11<00:11, 498.65it/s] 42%|████▏     | 4150/10000 [00:11<00:10, 547.16it/s] 42%|████▏     | 4206/10000 [00:11<00:11, 525.03it/s] 43%|████▎     | 4270/10000 [00:11<00:10, 540.55it/s] 43%|████▎     | 4332/10000 [00:11<00:10, 543.70it/s] 44%|████▍     | 4391/10000 [00:11<00:10, 535.80it/s] 44%|████▍     | 4445/10000 [00:12<00:12, 458.31it/s] 45%|████▍     | 4493/10000 [00:12<00:14, 379.03it/s] 45%|████▌     | 4534/10000 [00:12<00:17, 307.98it/s] 46%|████▌     | 4569/10000 [00:12<00:19, 284.28it/s] 46%|████▌     | 4600/10000 [00:12<00:21, 254.42it/s] 46%|████▋     | 4628/10000 [00:12<00:21, 246.52it/s] 47%|████▋     | 4662/10000 [00:13<00:20, 261.31it/s] 47%|████▋     | 4690/10000 [00:13<00:20, 256.31it/s] 47%|████▋     | 4718/10000 [00:13<00:20, 260.22it/s] 48%|████▊     | 4750/10000 [00:13<00:19, 270.40it/s] 48%|████▊     | 4789/10000 [00:13<00:17, 297.66it/s] 48%|████▊     | 4820/10000 [00:13<00:19, 271.06it/s] 48%|████▊     | 4848/10000 [00:13<00:20, 253.16it/s] 49%|████▊     | 4874/10000 [00:13<00:20, 245.12it/s] 49%|████▉     | 4899/10000 [00:13<00:21, 233.67it/s] 49%|████▉     | 4927/10000 [00:14<00:21, 240.22it/s] 50%|████▉     | 4952/10000 [00:14<00:23, 213.64it/s] 50%|████▉     | 4982/10000 [00:14<00:21, 231.75it/s] 50%|█████     | 5028/10000 [00:14<00:17, 291.30it/s] 51%|█████     | 5068/10000 [00:14<00:15, 312.01it/s] 51%|█████     | 5118/10000 [00:14<00:13, 361.37it/s] 52%|█████▏    | 5186/10000 [00:14<00:10, 443.13it/s] 52%|█████▏    | 5232/10000 [00:14<00:12, 375.55it/s] 53%|█████▎    | 5272/10000 [00:15<00:14, 320.48it/s] 53%|█████▎    | 5307/10000 [00:15<00:15, 294.29it/s] 53%|█████▎    | 5339/10000 [00:15<00:16, 281.86it/s] 54%|█████▎    | 5369/10000 [00:15<00:17, 262.28it/s] 54%|█████▍    | 5397/10000 [00:15<00:19, 239.63it/s] 54%|█████▍    | 5429/10000 [00:15<00:17, 255.83it/s] 55%|█████▍    | 5484/10000 [00:15<00:14, 317.94it/s] 55%|█████▌    | 5525/10000 [00:15<00:13, 341.36it/s] 56%|█████▌    | 5570/10000 [00:16<00:12, 367.55it/s] 56%|█████▌    | 5610/10000 [00:16<00:11, 376.42it/s] 57%|█████▋    | 5656/10000 [00:16<00:10, 397.48it/s] 57%|█████▋    | 5709/10000 [00:16<00:09, 429.11it/s] 58%|█████▊    | 5763/10000 [00:16<00:09, 460.69it/s] 58%|█████▊    | 5810/10000 [00:16<00:10, 400.11it/s] 59%|█████▊    | 5852/10000 [00:16<00:11, 346.23it/s] 59%|█████▉    | 5889/10000 [00:16<00:11, 351.47it/s] 59%|█████▉    | 5926/10000 [00:17<00:11, 345.98it/s] 60%|█████▉    | 5962/10000 [00:17<00:11, 346.58it/s] 60%|█████▉    | 5998/10000 [00:17<00:12, 308.60it/s] 61%|██████    | 6052/10000 [00:17<00:11, 355.73it/s] 61%|██████    | 6098/10000 [00:17<00:10, 375.17it/s] 62%|██████▏   | 6155/10000 [00:17<00:09, 421.62it/s] 62%|██████▏   | 6201/10000 [00:17<00:09, 420.44it/s] 62%|██████▏   | 6244/10000 [00:17<00:10, 353.39it/s] 63%|██████▎   | 6287/10000 [00:17<00:10, 370.12it/s] 63%|██████▎   | 6326/10000 [00:18<00:11, 308.78it/s] 64%|██████▎   | 6360/10000 [00:18<00:12, 300.09it/s] 64%|██████▍   | 6392/10000 [00:18<00:13, 274.81it/s] 64%|██████▍   | 6421/10000 [00:18<00:13, 270.58it/s] 65%|██████▍   | 6453/10000 [00:18<00:13, 272.30it/s] 65%|██████▍   | 6483/10000 [00:18<00:12, 272.27it/s] 65%|██████▌   | 6512/10000 [00:18<00:13, 265.88it/s] 65%|██████▌   | 6540/10000 [00:18<00:13, 263.92it/s] 66%|██████▌   | 6574/10000 [00:19<00:12, 264.85it/s] 66%|██████▌   | 6601/10000 [00:19<00:14, 241.06it/s] 66%|██████▋   | 6650/10000 [00:19<00:11, 297.77it/s] 67%|██████▋   | 6681/10000 [00:19<00:11, 291.11it/s] 67%|██████▋   | 6712/10000 [00:19<00:11, 292.15it/s] 67%|██████▋   | 6747/10000 [00:19<00:10, 299.75it/s] 68%|██████▊   | 6780/10000 [00:19<00:10, 303.11it/s] 68%|██████▊   | 6829/10000 [00:19<00:09, 349.93it/s] 69%|██████▉   | 6882/10000 [00:20<00:07, 390.96it/s] 69%|██████▉   | 6940/10000 [00:20<00:07, 436.15it/s] 70%|██████▉   | 6987/10000 [00:20<00:06, 438.08it/s] 70%|███████   | 7039/10000 [00:20<00:06, 453.00it/s] 71%|███████   | 7085/10000 [00:20<00:06, 443.33it/s] 71%|███████▏  | 7130/10000 [00:20<00:07, 400.47it/s] 72%|███████▏  | 7178/10000 [00:20<00:06, 419.39it/s] 72%|███████▏  | 7233/10000 [00:20<00:06, 454.30it/s] 73%|███████▎  | 7282/10000 [00:20<00:05, 461.74it/s] 73%|███████▎  | 7338/10000 [00:20<00:05, 486.94it/s] 74%|███████▍  | 7388/10000 [00:21<00:05, 486.35it/s] 74%|███████▍  | 7437/10000 [00:21<00:05, 458.19it/s] 75%|███████▌  | 7504/10000 [00:21<00:04, 514.69it/s] 76%|███████▌  | 7557/10000 [00:21<00:04, 517.89it/s] 76%|███████▌  | 7610/10000 [00:21<00:05, 454.57it/s] 77%|███████▋  | 7658/10000 [00:21<00:06, 363.66it/s] 77%|███████▋  | 7699/10000 [00:21<00:06, 349.08it/s] 77%|███████▋  | 7739/10000 [00:22<00:06, 335.06it/s] 78%|███████▊  | 7775/10000 [00:22<00:06, 336.84it/s] 78%|███████▊  | 7811/10000 [00:22<00:06, 339.54it/s] 79%|███████▉  | 7875/10000 [00:22<00:05, 413.59it/s] 79%|███████▉  | 7918/10000 [00:22<00:05, 404.28it/s] 80%|███████▉  | 7975/10000 [00:22<00:04, 444.83it/s] 80%|████████  | 8046/10000 [00:22<00:03, 513.04it/s] 81%|████████  | 8113/10000 [00:22<00:03, 550.97it/s] 82%|████████▏ | 8169/10000 [00:22<00:03, 538.58it/s] 82%|████████▏ | 8224/10000 [00:23<00:03, 484.76it/s] 83%|████████▎ | 8274/10000 [00:23<00:04, 417.92it/s] 83%|████████▎ | 8319/10000 [00:23<00:04, 367.20it/s] 84%|████████▎ | 8358/10000 [00:23<00:04, 346.64it/s] 84%|████████▍ | 8395/10000 [00:23<00:05, 314.44it/s] 84%|████████▍ | 8428/10000 [00:23<00:05, 306.77it/s] 85%|████████▍ | 8470/10000 [00:23<00:04, 316.37it/s] 85%|████████▌ | 8514/10000 [00:23<00:04, 344.26it/s] 86%|████████▌ | 8555/10000 [00:24<00:04, 351.64it/s] 86%|████████▌ | 8598/10000 [00:24<00:03, 369.54it/s] 86%|████████▋ | 8636/10000 [00:24<00:03, 369.08it/s] 87%|████████▋ | 8736/10000 [00:24<00:02, 544.66it/s] 88%|████████▊ | 8793/10000 [00:24<00:02, 551.18it/s] 89%|████████▊ | 8859/10000 [00:24<00:01, 579.83it/s] 89%|████████▉ | 8933/10000 [00:24<00:01, 624.19it/s] 90%|█████████ | 9002/10000 [00:24<00:01, 636.84it/s] 91%|█████████ | 9075/10000 [00:24<00:01, 658.58it/s] 91%|█████████▏| 9142/10000 [00:25<00:01, 603.74it/s] 92%|█████████▏| 9204/10000 [00:25<00:01, 568.17it/s] 93%|█████████▎| 9262/10000 [00:25<00:01, 436.10it/s] 93%|█████████▎| 9311/10000 [00:25<00:01, 376.93it/s] 94%|█████████▎| 9354/10000 [00:25<00:01, 348.86it/s] 94%|█████████▍| 9392/10000 [00:25<00:02, 296.44it/s] 94%|█████████▍| 9425/10000 [00:26<00:01, 302.74it/s] 95%|█████████▍| 9471/10000 [00:26<00:01, 334.34it/s] 95%|█████████▌| 9507/10000 [00:26<00:01, 314.89it/s] 95%|█████████▌| 9541/10000 [00:26<00:01, 307.43it/s] 96%|█████████▌| 9573/10000 [00:26<00:01, 289.11it/s] 96%|█████████▌| 9621/10000 [00:26<00:01, 326.80it/s] 97%|█████████▋| 9657/10000 [00:26<00:01, 330.25it/s] 97%|█████████▋| 9691/10000 [00:26<00:00, 323.93it/s] 97%|█████████▋| 9732/10000 [00:26<00:00, 339.52it/s] 98%|█████████▊| 9767/10000 [00:27<00:00, 330.31it/s] 98%|█████████▊| 9801/10000 [00:27<00:00, 326.72it/s] 99%|█████████▊| 9872/10000 [00:27<00:00, 427.87it/s] 99%|█████████▉| 9933/10000 [00:27<00:00, 473.00it/s]100%|██████████| 10000/10000 [00:27<00:00, 364.49it/s]
test_neglected_p96 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p96
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p96.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:42,  1.09s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:05,  6.46it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 12.42it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 18.49it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 24.26it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 29.35it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 33.63it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 36.97it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 20.38it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p96_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p96_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p96_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p96_Holmes_probs.npy
{'Accuracy': 0.0216, 'Precision': 0.0252, 'Recall': 0.0213, 'F1-score': 0.0191}
starting gen taf script for test_neglected_p97
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 66/10000 [00:00<00:15, 643.96it/s]  1%|▏         | 131/10000 [00:00<00:31, 314.82it/s]  2%|▏         | 172/10000 [00:00<00:35, 273.68it/s]  2%|▏         | 204/10000 [00:00<00:37, 259.58it/s]  2%|▏         | 233/10000 [00:00<00:38, 254.80it/s]  3%|▎         | 260/10000 [00:00<00:37, 256.93it/s]  3%|▎         | 290/10000 [00:01<00:36, 266.63it/s]  3%|▎         | 318/10000 [00:01<00:37, 258.92it/s]  3%|▎         | 347/10000 [00:01<00:36, 263.20it/s]  4%|▍         | 380/10000 [00:01<00:35, 273.81it/s]  4%|▍         | 412/10000 [00:01<00:34, 280.44it/s]  4%|▍         | 447/10000 [00:01<00:32, 294.81it/s]  5%|▍         | 485/10000 [00:01<00:30, 313.52it/s]  5%|▌         | 517/10000 [00:01<00:32, 291.05it/s]  6%|▌         | 553/10000 [00:01<00:30, 305.46it/s]  6%|▌         | 592/10000 [00:02<00:29, 323.10it/s]  6%|▋         | 631/10000 [00:02<00:28, 333.12it/s]  7%|▋         | 665/10000 [00:02<00:28, 331.45it/s]  7%|▋         | 699/10000 [00:02<00:29, 320.14it/s]  7%|▋         | 740/10000 [00:02<00:27, 340.80it/s]  8%|▊         | 787/10000 [00:02<00:25, 357.17it/s]  8%|▊         | 823/10000 [00:02<00:28, 323.76it/s]  9%|▊         | 860/10000 [00:02<00:27, 333.26it/s]  9%|▉         | 898/10000 [00:02<00:26, 345.92it/s]  9%|▉         | 935/10000 [00:03<00:26, 347.10it/s] 10%|▉         | 971/10000 [00:03<00:30, 300.77it/s] 10%|█         | 1010/10000 [00:03<00:29, 306.44it/s] 11%|█         | 1054/10000 [00:03<00:26, 335.45it/s] 11%|█         | 1089/10000 [00:03<00:28, 313.40it/s] 11%|█         | 1124/10000 [00:03<00:28, 306.86it/s] 12%|█▏        | 1168/10000 [00:03<00:25, 341.23it/s] 12%|█▏        | 1204/10000 [00:03<00:29, 297.01it/s] 13%|█▎        | 1255/10000 [00:04<00:25, 339.13it/s] 13%|█▎        | 1300/10000 [00:04<00:23, 366.19it/s] 14%|█▎        | 1350/10000 [00:04<00:22, 389.96it/s] 14%|█▍        | 1398/10000 [00:04<00:21, 404.84it/s] 14%|█▍        | 1440/10000 [00:04<00:28, 301.31it/s] 15%|█▍        | 1475/10000 [00:04<00:30, 278.96it/s] 15%|█▌        | 1506/10000 [00:04<00:38, 222.32it/s] 15%|█▌        | 1532/10000 [00:05<00:41, 205.83it/s] 16%|█▌        | 1556/10000 [00:05<00:40, 210.53it/s] 16%|█▌        | 1582/10000 [00:05<00:39, 215.22it/s] 16%|█▌        | 1611/10000 [00:05<00:36, 232.77it/s] 17%|█▋        | 1668/10000 [00:05<00:26, 314.13it/s] 17%|█▋        | 1739/10000 [00:05<00:19, 418.00it/s] 18%|█▊        | 1784/10000 [00:05<00:19, 420.61it/s] 19%|█▊        | 1864/10000 [00:05<00:15, 521.51it/s] 20%|█▉        | 1963/10000 [00:05<00:12, 646.87it/s] 20%|██        | 2030/10000 [00:06<00:14, 538.58it/s] 21%|██        | 2089/10000 [00:06<00:15, 522.99it/s] 21%|██▏       | 2145/10000 [00:06<00:17, 449.33it/s] 22%|██▏       | 2194/10000 [00:06<00:17, 448.40it/s] 22%|██▏       | 2242/10000 [00:06<00:20, 387.20it/s] 23%|██▎       | 2284/10000 [00:06<00:21, 354.17it/s] 23%|██▎       | 2322/10000 [00:07<00:23, 327.28it/s] 24%|██▎       | 2357/10000 [00:07<00:23, 323.30it/s] 24%|██▍       | 2391/10000 [00:07<00:25, 298.71it/s] 24%|██▍       | 2422/10000 [00:07<00:25, 296.81it/s] 25%|██▍       | 2478/10000 [00:07<00:21, 350.88it/s] 25%|██▌       | 2516/10000 [00:07<00:20, 357.11it/s] 26%|██▌       | 2563/10000 [00:07<00:19, 379.10it/s] 26%|██▌       | 2602/10000 [00:07<00:19, 373.11it/s] 26%|██▋       | 2640/10000 [00:07<00:23, 310.50it/s] 27%|██▋       | 2673/10000 [00:08<00:30, 242.92it/s] 27%|██▋       | 2701/10000 [00:08<00:31, 235.02it/s] 27%|██▋       | 2727/10000 [00:08<00:36, 199.71it/s] 27%|██▋       | 2749/10000 [00:08<00:37, 191.61it/s] 28%|██▊       | 2770/10000 [00:08<00:42, 171.34it/s] 28%|██▊       | 2809/10000 [00:08<00:33, 216.89it/s] 29%|██▊       | 2863/10000 [00:09<00:24, 287.43it/s] 29%|██▉       | 2911/10000 [00:09<00:21, 329.37it/s] 30%|██▉       | 2957/10000 [00:09<00:19, 353.72it/s] 30%|██▉       | 2995/10000 [00:09<00:20, 342.26it/s] 30%|███       | 3031/10000 [00:09<00:20, 339.77it/s] 31%|███       | 3067/10000 [00:09<00:23, 298.46it/s] 31%|███       | 3099/10000 [00:09<00:23, 291.51it/s] 31%|███▏      | 3146/10000 [00:09<00:20, 331.89it/s] 32%|███▏      | 3181/10000 [00:10<00:22, 300.05it/s] 32%|███▏      | 3229/10000 [00:10<00:19, 344.50it/s] 33%|███▎      | 3300/10000 [00:10<00:15, 439.98it/s] 34%|███▎      | 3370/10000 [00:10<00:12, 511.05it/s] 34%|███▍      | 3424/10000 [00:10<00:12, 513.75it/s] 35%|███▍      | 3478/10000 [00:10<00:15, 422.31it/s] 35%|███▌      | 3529/10000 [00:10<00:15, 427.81it/s] 36%|███▌      | 3575/10000 [00:10<00:16, 377.99it/s] 36%|███▋      | 3627/10000 [00:10<00:15, 403.90it/s] 37%|███▋      | 3687/10000 [00:11<00:14, 444.75it/s] 37%|███▋      | 3748/10000 [00:11<00:12, 487.30it/s] 38%|███▊      | 3806/10000 [00:11<00:12, 508.86it/s] 39%|███▊      | 3859/10000 [00:11<00:14, 434.95it/s] 39%|███▉      | 3906/10000 [00:11<00:14, 412.43it/s] 40%|███▉      | 3950/10000 [00:11<00:14, 410.51it/s] 40%|███▉      | 3999/10000 [00:11<00:13, 428.94it/s] 41%|████      | 4054/10000 [00:11<00:13, 450.69it/s] 41%|████      | 4122/10000 [00:12<00:11, 499.83it/s] 42%|████▏     | 4181/10000 [00:12<00:11, 516.36it/s] 42%|████▏     | 4235/10000 [00:12<00:11, 512.98it/s] 43%|████▎     | 4288/10000 [00:12<00:11, 493.30it/s] 44%|████▎     | 4357/10000 [00:12<00:10, 542.59it/s] 44%|████▍     | 4412/10000 [00:12<00:13, 419.73it/s] 45%|████▍     | 4459/10000 [00:12<00:14, 391.76it/s] 45%|████▌     | 4502/10000 [00:12<00:16, 342.62it/s] 45%|████▌     | 4540/10000 [00:13<00:16, 323.53it/s] 46%|████▌     | 4575/10000 [00:13<00:20, 263.41it/s] 46%|████▌     | 4604/10000 [00:13<00:21, 256.22it/s] 46%|████▋     | 4632/10000 [00:13<00:21, 249.75it/s] 47%|████▋     | 4676/10000 [00:13<00:18, 286.16it/s] 47%|████▋     | 4707/10000 [00:13<00:19, 267.02it/s] 47%|████▋     | 4735/10000 [00:13<00:20, 260.60it/s] 48%|████▊     | 4762/10000 [00:14<00:20, 260.98it/s] 48%|████▊     | 4792/10000 [00:14<00:19, 262.91it/s] 48%|████▊     | 4819/10000 [00:14<00:23, 224.43it/s] 48%|████▊     | 4848/10000 [00:14<00:21, 240.13it/s] 49%|████▊     | 4874/10000 [00:14<00:24, 213.16it/s] 49%|████▉     | 4897/10000 [00:14<00:24, 207.13it/s] 49%|████▉     | 4925/10000 [00:14<00:23, 220.30it/s] 50%|████▉     | 4952/10000 [00:14<00:21, 231.95it/s] 50%|████▉     | 4976/10000 [00:15<00:25, 196.22it/s] 50%|█████     | 5024/10000 [00:15<00:19, 261.74it/s] 51%|█████     | 5082/10000 [00:15<00:14, 342.43it/s] 51%|█████     | 5120/10000 [00:15<00:14, 339.59it/s] 52%|█████▏    | 5169/10000 [00:15<00:12, 373.77it/s] 52%|█████▏    | 5211/10000 [00:15<00:13, 362.15it/s] 52%|█████▏    | 5249/10000 [00:15<00:13, 346.13it/s] 53%|█████▎    | 5285/10000 [00:15<00:16, 280.15it/s] 53%|█████▎    | 5316/10000 [00:16<00:17, 268.26it/s] 53%|█████▎    | 5345/10000 [00:16<00:19, 236.64it/s] 54%|█████▎    | 5372/10000 [00:16<00:19, 241.19it/s] 54%|█████▍    | 5398/10000 [00:16<00:19, 235.31it/s] 54%|█████▍    | 5444/10000 [00:16<00:16, 284.23it/s] 55%|█████▍    | 5474/10000 [00:16<00:15, 286.81it/s] 55%|█████▌    | 5533/10000 [00:16<00:12, 366.69it/s] 56%|█████▌    | 5572/10000 [00:16<00:12, 355.15it/s] 56%|█████▌    | 5612/10000 [00:16<00:11, 367.12it/s] 57%|█████▋    | 5662/10000 [00:17<00:10, 397.23it/s] 57%|█████▋    | 5716/10000 [00:17<00:09, 433.53it/s] 58%|█████▊    | 5760/10000 [00:17<00:11, 384.37it/s] 58%|█████▊    | 5800/10000 [00:17<00:10, 386.48it/s] 58%|█████▊    | 5840/10000 [00:17<00:13, 305.44it/s] 59%|█████▊    | 5874/10000 [00:17<00:14, 285.90it/s] 59%|█████▉    | 5915/10000 [00:17<00:13, 306.56it/s] 59%|█████▉    | 5948/10000 [00:18<00:13, 298.30it/s] 60%|█████▉    | 5980/10000 [00:18<00:13, 294.20it/s] 60%|██████    | 6019/10000 [00:18<00:12, 316.08it/s] 61%|██████    | 6056/10000 [00:18<00:12, 327.83it/s] 61%|██████    | 6101/10000 [00:18<00:10, 357.82it/s] 62%|██████▏   | 6161/10000 [00:18<00:09, 417.46it/s] 62%|██████▏   | 6204/10000 [00:18<00:10, 363.47it/s] 62%|██████▏   | 6242/10000 [00:18<00:10, 349.67it/s] 63%|██████▎   | 6279/10000 [00:19<00:12, 296.77it/s] 63%|██████▎   | 6311/10000 [00:19<00:13, 268.34it/s] 63%|██████▎   | 6340/10000 [00:19<00:13, 261.90it/s] 64%|██████▎   | 6368/10000 [00:19<00:15, 239.29it/s] 64%|██████▍   | 6393/10000 [00:19<00:15, 237.14it/s] 64%|██████▍   | 6421/10000 [00:19<00:14, 245.09it/s] 64%|██████▍   | 6447/10000 [00:19<00:17, 206.86it/s] 65%|██████▍   | 6492/10000 [00:19<00:13, 257.49it/s] 65%|██████▌   | 6520/10000 [00:20<00:14, 233.31it/s] 66%|██████▌   | 6553/10000 [00:20<00:13, 253.63it/s] 66%|██████▌   | 6580/10000 [00:20<00:13, 255.66it/s] 66%|██████▌   | 6607/10000 [00:20<00:13, 259.12it/s] 66%|██████▋   | 6634/10000 [00:20<00:13, 251.53it/s] 67%|██████▋   | 6666/10000 [00:20<00:12, 263.13it/s] 67%|██████▋   | 6693/10000 [00:20<00:12, 259.01it/s] 67%|██████▋   | 6732/10000 [00:20<00:11, 291.64it/s] 68%|██████▊   | 6770/10000 [00:20<00:10, 298.17it/s] 68%|██████▊   | 6801/10000 [00:21<00:10, 299.75it/s] 69%|██████▊   | 6861/10000 [00:21<00:08, 383.34it/s] 69%|██████▉   | 6902/10000 [00:21<00:07, 388.29it/s] 70%|██████▉   | 6951/10000 [00:21<00:07, 417.40it/s] 70%|██████▉   | 6994/10000 [00:21<00:07, 419.82it/s] 71%|███████   | 7052/10000 [00:21<00:06, 464.58it/s] 71%|███████   | 7099/10000 [00:21<00:06, 456.71it/s] 71%|███████▏  | 7145/10000 [00:21<00:06, 422.94it/s] 72%|███████▏  | 7190/10000 [00:21<00:06, 430.33it/s] 72%|███████▏  | 7244/10000 [00:21<00:06, 458.56it/s] 73%|███████▎  | 7291/10000 [00:22<00:06, 433.76it/s] 74%|███████▎  | 7364/10000 [00:22<00:05, 506.75it/s] 74%|███████▍  | 7416/10000 [00:22<00:05, 502.81it/s] 75%|███████▍  | 7469/10000 [00:22<00:05, 495.44it/s] 75%|███████▌  | 7519/10000 [00:22<00:05, 478.62it/s] 76%|███████▌  | 7568/10000 [00:22<00:05, 432.50it/s] 76%|███████▌  | 7613/10000 [00:22<00:05, 414.73it/s] 77%|███████▋  | 7656/10000 [00:22<00:05, 416.81it/s] 77%|███████▋  | 7699/10000 [00:23<00:05, 391.91it/s] 77%|███████▋  | 7739/10000 [00:23<00:06, 343.14it/s] 78%|███████▊  | 7782/10000 [00:23<00:06, 353.89it/s] 78%|███████▊  | 7833/10000 [00:23<00:05, 385.71it/s] 79%|███████▉  | 7883/10000 [00:23<00:05, 413.50it/s] 79%|███████▉  | 7943/10000 [00:23<00:04, 460.15it/s] 80%|████████  | 8026/10000 [00:23<00:03, 556.60it/s] 81%|████████  | 8083/10000 [00:23<00:03, 515.47it/s] 82%|████████▏ | 8165/10000 [00:23<00:03, 566.74it/s] 82%|████████▏ | 8223/10000 [00:24<00:04, 425.60it/s] 83%|████████▎ | 8271/10000 [00:24<00:04, 401.29it/s] 83%|████████▎ | 8315/10000 [00:24<00:05, 332.15it/s] 84%|████████▎ | 8353/10000 [00:24<00:05, 328.12it/s] 84%|████████▍ | 8389/10000 [00:24<00:05, 292.69it/s] 84%|████████▍ | 8421/10000 [00:24<00:05, 265.90it/s] 85%|████████▍ | 8472/10000 [00:25<00:04, 314.51it/s] 85%|████████▌ | 8507/10000 [00:25<00:04, 309.16it/s] 85%|████████▌ | 8540/10000 [00:25<00:04, 296.04it/s] 86%|████████▌ | 8571/10000 [00:25<00:04, 286.74it/s] 86%|████████▋ | 8636/10000 [00:25<00:03, 372.58it/s] 87%|████████▋ | 8724/10000 [00:25<00:02, 499.41it/s] 88%|████████▊ | 8781/10000 [00:25<00:02, 514.50it/s] 88%|████████▊ | 8835/10000 [00:25<00:02, 515.72it/s] 89%|████████▉ | 8888/10000 [00:25<00:02, 511.40it/s] 90%|████████▉ | 8956/10000 [00:26<00:01, 551.28it/s] 90%|█████████ | 9024/10000 [00:26<00:01, 585.35it/s] 91%|█████████ | 9084/10000 [00:26<00:01, 546.17it/s] 91%|█████████▏| 9144/10000 [00:26<00:01, 560.43it/s] 92%|█████████▏| 9201/10000 [00:26<00:01, 529.53it/s] 93%|█████████▎| 9255/10000 [00:26<00:01, 412.46it/s] 93%|█████████▎| 9301/10000 [00:26<00:01, 365.60it/s] 93%|█████████▎| 9342/10000 [00:27<00:01, 363.58it/s] 94%|█████████▍| 9381/10000 [00:27<00:02, 301.73it/s] 94%|█████████▍| 9415/10000 [00:27<00:02, 279.36it/s] 94%|█████████▍| 9445/10000 [00:27<00:02, 272.57it/s] 95%|█████████▍| 9492/10000 [00:27<00:01, 310.72it/s] 95%|█████████▌| 9525/10000 [00:27<00:01, 282.73it/s] 96%|█████████▌| 9558/10000 [00:27<00:01, 291.28it/s] 96%|█████████▌| 9589/10000 [00:27<00:01, 292.36it/s] 96%|█████████▋| 9638/10000 [00:28<00:01, 344.05it/s] 97%|█████████▋| 9674/10000 [00:28<00:01, 307.68it/s] 97%|█████████▋| 9722/10000 [00:28<00:00, 345.03it/s] 98%|█████████▊| 9758/10000 [00:28<00:00, 310.34it/s] 98%|█████████▊| 9804/10000 [00:28<00:00, 347.89it/s] 99%|█████████▊| 9858/10000 [00:28<00:00, 396.32it/s] 99%|█████████▉| 9904/10000 [00:28<00:00, 410.44it/s]100%|█████████▉| 9978/10000 [00:28<00:00, 493.58it/s]100%|██████████| 10000/10000 [00:28<00:00, 346.15it/s]
test_neglected_p97 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p97
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p97.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:40,  1.03s/it]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  6.82it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.04it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.24it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.09it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.25it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.63it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 38.12it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.31it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p97_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p97_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p97_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p97_Holmes_probs.npy
{'Accuracy': 0.0214, 'Precision': 0.0249, 'Recall': 0.0211, 'F1-score': 0.0188}
starting gen taf script for test_neglected_p98
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 66/10000 [00:00<00:15, 652.33it/s]  1%|▏         | 132/10000 [00:00<00:27, 364.29it/s]  2%|▏         | 176/10000 [00:00<00:32, 305.56it/s]  2%|▏         | 211/10000 [00:00<00:33, 292.21it/s]  2%|▏         | 243/10000 [00:00<00:34, 286.58it/s]  3%|▎         | 273/10000 [00:00<00:36, 269.39it/s]  3%|▎         | 301/10000 [00:01<00:38, 253.55it/s]  3%|▎         | 327/10000 [00:01<00:40, 236.27it/s]  4%|▎         | 358/10000 [00:01<00:38, 251.94it/s]  4%|▍         | 385/10000 [00:01<00:37, 256.63it/s]  4%|▍         | 412/10000 [00:01<00:40, 234.96it/s]  5%|▍         | 453/10000 [00:01<00:34, 277.16it/s]  5%|▍         | 486/10000 [00:01<00:33, 284.79it/s]  5%|▌         | 528/10000 [00:01<00:29, 317.25it/s]  6%|▌         | 565/10000 [00:01<00:28, 327.10it/s]  6%|▌         | 616/10000 [00:02<00:24, 377.54it/s]  7%|▋         | 676/10000 [00:02<00:21, 438.89it/s]  7%|▋         | 738/10000 [00:02<00:18, 491.07it/s]  8%|▊         | 797/10000 [00:02<00:18, 511.02it/s]  8%|▊         | 849/10000 [00:02<00:18, 501.97it/s]  9%|▉         | 900/10000 [00:02<00:19, 469.06it/s] 10%|▉         | 959/10000 [00:02<00:18, 488.22it/s] 10%|█         | 1009/10000 [00:02<00:23, 374.87it/s] 11%|█         | 1051/10000 [00:03<00:27, 328.63it/s] 11%|█         | 1088/10000 [00:03<00:26, 331.68it/s] 11%|█         | 1124/10000 [00:03<00:27, 326.04it/s] 12%|█▏        | 1159/10000 [00:03<00:26, 330.99it/s] 12%|█▏        | 1194/10000 [00:03<00:28, 312.29it/s] 12%|█▏        | 1245/10000 [00:03<00:24, 362.64it/s] 13%|█▎        | 1318/10000 [00:03<00:18, 460.82it/s] 14%|█▎        | 1371/10000 [00:03<00:18, 478.06it/s] 14%|█▍        | 1421/10000 [00:03<00:20, 413.14it/s] 15%|█▍        | 1465/10000 [00:04<00:29, 287.59it/s] 15%|█▌        | 1501/10000 [00:04<00:32, 259.56it/s] 15%|█▌        | 1532/10000 [00:04<00:37, 224.34it/s] 16%|█▌        | 1559/10000 [00:04<00:36, 230.26it/s] 16%|█▌        | 1585/10000 [00:04<00:40, 206.93it/s] 16%|█▋        | 1637/10000 [00:05<00:31, 267.45it/s] 17%|█▋        | 1679/10000 [00:05<00:27, 301.61it/s] 18%|█▊        | 1750/10000 [00:05<00:20, 396.95it/s] 18%|█▊        | 1813/10000 [00:05<00:18, 450.13it/s] 19%|█▉        | 1883/10000 [00:05<00:15, 515.93it/s] 20%|█▉        | 1958/10000 [00:05<00:13, 580.20it/s] 20%|██        | 2020/10000 [00:05<00:14, 567.75it/s] 21%|██        | 2079/10000 [00:05<00:17, 449.15it/s] 21%|██▏       | 2130/10000 [00:06<00:19, 414.04it/s] 22%|██▏       | 2184/10000 [00:06<00:18, 434.10it/s] 22%|██▏       | 2231/10000 [00:06<00:19, 405.57it/s] 23%|██▎       | 2274/10000 [00:06<00:21, 359.56it/s] 23%|██▎       | 2313/10000 [00:06<00:24, 317.84it/s] 23%|██▎       | 2347/10000 [00:06<00:24, 309.66it/s] 24%|██▍       | 2380/10000 [00:06<00:28, 267.53it/s] 24%|██▍       | 2434/10000 [00:06<00:23, 326.55it/s] 25%|██▍       | 2491/10000 [00:07<00:19, 384.94it/s] 25%|██▌       | 2534/10000 [00:07<00:20, 360.00it/s] 26%|██▌       | 2585/10000 [00:07<00:18, 395.91it/s] 26%|██▋       | 2628/10000 [00:07<00:22, 326.39it/s] 27%|██▋       | 2665/10000 [00:07<00:25, 287.73it/s] 27%|██▋       | 2697/10000 [00:07<00:30, 237.16it/s] 27%|██▋       | 2724/10000 [00:08<00:31, 232.32it/s] 28%|██▊       | 2750/10000 [00:08<00:34, 208.49it/s] 28%|██▊       | 2773/10000 [00:08<00:35, 201.59it/s] 28%|██▊       | 2795/10000 [00:08<00:36, 198.05it/s] 28%|██▊       | 2838/10000 [00:08<00:28, 250.35it/s] 29%|██▉       | 2911/10000 [00:08<00:19, 361.41it/s] 30%|██▉       | 2964/10000 [00:08<00:17, 403.27it/s] 30%|███       | 3007/10000 [00:08<00:18, 381.92it/s] 30%|███       | 3048/10000 [00:09<00:19, 355.40it/s] 31%|███       | 3086/10000 [00:09<00:21, 320.57it/s] 31%|███       | 3120/10000 [00:09<00:21, 319.61it/s] 32%|███▏      | 3153/10000 [00:09<00:23, 291.04it/s] 32%|███▏      | 3193/10000 [00:09<00:21, 312.65it/s] 33%|███▎      | 3268/10000 [00:09<00:16, 417.92it/s] 33%|███▎      | 3329/10000 [00:09<00:14, 468.67it/s] 34%|███▍      | 3408/10000 [00:09<00:12, 548.10it/s] 35%|███▍      | 3465/10000 [00:09<00:13, 477.32it/s] 35%|███▌      | 3516/10000 [00:10<00:13, 475.56it/s] 36%|███▌      | 3566/10000 [00:10<00:14, 444.20it/s] 36%|███▌      | 3612/10000 [00:10<00:14, 434.05it/s] 37%|███▋      | 3663/10000 [00:10<00:14, 450.44it/s] 37%|███▋      | 3729/10000 [00:10<00:12, 506.85it/s] 38%|███▊      | 3791/10000 [00:10<00:11, 528.59it/s] 38%|███▊      | 3845/10000 [00:10<00:12, 498.03it/s] 39%|███▉      | 3896/10000 [00:10<00:13, 440.21it/s] 40%|███▉      | 3955/10000 [00:11<00:12, 469.92it/s] 40%|████      | 4004/10000 [00:11<00:14, 427.55it/s] 41%|████      | 4075/10000 [00:11<00:11, 499.00it/s] 41%|████▏     | 4128/10000 [00:11<00:11, 505.13it/s] 42%|████▏     | 4206/10000 [00:11<00:10, 568.09it/s] 43%|████▎     | 4272/10000 [00:11<00:09, 579.13it/s] 43%|████▎     | 4336/10000 [00:11<00:09, 595.62it/s] 44%|████▍     | 4397/10000 [00:11<00:09, 594.69it/s] 45%|████▍     | 4458/10000 [00:12<00:13, 416.36it/s] 45%|████▌     | 4508/10000 [00:12<00:16, 333.76it/s] 45%|████▌     | 4549/10000 [00:12<00:16, 320.84it/s] 46%|████▌     | 4587/10000 [00:12<00:17, 303.09it/s] 46%|████▌     | 4621/10000 [00:12<00:18, 293.11it/s] 47%|████▋     | 4653/10000 [00:12<00:18, 282.82it/s] 47%|████▋     | 4683/10000 [00:12<00:19, 273.80it/s] 47%|████▋     | 4712/10000 [00:13<00:19, 275.55it/s] 47%|████▋     | 4741/10000 [00:13<00:19, 272.78it/s] 48%|████▊     | 4769/10000 [00:13<00:19, 269.04it/s] 48%|████▊     | 4797/10000 [00:13<00:19, 264.09it/s] 48%|████▊     | 4824/10000 [00:13<00:20, 252.78it/s] 49%|████▊     | 4851/10000 [00:13<00:20, 257.31it/s] 49%|████▉     | 4877/10000 [00:13<00:22, 222.94it/s] 49%|████▉     | 4904/10000 [00:13<00:22, 227.86it/s] 49%|████▉     | 4930/10000 [00:14<00:23, 219.73it/s] 50%|████▉     | 4957/10000 [00:14<00:21, 231.48it/s] 50%|████▉     | 4981/10000 [00:14<00:21, 228.45it/s] 50%|█████     | 5009/10000 [00:14<00:21, 234.58it/s] 51%|█████     | 5051/10000 [00:14<00:17, 279.10it/s] 51%|█████     | 5116/10000 [00:14<00:12, 381.57it/s] 52%|█████▏    | 5160/10000 [00:14<00:12, 391.37it/s] 52%|█████▏    | 5200/10000 [00:14<00:12, 388.25it/s] 52%|█████▏    | 5240/10000 [00:14<00:12, 372.06it/s] 53%|█████▎    | 5278/10000 [00:15<00:17, 275.95it/s] 53%|█████▎    | 5310/10000 [00:15<00:16, 276.60it/s] 53%|█████▎    | 5341/10000 [00:15<00:18, 253.50it/s] 54%|█████▎    | 5369/10000 [00:15<00:19, 236.83it/s] 54%|█████▍    | 5395/10000 [00:15<00:19, 231.32it/s] 54%|█████▍    | 5428/10000 [00:15<00:18, 249.76it/s] 55%|█████▍    | 5468/10000 [00:15<00:16, 282.48it/s] 55%|█████▌    | 5521/10000 [00:15<00:13, 344.03it/s] 56%|█████▌    | 5566/10000 [00:16<00:11, 371.72it/s] 56%|█████▌    | 5605/10000 [00:16<00:11, 373.52it/s] 57%|█████▋    | 5655/10000 [00:16<00:10, 408.74it/s] 57%|█████▋    | 5697/10000 [00:16<00:10, 399.28it/s] 58%|█████▊    | 5753/10000 [00:16<00:09, 432.92it/s] 58%|█████▊    | 5797/10000 [00:16<00:10, 414.65it/s] 58%|█████▊    | 5839/10000 [00:16<00:11, 373.81it/s] 59%|█████▉    | 5878/10000 [00:16<00:12, 342.99it/s] 59%|█████▉    | 5926/10000 [00:16<00:10, 374.55it/s] 60%|█████▉    | 5965/10000 [00:17<00:11, 352.74it/s] 60%|██████    | 6002/10000 [00:17<00:12, 313.64it/s] 60%|██████    | 6048/10000 [00:17<00:11, 341.31it/s] 61%|██████    | 6093/10000 [00:17<00:10, 359.12it/s] 61%|██████▏   | 6148/10000 [00:17<00:09, 408.03it/s] 62%|██████▏   | 6195/10000 [00:17<00:09, 411.90it/s] 62%|██████▏   | 6238/10000 [00:17<00:11, 318.77it/s] 63%|██████▎   | 6274/10000 [00:18<00:12, 304.59it/s] 63%|██████▎   | 6307/10000 [00:18<00:12, 295.79it/s] 63%|██████▎   | 6339/10000 [00:18<00:13, 266.97it/s] 64%|██████▎   | 6369/10000 [00:18<00:13, 274.37it/s] 64%|██████▍   | 6398/10000 [00:18<00:14, 248.07it/s] 64%|██████▍   | 6424/10000 [00:18<00:14, 244.02it/s] 64%|██████▍   | 6450/10000 [00:18<00:15, 227.74it/s] 65%|██████▍   | 6481/10000 [00:18<00:14, 246.17it/s] 65%|██████▌   | 6507/10000 [00:19<00:14, 242.07it/s] 65%|██████▌   | 6532/10000 [00:19<00:15, 228.81it/s] 66%|██████▌   | 6574/10000 [00:19<00:12, 275.02it/s] 66%|██████▌   | 6603/10000 [00:19<00:13, 254.26it/s] 66%|██████▋   | 6637/10000 [00:19<00:12, 276.45it/s] 67%|██████▋   | 6666/10000 [00:19<00:12, 264.67it/s] 67%|██████▋   | 6700/10000 [00:19<00:11, 283.35it/s] 67%|██████▋   | 6730/10000 [00:19<00:11, 281.37it/s] 68%|██████▊   | 6759/10000 [00:19<00:11, 279.40it/s] 68%|██████▊   | 6788/10000 [00:20<00:11, 271.66it/s] 69%|██████▊   | 6865/10000 [00:20<00:07, 399.90it/s] 69%|██████▉   | 6924/10000 [00:20<00:06, 448.02it/s] 70%|██████▉   | 6988/10000 [00:20<00:06, 495.27it/s] 70%|███████   | 7038/10000 [00:20<00:06, 435.16it/s] 71%|███████   | 7083/10000 [00:20<00:06, 422.13it/s] 71%|███████▏  | 7127/10000 [00:20<00:06, 417.78it/s] 72%|███████▏  | 7170/10000 [00:20<00:06, 415.96it/s] 72%|███████▏  | 7221/10000 [00:20<00:06, 437.54it/s] 73%|███████▎  | 7283/10000 [00:21<00:05, 479.92it/s] 74%|███████▎  | 7357/10000 [00:21<00:04, 537.72it/s] 74%|███████▍  | 7411/10000 [00:21<00:04, 522.00it/s] 75%|███████▍  | 7464/10000 [00:21<00:04, 513.69it/s] 75%|███████▌  | 7516/10000 [00:21<00:04, 507.46it/s] 76%|███████▌  | 7567/10000 [00:21<00:05, 455.60it/s] 76%|███████▌  | 7614/10000 [00:21<00:06, 393.85it/s] 77%|███████▋  | 7660/10000 [00:21<00:05, 408.05it/s] 77%|███████▋  | 7703/10000 [00:21<00:05, 408.16it/s] 77%|███████▋  | 7745/10000 [00:22<00:07, 319.60it/s] 78%|███████▊  | 7793/10000 [00:22<00:06, 339.26it/s] 79%|███████▊  | 7871/10000 [00:22<00:04, 434.46it/s] 79%|███████▉  | 7933/10000 [00:22<00:04, 480.45it/s] 80%|████████  | 8005/10000 [00:22<00:03, 541.72it/s] 81%|████████  | 8063/10000 [00:22<00:03, 532.01it/s] 81%|████████  | 8119/10000 [00:22<00:03, 491.40it/s] 82%|████████▏ | 8171/10000 [00:22<00:03, 470.09it/s] 82%|████████▏ | 8220/10000 [00:23<00:03, 457.12it/s] 83%|████████▎ | 8267/10000 [00:23<00:04, 390.43it/s] 83%|████████▎ | 8309/10000 [00:23<00:05, 327.41it/s] 83%|████████▎ | 8345/10000 [00:23<00:05, 280.97it/s] 84%|████████▍ | 8385/10000 [00:23<00:05, 292.96it/s] 84%|████████▍ | 8418/10000 [00:23<00:05, 298.66it/s] 84%|████████▍ | 8450/10000 [00:23<00:05, 303.29it/s] 85%|████████▍ | 8482/10000 [00:24<00:05, 300.67it/s] 85%|████████▌ | 8521/10000 [00:24<00:04, 307.74it/s] 86%|████████▌ | 8559/10000 [00:24<00:04, 321.60it/s] 86%|████████▌ | 8594/10000 [00:24<00:04, 328.80it/s] 87%|████████▋ | 8662/10000 [00:24<00:03, 424.97it/s] 87%|████████▋ | 8734/10000 [00:24<00:02, 503.67it/s] 88%|████████▊ | 8787/10000 [00:24<00:02, 508.57it/s] 89%|████████▊ | 8872/10000 [00:24<00:01, 604.61it/s] 89%|████████▉ | 8935/10000 [00:24<00:01, 600.80it/s] 90%|████████▉ | 8996/10000 [00:25<00:01, 590.97it/s] 91%|█████████ | 9060/10000 [00:25<00:01, 603.88it/s] 91%|█████████ | 9121/10000 [00:25<00:01, 591.38it/s] 92%|█████████▏| 9181/10000 [00:25<00:01, 526.65it/s] 92%|█████████▏| 9236/10000 [00:25<00:01, 471.84it/s] 93%|█████████▎| 9285/10000 [00:25<00:01, 432.26it/s] 93%|█████████▎| 9330/10000 [00:25<00:01, 389.77it/s] 94%|█████████▎| 9371/10000 [00:25<00:01, 355.57it/s] 94%|█████████▍| 9408/10000 [00:26<00:01, 300.41it/s] 94%|█████████▍| 9440/10000 [00:26<00:01, 296.04it/s] 95%|█████████▍| 9471/10000 [00:26<00:01, 276.67it/s] 95%|█████████▌| 9500/10000 [00:26<00:01, 264.67it/s] 95%|█████████▌| 9527/10000 [00:26<00:01, 265.68it/s] 96%|█████████▌| 9567/10000 [00:26<00:01, 284.51it/s] 96%|█████████▌| 9596/10000 [00:26<00:01, 280.27it/s] 96%|█████████▋| 9632/10000 [00:26<00:01, 292.42it/s] 97%|█████████▋| 9683/10000 [00:27<00:00, 350.64it/s] 97%|█████████▋| 9719/10000 [00:27<00:00, 335.26it/s] 98%|█████████▊| 9754/10000 [00:27<00:00, 331.88it/s] 98%|█████████▊| 9790/10000 [00:27<00:00, 311.56it/s] 98%|█████████▊| 9843/10000 [00:27<00:00, 364.40it/s] 99%|█████████▉| 9927/10000 [00:27<00:00, 487.54it/s]100%|██████████| 10000/10000 [00:27<00:00, 360.70it/s]
test_neglected_p98 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p98
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p98.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.03it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.09it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.33it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.62it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.40it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.32it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.26it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.44it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.51it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p98_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p98_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p98_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p98_Holmes_probs.npy
{'Accuracy': 0.0214, 'Precision': 0.0239, 'Recall': 0.0211, 'F1-score': 0.0187}
starting gen taf script for test_neglected_p99
  0%|          | 0/10000 [00:00<?, ?it/s]  0%|          | 33/10000 [00:00<00:34, 292.15it/s]  1%|          | 76/10000 [00:00<00:27, 367.14it/s]  1%|          | 114/10000 [00:00<00:33, 295.59it/s]  1%|▏         | 148/10000 [00:00<00:31, 308.87it/s]  2%|▏         | 181/10000 [00:00<00:32, 305.60it/s]  2%|▏         | 213/10000 [00:00<00:33, 292.16it/s]  2%|▏         | 243/10000 [00:00<00:33, 290.21it/s]  3%|▎         | 273/10000 [00:00<00:36, 267.63it/s]  3%|▎         | 301/10000 [00:01<00:37, 260.73it/s]  3%|▎         | 328/10000 [00:01<00:38, 253.69it/s]  4%|▎         | 354/10000 [00:01<00:38, 248.83it/s]  4%|▍         | 379/10000 [00:01<00:41, 234.39it/s]  4%|▍         | 410/10000 [00:01<00:38, 249.48it/s]  4%|▍         | 450/10000 [00:01<00:33, 285.86it/s]  5%|▍         | 490/10000 [00:01<00:30, 316.87it/s]  5%|▌         | 523/10000 [00:01<00:31, 304.84it/s]  6%|▌         | 554/10000 [00:01<00:32, 293.24it/s]  6%|▌         | 584/10000 [00:02<00:32, 289.79it/s]  6%|▌         | 619/10000 [00:02<00:31, 298.85it/s]  6%|▋         | 650/10000 [00:02<00:32, 287.52it/s]  7%|▋         | 692/10000 [00:02<00:28, 323.48it/s]  7%|▋         | 745/10000 [00:02<00:24, 372.74it/s]  8%|▊         | 799/10000 [00:02<00:23, 399.70it/s]  8%|▊         | 847/10000 [00:02<00:22, 409.68it/s]  9%|▉         | 896/10000 [00:02<00:21, 430.63it/s]  9%|▉         | 940/10000 [00:02<00:24, 376.21it/s] 10%|▉         | 981/10000 [00:03<00:23, 377.71it/s] 10%|█         | 1020/10000 [00:03<00:28, 311.85it/s] 11%|█         | 1054/10000 [00:03<00:28, 316.61it/s] 11%|█         | 1088/10000 [00:03<00:28, 317.18it/s] 11%|█         | 1121/10000 [00:03<00:30, 293.00it/s] 12%|█▏        | 1161/10000 [00:03<00:28, 311.37it/s] 12%|█▏        | 1194/10000 [00:03<00:28, 310.82it/s] 12%|█▏        | 1241/10000 [00:03<00:25, 343.71it/s] 13%|█▎        | 1277/10000 [00:04<00:25, 341.30it/s] 13%|█▎        | 1335/10000 [00:04<00:21, 406.88it/s] 14%|█▍        | 1377/10000 [00:04<00:21, 402.53it/s] 14%|█▍        | 1418/10000 [00:04<00:23, 358.84it/s] 15%|█▍        | 1456/10000 [00:04<00:30, 280.89it/s] 15%|█▍        | 1488/10000 [00:04<00:32, 265.52it/s] 15%|█▌        | 1517/10000 [00:04<00:36, 231.49it/s] 15%|█▌        | 1543/10000 [00:05<00:39, 215.36it/s] 16%|█▌        | 1566/10000 [00:05<00:41, 201.31it/s] 16%|█▌        | 1587/10000 [00:05<00:42, 198.03it/s] 16%|█▋        | 1625/10000 [00:05<00:34, 241.27it/s] 17%|█▋        | 1682/10000 [00:05<00:26, 318.88it/s] 17%|█▋        | 1737/10000 [00:05<00:22, 372.90it/s] 18%|█▊        | 1795/10000 [00:05<00:19, 424.66it/s] 19%|█▊        | 1851/10000 [00:05<00:17, 461.61it/s] 19%|█▉        | 1927/10000 [00:05<00:14, 538.36it/s] 20%|█▉        | 1992/10000 [00:06<00:14, 570.05it/s] 21%|██        | 2051/10000 [00:06<00:17, 459.92it/s] 21%|██        | 2117/10000 [00:06<00:15, 498.12it/s] 22%|██▏       | 2171/10000 [00:06<00:17, 449.94it/s] 22%|██▏       | 2219/10000 [00:06<00:18, 409.63it/s] 23%|██▎       | 2263/10000 [00:06<00:20, 369.12it/s] 23%|██▎       | 2302/10000 [00:06<00:23, 328.59it/s] 23%|██▎       | 2337/10000 [00:07<00:27, 277.78it/s] 24%|██▎       | 2367/10000 [00:07<00:27, 280.37it/s] 24%|██▍       | 2397/10000 [00:07<00:28, 270.25it/s] 25%|██▍       | 2452/10000 [00:07<00:22, 328.28it/s] 25%|██▌       | 2516/10000 [00:07<00:18, 405.81it/s] 26%|██▌       | 2560/10000 [00:07<00:18, 405.98it/s] 26%|██▌       | 2603/10000 [00:07<00:22, 326.01it/s] 26%|██▋       | 2640/10000 [00:08<00:25, 288.84it/s] 27%|██▋       | 2672/10000 [00:08<00:29, 246.41it/s] 27%|██▋       | 2700/10000 [00:08<00:30, 241.26it/s] 27%|██▋       | 2726/10000 [00:08<00:33, 215.79it/s] 27%|██▋       | 2749/10000 [00:08<00:34, 211.46it/s] 28%|██▊       | 2772/10000 [00:08<00:37, 191.33it/s] 28%|██▊       | 2794/10000 [00:08<00:37, 193.12it/s] 28%|██▊       | 2821/10000 [00:09<00:34, 207.60it/s] 29%|██▊       | 2861/10000 [00:09<00:27, 256.02it/s] 29%|██▉       | 2915/10000 [00:09<00:21, 323.04it/s] 30%|██▉       | 2963/10000 [00:09<00:19, 365.24it/s] 30%|███       | 3007/10000 [00:09<00:18, 381.40it/s] 30%|███       | 3047/10000 [00:09<00:20, 344.53it/s] 31%|███       | 3083/10000 [00:09<00:23, 291.90it/s] 31%|███       | 3115/10000 [00:09<00:25, 274.73it/s] 32%|███▏      | 3151/10000 [00:09<00:23, 294.75it/s] 32%|███▏      | 3183/10000 [00:10<00:24, 282.17it/s] 32%|███▏      | 3226/10000 [00:10<00:21, 308.97it/s] 33%|███▎      | 3276/10000 [00:10<00:18, 357.48it/s] 34%|███▎      | 3350/10000 [00:10<00:14, 459.90it/s] 34%|███▍      | 3399/10000 [00:10<00:15, 434.09it/s] 34%|███▍      | 3445/10000 [00:10<00:15, 411.05it/s] 35%|███▍      | 3488/10000 [00:10<00:15, 408.08it/s] 35%|███▌      | 3530/10000 [00:10<00:16, 389.93it/s] 36%|███▌      | 3570/10000 [00:11<00:19, 329.29it/s] 36%|███▌      | 3620/10000 [00:11<00:17, 369.93it/s] 37%|███▋      | 3682/10000 [00:11<00:14, 427.58it/s] 37%|███▋      | 3727/10000 [00:11<00:14, 429.49it/s] 38%|███▊      | 3807/10000 [00:11<00:11, 528.58it/s] 39%|███▊      | 3862/10000 [00:11<00:14, 411.48it/s] 39%|███▉      | 3909/10000 [00:11<00:17, 357.82it/s] 40%|███▉      | 3950/10000 [00:12<00:16, 365.40it/s] 40%|████      | 4004/10000 [00:12<00:14, 406.85it/s] 41%|████      | 4073/10000 [00:12<00:12, 470.59it/s] 42%|████▏     | 4152/10000 [00:12<00:10, 551.25it/s] 42%|████▏     | 4214/10000 [00:12<00:10, 569.56it/s] 43%|████▎     | 4280/10000 [00:12<00:09, 578.80it/s] 43%|████▎     | 4340/10000 [00:12<00:09, 573.62it/s] 44%|████▍     | 4399/10000 [00:12<00:10, 514.60it/s] 45%|████▍     | 4453/10000 [00:12<00:11, 472.80it/s] 45%|████▌     | 4502/10000 [00:13<00:16, 334.12it/s] 45%|████▌     | 4542/10000 [00:13<00:18, 302.18it/s] 46%|████▌     | 4577/10000 [00:13<00:17, 309.56it/s] 46%|████▌     | 4612/10000 [00:13<00:18, 288.90it/s] 46%|████▋     | 4644/10000 [00:13<00:19, 275.86it/s] 47%|████▋     | 4682/10000 [00:13<00:18, 293.99it/s] 47%|████▋     | 4713/10000 [00:13<00:19, 271.76it/s] 47%|████▋     | 4742/10000 [00:14<00:20, 255.30it/s] 48%|████▊     | 4779/10000 [00:14<00:18, 278.95it/s] 48%|████▊     | 4808/10000 [00:14<00:20, 250.77it/s] 48%|████▊     | 4838/10000 [00:14<00:20, 255.91it/s] 49%|████▊     | 4865/10000 [00:14<00:21, 236.62it/s] 49%|████▉     | 4891/10000 [00:14<00:21, 237.61it/s] 49%|████▉     | 4916/10000 [00:14<00:22, 224.12it/s] 49%|████▉     | 4943/10000 [00:14<00:21, 232.56it/s] 50%|████▉     | 4967/10000 [00:15<00:23, 217.10it/s] 50%|████▉     | 4990/10000 [00:15<00:24, 207.87it/s] 50%|█████     | 5032/10000 [00:15<00:18, 262.08it/s] 51%|█████     | 5083/10000 [00:15<00:15, 326.41it/s] 51%|█████▏    | 5143/10000 [00:15<00:12, 396.80it/s] 52%|█████▏    | 5202/10000 [00:15<00:10, 445.74it/s] 52%|█████▏    | 5248/10000 [00:15<00:14, 334.40it/s] 53%|█████▎    | 5287/10000 [00:16<00:17, 267.89it/s] 53%|█████▎    | 5319/10000 [00:16<00:18, 254.90it/s] 54%|█████▎    | 5350/10000 [00:16<00:17, 261.03it/s] 54%|█████▍    | 5379/10000 [00:16<00:18, 248.98it/s] 54%|█████▍    | 5412/10000 [00:16<00:17, 267.70it/s] 54%|█████▍    | 5443/10000 [00:16<00:16, 277.63it/s] 55%|█████▍    | 5476/10000 [00:16<00:15, 286.58it/s] 55%|█████▌    | 5537/10000 [00:16<00:12, 363.64it/s] 56%|█████▌    | 5576/10000 [00:16<00:12, 354.84it/s] 56%|█████▌    | 5615/10000 [00:17<00:12, 358.26it/s] 57%|█████▋    | 5676/10000 [00:17<00:10, 418.41it/s] 57%|█████▋    | 5732/10000 [00:17<00:09, 442.87it/s] 58%|█████▊    | 5792/10000 [00:17<00:08, 484.44it/s] 58%|█████▊    | 5841/10000 [00:17<00:11, 372.98it/s] 59%|█████▉    | 5883/10000 [00:17<00:11, 346.76it/s] 59%|█████▉    | 5921/10000 [00:17<00:12, 330.49it/s] 60%|█████▉    | 5960/10000 [00:18<00:12, 319.14it/s] 60%|█████▉    | 5994/10000 [00:18<00:12, 309.66it/s] 60%|██████    | 6045/10000 [00:18<00:11, 358.13it/s] 61%|██████    | 6086/10000 [00:18<00:10, 371.34it/s] 61%|██████▏   | 6138/10000 [00:18<00:09, 408.14it/s] 62%|██████▏   | 6199/10000 [00:18<00:08, 459.72it/s] 62%|██████▏   | 6247/10000 [00:18<00:10, 345.14it/s] 63%|██████▎   | 6287/10000 [00:18<00:12, 288.87it/s] 63%|██████▎   | 6321/10000 [00:19<00:12, 296.67it/s] 64%|██████▎   | 6355/10000 [00:19<00:14, 259.56it/s] 64%|██████▍   | 6388/10000 [00:19<00:13, 267.69it/s] 64%|██████▍   | 6418/10000 [00:19<00:14, 251.29it/s] 65%|██████▍   | 6460/10000 [00:19<00:12, 289.60it/s] 65%|██████▍   | 6492/10000 [00:19<00:12, 284.16it/s] 65%|██████▌   | 6522/10000 [00:19<00:13, 256.07it/s] 66%|██████▌   | 6555/10000 [00:20<00:12, 269.06it/s] 66%|██████▌   | 6584/10000 [00:20<00:13, 256.76it/s] 66%|██████▌   | 6617/10000 [00:20<00:12, 260.66it/s] 66%|██████▋   | 6647/10000 [00:20<00:13, 246.93it/s] 67%|██████▋   | 6674/10000 [00:20<00:13, 250.57it/s] 67%|██████▋   | 6700/10000 [00:20<00:13, 251.06it/s] 68%|██████▊   | 6750/10000 [00:20<00:10, 315.90it/s] 68%|██████▊   | 6783/10000 [00:20<00:10, 298.87it/s] 68%|██████▊   | 6842/10000 [00:20<00:08, 372.65it/s] 69%|██████▉   | 6881/10000 [00:21<00:08, 362.13it/s] 69%|██████▉   | 6948/10000 [00:21<00:06, 438.53it/s] 70%|██████▉   | 6993/10000 [00:21<00:07, 408.15it/s] 70%|███████   | 7048/10000 [00:21<00:06, 440.49it/s] 71%|███████   | 7093/10000 [00:21<00:06, 417.67it/s] 71%|███████▏  | 7143/10000 [00:21<00:06, 433.71it/s] 72%|███████▏  | 7187/10000 [00:21<00:06, 421.61it/s] 72%|███████▏  | 7232/10000 [00:21<00:06, 426.84it/s] 73%|███████▎  | 7282/10000 [00:21<00:06, 436.02it/s] 73%|███████▎  | 7337/10000 [00:22<00:05, 455.86it/s] 74%|███████▍  | 7405/10000 [00:22<00:05, 507.75it/s] 75%|███████▍  | 7460/10000 [00:22<00:04, 519.67it/s] 75%|███████▌  | 7513/10000 [00:22<00:04, 499.42it/s] 76%|███████▌  | 7579/10000 [00:22<00:04, 538.53it/s] 76%|███████▋  | 7634/10000 [00:22<00:05, 398.74it/s] 77%|███████▋  | 7680/10000 [00:22<00:05, 409.09it/s] 77%|███████▋  | 7725/10000 [00:22<00:06, 371.67it/s] 78%|███████▊  | 7766/10000 [00:23<00:06, 354.56it/s] 78%|███████▊  | 7804/10000 [00:23<00:06, 357.50it/s] 79%|███████▊  | 7863/10000 [00:23<00:05, 415.56it/s] 79%|███████▉  | 7923/10000 [00:23<00:04, 456.71it/s] 80%|███████▉  | 7976/10000 [00:23<00:04, 472.21it/s] 81%|████████  | 8069/10000 [00:23<00:03, 591.40it/s] 81%|████████▏ | 8130/10000 [00:23<00:03, 563.96it/s] 82%|████████▏ | 8188/10000 [00:23<00:03, 491.75it/s] 82%|████████▏ | 8240/10000 [00:24<00:04, 398.33it/s] 83%|████████▎ | 8284/10000 [00:24<00:04, 387.06it/s] 83%|████████▎ | 8326/10000 [00:24<00:04, 378.53it/s] 84%|████████▎ | 8366/10000 [00:24<00:04, 337.25it/s] 84%|████████▍ | 8402/10000 [00:24<00:05, 317.55it/s] 84%|████████▍ | 8435/10000 [00:24<00:04, 314.55it/s] 85%|████████▍ | 8468/10000 [00:24<00:04, 308.36it/s] 85%|████████▌ | 8504/10000 [00:24<00:04, 313.81it/s] 85%|████████▌ | 8536/10000 [00:25<00:04, 307.48it/s] 86%|████████▌ | 8578/10000 [00:25<00:04, 332.08it/s] 86%|████████▋ | 8629/10000 [00:25<00:03, 379.48it/s] 87%|████████▋ | 8709/10000 [00:25<00:02, 492.98it/s] 88%|████████▊ | 8769/10000 [00:25<00:02, 518.19it/s] 88%|████████▊ | 8831/10000 [00:25<00:02, 538.27it/s] 89%|████████▉ | 8909/10000 [00:25<00:01, 596.50it/s] 90%|████████▉ | 8983/10000 [00:25<00:01, 633.81it/s] 90%|█████████ | 9047/10000 [00:25<00:01, 593.79it/s] 91%|█████████ | 9108/10000 [00:26<00:01, 592.50it/s] 92%|█████████▏| 9168/10000 [00:26<00:01, 589.34it/s] 92%|█████████▏| 9228/10000 [00:26<00:01, 469.40it/s] 93%|█████████▎| 9279/10000 [00:26<00:01, 374.73it/s] 93%|█████████▎| 9325/10000 [00:26<00:01, 390.46it/s] 94%|█████████▎| 9369/10000 [00:26<00:01, 333.76it/s] 94%|█████████▍| 9407/10000 [00:26<00:01, 332.09it/s] 94%|█████████▍| 9443/10000 [00:27<00:01, 299.90it/s] 95%|█████████▍| 9476/10000 [00:27<00:01, 293.66it/s] 95%|█████████▌| 9507/10000 [00:27<00:01, 281.24it/s] 96%|█████████▌| 9557/10000 [00:27<00:01, 329.34it/s] 96%|█████████▌| 9592/10000 [00:27<00:01, 319.12it/s] 96%|█████████▋| 9625/10000 [00:27<00:01, 316.26it/s] 97%|█████████▋| 9658/10000 [00:27<00:01, 313.26it/s] 97%|█████████▋| 9693/10000 [00:27<00:00, 320.35it/s] 97%|█████████▋| 9737/10000 [00:27<00:00, 352.98it/s] 98%|█████████▊| 9773/10000 [00:28<00:00, 329.68it/s] 98%|█████████▊| 9807/10000 [00:28<00:00, 314.15it/s] 99%|█████████▉| 9896/10000 [00:28<00:00, 465.51it/s]100%|█████████▉| 9953/10000 [00:28<00:00, 477.17it/s]100%|██████████| 10000/10000 [00:28<00:00, 350.96it/s]
test_neglected_p99 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p99
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p99.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:01<00:39,  1.02s/it]evaluating model with Holmes:  12%|█▎        | 5/40 [00:01<00:06,  5.79it/s]evaluating model with Holmes:  25%|██▌       | 10/40 [00:01<00:02, 12.32it/s]evaluating model with Holmes:  38%|███▊      | 15/40 [00:01<00:01, 18.77it/s]evaluating model with Holmes:  50%|█████     | 20/40 [00:01<00:00, 24.73it/s]evaluating model with Holmes:  62%|██████▎   | 25/40 [00:01<00:00, 29.96it/s]evaluating model with Holmes:  75%|███████▌  | 30/40 [00:01<00:00, 34.40it/s]evaluating model with Holmes:  88%|████████▊ | 35/40 [00:01<00:00, 37.97it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 40.44it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.27it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p99_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p99_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p99_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p99_Holmes_probs.npy
{'Accuracy': 0.0208, 'Precision': 0.0233, 'Recall': 0.0204, 'F1-score': 0.0182}
starting gen taf script for test_neglected_p100
  0%|          | 0/10000 [00:00<?, ?it/s]  1%|          | 66/10000 [00:00<00:16, 594.30it/s]  1%|▏         | 126/10000 [00:00<00:25, 383.32it/s]  2%|▏         | 169/10000 [00:00<00:33, 295.60it/s]  2%|▏         | 202/10000 [00:00<00:36, 269.40it/s]  2%|▏         | 237/10000 [00:00<00:34, 284.40it/s]  3%|▎         | 267/10000 [00:00<00:33, 288.07it/s]  3%|▎         | 297/10000 [00:01<00:36, 267.44it/s]  3%|▎         | 327/10000 [00:01<00:36, 266.49it/s]  4%|▎         | 355/10000 [00:01<00:37, 253.86it/s]  4%|▍         | 385/10000 [00:01<00:36, 264.41it/s]  4%|▍         | 416/10000 [00:01<00:34, 275.82it/s]  5%|▍         | 455/10000 [00:01<00:31, 307.04it/s]  5%|▍         | 499/10000 [00:01<00:27, 343.43it/s]  5%|▌         | 534/10000 [00:01<00:27, 340.97it/s]  6%|▌         | 569/10000 [00:01<00:30, 306.13it/s]  6%|▌         | 606/10000 [00:02<00:29, 317.27it/s]  6%|▋         | 639/10000 [00:02<00:29, 316.07it/s]  7%|▋         | 676/10000 [00:02<00:28, 324.29it/s]  7%|▋         | 713/10000 [00:02<00:27, 332.65it/s]  8%|▊         | 763/10000 [00:02<00:25, 360.99it/s]  8%|▊         | 811/10000 [00:02<00:23, 392.86it/s]  9%|▊         | 851/10000 [00:02<00:23, 391.85it/s]  9%|▉         | 891/10000 [00:02<00:23, 385.20it/s]  9%|▉         | 930/10000 [00:02<00:24, 376.22it/s] 10%|▉         | 968/10000 [00:03<00:27, 328.70it/s] 10%|█         | 1002/10000 [00:03<00:29, 309.39it/s] 10%|█         | 1037/10000 [00:03<00:28, 316.18it/s] 11%|█         | 1070/10000 [00:03<00:30, 292.94it/s] 11%|█         | 1109/10000 [00:03<00:30, 294.29it/s] 12%|█▏        | 1150/10000 [00:03<00:27, 322.67it/s] 12%|█▏        | 1184/10000 [00:03<00:31, 278.20it/s] 12%|█▏        | 1245/10000 [00:03<00:24, 354.50it/s] 13%|█▎        | 1283/10000 [00:03<00:24, 352.17it/s] 13%|█▎        | 1320/10000 [00:04<00:25, 342.10it/s] 14%|█▎        | 1366/10000 [00:04<00:23, 372.64it/s] 14%|█▍        | 1415/10000 [00:04<00:21, 399.26it/s] 15%|█▍        | 1456/10000 [00:04<00:29, 291.73it/s] 15%|█▍        | 1490/10000 [00:04<00:33, 257.86it/s] 15%|█▌        | 1520/10000 [00:04<00:37, 224.93it/s] 15%|█▌        | 1546/10000 [00:05<00:42, 200.07it/s] 16%|█▌        | 1572/10000 [00:05<00:40, 208.76it/s] 16%|█▌        | 1599/10000 [00:05<00:39, 210.09it/s] 17%|█▋        | 1663/10000 [00:05<00:27, 302.82it/s] 17%|█▋        | 1727/10000 [00:05<00:21, 384.43it/s] 18%|█▊        | 1781/10000 [00:05<00:19, 421.52it/s] 18%|█▊        | 1845/10000 [00:05<00:17, 470.78it/s] 19%|█▉        | 1939/10000 [00:05<00:13, 598.20it/s] 20%|██        | 2015/10000 [00:05<00:12, 639.91it/s] 21%|██        | 2082/10000 [00:06<00:16, 479.94it/s] 21%|██▏       | 2138/10000 [00:06<00:16, 476.87it/s] 22%|██▏       | 2191/10000 [00:06<00:16, 468.19it/s] 22%|██▏       | 2242/10000 [00:06<00:19, 398.00it/s] 23%|██▎       | 2286/10000 [00:06<00:22, 349.04it/s] 23%|██▎       | 2325/10000 [00:06<00:23, 323.03it/s] 24%|██▎       | 2360/10000 [00:07<00:27, 274.79it/s] 24%|██▍       | 2390/10000 [00:07<00:28, 264.00it/s] 24%|██▍       | 2425/10000 [00:07<00:27, 278.53it/s] 25%|██▍       | 2475/10000 [00:07<00:22, 328.89it/s] 25%|██▌       | 2539/10000 [00:07<00:18, 405.22it/s] 26%|██▌       | 2583/10000 [00:07<00:18, 410.24it/s] 26%|██▋       | 2627/10000 [00:07<00:20, 351.62it/s] 27%|██▋       | 2665/10000 [00:08<00:28, 258.27it/s] 27%|██▋       | 2697/10000 [00:08<00:34, 213.85it/s] 27%|██▋       | 2723/10000 [00:08<00:34, 208.06it/s] 27%|██▋       | 2747/10000 [00:08<00:33, 214.11it/s] 28%|██▊       | 2771/10000 [00:08<00:34, 209.07it/s] 28%|██▊       | 2794/10000 [00:08<00:38, 188.70it/s] 28%|██▊       | 2836/10000 [00:08<00:29, 240.39it/s] 29%|██▉       | 2908/10000 [00:09<00:20, 347.01it/s] 30%|██▉       | 2953/10000 [00:09<00:19, 366.99it/s] 30%|██▉       | 2993/10000 [00:09<00:19, 359.73it/s] 30%|███       | 3032/10000 [00:09<00:19, 349.61it/s] 31%|███       | 3069/10000 [00:09<00:21, 319.46it/s] 31%|███       | 3103/10000 [00:09<00:23, 299.33it/s] 31%|███▏      | 3136/10000 [00:09<00:22, 304.79it/s] 32%|███▏      | 3168/10000 [00:09<00:22, 307.52it/s] 32%|███▏      | 3200/10000 [00:09<00:23, 295.29it/s] 33%|███▎      | 3268/10000 [00:10<00:16, 396.96it/s] 33%|███▎      | 3328/10000 [00:10<00:14, 449.79it/s] 34%|███▍      | 3419/10000 [00:10<00:11, 566.59it/s] 35%|███▍      | 3477/10000 [00:10<00:12, 531.29it/s] 35%|███▌      | 3532/10000 [00:10<00:12, 506.24it/s] 36%|███▌      | 3584/10000 [00:10<00:13, 468.19it/s] 36%|███▋      | 3632/10000 [00:10<00:14, 444.75it/s] 37%|███▋      | 3694/10000 [00:10<00:12, 485.34it/s] 37%|███▋      | 3744/10000 [00:11<00:13, 452.85it/s] 38%|███▊      | 3791/10000 [00:11<00:13, 450.50it/s] 38%|███▊      | 3837/10000 [00:11<00:14, 437.17it/s] 39%|███▉      | 3883/10000 [00:11<00:13, 437.51it/s] 39%|███▉      | 3928/10000 [00:11<00:15, 396.43it/s] 40%|███▉      | 3977/10000 [00:11<00:14, 418.19it/s] 40%|████      | 4020/10000 [00:11<00:14, 418.26it/s] 41%|████      | 4063/10000 [00:11<00:14, 396.34it/s] 42%|████▏     | 4157/10000 [00:11<00:10, 543.26it/s] 42%|████▏     | 4214/10000 [00:12<00:11, 510.79it/s] 43%|████▎     | 4283/10000 [00:12<00:10, 553.37it/s] 43%|████▎     | 4340/10000 [00:12<00:10, 543.84it/s] 44%|████▍     | 4396/10000 [00:12<00:11, 493.58it/s] 44%|████▍     | 4447/10000 [00:12<00:13, 415.37it/s] 45%|████▍     | 4492/10000 [00:12<00:14, 378.66it/s] 45%|████▌     | 4533/10000 [00:12<00:17, 319.63it/s] 46%|████▌     | 4568/10000 [00:13<00:18, 295.93it/s] 46%|████▌     | 4600/10000 [00:13<00:21, 253.76it/s] 46%|████▋     | 4636/10000 [00:13<00:19, 275.05it/s] 47%|████▋     | 4666/10000 [00:13<00:19, 268.39it/s] 47%|████▋     | 4695/10000 [00:13<00:20, 263.34it/s] 47%|████▋     | 4727/10000 [00:13<00:19, 264.35it/s] 48%|████▊     | 4759/10000 [00:13<00:19, 270.93it/s] 48%|████▊     | 4787/10000 [00:13<00:22, 234.89it/s] 48%|████▊     | 4814/10000 [00:14<00:22, 234.83it/s] 48%|████▊     | 4842/10000 [00:14<00:21, 241.28it/s] 49%|████▉     | 4879/10000 [00:14<00:19, 268.37it/s] 49%|████▉     | 4907/10000 [00:14<00:19, 258.37it/s] 49%|████▉     | 4934/10000 [00:14<00:21, 236.22it/s] 50%|████▉     | 4959/10000 [00:14<00:22, 222.57it/s] 50%|████▉     | 4982/10000 [00:14<00:23, 210.93it/s] 50%|█████     | 5027/10000 [00:14<00:18, 271.12it/s] 51%|█████     | 5080/10000 [00:15<00:15, 319.90it/s] 51%|█████     | 5122/10000 [00:15<00:14, 345.31it/s] 52%|█████▏    | 5179/10000 [00:15<00:12, 396.21it/s] 52%|█████▏    | 5220/10000 [00:15<00:13, 363.41it/s] 53%|█████▎    | 5258/10000 [00:15<00:14, 320.09it/s] 53%|█████▎    | 5292/10000 [00:15<00:17, 269.96it/s] 53%|█████▎    | 5321/10000 [00:15<00:18, 247.59it/s] 53%|█████▎    | 5348/10000 [00:16<00:18, 247.07it/s] 54%|█████▎    | 5374/10000 [00:16<00:18, 247.96it/s] 54%|█████▍    | 5400/10000 [00:16<00:21, 216.64it/s] 54%|█████▍    | 5441/10000 [00:16<00:17, 259.49it/s] 55%|█████▍    | 5485/10000 [00:16<00:14, 302.51it/s] 55%|█████▌    | 5535/10000 [00:16<00:12, 351.57it/s] 56%|█████▌    | 5591/10000 [00:16<00:10, 403.49it/s] 56%|█████▋    | 5638/10000 [00:16<00:10, 421.40it/s] 57%|█████▋    | 5697/10000 [00:16<00:09, 466.39it/s] 58%|█████▊    | 5755/10000 [00:16<00:08, 491.95it/s] 58%|█████▊    | 5806/10000 [00:17<00:09, 424.55it/s] 59%|█████▊    | 5851/10000 [00:17<00:10, 392.21it/s] 59%|█████▉    | 5892/10000 [00:17<00:11, 355.10it/s] 59%|█████▉    | 5930/10000 [00:17<00:11, 350.65it/s] 60%|█████▉    | 5967/10000 [00:17<00:12, 324.11it/s] 60%|██████    | 6001/10000 [00:17<00:12, 312.91it/s] 61%|██████    | 6051/10000 [00:17<00:10, 360.08it/s] 61%|██████    | 6105/10000 [00:18<00:09, 407.41it/s] 62%|██████▏   | 6158/10000 [00:18<00:08, 436.16it/s] 62%|██████▏   | 6207/10000 [00:18<00:08, 449.92it/s] 63%|██████▎   | 6253/10000 [00:18<00:09, 386.45it/s] 63%|██████▎   | 6294/10000 [00:18<00:11, 319.20it/s] 63%|██████▎   | 6330/10000 [00:18<00:12, 289.32it/s] 64%|██████▎   | 6362/10000 [00:18<00:15, 234.54it/s] 64%|██████▍   | 6397/10000 [00:19<00:14, 257.36it/s] 64%|██████▍   | 6426/10000 [00:19<00:15, 236.90it/s] 65%|██████▍   | 6453/10000 [00:19<00:14, 240.70it/s] 65%|██████▍   | 6484/10000 [00:19<00:13, 251.91it/s] 65%|██████▌   | 6511/10000 [00:19<00:14, 236.18it/s] 65%|██████▌   | 6546/10000 [00:19<00:13, 261.36it/s] 66%|██████▌   | 6574/10000 [00:19<00:13, 256.20it/s] 66%|██████▌   | 6612/10000 [00:19<00:12, 279.81it/s] 66%|██████▋   | 6646/10000 [00:19<00:11, 292.89it/s] 67%|██████▋   | 6676/10000 [00:20<00:12, 276.54it/s] 67%|██████▋   | 6712/10000 [00:20<00:11, 293.36it/s] 67%|██████▋   | 6744/10000 [00:20<00:11, 293.32it/s] 68%|██████▊   | 6774/10000 [00:20<00:11, 269.74it/s] 68%|██████▊   | 6818/10000 [00:20<00:10, 312.73it/s] 69%|██████▉   | 6888/10000 [00:20<00:07, 413.62it/s] 69%|██████▉   | 6931/10000 [00:20<00:07, 398.24it/s] 70%|██████▉   | 6980/10000 [00:20<00:07, 422.92it/s] 70%|███████   | 7032/10000 [00:20<00:06, 435.15it/s] 71%|███████   | 7083/10000 [00:21<00:06, 447.31it/s] 71%|███████▏  | 7129/10000 [00:21<00:06, 430.16it/s] 72%|███████▏  | 7173/10000 [00:21<00:07, 371.41it/s] 73%|███████▎  | 7268/10000 [00:21<00:05, 510.70it/s] 73%|███████▎  | 7322/10000 [00:21<00:05, 509.02it/s] 74%|███████▍  | 7375/10000 [00:21<00:05, 495.05it/s] 74%|███████▍  | 7426/10000 [00:21<00:05, 480.77it/s] 75%|███████▍  | 7494/10000 [00:21<00:04, 534.77it/s] 75%|███████▌  | 7549/10000 [00:22<00:05, 485.11it/s] 76%|███████▌  | 7604/10000 [00:22<00:04, 494.68it/s] 77%|███████▋  | 7655/10000 [00:22<00:05, 417.18it/s] 77%|███████▋  | 7700/10000 [00:22<00:05, 395.69it/s] 77%|███████▋  | 7742/10000 [00:22<00:05, 376.43it/s] 78%|███████▊  | 7781/10000 [00:22<00:06, 360.95it/s] 78%|███████▊  | 7838/10000 [00:22<00:05, 411.84it/s] 79%|███████▉  | 7888/10000 [00:22<00:04, 428.99it/s] 80%|███████▉  | 7953/10000 [00:23<00:04, 480.68it/s] 80%|████████  | 8004/10000 [00:23<00:04, 484.13it/s] 81%|████████  | 8069/10000 [00:23<00:03, 529.59it/s] 81%|████████  | 8123/10000 [00:23<00:03, 496.07it/s] 82%|████████▏ | 8177/10000 [00:23<00:03, 502.29it/s] 82%|████████▏ | 8228/10000 [00:23<00:03, 444.55it/s] 83%|████████▎ | 8274/10000 [00:23<00:04, 392.18it/s] 83%|████████▎ | 8316/10000 [00:23<00:04, 337.13it/s] 84%|████████▎ | 8352/10000 [00:24<00:04, 335.13it/s] 84%|████████▍ | 8388/10000 [00:24<00:05, 322.06it/s] 84%|████████▍ | 8422/10000 [00:24<00:05, 309.93it/s] 85%|████████▍ | 8457/10000 [00:24<00:04, 319.85it/s] 85%|████████▍ | 8490/10000 [00:24<00:04, 319.90it/s] 85%|████████▌ | 8523/10000 [00:24<00:04, 300.81it/s] 86%|████████▌ | 8554/10000 [00:24<00:04, 299.57it/s] 86%|████████▌ | 8585/10000 [00:24<00:04, 294.13it/s] 87%|████████▋ | 8659/10000 [00:24<00:03, 414.64it/s] 87%|████████▋ | 8712/10000 [00:25<00:02, 443.48it/s] 88%|████████▊ | 8781/10000 [00:25<00:02, 513.41it/s] 88%|████████▊ | 8850/10000 [00:25<00:02, 560.12it/s] 89%|████████▉ | 8922/10000 [00:25<00:01, 606.35it/s] 90%|████████▉ | 8984/10000 [00:25<00:01, 592.37it/s] 91%|█████████ | 9060/10000 [00:25<00:01, 637.12it/s] 91%|█████████▏| 9125/10000 [00:25<00:01, 561.37it/s] 92%|█████████▏| 9184/10000 [00:25<00:01, 524.63it/s] 92%|█████████▏| 9239/10000 [00:26<00:01, 443.24it/s] 93%|█████████▎| 9287/10000 [00:26<00:01, 393.88it/s] 93%|█████████▎| 9329/10000 [00:26<00:01, 369.00it/s] 94%|█████████▎| 9368/10000 [00:26<00:02, 299.20it/s] 94%|█████████▍| 9401/10000 [00:26<00:02, 276.43it/s] 94%|█████████▍| 9440/10000 [00:26<00:01, 295.82it/s] 95%|█████████▍| 9486/10000 [00:26<00:01, 324.01it/s] 95%|█████████▌| 9521/10000 [00:27<00:01, 296.62it/s] 96%|█████████▌| 9553/10000 [00:27<00:01, 274.79it/s] 96%|█████████▌| 9593/10000 [00:27<00:01, 292.47it/s] 96%|█████████▋| 9627/10000 [00:27<00:01, 303.26it/s] 97%|█████████▋| 9677/10000 [00:27<00:00, 350.40it/s] 97%|█████████▋| 9714/10000 [00:27<00:00, 319.82it/s] 97%|█████████▋| 9749/10000 [00:27<00:00, 326.44it/s] 98%|█████████▊| 9783/10000 [00:27<00:00, 316.90it/s] 98%|█████████▊| 9844/10000 [00:27<00:00, 391.78it/s] 99%|█████████▉| 9894/10000 [00:28<00:00, 416.30it/s] 99%|█████████▉| 9937/10000 [00:28<00:00, 403.97it/s]100%|██████████| 10000/10000 [00:28<00:00, 354.04it/s]
test_neglected_p100 process done: X = (10000, 3, 2, 2000), y = (10000,)

Size Analysis:
--------------
Total raw size: 915.60 MB
Estimated compressed size: 457.80 MB
Overhead: 1.50 KB

Size per array:
X: 915.53 MB
y: 78.12 KB
finished gen taf script for test_neglected_p100
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/taf_test_neglected_p100.npz
Valid: X=torch.Size([13500, 3, 2, 2000]), y=torch.Size([13500])
Test: X=torch.Size([10000, 3, 2, 2000]), y=torch.Size([10000])
num_classes: 45
evaluating model with Holmes:   0%|          | 0/40 [00:00<?, ?it/s]evaluating model with Holmes:   2%|▎         | 1/40 [00:00<00:38,  1.01it/s]evaluating model with Holmes:  15%|█▌        | 6/40 [00:01<00:04,  7.04it/s]evaluating model with Holmes:  28%|██▊       | 11/40 [00:01<00:02, 13.32it/s]evaluating model with Holmes:  40%|████      | 16/40 [00:01<00:01, 19.58it/s]evaluating model with Holmes:  52%|█████▎    | 21/40 [00:01<00:00, 25.43it/s]evaluating model with Holmes:  65%|██████▌   | 26/40 [00:01<00:00, 30.40it/s]evaluating model with Holmes:  78%|███████▊  | 31/40 [00:01<00:00, 34.60it/s]evaluating model with Holmes:  90%|█████████ | 36/40 [00:01<00:00, 37.98it/s]evaluating model with Holmes: 100%|██████████| 40/40 [00:01<00:00, 21.53it/s]
Saved predictions to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p100_Holmes_predictions.npy
Saved true labels to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p100_Holmes_true_labels.npy
Saved logits to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p100_Holmes_logits.npy
Saved proba to /home/kka151/scratch/holmes/datasets/Tik_Tok_removed_50_43/holmes_predictions/taf_test_neglected_p100_Holmes_probs.npy
{'Accuracy': 0.0211, 'Precision': 0.0237, 'Recall': 0.0208, 'F1-score': 0.0185}
