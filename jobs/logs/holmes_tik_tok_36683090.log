  0%|          | 0/76950 [00:00<?, ?it/s] 12%|█▏        | 9189/76950 [00:00<00:00, 91874.97it/s] 24%|██▍       | 18377/76950 [00:00<00:00, 91854.28it/s] 36%|███▌      | 27563/76950 [00:00<00:00, 91804.97it/s] 48%|████▊     | 36757/76950 [00:00<00:00, 91853.54it/s] 60%|█████▉    | 45964/76950 [00:00<00:00, 91929.47it/s] 72%|███████▏  | 55176/76950 [00:00<00:00, 91990.54it/s] 84%|████████▎ | 64376/76950 [00:00<00:00, 91955.46it/s] 96%|█████████▌| 73582/76950 [00:00<00:00, 91984.22it/s]100%|██████████| 76950/76950 [00:00<00:00, 91855.14it/s]
Shape of temporal_X: (76950, 2, 1000)
/home/kka151/scratch/holmes/datasets/Tik_Tok/temporal_valid.npz has been generated.
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Train: X=torch.Size([76950, 1, 2, 1000]), y=torch.Size([76950])
Valid: X=torch.Size([8550, 1, 2, 1000]), y=torch.Size([8550])
num_classes: 95
No pre-trained model
epoch: 0
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]going through batches for holmes training:   0%|          | 1/384 [00:02<14:07,  2.21s/it]going through batches for holmes training:   2%|▏         | 6/384 [00:02<01:49,  3.44it/s]going through batches for holmes training:   3%|▎         | 11/384 [00:02<00:52,  7.14it/s]going through batches for holmes training:   4%|▍         | 17/384 [00:02<00:29, 12.41it/s]going through batches for holmes training:   6%|▌         | 23/384 [00:02<00:19, 18.38it/s]going through batches for holmes training:   8%|▊         | 29/384 [00:02<00:14, 24.63it/s]going through batches for holmes training:   9%|▉         | 35/384 [00:02<00:11, 30.79it/s]going through batches for holmes training:  11%|█         | 41/384 [00:02<00:09, 36.52it/s]going through batches for holmes training:  12%|█▏        | 47/384 [00:03<00:08, 41.56it/s]going through batches for holmes training:  14%|█▍        | 53/384 [00:03<00:07, 45.77it/s]going through batches for holmes training:  15%|█▌        | 59/384 [00:03<00:06, 49.10it/s]going through batches for holmes training:  17%|█▋        | 65/384 [00:03<00:06, 51.67it/s]going through batches for holmes training:  18%|█▊        | 71/384 [00:03<00:05, 53.64it/s]going through batches for holmes training:  20%|██        | 77/384 [00:03<00:05, 55.05it/s]going through batches for holmes training:  22%|██▏       | 83/384 [00:03<00:05, 55.95it/s]going through batches for holmes training:  23%|██▎       | 89/384 [00:03<00:05, 56.70it/s]going through batches for holmes training:  25%|██▍       | 95/384 [00:03<00:05, 57.23it/s]going through batches for holmes training:  26%|██▋       | 101/384 [00:03<00:04, 57.68it/s]going through batches for holmes training:  28%|██▊       | 107/384 [00:04<00:04, 57.99it/s]going through batches for holmes training:  29%|██▉       | 113/384 [00:04<00:04, 58.08it/s]going through batches for holmes training:  31%|███       | 119/384 [00:04<00:04, 58.31it/s]going through batches for holmes training:  33%|███▎      | 125/384 [00:04<00:04, 58.29it/s]going through batches for holmes training:  34%|███▍      | 131/384 [00:04<00:04, 58.41it/s]going through batches for holmes training:  36%|███▌      | 137/384 [00:04<00:04, 58.57it/s]going through batches for holmes training:  37%|███▋      | 143/384 [00:04<00:04, 58.65it/s]going through batches for holmes training:  39%|███▉      | 149/384 [00:04<00:04, 58.65it/s]going through batches for holmes training:  40%|████      | 155/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  42%|████▏     | 161/384 [00:04<00:03, 58.88it/s]going through batches for holmes training:  43%|████▎     | 167/384 [00:05<00:03, 58.87it/s]going through batches for holmes training:  45%|████▌     | 173/384 [00:05<00:03, 58.84it/s]going through batches for holmes training:  47%|████▋     | 179/384 [00:05<00:03, 58.83it/s]going through batches for holmes training:  48%|████▊     | 185/384 [00:05<00:03, 58.84it/s]going through batches for holmes training:  50%|████▉     | 191/384 [00:05<00:03, 58.86it/s]going through batches for holmes training:  51%|█████▏    | 197/384 [00:05<00:03, 58.86it/s]going through batches for holmes training:  53%|█████▎    | 203/384 [00:05<00:03, 58.87it/s]going through batches for holmes training:  54%|█████▍    | 209/384 [00:05<00:02, 58.90it/s]going through batches for holmes training:  56%|█████▌    | 215/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  58%|█████▊    | 221/384 [00:06<00:02, 58.98it/s]going through batches for holmes training:  59%|█████▉    | 227/384 [00:06<00:02, 59.03it/s]going through batches for holmes training:  61%|██████    | 233/384 [00:06<00:02, 58.98it/s]going through batches for holmes training:  62%|██████▏   | 239/384 [00:06<00:02, 58.92it/s]going through batches for holmes training:  64%|██████▍   | 245/384 [00:06<00:02, 58.99it/s]going through batches for holmes training:  65%|██████▌   | 251/384 [00:06<00:02, 58.93it/s]going through batches for holmes training:  67%|██████▋   | 257/384 [00:06<00:02, 58.90it/s]going through batches for holmes training:  68%|██████▊   | 263/384 [00:06<00:02, 58.91it/s]going through batches for holmes training:  70%|███████   | 269/384 [00:06<00:01, 58.88it/s]going through batches for holmes training:  72%|███████▏  | 275/384 [00:06<00:01, 58.94it/s]going through batches for holmes training:  73%|███████▎  | 281/384 [00:07<00:01, 58.94it/s]going through batches for holmes training:  75%|███████▍  | 287/384 [00:07<00:01, 58.92it/s]going through batches for holmes training:  76%|███████▋  | 293/384 [00:07<00:01, 58.96it/s]going through batches for holmes training:  78%|███████▊  | 299/384 [00:07<00:01, 58.90it/s]going through batches for holmes training:  79%|███████▉  | 305/384 [00:07<00:01, 58.83it/s]going through batches for holmes training:  81%|████████  | 311/384 [00:07<00:01, 58.88it/s]going through batches for holmes training:  83%|████████▎ | 317/384 [00:07<00:01, 58.86it/s]going through batches for holmes training:  84%|████████▍ | 323/384 [00:07<00:01, 58.94it/s]going through batches for holmes training:  86%|████████▌ | 329/384 [00:07<00:00, 58.98it/s]going through batches for holmes training:  87%|████████▋ | 335/384 [00:07<00:00, 58.96it/s]going through batches for holmes training:  89%|████████▉ | 341/384 [00:08<00:00, 58.93it/s]going through batches for holmes training:  90%|█████████ | 347/384 [00:08<00:00, 58.92it/s]going through batches for holmes training:  92%|█████████▏| 353/384 [00:08<00:00, 58.98it/s]going through batches for holmes training:  93%|█████████▎| 359/384 [00:08<00:00, 59.00it/s]going through batches for holmes training:  95%|█████████▌| 365/384 [00:08<00:00, 58.53it/s]going through batches for holmes training:  97%|█████████▋| 371/384 [00:08<00:00, 58.76it/s]going through batches for holmes training:  98%|█████████▊| 377/384 [00:08<00:00, 58.88it/s]going through batches for holmes training: 100%|█████████▉| 383/384 [00:08<00:00, 58.98it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:08<00:00, 43.60it/s]
epoch 0: train_loss = 4.556
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
0: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 1
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:50,  1.23s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:54,  6.95it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.73it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 21.89it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.56it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.77it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.22it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.72it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.28it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.03it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.11it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.71it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.79it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.58it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.19it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.51it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.77it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.04it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.26it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.44it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.46it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.22it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.38it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.43it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.57it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.64it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.80it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.79it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.79it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.75it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.76it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.74it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.79it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.72it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.44it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.53it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.62it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.66it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.75it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.44it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.28it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.17it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.10it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 57.94it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.16it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.37it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.47it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.50it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.59it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.23it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.50it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.69it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.19it/s]
epoch 1: train_loss = 4.555
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
1: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 2
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:49,  1.07s/it]going through batches for holmes training:   2%|▏         | 6/384 [00:01<00:57,  6.62it/s]going through batches for holmes training:   3%|▎         | 12/384 [00:01<00:26, 14.18it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:15, 22.98it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:11, 30.92it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:09, 36.66it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 41.64it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 45.82it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:01<00:06, 49.14it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.68it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.53it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.89it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.94it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.65it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.09it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.39it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.67it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 57.86it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:02<00:04, 57.96it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.02it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.02it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.07it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.20it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.25it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.35it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.43it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.49it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:03<00:03, 58.50it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:03<00:03, 58.42it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.29it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.35it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.33it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.35it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.40it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.46it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.43it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.48it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:04<00:02, 58.41it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.19it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.21it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.24it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.29it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.31it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.37it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.39it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.40it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.45it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:05<00:01, 58.44it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.47it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.38it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.45it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.40it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.49it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.49it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.39it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.37it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.31it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:06<00:00, 58.39it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.39it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.45it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.43it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.09it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.39it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.60it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.95it/s]
epoch 2: train_loss = 4.555
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 3
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:16,  1.14s/it]going through batches for holmes training:   1%|          | 2/384 [00:01<03:23,  1.88it/s]going through batches for holmes training:   2%|▏         | 8/384 [00:01<00:39,  9.59it/s]going through batches for holmes training:   4%|▎         | 14/384 [00:01<00:21, 17.26it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:14, 25.05it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:11, 32.16it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:09, 38.29it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:07, 43.32it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 47.25it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 50.27it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 52.63it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:05, 54.29it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 55.49it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 56.35it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.89it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.18it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.47it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.72it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:03<00:04, 57.94it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 57.99it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.14it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.26it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.26it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.33it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.34it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.27it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.25it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.35it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.32it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.34it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.38it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.49it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.42it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.48it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.43it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.49it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.49it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.43it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.40it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.41it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.36it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.25it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.31it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.32it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.32it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.34it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.44it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.40it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.39it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.24it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.32it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.29it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.34it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.46it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.50it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.51it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.42it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:07<00:00, 58.29it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.20it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.23it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.30it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.30it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.03it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.31it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.51it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 48.93it/s]
epoch 3: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
3: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 4
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:00,  1.10s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:49,  7.63it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:24, 14.94it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:16, 22.41it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:12, 29.52it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:09, 35.85it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 41.18it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 45.58it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:01<00:06, 48.84it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 51.51it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 53.33it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 54.76it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 55.89it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 56.69it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 57.33it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.76it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:04, 57.98it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:02<00:04, 58.19it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:02<00:04, 58.32it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 58.48it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 58.60it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.68it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.82it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.76it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.72it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:03<00:03, 58.77it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:03<00:03, 58.63it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 58.66it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.84it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.78it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.82it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:04<00:02, 58.86it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:04<00:02, 58.84it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.83it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.74it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 58.83it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 58.83it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 58.82it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 58.81it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.75it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:05<00:01, 58.79it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.77it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.84it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.84it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.60it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.77it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.80it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:06<00:00, 58.79it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:06<00:00, 58.80it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.80it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.84it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 58.87it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 58.44it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 58.60it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 58.74it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 50.04it/s]
epoch 4: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
4: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 5
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:16,  1.14s/it]going through batches for holmes training:   1%|▏         | 5/384 [00:01<01:12,  5.20it/s]going through batches for holmes training:   3%|▎         | 12/384 [00:01<00:27, 13.76it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:16, 22.20it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:12, 29.01it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:10, 35.22it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 40.64it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 45.14it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:01<00:06, 48.68it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 51.44it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 53.46it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 54.98it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 56.10it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 56.87it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 57.38it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.80it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:04, 57.97it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:02<00:04, 58.30it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:03<00:04, 58.45it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 58.54it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 58.65it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.75it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.80it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.75it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.71it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.78it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.75it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:03<00:03, 58.47it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:04<00:03, 58.48it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 58.59it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.60it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.67it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.67it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.71it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.66it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:04<00:02, 58.77it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.74it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 58.75it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 58.72it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 58.72it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 58.70it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 58.69it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.71it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:05<00:01, 58.72it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.63it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.55it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.67it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.66it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.63it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.68it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:06<00:00, 58.68it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:06<00:00, 58.68it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.64it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.67it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 56.60it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 56.68it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 57.28it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 57.78it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.55it/s]
epoch 5: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
5: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 6
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:32,  1.03s/it]going through batches for holmes training:   1%|          | 2/384 [00:01<03:32,  1.80it/s]going through batches for holmes training:   2%|▏         | 8/384 [00:01<00:40,  9.32it/s]going through batches for holmes training:   4%|▎         | 14/384 [00:01<00:21, 17.23it/s]going through batches for holmes training:   5%|▌         | 21/384 [00:01<00:13, 26.08it/s]going through batches for holmes training:   7%|▋         | 28/384 [00:01<00:10, 33.81it/s]going through batches for holmes training:   9%|▉         | 34/384 [00:01<00:08, 39.32it/s]going through batches for holmes training:  10%|█         | 40/384 [00:01<00:07, 43.97it/s]going through batches for holmes training:  12%|█▏        | 46/384 [00:02<00:07, 47.71it/s]going through batches for holmes training:  14%|█▎        | 52/384 [00:02<00:06, 50.69it/s]going through batches for holmes training:  15%|█▌        | 58/384 [00:02<00:06, 52.89it/s]going through batches for holmes training:  17%|█▋        | 64/384 [00:02<00:05, 54.57it/s]going through batches for holmes training:  18%|█▊        | 70/384 [00:02<00:05, 55.80it/s]going through batches for holmes training:  20%|█▉        | 76/384 [00:02<00:05, 56.67it/s]going through batches for holmes training:  21%|██▏       | 82/384 [00:02<00:05, 57.30it/s]going through batches for holmes training:  23%|██▎       | 88/384 [00:02<00:05, 57.78it/s]going through batches for holmes training:  24%|██▍       | 94/384 [00:02<00:04, 58.12it/s]going through batches for holmes training:  26%|██▌       | 100/384 [00:02<00:04, 58.27it/s]going through batches for holmes training:  28%|██▊       | 106/384 [00:03<00:04, 58.46it/s]going through batches for holmes training:  29%|██▉       | 112/384 [00:03<00:04, 58.50it/s]going through batches for holmes training:  31%|███       | 118/384 [00:03<00:04, 58.65it/s]going through batches for holmes training:  32%|███▏      | 124/384 [00:03<00:04, 58.68it/s]going through batches for holmes training:  34%|███▍      | 130/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  35%|███▌      | 136/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  37%|███▋      | 142/384 [00:03<00:04, 58.70it/s]going through batches for holmes training:  39%|███▊      | 148/384 [00:03<00:04, 58.71it/s]going through batches for holmes training:  40%|████      | 154/384 [00:03<00:03, 58.72it/s]going through batches for holmes training:  42%|████▏     | 160/384 [00:03<00:03, 58.74it/s]going through batches for holmes training:  43%|████▎     | 166/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  45%|████▍     | 172/384 [00:04<00:03, 58.79it/s]going through batches for holmes training:  46%|████▋     | 178/384 [00:04<00:03, 58.88it/s]going through batches for holmes training:  48%|████▊     | 184/384 [00:04<00:03, 58.89it/s]going through batches for holmes training:  49%|████▉     | 190/384 [00:04<00:03, 58.87it/s]going through batches for holmes training:  51%|█████     | 196/384 [00:04<00:03, 58.93it/s]going through batches for holmes training:  53%|█████▎    | 202/384 [00:04<00:03, 58.84it/s]going through batches for holmes training:  54%|█████▍    | 208/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  56%|█████▌    | 214/384 [00:04<00:02, 58.77it/s]going through batches for holmes training:  57%|█████▋    | 220/384 [00:04<00:02, 58.74it/s]going through batches for holmes training:  59%|█████▉    | 226/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  60%|██████    | 232/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  62%|██████▏   | 238/384 [00:05<00:02, 58.91it/s]going through batches for holmes training:  64%|██████▎   | 244/384 [00:05<00:02, 58.82it/s]going through batches for holmes training:  65%|██████▌   | 250/384 [00:05<00:02, 58.77it/s]going through batches for holmes training:  67%|██████▋   | 256/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  68%|██████▊   | 262/384 [00:05<00:02, 58.88it/s]going through batches for holmes training:  70%|██████▉   | 268/384 [00:05<00:01, 58.89it/s]going through batches for holmes training:  71%|███████▏  | 274/384 [00:05<00:01, 58.90it/s]going through batches for holmes training:  73%|███████▎  | 280/384 [00:05<00:01, 58.88it/s]going through batches for holmes training:  74%|███████▍  | 286/384 [00:06<00:01, 58.73it/s]going through batches for holmes training:  76%|███████▌  | 292/384 [00:06<00:01, 58.71it/s]going through batches for holmes training:  78%|███████▊  | 298/384 [00:06<00:01, 58.77it/s]going through batches for holmes training:  79%|███████▉  | 304/384 [00:06<00:01, 58.75it/s]going through batches for holmes training:  81%|████████  | 310/384 [00:06<00:01, 58.83it/s]going through batches for holmes training:  82%|████████▏ | 316/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  84%|████████▍ | 322/384 [00:06<00:01, 58.84it/s]going through batches for holmes training:  85%|████████▌ | 328/384 [00:06<00:00, 58.85it/s]going through batches for holmes training:  87%|████████▋ | 334/384 [00:06<00:00, 58.85it/s]going through batches for holmes training:  89%|████████▊ | 340/384 [00:07<00:00, 58.87it/s]going through batches for holmes training:  90%|█████████ | 346/384 [00:07<00:00, 58.81it/s]going through batches for holmes training:  92%|█████████▏| 352/384 [00:07<00:00, 58.78it/s]going through batches for holmes training:  93%|█████████▎| 358/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  95%|█████████▍| 364/384 [00:07<00:00, 58.76it/s]going through batches for holmes training:  96%|█████████▋| 370/384 [00:07<00:00, 58.31it/s]going through batches for holmes training:  98%|█████████▊| 376/384 [00:07<00:00, 58.57it/s]going through batches for holmes training:  99%|█████████▉| 382/384 [00:07<00:00, 58.79it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.23it/s]
epoch 6: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
6: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 7
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:49,  1.07s/it]going through batches for holmes training:   1%|          | 2/384 [00:01<03:18,  1.92it/s]going through batches for holmes training:   2%|▏         | 8/384 [00:01<00:37,  9.90it/s]going through batches for holmes training:   4%|▍         | 15/384 [00:01<00:19, 19.29it/s]going through batches for holmes training:   5%|▌         | 21/384 [00:01<00:13, 26.84it/s]going through batches for holmes training:   7%|▋         | 27/384 [00:01<00:10, 33.68it/s]going through batches for holmes training:   9%|▊         | 33/384 [00:01<00:08, 39.53it/s]going through batches for holmes training:  10%|█         | 39/384 [00:01<00:07, 44.35it/s]going through batches for holmes training:  12%|█▏        | 45/384 [00:01<00:07, 48.13it/s]going through batches for holmes training:  13%|█▎        | 51/384 [00:02<00:06, 51.05it/s]going through batches for holmes training:  15%|█▍        | 57/384 [00:02<00:06, 53.21it/s]going through batches for holmes training:  16%|█▋        | 63/384 [00:02<00:05, 54.76it/s]going through batches for holmes training:  18%|█▊        | 69/384 [00:02<00:05, 55.88it/s]going through batches for holmes training:  20%|█▉        | 75/384 [00:02<00:05, 56.75it/s]going through batches for holmes training:  21%|██        | 81/384 [00:02<00:05, 57.02it/s]going through batches for holmes training:  23%|██▎       | 87/384 [00:02<00:05, 57.56it/s]going through batches for holmes training:  24%|██▍       | 93/384 [00:02<00:05, 57.89it/s]going through batches for holmes training:  26%|██▌       | 99/384 [00:02<00:04, 58.07it/s]going through batches for holmes training:  27%|██▋       | 105/384 [00:02<00:04, 58.29it/s]going through batches for holmes training:  29%|██▉       | 111/384 [00:03<00:04, 58.46it/s]going through batches for holmes training:  30%|███       | 117/384 [00:03<00:04, 58.56it/s]going through batches for holmes training:  32%|███▏      | 123/384 [00:03<00:04, 58.60it/s]going through batches for holmes training:  34%|███▎      | 129/384 [00:03<00:04, 58.61it/s]going through batches for holmes training:  35%|███▌      | 135/384 [00:03<00:04, 56.83it/s]going through batches for holmes training:  37%|███▋      | 141/384 [00:03<00:04, 57.27it/s]going through batches for holmes training:  38%|███▊      | 147/384 [00:03<00:04, 57.71it/s]going through batches for holmes training:  40%|███▉      | 153/384 [00:03<00:03, 57.96it/s]going through batches for holmes training:  41%|████▏     | 159/384 [00:03<00:03, 58.20it/s]going through batches for holmes training:  43%|████▎     | 165/384 [00:03<00:03, 58.22it/s]going through batches for holmes training:  45%|████▍     | 171/384 [00:04<00:03, 58.39it/s]going through batches for holmes training:  46%|████▌     | 177/384 [00:04<00:03, 58.55it/s]going through batches for holmes training:  48%|████▊     | 183/384 [00:04<00:03, 58.62it/s]going through batches for holmes training:  49%|████▉     | 189/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  51%|█████     | 195/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  52%|█████▏    | 201/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  54%|█████▍    | 207/384 [00:04<00:03, 58.74it/s]going through batches for holmes training:  55%|█████▌    | 213/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  57%|█████▋    | 219/384 [00:04<00:02, 58.79it/s]going through batches for holmes training:  59%|█████▊    | 225/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  60%|██████    | 231/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  62%|██████▏   | 237/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  63%|██████▎   | 243/384 [00:05<00:02, 58.88it/s]going through batches for holmes training:  65%|██████▍   | 249/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  66%|██████▋   | 255/384 [00:05<00:02, 58.83it/s]going through batches for holmes training:  68%|██████▊   | 261/384 [00:05<00:02, 58.84it/s]going through batches for holmes training:  70%|██████▉   | 267/384 [00:05<00:01, 58.73it/s]going through batches for holmes training:  71%|███████   | 273/384 [00:05<00:01, 58.74it/s]going through batches for holmes training:  73%|███████▎  | 279/384 [00:05<00:01, 58.75it/s]going through batches for holmes training:  74%|███████▍  | 285/384 [00:06<00:01, 58.82it/s]going through batches for holmes training:  76%|███████▌  | 291/384 [00:06<00:01, 58.80it/s]going through batches for holmes training:  77%|███████▋  | 297/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  79%|███████▉  | 303/384 [00:06<00:01, 58.82it/s]going through batches for holmes training:  80%|████████  | 309/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  82%|████████▏ | 315/384 [00:06<00:01, 58.85it/s]going through batches for holmes training:  84%|████████▎ | 321/384 [00:06<00:01, 58.73it/s]going through batches for holmes training:  85%|████████▌ | 327/384 [00:06<00:00, 58.79it/s]going through batches for holmes training:  87%|████████▋ | 333/384 [00:06<00:00, 58.86it/s]going through batches for holmes training:  88%|████████▊ | 339/384 [00:06<00:00, 58.75it/s]going through batches for holmes training:  90%|████████▉ | 345/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  91%|█████████▏| 351/384 [00:07<00:00, 58.73it/s]going through batches for holmes training:  93%|█████████▎| 357/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  95%|█████████▍| 363/384 [00:07<00:00, 58.76it/s]going through batches for holmes training:  96%|█████████▌| 369/384 [00:07<00:00, 58.32it/s]going through batches for holmes training:  98%|█████████▊| 375/384 [00:07<00:00, 58.51it/s]going through batches for holmes training:  99%|█████████▉| 381/384 [00:07<00:00, 58.72it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.47it/s]
epoch 7: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
7: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 8
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:44,  1.21s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:53,  6.99it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:26, 13.87it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 22.09it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.82it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 35.00it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.40it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.89it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.50it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.36it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.51it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.99it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 56.07it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.86it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.41it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.89it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.16it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.39it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.56it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.67it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.67it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.63it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.65it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.73it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.76it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.77it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.76it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:03<00:03, 58.78it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.80it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.79it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.82it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.81it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.84it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.81it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.85it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.93it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.91it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.86it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.87it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.90it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.85it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.88it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.88it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.87it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.85it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.89it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.97it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.96it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.90it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.89it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.93it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.90it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.94it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.87it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.88it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.89it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.52it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.67it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.85it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.48it/s]
epoch 8: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
8: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 9
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:32,  1.03s/it]going through batches for holmes training:   1%|          | 3/384 [00:01<01:58,  3.22it/s]going through batches for holmes training:   2%|▏         | 9/384 [00:01<00:33, 11.25it/s]going through batches for holmes training:   4%|▍         | 16/384 [00:01<00:17, 20.64it/s]going through batches for holmes training:   6%|▌         | 23/384 [00:01<00:12, 29.14it/s]going through batches for holmes training:   8%|▊         | 29/384 [00:01<00:09, 35.51it/s]going through batches for holmes training:   9%|▉         | 35/384 [00:01<00:08, 40.90it/s]going through batches for holmes training:  11%|█         | 41/384 [00:01<00:07, 45.35it/s]going through batches for holmes training:  12%|█▏        | 47/384 [00:01<00:06, 48.90it/s]going through batches for holmes training:  14%|█▍        | 53/384 [00:02<00:06, 51.51it/s]going through batches for holmes training:  15%|█▌        | 59/384 [00:02<00:06, 53.51it/s]going through batches for holmes training:  17%|█▋        | 65/384 [00:02<00:05, 55.03it/s]going through batches for holmes training:  18%|█▊        | 71/384 [00:02<00:05, 56.07it/s]going through batches for holmes training:  20%|██        | 77/384 [00:02<00:05, 56.94it/s]going through batches for holmes training:  22%|██▏       | 83/384 [00:02<00:05, 57.44it/s]going through batches for holmes training:  23%|██▎       | 89/384 [00:02<00:05, 57.82it/s]going through batches for holmes training:  25%|██▍       | 95/384 [00:02<00:04, 57.81it/s]going through batches for holmes training:  26%|██▋       | 101/384 [00:02<00:04, 58.10it/s]going through batches for holmes training:  28%|██▊       | 107/384 [00:02<00:04, 58.32it/s]going through batches for holmes training:  29%|██▉       | 113/384 [00:03<00:04, 58.44it/s]going through batches for holmes training:  31%|███       | 119/384 [00:03<00:04, 58.55it/s]going through batches for holmes training:  33%|███▎      | 125/384 [00:03<00:04, 58.62it/s]going through batches for holmes training:  34%|███▍      | 131/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  36%|███▌      | 137/384 [00:03<00:04, 58.64it/s]going through batches for holmes training:  37%|███▋      | 143/384 [00:03<00:04, 58.73it/s]going through batches for holmes training:  39%|███▉      | 149/384 [00:03<00:03, 58.76it/s]going through batches for holmes training:  40%|████      | 155/384 [00:03<00:03, 58.73it/s]going through batches for holmes training:  42%|████▏     | 161/384 [00:03<00:03, 58.74it/s]going through batches for holmes training:  43%|████▎     | 167/384 [00:03<00:03, 58.67it/s]going through batches for holmes training:  45%|████▌     | 173/384 [00:04<00:03, 58.68it/s]going through batches for holmes training:  47%|████▋     | 179/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  48%|████▊     | 185/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  50%|████▉     | 191/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  51%|█████▏    | 197/384 [00:04<00:03, 58.80it/s]going through batches for holmes training:  53%|█████▎    | 203/384 [00:04<00:03, 58.81it/s]going through batches for holmes training:  54%|█████▍    | 209/384 [00:04<00:02, 58.78it/s]going through batches for holmes training:  56%|█████▌    | 215/384 [00:04<00:02, 58.80it/s]going through batches for holmes training:  58%|█████▊    | 221/384 [00:04<00:02, 58.87it/s]going through batches for holmes training:  59%|█████▉    | 227/384 [00:04<00:02, 58.92it/s]going through batches for holmes training:  61%|██████    | 233/384 [00:05<00:02, 58.88it/s]going through batches for holmes training:  62%|██████▏   | 239/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  64%|██████▍   | 245/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  65%|██████▌   | 251/384 [00:05<00:02, 58.68it/s]going through batches for holmes training:  67%|██████▋   | 257/384 [00:05<00:02, 58.76it/s]going through batches for holmes training:  68%|██████▊   | 263/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  70%|███████   | 269/384 [00:05<00:01, 58.89it/s]going through batches for holmes training:  72%|███████▏  | 275/384 [00:05<00:01, 58.89it/s]going through batches for holmes training:  73%|███████▎  | 281/384 [00:05<00:01, 58.91it/s]going through batches for holmes training:  75%|███████▍  | 287/384 [00:05<00:01, 58.92it/s]going through batches for holmes training:  76%|███████▋  | 293/384 [00:06<00:01, 58.90it/s]going through batches for holmes training:  78%|███████▊  | 299/384 [00:06<00:01, 58.84it/s]going through batches for holmes training:  79%|███████▉  | 305/384 [00:06<00:01, 58.57it/s]going through batches for holmes training:  81%|████████  | 311/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  83%|████████▎ | 317/384 [00:06<00:01, 58.77it/s]going through batches for holmes training:  84%|████████▍ | 323/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  86%|████████▌ | 329/384 [00:06<00:00, 58.79it/s]going through batches for holmes training:  87%|████████▋ | 335/384 [00:06<00:00, 58.84it/s]going through batches for holmes training:  89%|████████▉ | 341/384 [00:06<00:00, 58.83it/s]going through batches for holmes training:  90%|█████████ | 347/384 [00:07<00:00, 58.76it/s]going through batches for holmes training:  92%|█████████▏| 353/384 [00:07<00:00, 58.81it/s]going through batches for holmes training:  93%|█████████▎| 359/384 [00:07<00:00, 58.72it/s]going through batches for holmes training:  95%|█████████▌| 365/384 [00:07<00:00, 58.29it/s]going through batches for holmes training:  97%|█████████▋| 371/384 [00:07<00:00, 58.40it/s]going through batches for holmes training:  98%|█████████▊| 377/384 [00:07<00:00, 58.62it/s]going through batches for holmes training: 100%|█████████▉| 383/384 [00:07<00:00, 58.79it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.98it/s]
epoch 9: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
9: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 10
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:38,  1.04s/it]going through batches for holmes training:   1%|          | 2/384 [00:01<03:12,  1.98it/s]going through batches for holmes training:   2%|▏         | 8/384 [00:01<00:36, 10.19it/s]going through batches for holmes training:   4%|▎         | 14/384 [00:01<00:19, 18.57it/s]going through batches for holmes training:   5%|▌         | 21/384 [00:01<00:13, 27.66it/s]going through batches for holmes training:   7%|▋         | 27/384 [00:01<00:10, 34.38it/s]going through batches for holmes training:   9%|▊         | 33/384 [00:01<00:08, 40.07it/s]going through batches for holmes training:  10%|█         | 39/384 [00:01<00:07, 44.72it/s]going through batches for holmes training:  12%|█▏        | 45/384 [00:01<00:07, 48.42it/s]going through batches for holmes training:  13%|█▎        | 51/384 [00:02<00:06, 51.26it/s]going through batches for holmes training:  15%|█▍        | 57/384 [00:02<00:06, 53.26it/s]going through batches for holmes training:  16%|█▋        | 63/384 [00:02<00:05, 54.74it/s]going through batches for holmes training:  18%|█▊        | 69/384 [00:02<00:05, 55.93it/s]going through batches for holmes training:  20%|█▉        | 75/384 [00:02<00:05, 56.75it/s]going through batches for holmes training:  21%|██        | 81/384 [00:02<00:05, 57.35it/s]going through batches for holmes training:  23%|██▎       | 87/384 [00:02<00:05, 57.78it/s]going through batches for holmes training:  24%|██▍       | 93/384 [00:02<00:05, 58.06it/s]going through batches for holmes training:  26%|██▌       | 99/384 [00:02<00:04, 58.29it/s]going through batches for holmes training:  27%|██▋       | 105/384 [00:02<00:04, 58.46it/s]going through batches for holmes training:  29%|██▉       | 111/384 [00:03<00:04, 58.57it/s]going through batches for holmes training:  30%|███       | 117/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  32%|███▏      | 123/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  34%|███▎      | 129/384 [00:03<00:04, 58.78it/s]going through batches for holmes training:  35%|███▌      | 135/384 [00:03<00:04, 58.84it/s]going through batches for holmes training:  37%|███▋      | 141/384 [00:03<00:04, 58.62it/s]going through batches for holmes training:  38%|███▊      | 147/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  40%|███▉      | 153/384 [00:03<00:03, 58.72it/s]going through batches for holmes training:  41%|████▏     | 159/384 [00:03<00:03, 58.69it/s]going through batches for holmes training:  43%|████▎     | 165/384 [00:03<00:03, 58.59it/s]going through batches for holmes training:  45%|████▍     | 171/384 [00:04<00:03, 58.64it/s]going through batches for holmes training:  46%|████▌     | 177/384 [00:04<00:03, 58.65it/s]going through batches for holmes training:  48%|████▊     | 183/384 [00:04<00:03, 58.63it/s]going through batches for holmes training:  49%|████▉     | 189/384 [00:04<00:03, 58.62it/s]going through batches for holmes training:  51%|█████     | 195/384 [00:04<00:03, 58.62it/s]going through batches for holmes training:  52%|█████▏    | 201/384 [00:04<00:03, 58.61it/s]going through batches for holmes training:  54%|█████▍    | 207/384 [00:04<00:03, 58.67it/s]going through batches for holmes training:  55%|█████▌    | 213/384 [00:04<00:02, 58.72it/s]going through batches for holmes training:  57%|█████▋    | 219/384 [00:04<00:02, 58.71it/s]going through batches for holmes training:  59%|█████▊    | 225/384 [00:04<00:02, 58.68it/s]going through batches for holmes training:  60%|██████    | 231/384 [00:05<00:02, 58.68it/s]going through batches for holmes training:  62%|██████▏   | 237/384 [00:05<00:02, 58.67it/s]going through batches for holmes training:  63%|██████▎   | 243/384 [00:05<00:02, 58.66it/s]going through batches for holmes training:  65%|██████▍   | 249/384 [00:05<00:02, 58.67it/s]going through batches for holmes training:  66%|██████▋   | 255/384 [00:05<00:02, 58.57it/s]going through batches for holmes training:  68%|██████▊   | 261/384 [00:05<00:02, 58.60it/s]going through batches for holmes training:  70%|██████▉   | 267/384 [00:05<00:01, 58.62it/s]going through batches for holmes training:  71%|███████   | 273/384 [00:05<00:01, 58.56it/s]going through batches for holmes training:  73%|███████▎  | 279/384 [00:05<00:01, 56.03it/s]going through batches for holmes training:  74%|███████▍  | 285/384 [00:06<00:01, 56.73it/s]going through batches for holmes training:  76%|███████▌  | 291/384 [00:06<00:01, 57.07it/s]going through batches for holmes training:  77%|███████▋  | 297/384 [00:06<00:01, 57.54it/s]going through batches for holmes training:  79%|███████▉  | 303/384 [00:06<00:01, 57.89it/s]going through batches for holmes training:  80%|████████  | 309/384 [00:06<00:01, 58.11it/s]going through batches for holmes training:  82%|████████▏ | 315/384 [00:06<00:01, 58.23it/s]going through batches for holmes training:  84%|████████▎ | 321/384 [00:06<00:01, 58.33it/s]going through batches for holmes training:  85%|████████▌ | 327/384 [00:06<00:00, 58.11it/s]going through batches for holmes training:  87%|████████▋ | 333/384 [00:06<00:00, 58.22it/s]going through batches for holmes training:  88%|████████▊ | 339/384 [00:06<00:00, 58.34it/s]going through batches for holmes training:  90%|████████▉ | 345/384 [00:07<00:00, 58.37it/s]going through batches for holmes training:  91%|█████████▏| 351/384 [00:07<00:00, 58.51it/s]going through batches for holmes training:  93%|█████████▎| 357/384 [00:07<00:00, 58.37it/s]going through batches for holmes training:  95%|█████████▍| 363/384 [00:07<00:00, 58.45it/s]going through batches for holmes training:  96%|█████████▌| 369/384 [00:07<00:00, 58.12it/s]going through batches for holmes training:  98%|█████████▊| 375/384 [00:07<00:00, 58.41it/s]going through batches for holmes training:  99%|█████████▉| 381/384 [00:07<00:00, 58.53it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.58it/s]
epoch 10: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
10: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 11
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:25,  1.16s/it]going through batches for holmes training:   2%|▏         | 6/384 [00:01<01:00,  6.23it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:25, 14.51it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 22.73it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 29.39it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:09, 35.50it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.84it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 45.23it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.62it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.36it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.45it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.97it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 56.10it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.94it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.53it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.96it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.16it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.36it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.52it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.59it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.63it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.61it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.63it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.67it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.79it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.79it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:03<00:03, 58.82it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.84it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.89it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.88it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.83it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.89it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.83it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.81it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.83it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.85it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:04<00:02, 58.87it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.87it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.88it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.90it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.93it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.91it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.92it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.78it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:05<00:01, 58.83it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.85it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.78it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.81it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.83it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.67it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.62it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.72it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.69it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.74it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.70it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.71it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.78it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.46it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.63it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.80it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.62it/s]
epoch 11: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
11: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 12
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:40,  1.20s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:53,  7.06it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:26, 13.90it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 22.10it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.72it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.87it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.14it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.52it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.06it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 50.94it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.12it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 53.36it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 54.78it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 55.74it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 56.59it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.19it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.49it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 57.82it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.05it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.22it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.42it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.56it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.70it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.68it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.73it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.59it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.54it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.63it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.67it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.81it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.83it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.87it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.79it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.76it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.73it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.66it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.67it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.68it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.63it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.73it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.75it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.74it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.73it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.70it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.67it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.70it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.67it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.59it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.24it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.48it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.73it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.24it/s]
epoch 12: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
12: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 13
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:50,  1.23s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:54,  6.94it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.71it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:17, 20.86it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:12, 27.81it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:10, 34.10it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 39.63it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 44.24it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:02<00:06, 47.87it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 50.75it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 52.98it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 54.63it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 55.71it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 56.58it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 57.16it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.60it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:04, 57.89it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:02<00:04, 58.01it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:03<00:04, 58.13it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 58.23it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 58.26it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.27it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.31it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.30it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.35it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.35it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.31it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:04<00:03, 58.36it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:04<00:03, 58.10it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 58.04it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.14it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.24it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.34it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.35it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.41it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.45it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.46it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:05<00:02, 58.45it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:05<00:02, 58.35it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.37it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.40it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 58.30it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 58.36it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 58.38it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 58.34it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 58.37it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.29it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:06<00:01, 58.32it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.44it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.30it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.35it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.19it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.16it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.17it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.15it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.17it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:06<00:00, 58.28it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:07<00:00, 58.19it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.23it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.21it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 58.11it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 57.58it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 57.86it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 58.17it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 48.99it/s]
epoch 13: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
13: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 14
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:52,  1.23s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:54,  6.95it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.67it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 21.81it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.49it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.69it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.11it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.66it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.33it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.16it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.31it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.82it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.96it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.83it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.28it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.68it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.07it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.37it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.57it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.61it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.61it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.67it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.74it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.70it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.70it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.70it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.70it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.78it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.82it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.72it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.39it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.54it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.56it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.58it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.62it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.69it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.66it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.70it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.66it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.75it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.77it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.75it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.83it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.89it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.80it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.79it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.77it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.76it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.68it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.78it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.34it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.56it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.68it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.26it/s]
epoch 14: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
14: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 15
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<08:15,  1.29s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:56,  6.64it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:28, 13.17it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:17, 21.15it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 27.80it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.02it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 39.57it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:02<00:07, 44.23it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 47.95it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 50.90it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.08it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.66it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.76it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.64it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.35it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.73it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.08it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:03<00:04, 58.33it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.42it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.52it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.60it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.78it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.84it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.89it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.93it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.95it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.94it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.91it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.88it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.83it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.30it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.37it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.45it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.56it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.70it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.84it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.73it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.76it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.85it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:06<00:01, 58.85it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.81it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.75it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.80it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.77it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.72it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.69it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.76it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.73it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.24it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.49it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.61it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 48.90it/s]
epoch 15: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
15: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 16
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:00<05:26,  1.17it/s]going through batches for holmes training:   1%|          | 2/384 [00:01<02:58,  2.14it/s]going through batches for holmes training:   1%|          | 4/384 [00:01<01:23,  4.54it/s]going through batches for holmes training:   3%|▎         | 10/384 [00:01<00:26, 13.90it/s]going through batches for holmes training:   4%|▍         | 16/384 [00:01<00:16, 22.85it/s]going through batches for holmes training:   6%|▌         | 23/384 [00:01<00:11, 31.98it/s]going through batches for holmes training:   8%|▊         | 29/384 [00:01<00:09, 38.23it/s]going through batches for holmes training:   9%|▉         | 35/384 [00:01<00:08, 43.35it/s]going through batches for holmes training:  11%|█         | 41/384 [00:01<00:07, 47.30it/s]going through batches for holmes training:  12%|█▏        | 47/384 [00:01<00:06, 50.42it/s]going through batches for holmes training:  14%|█▍        | 53/384 [00:02<00:06, 52.71it/s]going through batches for holmes training:  15%|█▌        | 59/384 [00:02<00:05, 54.29it/s]going through batches for holmes training:  17%|█▋        | 65/384 [00:02<00:05, 55.50it/s]going through batches for holmes training:  18%|█▊        | 71/384 [00:02<00:05, 56.44it/s]going through batches for holmes training:  20%|██        | 77/384 [00:02<00:05, 57.17it/s]going through batches for holmes training:  22%|██▏       | 83/384 [00:02<00:05, 57.64it/s]going through batches for holmes training:  23%|██▎       | 89/384 [00:02<00:05, 57.99it/s]going through batches for holmes training:  25%|██▍       | 95/384 [00:02<00:04, 58.18it/s]going through batches for holmes training:  26%|██▋       | 101/384 [00:02<00:04, 58.37it/s]going through batches for holmes training:  28%|██▊       | 107/384 [00:02<00:04, 58.52it/s]going through batches for holmes training:  29%|██▉       | 113/384 [00:03<00:04, 58.45it/s]going through batches for holmes training:  31%|███       | 119/384 [00:03<00:04, 58.55it/s]going through batches for holmes training:  33%|███▎      | 125/384 [00:03<00:04, 58.62it/s]going through batches for holmes training:  34%|███▍      | 131/384 [00:03<00:04, 58.65it/s]going through batches for holmes training:  36%|███▌      | 137/384 [00:03<00:04, 58.70it/s]going through batches for holmes training:  37%|███▋      | 143/384 [00:03<00:04, 58.74it/s]going through batches for holmes training:  39%|███▉      | 149/384 [00:03<00:04, 58.75it/s]going through batches for holmes training:  40%|████      | 155/384 [00:03<00:03, 58.72it/s]going through batches for holmes training:  42%|████▏     | 161/384 [00:03<00:03, 58.78it/s]going through batches for holmes training:  43%|████▎     | 167/384 [00:03<00:03, 58.75it/s]going through batches for holmes training:  45%|████▌     | 173/384 [00:04<00:03, 58.83it/s]going through batches for holmes training:  47%|████▋     | 179/384 [00:04<00:03, 58.81it/s]going through batches for holmes training:  48%|████▊     | 185/384 [00:04<00:03, 58.72it/s]going through batches for holmes training:  50%|████▉     | 191/384 [00:04<00:03, 58.67it/s]going through batches for holmes training:  51%|█████▏    | 197/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  53%|█████▎    | 203/384 [00:04<00:03, 58.73it/s]going through batches for holmes training:  54%|█████▍    | 209/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  56%|█████▌    | 215/384 [00:04<00:02, 58.81it/s]going through batches for holmes training:  58%|█████▊    | 221/384 [00:04<00:02, 58.86it/s]going through batches for holmes training:  59%|█████▉    | 227/384 [00:04<00:02, 58.83it/s]going through batches for holmes training:  61%|██████    | 233/384 [00:05<00:02, 58.84it/s]going through batches for holmes training:  62%|██████▏   | 239/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  64%|██████▍   | 245/384 [00:05<00:02, 58.77it/s]going through batches for holmes training:  65%|██████▌   | 251/384 [00:05<00:02, 58.35it/s]going through batches for holmes training:  67%|██████▋   | 257/384 [00:05<00:02, 58.40it/s]going through batches for holmes training:  68%|██████▊   | 263/384 [00:05<00:02, 58.52it/s]going through batches for holmes training:  70%|███████   | 269/384 [00:05<00:01, 58.63it/s]going through batches for holmes training:  72%|███████▏  | 275/384 [00:05<00:01, 58.68it/s]going through batches for holmes training:  73%|███████▎  | 281/384 [00:05<00:01, 58.72it/s]going through batches for holmes training:  75%|███████▍  | 287/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  76%|███████▋  | 293/384 [00:06<00:01, 58.81it/s]going through batches for holmes training:  78%|███████▊  | 299/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  79%|███████▉  | 305/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  81%|████████  | 311/384 [00:06<00:01, 58.71it/s]going through batches for holmes training:  83%|████████▎ | 317/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  84%|████████▍ | 323/384 [00:06<00:01, 58.68it/s]going through batches for holmes training:  86%|████████▌ | 329/384 [00:06<00:00, 58.75it/s]going through batches for holmes training:  87%|████████▋ | 335/384 [00:06<00:00, 58.75it/s]going through batches for holmes training:  89%|████████▉ | 341/384 [00:06<00:00, 58.82it/s]going through batches for holmes training:  90%|█████████ | 347/384 [00:07<00:00, 58.88it/s]going through batches for holmes training:  92%|█████████▏| 353/384 [00:07<00:00, 58.85it/s]going through batches for holmes training:  93%|█████████▎| 359/384 [00:07<00:00, 58.84it/s]going through batches for holmes training:  95%|█████████▌| 365/384 [00:07<00:00, 58.26it/s]going through batches for holmes training:  97%|█████████▋| 371/384 [00:07<00:00, 58.48it/s]going through batches for holmes training:  98%|█████████▊| 377/384 [00:07<00:00, 58.59it/s]going through batches for holmes training: 100%|█████████▉| 383/384 [00:07<00:00, 58.74it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.83it/s]
epoch 16: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
16: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 17
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:51,  1.23s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:54,  6.96it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.71it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 21.90it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.58it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.76it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.16it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.70it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.38it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.23it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.34it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.86it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.91it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.83it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.44it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.79it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.13it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.32it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.45it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.55it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.54it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.64it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.71it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.80it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.78it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.79it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.86it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.81it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.70it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.83it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.74it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.71it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.73it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.69it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.74it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.79it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.69it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.67it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.65it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.65it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.67it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.76it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.82it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.80it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.68it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.66it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.70it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.65it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.73it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.70it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.65it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.25it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.46it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.67it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.30it/s]
epoch 17: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
17: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 18
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:05,  1.11s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:49,  7.55it/s]going through batches for holmes training:   4%|▎         | 14/384 [00:01<00:23, 15.86it/s]going through batches for holmes training:   5%|▌         | 21/384 [00:01<00:15, 24.01it/s]going through batches for holmes training:   7%|▋         | 27/384 [00:01<00:11, 30.44it/s]going through batches for holmes training:   9%|▊         | 33/384 [00:01<00:09, 36.33it/s]going through batches for holmes training:  10%|█         | 39/384 [00:01<00:08, 41.38it/s]going through batches for holmes training:  12%|█▏        | 45/384 [00:01<00:07, 45.68it/s]going through batches for holmes training:  13%|█▎        | 51/384 [00:01<00:06, 49.08it/s]going through batches for holmes training:  15%|█▍        | 57/384 [00:02<00:06, 51.68it/s]going through batches for holmes training:  16%|█▋        | 63/384 [00:02<00:05, 53.66it/s]going through batches for holmes training:  18%|█▊        | 69/384 [00:02<00:05, 55.11it/s]going through batches for holmes training:  20%|█▉        | 75/384 [00:02<00:05, 56.17it/s]going through batches for holmes training:  21%|██        | 81/384 [00:02<00:05, 56.95it/s]going through batches for holmes training:  23%|██▎       | 87/384 [00:02<00:05, 57.47it/s]going through batches for holmes training:  24%|██▍       | 93/384 [00:02<00:05, 57.93it/s]going through batches for holmes training:  26%|██▌       | 99/384 [00:02<00:04, 58.22it/s]going through batches for holmes training:  27%|██▋       | 105/384 [00:02<00:04, 58.38it/s]going through batches for holmes training:  29%|██▉       | 111/384 [00:02<00:04, 58.51it/s]going through batches for holmes training:  30%|███       | 117/384 [00:03<00:04, 58.64it/s]going through batches for holmes training:  32%|███▏      | 123/384 [00:03<00:04, 58.67it/s]going through batches for holmes training:  34%|███▎      | 129/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  35%|███▌      | 135/384 [00:03<00:04, 58.82it/s]going through batches for holmes training:  37%|███▋      | 141/384 [00:03<00:04, 58.86it/s]going through batches for holmes training:  38%|███▊      | 147/384 [00:03<00:04, 58.87it/s]going through batches for holmes training:  40%|███▉      | 153/384 [00:03<00:03, 58.84it/s]going through batches for holmes training:  41%|████▏     | 159/384 [00:03<00:03, 58.81it/s]going through batches for holmes training:  43%|████▎     | 165/384 [00:03<00:03, 58.80it/s]going through batches for holmes training:  45%|████▍     | 171/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  46%|████▌     | 177/384 [00:04<00:03, 58.64it/s]going through batches for holmes training:  48%|████▊     | 183/384 [00:04<00:03, 58.70it/s]going through batches for holmes training:  49%|████▉     | 189/384 [00:04<00:03, 58.61it/s]going through batches for holmes training:  51%|█████     | 195/384 [00:04<00:03, 58.64it/s]going through batches for holmes training:  52%|█████▏    | 201/384 [00:04<00:03, 58.53it/s]going through batches for holmes training:  54%|█████▍    | 207/384 [00:04<00:03, 58.60it/s]going through batches for holmes training:  55%|█████▌    | 213/384 [00:04<00:02, 58.61it/s]going through batches for holmes training:  57%|█████▋    | 219/384 [00:04<00:02, 58.61it/s]going through batches for holmes training:  59%|█████▊    | 225/384 [00:04<00:02, 58.65it/s]going through batches for holmes training:  60%|██████    | 231/384 [00:05<00:02, 58.69it/s]going through batches for holmes training:  62%|██████▏   | 237/384 [00:05<00:02, 58.59it/s]going through batches for holmes training:  63%|██████▎   | 243/384 [00:05<00:02, 58.59it/s]going through batches for holmes training:  65%|██████▍   | 249/384 [00:05<00:02, 58.59it/s]going through batches for holmes training:  66%|██████▋   | 255/384 [00:05<00:02, 58.69it/s]going through batches for holmes training:  68%|██████▊   | 261/384 [00:05<00:02, 58.70it/s]going through batches for holmes training:  70%|██████▉   | 267/384 [00:05<00:01, 58.70it/s]going through batches for holmes training:  71%|███████   | 273/384 [00:05<00:01, 58.69it/s]going through batches for holmes training:  73%|███████▎  | 279/384 [00:05<00:01, 58.69it/s]going through batches for holmes training:  74%|███████▍  | 285/384 [00:05<00:01, 58.71it/s]going through batches for holmes training:  76%|███████▌  | 291/384 [00:06<00:01, 58.68it/s]going through batches for holmes training:  77%|███████▋  | 297/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  79%|███████▉  | 303/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  80%|████████  | 309/384 [00:06<00:01, 58.71it/s]going through batches for holmes training:  82%|████████▏ | 315/384 [00:06<00:01, 58.71it/s]going through batches for holmes training:  84%|████████▎ | 321/384 [00:06<00:01, 57.75it/s]going through batches for holmes training:  85%|████████▌ | 327/384 [00:06<00:00, 57.93it/s]going through batches for holmes training:  87%|████████▋ | 333/384 [00:06<00:00, 58.09it/s]going through batches for holmes training:  88%|████████▊ | 339/384 [00:06<00:00, 58.22it/s]going through batches for holmes training:  90%|████████▉ | 345/384 [00:06<00:00, 58.37it/s]going through batches for holmes training:  91%|█████████▏| 351/384 [00:07<00:00, 58.45it/s]going through batches for holmes training:  93%|█████████▎| 357/384 [00:07<00:00, 58.55it/s]going through batches for holmes training:  95%|█████████▍| 363/384 [00:07<00:00, 58.67it/s]going through batches for holmes training:  96%|█████████▌| 369/384 [00:07<00:00, 58.29it/s]going through batches for holmes training:  98%|█████████▊| 375/384 [00:07<00:00, 58.54it/s]going through batches for holmes training:  99%|█████████▉| 381/384 [00:07<00:00, 58.64it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.96it/s]
epoch 18: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
18: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 19
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:00<06:16,  1.02it/s]going through batches for holmes training:   1%|          | 2/384 [00:01<03:18,  1.92it/s]going through batches for holmes training:   2%|▏         | 8/384 [00:01<00:37,  9.95it/s]going through batches for holmes training:   4%|▎         | 14/384 [00:01<00:20, 18.21it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:13, 26.17it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:10, 33.27it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:08, 39.26it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:07, 44.11it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 47.96it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:01<00:06, 50.83it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 52.96it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:05, 54.59it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 55.76it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 56.45it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.76it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.25it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.58it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.82it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.08it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.28it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.35it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.38it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.42it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.51it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.38it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.31it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:03<00:03, 58.40it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.38it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.38it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.40it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.45it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.53it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.36it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.34it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.38it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.38it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:04<00:02, 58.45it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.42it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.46it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.44it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.36it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.41it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.43it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.40it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.45it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.45it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.45it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.33it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.31it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.32it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.20it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.26it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.25it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.33it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.35it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.37it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.46it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.51it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.47it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.39it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.02it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.19it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.13it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.50it/s]
epoch 19: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
19: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 20
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:21,  1.15s/it]going through batches for holmes training:   1%|▏         | 5/384 [00:01<01:15,  5.01it/s]going through batches for holmes training:   3%|▎         | 11/384 [00:01<00:30, 12.24it/s]going through batches for holmes training:   5%|▍         | 18/384 [00:01<00:17, 20.88it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:12, 28.95it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:10, 35.00it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 40.35it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 44.83it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:02<00:06, 48.46it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 51.27it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 53.35it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 54.88it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 56.04it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 56.88it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 57.45it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.84it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:04, 58.12it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:02<00:04, 58.34it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:03<00:04, 57.41it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 57.69it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 57.94it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.18it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.37it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.54it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.70it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.78it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.77it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:03<00:03, 58.83it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:04<00:03, 58.87it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 58.86it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.85it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.85it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.88it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.89it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.83it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.82it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.91it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:04<00:02, 58.78it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.84it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 58.94it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 58.95it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 58.90it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 58.95it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 58.96it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.94it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:06<00:01, 58.91it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.89it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.87it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.91it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.94it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.98it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.92it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.96it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.95it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:06<00:00, 59.02it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:07<00:00, 58.90it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.91it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.86it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 58.84it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 58.48it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 58.61it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 58.73it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.40it/s]
epoch 20: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
20: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 21
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<08:00,  1.26s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:55,  6.84it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.57it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 21.71it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.40it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.47it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 39.93it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.52it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.20it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.08it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.23it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.82it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.98it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.77it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.37it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.80it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.11it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:03<00:04, 58.29it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.44it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.56it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.60it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.70it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.73it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.74it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.79it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.75it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.79it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.79it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.82it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.80it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.81it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.72it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.71it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.74it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.75it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.82it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.87it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.90it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.93it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.90it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.92it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.90it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.86it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.80it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.88it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.75it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.81it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.85it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.81it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.79it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.79it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.73it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.73it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.84it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.84it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.83it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.59it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.78it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.89it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.19it/s]
epoch 21: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
21: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 22
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:54,  1.24s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:54,  6.89it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.65it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 21.80it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.45it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.62it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 40.07it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.64it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.31it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 51.17it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.31it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.89it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 56.06it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.81it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.41it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.80it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 58.06it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:02<00:04, 58.30it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.41it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.51it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.56it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.59it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.63it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.75it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.68it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.64it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.62it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.68it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.85it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.85it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.82it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.80it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.81it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.70it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.73it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.74it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.77it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.86it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.82it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.82it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.83it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.80it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.71it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.62it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.69it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.66it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:06<00:00, 58.51it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.57it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.62it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.70it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.71it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.24it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.45it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.57it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.27it/s]
epoch 22: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
22: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 23
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:16,  1.14s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:50,  7.43it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:25, 14.51it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:16, 21.90it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:12, 29.01it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:09, 35.40it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 40.90it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 45.38it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:01<00:06, 48.88it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 51.59it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 53.62it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 54.97it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 56.06it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 56.87it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 57.39it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.75it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:04, 58.04it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:02<00:04, 58.27it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:02<00:04, 58.40it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 58.49it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 58.52it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.64it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.73it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.66it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.63it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.70it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.70it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:03<00:03, 58.73it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.65it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.74it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.78it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.82it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.79it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.79it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:04<00:02, 58.80it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.77it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.76it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 55.95it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 56.62it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 57.21it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 57.67it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 57.98it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.06it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:05<00:01, 58.21it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.37it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.50it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.57it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.57it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.75it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:06<00:00, 58.80it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:06<00:00, 58.60it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.68it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.69it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 58.72it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 58.32it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 58.59it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 58.78it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.71it/s]
epoch 23: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
23: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 24
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<08:27,  1.32s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:58,  6.49it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:28, 12.98it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:17, 20.90it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:13, 27.50it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 33.71it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 39.20it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:02<00:07, 43.79it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:07, 47.45it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 50.33it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 52.55it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.32it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.57it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.44it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 56.97it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.40it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.78it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:03<00:04, 58.08it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.20it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.34it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.41it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.21it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.32it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.46it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.52it/s]going through batches for holmes training:  41%|████      | 158/384 [00:04<00:03, 58.62it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.64it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.70it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.67it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.70it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.77it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:05<00:02, 58.72it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.81it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.79it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.80it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.71it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.75it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.85it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.83it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.84it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.74it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:06<00:01, 58.52it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.28it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.20it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.37it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.55it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.63it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.60it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.70it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.75it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.76it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:07<00:00, 58.79it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.81it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.80it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.80it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.82it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.47it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.65it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.75it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 48.61it/s]
epoch 24: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
24: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 25
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:38,  1.04s/it]going through batches for holmes training:   1%|          | 4/384 [00:01<01:44,  3.63it/s]going through batches for holmes training:   3%|▎         | 10/384 [00:01<00:35, 10.41it/s]going through batches for holmes training:   4%|▍         | 17/384 [00:01<00:19, 18.76it/s]going through batches for holmes training:   6%|▌         | 23/384 [00:01<00:14, 25.75it/s]going through batches for holmes training:   8%|▊         | 29/384 [00:01<00:10, 32.37it/s]going through batches for holmes training:   9%|▉         | 35/384 [00:01<00:09, 37.96it/s]going through batches for holmes training:  11%|█         | 41/384 [00:01<00:07, 42.93it/s]going through batches for holmes training:  12%|█▏        | 47/384 [00:02<00:07, 46.93it/s]going through batches for holmes training:  14%|█▍        | 53/384 [00:02<00:06, 50.04it/s]going through batches for holmes training:  15%|█▌        | 59/384 [00:02<00:06, 52.37it/s]going through batches for holmes training:  17%|█▋        | 65/384 [00:02<00:05, 54.08it/s]going through batches for holmes training:  18%|█▊        | 71/384 [00:02<00:05, 55.26it/s]going through batches for holmes training:  20%|██        | 77/384 [00:02<00:05, 56.18it/s]going through batches for holmes training:  22%|██▏       | 83/384 [00:02<00:05, 56.86it/s]going through batches for holmes training:  23%|██▎       | 89/384 [00:02<00:05, 57.39it/s]going through batches for holmes training:  25%|██▍       | 95/384 [00:02<00:05, 57.75it/s]going through batches for holmes training:  26%|██▋       | 101/384 [00:02<00:04, 58.02it/s]going through batches for holmes training:  28%|██▊       | 107/384 [00:03<00:04, 58.25it/s]going through batches for holmes training:  29%|██▉       | 113/384 [00:03<00:04, 58.35it/s]going through batches for holmes training:  31%|███       | 119/384 [00:03<00:04, 58.27it/s]going through batches for holmes training:  33%|███▎      | 125/384 [00:03<00:04, 58.04it/s]going through batches for holmes training:  34%|███▍      | 131/384 [00:03<00:04, 58.16it/s]going through batches for holmes training:  36%|███▌      | 137/384 [00:03<00:04, 58.39it/s]going through batches for holmes training:  37%|███▋      | 143/384 [00:03<00:04, 58.32it/s]going through batches for holmes training:  39%|███▉      | 149/384 [00:03<00:04, 58.35it/s]going through batches for holmes training:  40%|████      | 155/384 [00:03<00:03, 58.32it/s]going through batches for holmes training:  42%|████▏     | 161/384 [00:04<00:03, 58.43it/s]going through batches for holmes training:  43%|████▎     | 167/384 [00:04<00:03, 58.56it/s]going through batches for holmes training:  45%|████▌     | 173/384 [00:04<00:03, 58.01it/s]going through batches for holmes training:  47%|████▋     | 179/384 [00:04<00:03, 57.70it/s]going through batches for holmes training:  48%|████▊     | 185/384 [00:04<00:03, 57.85it/s]going through batches for holmes training:  50%|████▉     | 191/384 [00:04<00:03, 57.80it/s]going through batches for holmes training:  51%|█████▏    | 197/384 [00:04<00:03, 58.09it/s]going through batches for holmes training:  53%|█████▎    | 203/384 [00:04<00:03, 58.30it/s]going through batches for holmes training:  54%|█████▍    | 209/384 [00:04<00:03, 58.04it/s]going through batches for holmes training:  56%|█████▌    | 215/384 [00:04<00:02, 58.19it/s]going through batches for holmes training:  58%|█████▊    | 221/384 [00:05<00:02, 58.38it/s]going through batches for holmes training:  59%|█████▉    | 227/384 [00:05<00:02, 58.50it/s]going through batches for holmes training:  61%|██████    | 233/384 [00:05<00:02, 58.33it/s]going through batches for holmes training:  62%|██████▏   | 239/384 [00:05<00:02, 58.32it/s]going through batches for holmes training:  64%|██████▍   | 245/384 [00:05<00:02, 58.34it/s]going through batches for holmes training:  65%|██████▌   | 251/384 [00:05<00:02, 58.40it/s]going through batches for holmes training:  67%|██████▋   | 257/384 [00:05<00:02, 58.49it/s]going through batches for holmes training:  68%|██████▊   | 263/384 [00:05<00:02, 58.65it/s]going through batches for holmes training:  70%|███████   | 269/384 [00:05<00:01, 58.72it/s]going through batches for holmes training:  72%|███████▏  | 275/384 [00:05<00:01, 58.70it/s]going through batches for holmes training:  73%|███████▎  | 281/384 [00:06<00:01, 58.79it/s]going through batches for holmes training:  75%|███████▍  | 287/384 [00:06<00:01, 58.83it/s]going through batches for holmes training:  76%|███████▋  | 293/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  78%|███████▊  | 299/384 [00:06<00:01, 58.57it/s]going through batches for holmes training:  79%|███████▉  | 305/384 [00:06<00:01, 58.43it/s]going through batches for holmes training:  81%|████████  | 311/384 [00:06<00:01, 58.42it/s]going through batches for holmes training:  83%|████████▎ | 317/384 [00:06<00:01, 58.38it/s]going through batches for holmes training:  84%|████████▍ | 323/384 [00:06<00:01, 58.35it/s]going through batches for holmes training:  86%|████████▌ | 329/384 [00:06<00:00, 58.35it/s]going through batches for holmes training:  87%|████████▋ | 335/384 [00:07<00:00, 58.46it/s]going through batches for holmes training:  89%|████████▉ | 341/384 [00:07<00:00, 58.46it/s]going through batches for holmes training:  90%|█████████ | 347/384 [00:07<00:00, 58.44it/s]going through batches for holmes training:  92%|█████████▏| 353/384 [00:07<00:00, 58.54it/s]going through batches for holmes training:  93%|█████████▎| 359/384 [00:07<00:00, 58.66it/s]going through batches for holmes training:  95%|█████████▌| 365/384 [00:07<00:00, 58.10it/s]going through batches for holmes training:  97%|█████████▋| 371/384 [00:07<00:00, 58.24it/s]going through batches for holmes training:  98%|█████████▊| 377/384 [00:07<00:00, 58.44it/s]going through batches for holmes training: 100%|█████████▉| 383/384 [00:07<00:00, 58.48it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 48.67it/s]
epoch 25: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
25: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 26
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<06:48,  1.07s/it]going through batches for holmes training:   1%|          | 3/384 [00:01<02:00,  3.17it/s]going through batches for holmes training:   2%|▏         | 9/384 [00:01<00:33, 11.25it/s]going through batches for holmes training:   4%|▍         | 15/384 [00:01<00:18, 19.46it/s]going through batches for holmes training:   5%|▌         | 21/384 [00:01<00:13, 27.31it/s]going through batches for holmes training:   7%|▋         | 27/384 [00:01<00:10, 34.22it/s]going through batches for holmes training:   9%|▊         | 33/384 [00:01<00:08, 39.80it/s]going through batches for holmes training:  10%|█         | 39/384 [00:01<00:07, 44.48it/s]going through batches for holmes training:  12%|█▏        | 45/384 [00:01<00:07, 48.10it/s]going through batches for holmes training:  13%|█▎        | 51/384 [00:01<00:06, 50.92it/s]going through batches for holmes training:  15%|█▍        | 57/384 [00:02<00:06, 53.14it/s]going through batches for holmes training:  16%|█▋        | 63/384 [00:02<00:05, 54.76it/s]going through batches for holmes training:  18%|█▊        | 69/384 [00:02<00:05, 55.84it/s]going through batches for holmes training:  20%|█▉        | 75/384 [00:02<00:05, 56.73it/s]going through batches for holmes training:  21%|██        | 81/384 [00:02<00:05, 57.35it/s]going through batches for holmes training:  23%|██▎       | 87/384 [00:02<00:05, 57.72it/s]going through batches for holmes training:  24%|██▍       | 93/384 [00:02<00:05, 57.99it/s]going through batches for holmes training:  26%|██▌       | 99/384 [00:02<00:04, 58.20it/s]going through batches for holmes training:  27%|██▋       | 105/384 [00:02<00:04, 58.19it/s]going through batches for holmes training:  29%|██▉       | 111/384 [00:03<00:04, 58.36it/s]going through batches for holmes training:  30%|███       | 117/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  32%|███▏      | 123/384 [00:03<00:04, 58.59it/s]going through batches for holmes training:  34%|███▎      | 129/384 [00:03<00:04, 58.60it/s]going through batches for holmes training:  35%|███▌      | 135/384 [00:03<00:04, 58.64it/s]going through batches for holmes training:  37%|███▋      | 141/384 [00:03<00:04, 58.54it/s]going through batches for holmes training:  38%|███▊      | 147/384 [00:03<00:04, 58.58it/s]going through batches for holmes training:  40%|███▉      | 153/384 [00:03<00:03, 58.59it/s]going through batches for holmes training:  41%|████▏     | 159/384 [00:03<00:03, 58.56it/s]going through batches for holmes training:  43%|████▎     | 165/384 [00:03<00:03, 58.56it/s]going through batches for holmes training:  45%|████▍     | 171/384 [00:04<00:03, 58.60it/s]going through batches for holmes training:  46%|████▌     | 177/384 [00:04<00:03, 58.61it/s]going through batches for holmes training:  48%|████▊     | 183/384 [00:04<00:03, 58.61it/s]going through batches for holmes training:  49%|████▉     | 189/384 [00:04<00:03, 58.65it/s]going through batches for holmes training:  51%|█████     | 195/384 [00:04<00:03, 58.72it/s]going through batches for holmes training:  52%|█████▏    | 201/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  54%|█████▍    | 207/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  55%|█████▌    | 213/384 [00:04<00:02, 58.71it/s]going through batches for holmes training:  57%|█████▋    | 219/384 [00:04<00:02, 58.72it/s]going through batches for holmes training:  59%|█████▊    | 225/384 [00:04<00:02, 58.68it/s]going through batches for holmes training:  60%|██████    | 231/384 [00:05<00:02, 58.68it/s]going through batches for holmes training:  62%|██████▏   | 237/384 [00:05<00:02, 58.56it/s]going through batches for holmes training:  63%|██████▎   | 243/384 [00:05<00:02, 58.47it/s]going through batches for holmes training:  65%|██████▍   | 249/384 [00:05<00:02, 58.50it/s]going through batches for holmes training:  66%|██████▋   | 255/384 [00:05<00:02, 58.46it/s]going through batches for holmes training:  68%|██████▊   | 261/384 [00:05<00:02, 58.54it/s]going through batches for holmes training:  70%|██████▉   | 267/384 [00:05<00:01, 58.59it/s]going through batches for holmes training:  71%|███████   | 273/384 [00:05<00:01, 58.57it/s]going through batches for holmes training:  73%|███████▎  | 279/384 [00:05<00:01, 58.56it/s]going through batches for holmes training:  74%|███████▍  | 285/384 [00:05<00:01, 58.56it/s]going through batches for holmes training:  76%|███████▌  | 291/384 [00:06<00:01, 58.58it/s]going through batches for holmes training:  77%|███████▋  | 297/384 [00:06<00:01, 58.57it/s]going through batches for holmes training:  79%|███████▉  | 303/384 [00:06<00:01, 58.54it/s]going through batches for holmes training:  80%|████████  | 309/384 [00:06<00:01, 58.58it/s]going through batches for holmes training:  82%|████████▏ | 315/384 [00:06<00:01, 58.60it/s]going through batches for holmes training:  84%|████████▎ | 321/384 [00:06<00:01, 58.66it/s]going through batches for holmes training:  85%|████████▌ | 327/384 [00:06<00:00, 58.68it/s]going through batches for holmes training:  87%|████████▋ | 333/384 [00:06<00:00, 58.58it/s]going through batches for holmes training:  88%|████████▊ | 339/384 [00:06<00:00, 58.57it/s]going through batches for holmes training:  90%|████████▉ | 345/384 [00:07<00:00, 58.57it/s]going through batches for holmes training:  91%|█████████▏| 351/384 [00:07<00:00, 58.68it/s]going through batches for holmes training:  93%|█████████▎| 357/384 [00:07<00:00, 58.66it/s]going through batches for holmes training:  95%|█████████▍| 363/384 [00:07<00:00, 58.64it/s]going through batches for holmes training:  96%|█████████▌| 369/384 [00:07<00:00, 58.24it/s]going through batches for holmes training:  98%|█████████▊| 375/384 [00:07<00:00, 57.24it/s]going through batches for holmes training:  99%|█████████▉| 381/384 [00:07<00:00, 57.48it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.71it/s]
epoch 26: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
26: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 27
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<08:01,  1.26s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:55,  6.77it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.46it/s]going through batches for holmes training:   5%|▌         | 20/384 [00:01<00:16, 21.54it/s]going through batches for holmes training:   7%|▋         | 26/384 [00:01<00:12, 28.17it/s]going through batches for holmes training:   8%|▊         | 32/384 [00:01<00:10, 34.35it/s]going through batches for holmes training:  10%|▉         | 38/384 [00:01<00:08, 39.78it/s]going through batches for holmes training:  11%|█▏        | 44/384 [00:01<00:07, 44.37it/s]going through batches for holmes training:  13%|█▎        | 50/384 [00:02<00:06, 48.05it/s]going through batches for holmes training:  15%|█▍        | 56/384 [00:02<00:06, 50.99it/s]going through batches for holmes training:  16%|█▌        | 62/384 [00:02<00:06, 53.11it/s]going through batches for holmes training:  18%|█▊        | 68/384 [00:02<00:05, 54.66it/s]going through batches for holmes training:  19%|█▉        | 74/384 [00:02<00:05, 55.87it/s]going through batches for holmes training:  21%|██        | 80/384 [00:02<00:05, 56.68it/s]going through batches for holmes training:  22%|██▏       | 86/384 [00:02<00:05, 57.20it/s]going through batches for holmes training:  24%|██▍       | 92/384 [00:02<00:05, 57.64it/s]going through batches for holmes training:  26%|██▌       | 98/384 [00:02<00:04, 57.97it/s]going through batches for holmes training:  27%|██▋       | 104/384 [00:03<00:04, 58.07it/s]going through batches for holmes training:  29%|██▊       | 110/384 [00:03<00:04, 58.27it/s]going through batches for holmes training:  30%|███       | 116/384 [00:03<00:04, 58.37it/s]going through batches for holmes training:  32%|███▏      | 122/384 [00:03<00:04, 58.47it/s]going through batches for holmes training:  33%|███▎      | 128/384 [00:03<00:04, 58.55it/s]going through batches for holmes training:  35%|███▍      | 134/384 [00:03<00:04, 58.67it/s]going through batches for holmes training:  36%|███▋      | 140/384 [00:03<00:04, 58.68it/s]going through batches for holmes training:  38%|███▊      | 146/384 [00:03<00:04, 58.75it/s]going through batches for holmes training:  40%|███▉      | 152/384 [00:03<00:03, 58.76it/s]going through batches for holmes training:  41%|████      | 158/384 [00:03<00:03, 58.76it/s]going through batches for holmes training:  43%|████▎     | 164/384 [00:04<00:03, 58.76it/s]going through batches for holmes training:  44%|████▍     | 170/384 [00:04<00:03, 58.75it/s]going through batches for holmes training:  46%|████▌     | 176/384 [00:04<00:03, 58.69it/s]going through batches for holmes training:  47%|████▋     | 182/384 [00:04<00:03, 58.66it/s]going through batches for holmes training:  49%|████▉     | 188/384 [00:04<00:03, 58.68it/s]going through batches for holmes training:  51%|█████     | 194/384 [00:04<00:03, 58.77it/s]going through batches for holmes training:  52%|█████▏    | 200/384 [00:04<00:03, 58.72it/s]going through batches for holmes training:  54%|█████▎    | 206/384 [00:04<00:03, 58.71it/s]going through batches for holmes training:  55%|█████▌    | 212/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  57%|█████▋    | 218/384 [00:04<00:02, 58.81it/s]going through batches for holmes training:  58%|█████▊    | 224/384 [00:05<00:02, 58.78it/s]going through batches for holmes training:  60%|█████▉    | 230/384 [00:05<00:02, 58.77it/s]going through batches for holmes training:  61%|██████▏   | 236/384 [00:05<00:02, 58.48it/s]going through batches for holmes training:  63%|██████▎   | 242/384 [00:05<00:02, 58.54it/s]going through batches for holmes training:  65%|██████▍   | 248/384 [00:05<00:02, 58.58it/s]going through batches for holmes training:  66%|██████▌   | 254/384 [00:05<00:02, 58.70it/s]going through batches for holmes training:  68%|██████▊   | 260/384 [00:05<00:02, 58.63it/s]going through batches for holmes training:  69%|██████▉   | 266/384 [00:05<00:02, 58.70it/s]going through batches for holmes training:  71%|███████   | 272/384 [00:05<00:01, 58.63it/s]going through batches for holmes training:  72%|███████▏  | 278/384 [00:05<00:01, 58.66it/s]going through batches for holmes training:  74%|███████▍  | 284/384 [00:06<00:01, 58.73it/s]going through batches for holmes training:  76%|███████▌  | 290/384 [00:06<00:01, 58.69it/s]going through batches for holmes training:  77%|███████▋  | 296/384 [00:06<00:01, 58.77it/s]going through batches for holmes training:  79%|███████▊  | 302/384 [00:06<00:01, 58.74it/s]going through batches for holmes training:  80%|████████  | 308/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  82%|████████▏ | 314/384 [00:06<00:01, 58.72it/s]going through batches for holmes training:  83%|████████▎ | 320/384 [00:06<00:01, 58.76it/s]going through batches for holmes training:  85%|████████▍ | 326/384 [00:06<00:00, 58.71it/s]going through batches for holmes training:  86%|████████▋ | 332/384 [00:06<00:00, 58.72it/s]going through batches for holmes training:  88%|████████▊ | 338/384 [00:07<00:00, 58.75it/s]going through batches for holmes training:  90%|████████▉ | 344/384 [00:07<00:00, 58.72it/s]going through batches for holmes training:  91%|█████████ | 350/384 [00:07<00:00, 58.74it/s]going through batches for holmes training:  93%|█████████▎| 356/384 [00:07<00:00, 58.80it/s]going through batches for holmes training:  94%|█████████▍| 362/384 [00:07<00:00, 58.82it/s]going through batches for holmes training:  96%|█████████▌| 368/384 [00:07<00:00, 58.44it/s]going through batches for holmes training:  97%|█████████▋| 374/384 [00:07<00:00, 58.58it/s]going through batches for holmes training:  99%|█████████▉| 380/384 [00:07<00:00, 58.74it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.07it/s]
epoch 27: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
27: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 28
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<07:21,  1.15s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:51,  7.35it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:25, 14.45it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:16, 21.82it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:12, 28.88it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:10, 35.29it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 40.81it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 45.35it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:01<00:06, 48.90it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 51.65it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 53.68it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 55.11it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 56.22it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 57.04it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 57.55it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.92it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:04, 58.12it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:02<00:04, 58.32it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:02<00:04, 58.39it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 58.55it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 58.56it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.61it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.72it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.78it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.87it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.90it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.88it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:03<00:03, 57.38it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:04<00:03, 57.73it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 57.97it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.19it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.36it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.44it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.56it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.65it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.75it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.76it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:04<00:02, 58.82it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:05<00:02, 58.88it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.94it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.96it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 58.94it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 58.88it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 58.89it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 58.83it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 58.80it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.75it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:05<00:01, 58.80it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.80it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.84it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.88it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.83it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.81it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.83it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.90it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.94it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:06<00:00, 58.87it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:06<00:00, 58.89it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.92it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.93it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 58.92it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 58.43it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 58.67it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 58.86it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 49.81it/s]
epoch 28: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
28: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
epoch: 29
going through batches for holmes training:   0%|          | 0/384 [00:00<?, ?it/s]/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
going through batches for holmes training:   0%|          | 1/384 [00:01<08:05,  1.27s/it]going through batches for holmes training:   2%|▏         | 7/384 [00:01<00:55,  6.73it/s]going through batches for holmes training:   3%|▎         | 13/384 [00:01<00:27, 13.42it/s]going through batches for holmes training:   5%|▍         | 19/384 [00:01<00:17, 20.47it/s]going through batches for holmes training:   7%|▋         | 25/384 [00:01<00:13, 27.43it/s]going through batches for holmes training:   8%|▊         | 31/384 [00:01<00:10, 33.86it/s]going through batches for holmes training:  10%|▉         | 37/384 [00:01<00:08, 39.48it/s]going through batches for holmes training:  11%|█         | 43/384 [00:01<00:07, 44.19it/s]going through batches for holmes training:  13%|█▎        | 49/384 [00:02<00:07, 47.83it/s]going through batches for holmes training:  14%|█▍        | 55/384 [00:02<00:06, 50.70it/s]going through batches for holmes training:  16%|█▌        | 61/384 [00:02<00:06, 52.91it/s]going through batches for holmes training:  17%|█▋        | 67/384 [00:02<00:05, 54.42it/s]going through batches for holmes training:  19%|█▉        | 73/384 [00:02<00:05, 55.38it/s]going through batches for holmes training:  21%|██        | 79/384 [00:02<00:05, 56.18it/s]going through batches for holmes training:  22%|██▏       | 85/384 [00:02<00:05, 56.83it/s]going through batches for holmes training:  24%|██▎       | 91/384 [00:02<00:05, 57.03it/s]going through batches for holmes training:  25%|██▌       | 97/384 [00:02<00:05, 57.22it/s]going through batches for holmes training:  27%|██▋       | 103/384 [00:03<00:04, 57.53it/s]going through batches for holmes training:  28%|██▊       | 109/384 [00:03<00:04, 57.65it/s]going through batches for holmes training:  30%|██▉       | 115/384 [00:03<00:04, 57.91it/s]going through batches for holmes training:  32%|███▏      | 121/384 [00:03<00:04, 58.09it/s]going through batches for holmes training:  33%|███▎      | 127/384 [00:03<00:04, 58.23it/s]going through batches for holmes training:  35%|███▍      | 133/384 [00:03<00:04, 58.33it/s]going through batches for holmes training:  36%|███▌      | 139/384 [00:03<00:04, 58.43it/s]going through batches for holmes training:  38%|███▊      | 145/384 [00:03<00:04, 58.55it/s]going through batches for holmes training:  39%|███▉      | 151/384 [00:03<00:03, 58.54it/s]going through batches for holmes training:  41%|████      | 157/384 [00:03<00:03, 58.38it/s]going through batches for holmes training:  42%|████▏     | 163/384 [00:04<00:03, 58.49it/s]going through batches for holmes training:  44%|████▍     | 169/384 [00:04<00:03, 58.60it/s]going through batches for holmes training:  46%|████▌     | 175/384 [00:04<00:03, 58.62it/s]going through batches for holmes training:  47%|████▋     | 181/384 [00:04<00:03, 58.65it/s]going through batches for holmes training:  49%|████▊     | 187/384 [00:04<00:03, 58.54it/s]going through batches for holmes training:  50%|█████     | 193/384 [00:04<00:03, 58.48it/s]going through batches for holmes training:  52%|█████▏    | 199/384 [00:04<00:03, 58.41it/s]going through batches for holmes training:  53%|█████▎    | 205/384 [00:04<00:03, 58.40it/s]going through batches for holmes training:  55%|█████▍    | 211/384 [00:04<00:02, 58.25it/s]going through batches for holmes training:  57%|█████▋    | 217/384 [00:04<00:02, 58.27it/s]going through batches for holmes training:  58%|█████▊    | 223/384 [00:05<00:02, 58.41it/s]going through batches for holmes training:  60%|█████▉    | 229/384 [00:05<00:02, 58.39it/s]going through batches for holmes training:  61%|██████    | 235/384 [00:05<00:02, 58.38it/s]going through batches for holmes training:  63%|██████▎   | 241/384 [00:05<00:02, 58.49it/s]going through batches for holmes training:  64%|██████▍   | 247/384 [00:05<00:02, 58.54it/s]going through batches for holmes training:  66%|██████▌   | 253/384 [00:05<00:02, 58.53it/s]going through batches for holmes training:  67%|██████▋   | 259/384 [00:05<00:02, 58.56it/s]going through batches for holmes training:  69%|██████▉   | 265/384 [00:05<00:02, 58.43it/s]going through batches for holmes training:  71%|███████   | 271/384 [00:05<00:01, 58.51it/s]going through batches for holmes training:  72%|███████▏  | 277/384 [00:05<00:01, 58.60it/s]going through batches for holmes training:  74%|███████▎  | 283/384 [00:06<00:01, 58.62it/s]going through batches for holmes training:  75%|███████▌  | 289/384 [00:06<00:01, 58.54it/s]going through batches for holmes training:  77%|███████▋  | 295/384 [00:06<00:01, 58.48it/s]going through batches for holmes training:  78%|███████▊  | 301/384 [00:06<00:01, 58.42it/s]going through batches for holmes training:  80%|███████▉  | 307/384 [00:06<00:01, 58.43it/s]going through batches for holmes training:  82%|████████▏ | 313/384 [00:06<00:01, 58.46it/s]going through batches for holmes training:  83%|████████▎ | 319/384 [00:06<00:01, 58.45it/s]going through batches for holmes training:  85%|████████▍ | 325/384 [00:06<00:01, 58.37it/s]going through batches for holmes training:  86%|████████▌ | 331/384 [00:06<00:00, 58.41it/s]going through batches for holmes training:  88%|████████▊ | 337/384 [00:07<00:00, 58.34it/s]going through batches for holmes training:  89%|████████▉ | 343/384 [00:07<00:00, 58.37it/s]going through batches for holmes training:  91%|█████████ | 349/384 [00:07<00:00, 58.29it/s]going through batches for holmes training:  92%|█████████▏| 355/384 [00:07<00:00, 58.09it/s]going through batches for holmes training:  94%|█████████▍| 361/384 [00:07<00:00, 58.16it/s]going through batches for holmes training:  96%|█████████▌| 367/384 [00:07<00:00, 57.60it/s]going through batches for holmes training:  97%|█████████▋| 373/384 [00:07<00:00, 57.84it/s]going through batches for holmes training:  99%|█████████▊| 379/384 [00:07<00:00, 58.08it/s]going through batches for holmes training: 100%|██████████| 384/384 [00:07<00:00, 48.79it/s]
epoch 29: train_loss = 4.554
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
29: {'Accuracy': 0.0105, 'Precision': 0.0001, 'Recall': 0.0105, 'F1-score': 0.0002}
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/data_analysis/feature_attr.py", line 67, in <module>
    raise FileNotFoundError(f"The dataset path does not exist: {in_path}")
FileNotFoundError: The dataset path does not exist: ./datasets/Tik_Tok
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/data_augmentation.py", line 84, in <module>
    temporal_data = np.load(os.path.join(args.checkpoints, args.dataset, args.model, f"attr_{args.attr_method}.npz"))["attr_values"]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/Tik_Tok/RF/attr_DeepLiftShap.npz'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/data_augmentation.py", line 84, in <module>
    temporal_data = np.load(os.path.join(args.checkpoints, args.dataset, args.model, f"attr_{args.attr_method}.npz"))["attr_values"]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/Tik_Tok/RF/attr_DeepLiftShap.npz'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/aug_train.npz'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/aug_valid.npz'
/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test.npz has been generated.
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/train.py", line 77, in <module>
    train_X, train_y = data_processor.load_data(os.path.join(in_path, f"{args.train_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_train.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/data_analysis/spatial_analysis.py", line 65, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p20.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p20.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p30.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p30.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p40.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p40.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p50.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p50.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p60.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p60.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p70.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p70.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p80.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p80.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p90.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p90.npz
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/dataset_process/gen_taf.py", line 44, in <module>
    data = np.load(os.path.join(in_path, f"{args.in_file}.npz"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/test_p100.npz'
/home/kka151/venvs/python_11_5/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/exp/test.py", line 75, in <module>
    valid_X, valid_y = data_processor.load_data(os.path.join(in_path, f"{args.valid_file}.npz"), args.feature, args.seq_len, args.num_tabs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre06/project/6058534/kka151/Website-Fingerprinting-Library/WFlib/tools/data_processor.py", line 37, in load_data
    data = np.load(data_path)
           ^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.11/site-packages/numpy/lib/npyio.py", line 427, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/home/kka151/scratch/holmes/datasets/Tik_Tok/taf_aug_valid.npz'
loading test file:  /home/kka151/scratch/holmes/datasets/Tik_Tok/taf_test_p100.npz
